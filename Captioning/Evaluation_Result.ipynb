{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "german-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7959\n"
     ]
    }
   ],
   "source": [
    "experiment = 'iu_x_transformer+_ca30_dropout0.5/log'\n",
    "log_text= open(\"./experiments/\"+experiment+\".txt\", \"r\")\n",
    "dfssdlkfj =log_text.readlines()\n",
    "print(len(dfssdlkfj))\n",
    "log= \"\".join(dfssdlkfj)\n",
    "log_text.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hawaiian-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 2022-02-16 14:42:43,764] Training with config:\n",
      "[INFO: 2022-02-16 14:42:43,766] {'DATA_LOADER': {'ALL_ID': './iu/txt/iu_all_image_id.txt',\n",
      "                 'CROP_SIZE': 448,\n",
      "                 'DROP_LAST': True,\n",
      "                 'INPUT_SEQ_PATH': './iu/sent/iu_train_input.pkl',\n",
      "                 'LEVERAGE_NORMAL': 'CA',\n",
      "                 'MAX_FEAT': 392,\n",
      "                 'NORMAL_ID': './iu/txt/iu_normal_image_id.txt',\n",
      "                 'NUM_CA': 30,\n",
      "                 'NUM_WORKERS': 4,\n",
      "                 'PIN_MEMORY': True,\n",
      "                 'RESIZE': 512,\n",
      "                 'SEQ_PER_IMG': 1,\n",
      "                 'SHUFFLE': True,\n",
      "                 'TARGET_SEQ_PATH': './iu/sent/iu_train_target.pkl',\n",
      "                 'TEST_GV_FEAT': '',\n",
      "                 'TEST_ID': './iu/txt/iu_test_image_id.txt',\n",
      "                 'TEST_INPUT_IMAGES': './iu/input_images',\n",
      "                 'TEST_NORMAL_IMAGES': './iu/normal_images/full_tensor',\n",
      "                 'TRAIN_GV_FEAT': '',\n",
      "                 'TRAIN_ID': './iu/txt/iu_train_image_id.txt',\n",
      "                 'TRAIN_INPUT_IMAGES': './iu/input_images',\n",
      "                 'TRAIN_NORMAL_IMAGES': './iu/normal_images/full_tensor',\n",
      "                 'VAL_GV_FEAT': '',\n",
      "                 'VAL_ID': './iu/txt/iu_val_image_id.txt',\n",
      "                 'VAL_INPUT_IMAGES': './iu/input_images',\n",
      "                 'VAL_NORMAL_IMAGES': './iu/normal_images/full_tensor'},\n",
      " 'EPS': 1e-14,\n",
      " 'INFERENCE': {'BEAM_SIZE': 2,\n",
      "               'CAP_KEY': 'caption',\n",
      "               'COCO_PATH': '../coco_caption',\n",
      "               'EVAL': 'COCO',\n",
      "               'GREEDY_DECODE': True,\n",
      "               'ID_KEY': 'image_id',\n",
      "               'TEST_ANNFILE': './iu/misc/captions_test.json',\n",
      "               'VAL_ANNFILE': './iu/misc/captions_val.json',\n",
      "               'VOCAB': './iu/txt/iu_vocabulary_transformer.txt'},\n",
      " 'LOGGER_NAME': 'log',\n",
      " 'LOSSES': {'LABELSMOOTHING': 0.1,\n",
      "            'RL_TYPE': 'RewardCriterion',\n",
      "            'XE_TYPE': 'LabelSmoothing'},\n",
      " 'MEAN': [0.485, 0.456, 0.406],\n",
      " 'MODEL': {'ATT_ACT': 'TANH',\n",
      "           'ATT_FEATS_DIM': 1024,\n",
      "           'ATT_FEATS_EMBED_ACT': 'CELU',\n",
      "           'ATT_FEATS_EMBED_DIM': 512,\n",
      "           'ATT_FEATS_NORM': True,\n",
      "           'ATT_HIDDEN_DROP': 0.0,\n",
      "           'ATT_HIDDEN_SIZE': -1,\n",
      "           'BILINEAR': {'ACT': 'CELU',\n",
      "                        'ATTTYPE': 'SCAtt',\n",
      "                        'ATT_DIM': 512,\n",
      "                        'BIFEAT_EMB_ACT': 'RELU',\n",
      "                        'DECODE_ATT_MID_DIM': [64, 32, 64],\n",
      "                        'DECODE_ATT_MID_DROPOUT': 0.1,\n",
      "                        'DECODE_BIFEAT_EMB_DROPOUT': 0.3,\n",
      "                        'DECODE_BLOCK': 'LowRankBilinearDec',\n",
      "                        'DECODE_DROPOUT': 0.5,\n",
      "                        'DECODE_FF_DROPOUT': 0.5,\n",
      "                        'DECODE_LAYERS': 6,\n",
      "                        'DIM': 512,\n",
      "                        'ELU_ALPHA': 1.3,\n",
      "                        'ENCODE_ATT_MID_DIM': [64, 32, 64],\n",
      "                        'ENCODE_ATT_MID_DROPOUT': 0.1,\n",
      "                        'ENCODE_BIFEAT_EMB_DROPOUT': 0.3,\n",
      "                        'ENCODE_BLOCK': 'LowRankBilinearEnc',\n",
      "                        'ENCODE_DROPOUT': 0.5,\n",
      "                        'ENCODE_FF_DROPOUT': 0.5,\n",
      "                        'ENCODE_LAYERS': 6,\n",
      "                        'HEAD': 8,\n",
      "                        'TYPE': 'LowRank'},\n",
      "           'BOTTOM_UP': {'DROPOUT_FIRST_INPUT': 0.0, 'DROPOUT_SEC_INPUT': 0.0},\n",
      "           'CONTRA_ATT_NUM_HEADS': 6,\n",
      "           'CONTRA_ATT_TYPE': 'dot',\n",
      "           'DROPOUT_ATT_EMBED': 0.5,\n",
      "           'DROPOUT_CA': 0.5,\n",
      "           'DROPOUT_GV_EMBED': 0.0,\n",
      "           'DROPOUT_LM': 0.5,\n",
      "           'DROPOUT_WORD_EMBED': 0.1,\n",
      "           'ENCODER_CFG_PATH': 'example.json',\n",
      "           'ENCODER_FUSION_GRAD': 'detach',\n",
      "           'ENCODER_FUSION_MODE': 'CA',\n",
      "           'ENCODER_PRETRAINED': 'Chexpert',\n",
      "           'ENCODER_PRETRAINED_PATH': 'Chexpert.pth',\n",
      "           'ENCODER_PROJ': 'fc',\n",
      "           'ENCODER_TRAINING': 'All',\n",
      "           'ENCODER_TYPE': 'densenet121',\n",
      "           'GVFEAT_DIM': 512,\n",
      "           'GVFEAT_EMBED_ACT': 'NONE',\n",
      "           'GVFEAT_EMBED_DIM': -1,\n",
      "           'RNN_SIZE': 512,\n",
      "           'SEQ_LEN': 201,\n",
      "           'TRANSFORMER': {'PE_MAX_LEN': 5000},\n",
      "           'TYPE': 'XTransformer',\n",
      "           'VOCAB_SIZE': 2151,\n",
      "           'WORD_EMBED_ACT': 'CELU',\n",
      "           'WORD_EMBED_DIM': 512,\n",
      "           'WORD_EMBED_NORM': False},\n",
      " 'PARAM': {'ATT_FEATS': 'ATT_FEATS',\n",
      "           'ATT_FEATS_MASK': 'ATT_FEATS_MASK',\n",
      "           'GLOBAL_FEAT': 'GV_FEAT',\n",
      "           'INDICES': 'INDICES',\n",
      "           'INPUT_IMAGES': 'INPUT_IMAGES',\n",
      "           'INPUT_SENT': 'INPUT_SENT',\n",
      "           'NORMAL_IMAGES': 'NORMAL_IMAGES',\n",
      "           'P_ATT_FEATS': 'P_ATT_FEATS',\n",
      "           'STATE': 'STATE',\n",
      "           'TARGET_SENT': 'TARGET_SENT',\n",
      "           'WT': 'WT'},\n",
      " 'ROOT_DIR': './experiments/iu_x_transformer+_ca30_dropout0.5',\n",
      " 'SCORER': {'CIDER_CACHED': './iu/misc/iu_train_cider.pkl',\n",
      "            'GT_PATH': './iu/misc/iu_train_gts.pkl',\n",
      "            'TYPES': ['CIDEr'],\n",
      "            'WEIGHTS': [1.0]},\n",
      " 'SEED': 1546884941.160048,\n",
      " 'SOLVER': {'ADAM': {'BETAS': [0.9, 0.98], 'EPS': 1e-09},\n",
      "            'BASE_LR': 0.0005,\n",
      "            'BIAS_LR_FACTOR': 1,\n",
      "            'DISPLAY': 20,\n",
      "            'GRAD_CLIP': 0.1,\n",
      "            'GRAD_CLIP_TYPE': 'Clamp',\n",
      "            'LR_POLICY': {'FACTOR': 2000.0,\n",
      "                          'GAMMA': 0.1,\n",
      "                          'MODEL_SIZE': 512,\n",
      "                          'PLATEAU_FACTOR': 0.5,\n",
      "                          'PLATEAU_PATIENCE': 3,\n",
      "                          'SETP_TYPE': 'Iter',\n",
      "                          'STEPS': [370, 390],\n",
      "                          'STEP_SIZE': 30,\n",
      "                          'SUB_SCHEDULE': False,\n",
      "                          'TYPE': 'ScaledNoam',\n",
      "                          'WARMUP': 5600},\n",
      "            'MAX_EPOCH': 400,\n",
      "            'MAX_ITER': -1,\n",
      "            'SGD': {'MOMENTUM': 0.9},\n",
      "            'SNAPSHOT_ITERS': 1,\n",
      "            'TEST_INTERVAL': 1,\n",
      "            'TYPE': 'RADAM',\n",
      "            'WEIGHT_DECAY': 0.0,\n",
      "            'WEIGHT_DECAY_BIAS': 0.0},\n",
      " 'STD': [0.229, 0.224, 0.225],\n",
      " 'TEMP_DIR': './data/temp',\n",
      " 'TEST': {'BATCH_SIZE': 4},\n",
      " 'TRAIN': {'BATCH_SIZE': 4,\n",
      "           'REINFORCEMENT': {'START': 9999},\n",
      "           'SCHEDULED_SAMPLING': {'INC_EVERY': 5,\n",
      "                                  'INC_PROB': 0.05,\n",
      "                                  'MAX_PROB': 0.25,\n",
      "                                  'START': 0}}}\n",
      "[INFO: 2022-02-16 14:44:12,386] Training with config:\n",
      "[INFO: 2022-02-16 14:44:12,388] {'DATA_LOADER': {'ALL_ID': './iu/txt/iu_all_image_id.txt',\n",
      "                 'CROP_SIZE': 448,\n",
      "                 'DROP_LAST': True,\n",
      "                 'INPUT_SEQ_PATH': './iu/sent/iu_train_input.pkl',\n",
      "                 'LEVERAGE_NORMAL': 'CA',\n",
      "                 'MAX_FEAT': 392,\n",
      "                 'NORMAL_ID': './iu/txt/iu_normal_image_id.txt',\n",
      "                 'NUM_CA': 30,\n",
      "                 'NUM_WORKERS': 4,\n",
      "                 'PIN_MEMORY': True,\n",
      "                 'RESIZE': 512,\n",
      "                 'SEQ_PER_IMG': 1,\n",
      "                 'SHUFFLE': True,\n",
      "                 'TARGET_SEQ_PATH': './iu/sent/iu_train_target.pkl',\n",
      "                 'TEST_GV_FEAT': '',\n",
      "                 'TEST_ID': './iu/txt/iu_test_image_id.txt',\n",
      "                 'TEST_INPUT_IMAGES': './iu/input_images',\n",
      "                 'TEST_NORMAL_IMAGES': './iu/normal_images/full_tensor',\n",
      "                 'TRAIN_GV_FEAT': '',\n",
      "                 'TRAIN_ID': './iu/txt/iu_train_image_id.txt',\n",
      "                 'TRAIN_INPUT_IMAGES': './iu/input_images',\n",
      "                 'TRAIN_NORMAL_IMAGES': './iu/normal_images/full_tensor',\n",
      "                 'VAL_GV_FEAT': '',\n",
      "                 'VAL_ID': './iu/txt/iu_val_image_id.txt',\n",
      "                 'VAL_INPUT_IMAGES': './iu/input_images',\n",
      "                 'VAL_NORMAL_IMAGES': './iu/normal_images/full_tensor'},\n",
      " 'EPS': 1e-14,\n",
      " 'INFERENCE': {'BEAM_SIZE': 2,\n",
      "               'CAP_KEY': 'caption',\n",
      "               'COCO_PATH': '../coco_caption',\n",
      "               'EVAL': 'COCO',\n",
      "               'GREEDY_DECODE': True,\n",
      "               'ID_KEY': 'image_id',\n",
      "               'TEST_ANNFILE': './iu/misc/captions_test.json',\n",
      "               'VAL_ANNFILE': './iu/misc/captions_val.json',\n",
      "               'VOCAB': './iu/txt/iu_vocabulary_transformer.txt'},\n",
      " 'LOGGER_NAME': 'log',\n",
      " 'LOSSES': {'LABELSMOOTHING': 0.1,\n",
      "            'RL_TYPE': 'RewardCriterion',\n",
      "            'XE_TYPE': 'LabelSmoothing'},\n",
      " 'MEAN': [0.485, 0.456, 0.406],\n",
      " 'MODEL': {'ATT_ACT': 'TANH',\n",
      "           'ATT_FEATS_DIM': 1024,\n",
      "           'ATT_FEATS_EMBED_ACT': 'CELU',\n",
      "           'ATT_FEATS_EMBED_DIM': 512,\n",
      "           'ATT_FEATS_NORM': True,\n",
      "           'ATT_HIDDEN_DROP': 0.0,\n",
      "           'ATT_HIDDEN_SIZE': -1,\n",
      "           'BILINEAR': {'ACT': 'CELU',\n",
      "                        'ATTTYPE': 'SCAtt',\n",
      "                        'ATT_DIM': 512,\n",
      "                        'BIFEAT_EMB_ACT': 'RELU',\n",
      "                        'DECODE_ATT_MID_DIM': [64, 32, 64],\n",
      "                        'DECODE_ATT_MID_DROPOUT': 0.1,\n",
      "                        'DECODE_BIFEAT_EMB_DROPOUT': 0.3,\n",
      "                        'DECODE_BLOCK': 'LowRankBilinearDec',\n",
      "                        'DECODE_DROPOUT': 0.5,\n",
      "                        'DECODE_FF_DROPOUT': 0.5,\n",
      "                        'DECODE_LAYERS': 6,\n",
      "                        'DIM': 512,\n",
      "                        'ELU_ALPHA': 1.3,\n",
      "                        'ENCODE_ATT_MID_DIM': [64, 32, 64],\n",
      "                        'ENCODE_ATT_MID_DROPOUT': 0.1,\n",
      "                        'ENCODE_BIFEAT_EMB_DROPOUT': 0.3,\n",
      "                        'ENCODE_BLOCK': 'LowRankBilinearEnc',\n",
      "                        'ENCODE_DROPOUT': 0.5,\n",
      "                        'ENCODE_FF_DROPOUT': 0.5,\n",
      "                        'ENCODE_LAYERS': 6,\n",
      "                        'HEAD': 8,\n",
      "                        'TYPE': 'LowRank'},\n",
      "           'BOTTOM_UP': {'DROPOUT_FIRST_INPUT': 0.0, 'DROPOUT_SEC_INPUT': 0.0},\n",
      "           'CONTRA_ATT_NUM_HEADS': 6,\n",
      "           'CONTRA_ATT_TYPE': 'dot',\n",
      "           'DROPOUT_ATT_EMBED': 0.5,\n",
      "           'DROPOUT_CA': 0.5,\n",
      "           'DROPOUT_GV_EMBED': 0.0,\n",
      "           'DROPOUT_LM': 0.5,\n",
      "           'DROPOUT_WORD_EMBED': 0.1,\n",
      "           'ENCODER_CFG_PATH': 'example.json',\n",
      "           'ENCODER_FUSION_GRAD': 'detach',\n",
      "           'ENCODER_FUSION_MODE': 'CA',\n",
      "           'ENCODER_PRETRAINED': 'Chexpert',\n",
      "           'ENCODER_PRETRAINED_PATH': 'Chexpert.pth',\n",
      "           'ENCODER_PROJ': 'fc',\n",
      "           'ENCODER_TRAINING': 'All',\n",
      "           'ENCODER_TYPE': 'densenet121',\n",
      "           'GVFEAT_DIM': 512,\n",
      "           'GVFEAT_EMBED_ACT': 'NONE',\n",
      "           'GVFEAT_EMBED_DIM': -1,\n",
      "           'RNN_SIZE': 512,\n",
      "           'SEQ_LEN': 201,\n",
      "           'TRANSFORMER': {'PE_MAX_LEN': 5000},\n",
      "           'TYPE': 'XTransformer',\n",
      "           'VOCAB_SIZE': 2151,\n",
      "           'WORD_EMBED_ACT': 'CELU',\n",
      "           'WORD_EMBED_DIM': 512,\n",
      "           'WORD_EMBED_NORM': False},\n",
      " 'PARAM': {'ATT_FEATS': 'ATT_FEATS',\n",
      "           'ATT_FEATS_MASK': 'ATT_FEATS_MASK',\n",
      "           'GLOBAL_FEAT': 'GV_FEAT',\n",
      "           'INDICES': 'INDICES',\n",
      "           'INPUT_IMAGES': 'INPUT_IMAGES',\n",
      "           'INPUT_SENT': 'INPUT_SENT',\n",
      "           'NORMAL_IMAGES': 'NORMAL_IMAGES',\n",
      "           'P_ATT_FEATS': 'P_ATT_FEATS',\n",
      "           'STATE': 'STATE',\n",
      "           'TARGET_SENT': 'TARGET_SENT',\n",
      "           'WT': 'WT'},\n",
      " 'ROOT_DIR': './experiments/iu_x_transformer+_ca30_dropout0.5',\n",
      " 'SCORER': {'CIDER_CACHED': './iu/misc/iu_train_cider.pkl',\n",
      "            'GT_PATH': './iu/misc/iu_train_gts.pkl',\n",
      "            'TYPES': ['CIDEr'],\n",
      "            'WEIGHTS': [1.0]},\n",
      " 'SEED': 1546884941.160048,\n",
      " 'SOLVER': {'ADAM': {'BETAS': [0.9, 0.98], 'EPS': 1e-09},\n",
      "            'BASE_LR': 0.0005,\n",
      "            'BIAS_LR_FACTOR': 1,\n",
      "            'DISPLAY': 20,\n",
      "            'GRAD_CLIP': 0.1,\n",
      "            'GRAD_CLIP_TYPE': 'Clamp',\n",
      "            'LR_POLICY': {'FACTOR': 2000.0,\n",
      "                          'GAMMA': 0.1,\n",
      "                          'MODEL_SIZE': 512,\n",
      "                          'PLATEAU_FACTOR': 0.5,\n",
      "                          'PLATEAU_PATIENCE': 3,\n",
      "                          'SETP_TYPE': 'Iter',\n",
      "                          'STEPS': [370, 390],\n",
      "                          'STEP_SIZE': 30,\n",
      "                          'SUB_SCHEDULE': False,\n",
      "                          'TYPE': 'ScaledNoam',\n",
      "                          'WARMUP': 5600},\n",
      "            'MAX_EPOCH': 400,\n",
      "            'MAX_ITER': -1,\n",
      "            'SGD': {'MOMENTUM': 0.9},\n",
      "            'SNAPSHOT_ITERS': 1,\n",
      "            'TEST_INTERVAL': 1,\n",
      "            'TYPE': 'RADAM',\n",
      "            'WEIGHT_DECAY': 0.0,\n",
      "            'WEIGHT_DECAY_BIAS': 0.0},\n",
      " 'STD': [0.229, 0.224, 0.225],\n",
      " 'TEMP_DIR': './data/temp',\n",
      " 'TEST': {'BATCH_SIZE': 4},\n",
      " 'TRAIN': {'BATCH_SIZE': 4,\n",
      "           'REINFORCEMENT': {'START': 9999},\n",
      "           'SCHEDULED_SAMPLING': {'INC_EVERY': 5,\n",
      "                                  'INC_PROB': 0.05,\n",
      "                                  'MAX_PROB': 0.25,\n",
      "                                  'START': 0}}}\n",
      "[INFO: 2022-02-16 14:44:25,980] Iteration 0 (DataTime/BatchTime: 2.01/3.3) losses = 6.9198, lr = [2.1091767467032774e-08, 2.109176746703277e-07]\n",
      "[INFO: 2022-02-16 14:44:26,015]   LabelSmoothing Loss = 6.919795989990234\n",
      "[INFO: 2022-02-16 14:44:42,228] Iteration 20 (DataTime/BatchTime: 0.0033/0.812) losses = 6.9407, lr = [2.320094421373605e-07, 2.3200944213736046e-06]\n",
      "[INFO: 2022-02-16 14:44:42,228]   LabelSmoothing Loss = 6.951554298400879\n",
      "[INFO: 2022-02-16 14:44:58,407] Iteration 40 (DataTime/BatchTime: 0.00137/0.809) losses = 6.9157, lr = [4.4292711680768824e-07, 4.4292711680768815e-06]\n",
      "[INFO: 2022-02-16 14:44:58,408]   LabelSmoothing Loss = 6.945693016052246\n",
      "[INFO: 2022-02-16 14:45:14,629] Iteration 60 (DataTime/BatchTime: 0.0015/0.811) losses = 6.93, lr = [6.53844791478016e-07, 6.538447914780159e-06]\n",
      "[INFO: 2022-02-16 14:45:14,630]   LabelSmoothing Loss = 6.908546447753906\n",
      "[INFO: 2022-02-16 14:45:30,851] Iteration 80 (DataTime/BatchTime: 0.00134/0.811) losses = 6.91, lr = [8.647624661483437e-07, 8.647624661483435e-06]\n",
      "[INFO: 2022-02-16 14:45:30,851]   LabelSmoothing Loss = 6.938315391540527\n",
      "[INFO: 2022-02-16 14:45:47,202] Iteration 100 (DataTime/BatchTime: 0.00146/0.818) losses = 6.8943, lr = [1.0756801408186714e-06, 1.0756801408186713e-05]\n",
      "[INFO: 2022-02-16 14:45:47,202]   LabelSmoothing Loss = 6.90019416809082\n",
      "[INFO: 2022-02-16 14:46:03,510] Iteration 120 (DataTime/BatchTime: 0.00148/0.815) losses = 6.8657, lr = [1.2865978154889992e-06, 1.286597815488999e-05]\n",
      "[INFO: 2022-02-16 14:46:03,511]   LabelSmoothing Loss = 6.918609142303467\n",
      "[INFO: 2022-02-16 14:46:19,963] Iteration 140 (DataTime/BatchTime: 0.00141/0.823) losses = 6.8475, lr = [1.497515490159327e-06, 1.4975154901593268e-05]\n",
      "[INFO: 2022-02-16 14:46:19,964]   LabelSmoothing Loss = 6.754445552825928\n",
      "[INFO: 2022-02-16 14:55:41,134] Training with config:\n",
      "[INFO: 2022-02-16 14:55:41,136] {'DATA_LOADER': {'ALL_ID': './iu/txt/iu_all_image_id.txt',\n",
      "                 'CROP_SIZE': 448,\n",
      "                 'DROP_LAST': True,\n",
      "                 'INPUT_SEQ_PATH': './iu/sent/iu_train_input.pkl',\n",
      "                 'LEVERAGE_NORMAL': 'CA',\n",
      "                 'MAX_FEAT': 392,\n",
      "                 'NORMAL_ID': './iu/txt/iu_normal_image_id.txt',\n",
      "                 'NUM_CA': 30,\n",
      "                 'NUM_WORKERS': 4,\n",
      "                 'PIN_MEMORY': True,\n",
      "                 'RESIZE': 512,\n",
      "                 'SEQ_PER_IMG': 1,\n",
      "                 'SHUFFLE': True,\n",
      "                 'TARGET_SEQ_PATH': './iu/sent/iu_train_target.pkl',\n",
      "                 'TEST_GV_FEAT': '',\n",
      "                 'TEST_ID': './iu/txt/iu_test_image_id.txt',\n",
      "                 'TEST_INPUT_IMAGES': './iu/input_images',\n",
      "                 'TEST_NORMAL_IMAGES': './iu/normal_images/full_tensor',\n",
      "                 'TRAIN_GV_FEAT': '',\n",
      "                 'TRAIN_ID': './iu/txt/iu_train_image_id.txt',\n",
      "                 'TRAIN_INPUT_IMAGES': './iu/input_images',\n",
      "                 'TRAIN_NORMAL_IMAGES': './iu/normal_images/full_tensor',\n",
      "                 'VAL_GV_FEAT': '',\n",
      "                 'VAL_ID': './iu/txt/iu_val_image_id.txt',\n",
      "                 'VAL_INPUT_IMAGES': './iu/input_images',\n",
      "                 'VAL_NORMAL_IMAGES': './iu/normal_images/full_tensor'},\n",
      " 'EPS': 1e-14,\n",
      " 'INFERENCE': {'BEAM_SIZE': 2,\n",
      "               'CAP_KEY': 'caption',\n",
      "               'COCO_PATH': '../coco_caption',\n",
      "               'EVAL': 'COCO',\n",
      "               'GREEDY_DECODE': True,\n",
      "               'ID_KEY': 'image_id',\n",
      "               'TEST_ANNFILE': './iu/misc/captions_test.json',\n",
      "               'VAL_ANNFILE': './iu/misc/captions_val.json',\n",
      "               'VOCAB': './iu/txt/iu_vocabulary_transformer.txt'},\n",
      " 'LOGGER_NAME': 'log',\n",
      " 'LOSSES': {'LABELSMOOTHING': 0.1,\n",
      "            'RL_TYPE': 'RewardCriterion',\n",
      "            'XE_TYPE': 'LabelSmoothing'},\n",
      " 'MEAN': [0.485, 0.456, 0.406],\n",
      " 'MODEL': {'ATT_ACT': 'TANH',\n",
      "           'ATT_FEATS_DIM': 1024,\n",
      "           'ATT_FEATS_EMBED_ACT': 'CELU',\n",
      "           'ATT_FEATS_EMBED_DIM': 512,\n",
      "           'ATT_FEATS_NORM': True,\n",
      "           'ATT_HIDDEN_DROP': 0.0,\n",
      "           'ATT_HIDDEN_SIZE': -1,\n",
      "           'BILINEAR': {'ACT': 'CELU',\n",
      "                        'ATTTYPE': 'SCAtt',\n",
      "                        'ATT_DIM': 512,\n",
      "                        'BIFEAT_EMB_ACT': 'RELU',\n",
      "                        'DECODE_ATT_MID_DIM': [64, 32, 64],\n",
      "                        'DECODE_ATT_MID_DROPOUT': 0.1,\n",
      "                        'DECODE_BIFEAT_EMB_DROPOUT': 0.3,\n",
      "                        'DECODE_BLOCK': 'LowRankBilinearDec',\n",
      "                        'DECODE_DROPOUT': 0.5,\n",
      "                        'DECODE_FF_DROPOUT': 0.5,\n",
      "                        'DECODE_LAYERS': 6,\n",
      "                        'DIM': 512,\n",
      "                        'ELU_ALPHA': 1.3,\n",
      "                        'ENCODE_ATT_MID_DIM': [64, 32, 64],\n",
      "                        'ENCODE_ATT_MID_DROPOUT': 0.1,\n",
      "                        'ENCODE_BIFEAT_EMB_DROPOUT': 0.3,\n",
      "                        'ENCODE_BLOCK': 'LowRankBilinearEnc',\n",
      "                        'ENCODE_DROPOUT': 0.5,\n",
      "                        'ENCODE_FF_DROPOUT': 0.5,\n",
      "                        'ENCODE_LAYERS': 6,\n",
      "                        'HEAD': 8,\n",
      "                        'TYPE': 'LowRank'},\n",
      "           'BOTTOM_UP': {'DROPOUT_FIRST_INPUT': 0.0, 'DROPOUT_SEC_INPUT': 0.0},\n",
      "           'CONTRA_ATT_NUM_HEADS': 6,\n",
      "           'CONTRA_ATT_TYPE': 'dot',\n",
      "           'DROPOUT_ATT_EMBED': 0.5,\n",
      "           'DROPOUT_CA': 0.5,\n",
      "           'DROPOUT_GV_EMBED': 0.0,\n",
      "           'DROPOUT_LM': 0.5,\n",
      "           'DROPOUT_WORD_EMBED': 0.1,\n",
      "           'ENCODER_CFG_PATH': 'example.json',\n",
      "           'ENCODER_FUSION_GRAD': 'detach',\n",
      "           'ENCODER_FUSION_MODE': 'CA',\n",
      "           'ENCODER_PRETRAINED': 'Chexpert',\n",
      "           'ENCODER_PRETRAINED_PATH': 'Chexpert.pth',\n",
      "           'ENCODER_PROJ': 'fc',\n",
      "           'ENCODER_TRAINING': 'All',\n",
      "           'ENCODER_TYPE': 'densenet121',\n",
      "           'GVFEAT_DIM': 512,\n",
      "           'GVFEAT_EMBED_ACT': 'NONE',\n",
      "           'GVFEAT_EMBED_DIM': -1,\n",
      "           'RNN_SIZE': 512,\n",
      "           'SEQ_LEN': 201,\n",
      "           'TRANSFORMER': {'PE_MAX_LEN': 5000},\n",
      "           'TYPE': 'XTransformer',\n",
      "           'VOCAB_SIZE': 2151,\n",
      "           'WORD_EMBED_ACT': 'CELU',\n",
      "           'WORD_EMBED_DIM': 512,\n",
      "           'WORD_EMBED_NORM': False},\n",
      " 'PARAM': {'ATT_FEATS': 'ATT_FEATS',\n",
      "           'ATT_FEATS_MASK': 'ATT_FEATS_MASK',\n",
      "           'GLOBAL_FEAT': 'GV_FEAT',\n",
      "           'INDICES': 'INDICES',\n",
      "           'INPUT_IMAGES': 'INPUT_IMAGES',\n",
      "           'INPUT_SENT': 'INPUT_SENT',\n",
      "           'NORMAL_IMAGES': 'NORMAL_IMAGES',\n",
      "           'P_ATT_FEATS': 'P_ATT_FEATS',\n",
      "           'STATE': 'STATE',\n",
      "           'TARGET_SENT': 'TARGET_SENT',\n",
      "           'WT': 'WT'},\n",
      " 'ROOT_DIR': './experiments/iu_x_transformer+_ca30_dropout0.5',\n",
      " 'SCORER': {'CIDER_CACHED': './iu/misc/iu_train_cider.pkl',\n",
      "            'GT_PATH': './iu/misc/iu_train_gts.pkl',\n",
      "            'TYPES': ['CIDEr'],\n",
      "            'WEIGHTS': [1.0]},\n",
      " 'SEED': 1546884941.160048,\n",
      " 'SOLVER': {'ADAM': {'BETAS': [0.9, 0.98], 'EPS': 1e-09},\n",
      "            'BASE_LR': 0.0005,\n",
      "            'BIAS_LR_FACTOR': 1,\n",
      "            'DISPLAY': 20,\n",
      "            'GRAD_CLIP': 0.1,\n",
      "            'GRAD_CLIP_TYPE': 'Clamp',\n",
      "            'LR_POLICY': {'FACTOR': 2000.0,\n",
      "                          'GAMMA': 0.1,\n",
      "                          'MODEL_SIZE': 512,\n",
      "                          'PLATEAU_FACTOR': 0.5,\n",
      "                          'PLATEAU_PATIENCE': 3,\n",
      "                          'SETP_TYPE': 'Iter',\n",
      "                          'STEPS': [370, 390],\n",
      "                          'STEP_SIZE': 30,\n",
      "                          'SUB_SCHEDULE': False,\n",
      "                          'TYPE': 'ScaledNoam',\n",
      "                          'WARMUP': 10000},\n",
      "            'MAX_EPOCH': 400,\n",
      "            'MAX_ITER': -1,\n",
      "            'SGD': {'MOMENTUM': 0.9},\n",
      "            'SNAPSHOT_ITERS': 1,\n",
      "            'TEST_INTERVAL': 1,\n",
      "            'TYPE': 'RADAM',\n",
      "            'WEIGHT_DECAY': 0.0,\n",
      "            'WEIGHT_DECAY_BIAS': 0.0},\n",
      " 'STD': [0.229, 0.224, 0.225],\n",
      " 'TEMP_DIR': './data/temp',\n",
      " 'TEST': {'BATCH_SIZE': 4},\n",
      " 'TRAIN': {'BATCH_SIZE': 2,\n",
      "           'REINFORCEMENT': {'START': 9999},\n",
      "           'SCHEDULED_SAMPLING': {'INC_EVERY': 5,\n",
      "                                  'INC_PROB': 0.05,\n",
      "                                  'MAX_PROB': 0.25,\n",
      "                                  'START': 0}}}\n",
      "[INFO: 2022-02-16 14:55:53,892] Iteration 0 (DataTime/BatchTime: 1.45/2.21) losses = 6.9774, lr = [8.838834764831845e-09, 8.838834764831845e-08]\n",
      "[INFO: 2022-02-16 14:55:53,892]   LabelSmoothing Loss = 6.977380275726318\n",
      "[INFO: 2022-02-16 14:56:03,706] Iteration 20 (DataTime/BatchTime: 0.00399/0.491) losses = 6.9534, lr = [9.72271824131503e-08, 9.72271824131503e-07]\n",
      "[INFO: 2022-02-16 14:56:03,706]   LabelSmoothing Loss = 6.889980316162109\n",
      "[INFO: 2022-02-16 14:56:13,509] Iteration 40 (DataTime/BatchTime: 0.00291/0.49) losses = 6.9151, lr = [1.8561553006146876e-07, 1.8561553006146873e-06]\n",
      "[INFO: 2022-02-16 14:56:13,510]   LabelSmoothing Loss = 7.124875068664551\n",
      "[INFO: 2022-02-16 14:56:23,303] Iteration 60 (DataTime/BatchTime: 0.00293/0.49) losses = 6.9649, lr = [2.740038777097872e-07, 2.740038777097872e-06]\n",
      "[INFO: 2022-02-16 14:56:23,303]   LabelSmoothing Loss = 6.9490065574646\n",
      "[INFO: 2022-02-16 14:56:33,051] Iteration 80 (DataTime/BatchTime: 0.00269/0.487) losses = 6.9434, lr = [3.6239222535810565e-07, 3.6239222535810564e-06]\n",
      "[INFO: 2022-02-16 14:56:33,052]   LabelSmoothing Loss = 6.996266841888428\n",
      "[INFO: 2022-02-16 14:56:42,780] Iteration 100 (DataTime/BatchTime: 0.00181/0.486) losses = 6.9155, lr = [4.5078057300642414e-07, 4.50780573006424e-06]\n",
      "[INFO: 2022-02-16 14:56:42,780]   LabelSmoothing Loss = 6.940808296203613\n",
      "[INFO: 2022-02-16 14:56:52,480] Iteration 120 (DataTime/BatchTime: 0.00445/0.485) losses = 6.9197, lr = [5.391689206547426e-07, 5.391689206547425e-06]\n",
      "[INFO: 2022-02-16 14:56:52,480]   LabelSmoothing Loss = 6.926783084869385\n",
      "[INFO: 2022-02-16 14:57:02,188] Iteration 140 (DataTime/BatchTime: 0.00384/0.485) losses = 6.9013, lr = [6.27557268303061e-07, 6.275572683030609e-06]\n",
      "[INFO: 2022-02-16 14:57:02,188]   LabelSmoothing Loss = 6.916512966156006\n",
      "[INFO: 2022-02-16 14:57:11,920] Iteration 160 (DataTime/BatchTime: 0.00347/0.487) losses = 6.8875, lr = [7.159456159513794e-07, 7.159456159513793e-06]\n",
      "[INFO: 2022-02-16 14:57:11,920]   LabelSmoothing Loss = 6.91536808013916\n",
      "[INFO: 2022-02-16 14:57:21,675] Iteration 180 (DataTime/BatchTime: 0.00351/0.488) losses = 6.8675, lr = [8.043339635996979e-07, 8.043339635996977e-06]\n",
      "[INFO: 2022-02-16 14:57:21,675]   LabelSmoothing Loss = 6.9233503341674805\n",
      "[INFO: 2022-02-16 14:57:31,465] Iteration 200 (DataTime/BatchTime: 0.00181/0.49) losses = 6.8676, lr = [8.927223112480164e-07, 8.927223112480162e-06]\n",
      "[INFO: 2022-02-16 14:57:31,465]   LabelSmoothing Loss = 6.901610851287842\n",
      "[INFO: 2022-02-16 14:57:41,180] Iteration 220 (DataTime/BatchTime: 0.00376/0.486) losses = 6.8445, lr = [9.811106588963349e-07, 9.811106588963348e-06]\n",
      "[INFO: 2022-02-16 14:57:41,180]   LabelSmoothing Loss = 6.838899612426758\n",
      "[INFO: 2022-02-16 14:57:50,926] Iteration 240 (DataTime/BatchTime: 0.00184/0.487) losses = 6.7988, lr = [1.0694990065446533e-06, 1.0694990065446532e-05]\n",
      "[INFO: 2022-02-16 14:57:50,926]   LabelSmoothing Loss = 6.864210605621338\n",
      "[INFO: 2022-02-16 14:58:00,709] Iteration 260 (DataTime/BatchTime: 0.00275/0.489) losses = 6.8334, lr = [1.1578873541929717e-06, 1.1578873541929716e-05]\n",
      "[INFO: 2022-02-16 14:58:00,709]   LabelSmoothing Loss = 6.846227645874023\n",
      "[INFO: 2022-02-16 14:58:10,472] Iteration 280 (DataTime/BatchTime: 0.0018/0.488) losses = 6.8082, lr = [1.2462757018412902e-06, 1.24627570184129e-05]\n",
      "[INFO: 2022-02-16 14:58:10,472]   LabelSmoothing Loss = 6.843561172485352\n",
      "[INFO: 2022-02-16 14:58:20,346] Iteration 300 (DataTime/BatchTime: 0.0036/0.494) losses = 6.7456, lr = [1.3346640494896086e-06, 1.3346640494896084e-05]\n",
      "[INFO: 2022-02-16 14:58:20,346]   LabelSmoothing Loss = 6.803574562072754\n",
      "[INFO: 2022-02-16 14:58:30,098] Iteration 320 (DataTime/BatchTime: 0.0018/0.488) losses = 6.7179, lr = [1.423052397137927e-06, 1.4230523971379268e-05]\n",
      "[INFO: 2022-02-16 14:58:30,098]   LabelSmoothing Loss = 6.750672817230225\n",
      "[INFO: 2022-02-16 14:58:39,847] Iteration 340 (DataTime/BatchTime: 0.00362/0.487) losses = 6.7088, lr = [1.5114407447862455e-06, 1.5114407447862453e-05]\n",
      "[INFO: 2022-02-16 14:58:39,848]   LabelSmoothing Loss = 6.73006534576416\n",
      "[INFO: 2022-02-16 14:58:49,561] Iteration 360 (DataTime/BatchTime: 0.00194/0.486) losses = 6.6103, lr = [1.5998290924345639e-06, 1.5998290924345637e-05]\n",
      "[INFO: 2022-02-16 14:58:49,561]   LabelSmoothing Loss = 6.631574630737305\n",
      "[INFO: 2022-02-16 14:58:59,268] Iteration 380 (DataTime/BatchTime: 0.00457/0.485) losses = 6.5888, lr = [1.6882174400828823e-06, 1.6882174400828823e-05]\n",
      "[INFO: 2022-02-16 14:58:59,269]   LabelSmoothing Loss = 6.7372212409973145\n",
      "[INFO: 2022-02-16 14:59:08,987] Iteration 400 (DataTime/BatchTime: 0.00288/0.486) losses = 6.5769, lr = [1.7766057877312008e-06, 1.7766057877312005e-05]\n",
      "[INFO: 2022-02-16 14:59:08,988]   LabelSmoothing Loss = 6.577794551849365\n",
      "[INFO: 2022-02-16 14:59:18,680] Iteration 420 (DataTime/BatchTime: 0.00445/0.485) losses = 6.5059, lr = [1.8649941353795192e-06, 1.864994135379519e-05]\n",
      "[INFO: 2022-02-16 14:59:18,680]   LabelSmoothing Loss = 6.316979885101318\n",
      "[INFO: 2022-02-16 14:59:28,357] Iteration 440 (DataTime/BatchTime: 0.00179/0.484) losses = 6.4487, lr = [1.9533824830278376e-06, 1.9533824830278376e-05]\n",
      "[INFO: 2022-02-16 14:59:28,357]   LabelSmoothing Loss = 6.33974027633667\n",
      "[INFO: 2022-02-16 14:59:38,049] Iteration 460 (DataTime/BatchTime: 0.0028/0.485) losses = 6.4219, lr = [2.0417708306761563e-06, 2.041770830676156e-05]\n",
      "[INFO: 2022-02-16 14:59:38,050]   LabelSmoothing Loss = 6.305975437164307\n",
      "[INFO: 2022-02-16 14:59:47,778] Iteration 480 (DataTime/BatchTime: 0.00178/0.486) losses = 6.3817, lr = [2.1301591783244745e-06, 2.1301591783244744e-05]\n",
      "[INFO: 2022-02-16 14:59:47,778]   LabelSmoothing Loss = 6.450980186462402\n",
      "[INFO: 2022-02-16 14:59:57,474] Iteration 500 (DataTime/BatchTime: 0.00179/0.485) losses = 6.3663, lr = [2.218547525972793e-06, 2.2185475259727926e-05]\n",
      "[INFO: 2022-02-16 14:59:57,474]   LabelSmoothing Loss = 6.418150901794434\n",
      "[INFO: 2022-02-16 15:00:07,189] Iteration 520 (DataTime/BatchTime: 0.00179/0.486) losses = 6.3073, lr = [2.3069358736211118e-06, 2.3069358736211115e-05]\n",
      "[INFO: 2022-02-16 15:00:07,189]   LabelSmoothing Loss = 6.181764602661133\n",
      "[INFO: 2022-02-16 15:00:17,027] Iteration 540 (DataTime/BatchTime: 0.00183/0.492) losses = 6.3156, lr = [2.39532422126943e-06, 2.3953242212694298e-05]\n",
      "[INFO: 2022-02-16 15:00:17,027]   LabelSmoothing Loss = 6.4972243309021\n",
      "[INFO: 2022-02-16 15:00:26,700] Iteration 560 (DataTime/BatchTime: 0.00267/0.483) losses = 6.1626, lr = [2.4837125689177487e-06, 2.4837125689177483e-05]\n",
      "[INFO: 2022-02-16 15:00:26,700]   LabelSmoothing Loss = 6.148372650146484\n",
      "[INFO: 2022-02-16 15:00:36,357] Iteration 580 (DataTime/BatchTime: 0.00351/0.484) losses = 6.0811, lr = [2.572100916566067e-06, 2.5721009165660665e-05]\n",
      "[INFO: 2022-02-16 15:00:36,357]   LabelSmoothing Loss = 6.098003387451172\n",
      "[INFO: 2022-02-16 15:00:46,083] Iteration 600 (DataTime/BatchTime: 0.00261/0.486) losses = 6.1302, lr = [2.6604892642143855e-06, 2.660489264214385e-05]\n",
      "[INFO: 2022-02-16 15:00:46,084]   LabelSmoothing Loss = 5.687130451202393\n",
      "[INFO: 2022-02-16 15:00:55,828] Iteration 620 (DataTime/BatchTime: 0.00182/0.487) losses = 5.9684, lr = [2.7488776118627037e-06, 2.7488776118627033e-05]\n",
      "[INFO: 2022-02-16 15:00:55,828]   LabelSmoothing Loss = 5.827769756317139\n",
      "[INFO: 2022-02-16 15:01:05,567] Iteration 640 (DataTime/BatchTime: 0.00181/0.487) losses = 6.0005, lr = [2.8372659595110224e-06, 2.8372659595110222e-05]\n",
      "[INFO: 2022-02-16 15:01:05,567]   LabelSmoothing Loss = 6.149779319763184\n",
      "[INFO: 2022-02-16 15:01:15,267] Iteration 660 (DataTime/BatchTime: 0.00186/0.485) losses = 5.9077, lr = [2.9256543071593406e-06, 2.9256543071593404e-05]\n",
      "[INFO: 2022-02-16 15:01:15,267]   LabelSmoothing Loss = 5.78351354598999\n",
      "[INFO: 2022-02-16 15:01:24,978] Iteration 680 (DataTime/BatchTime: 0.00175/0.486) losses = 5.8758, lr = [3.0140426548076593e-06, 3.014042654807659e-05]\n",
      "[INFO: 2022-02-16 15:01:24,978]   LabelSmoothing Loss = 6.167514801025391\n",
      "[INFO: 2022-02-16 15:01:34,650] Iteration 700 (DataTime/BatchTime: 0.00254/0.484) losses = 5.9486, lr = [3.1024310024559775e-06, 3.102431002455977e-05]\n",
      "[INFO: 2022-02-16 15:01:34,650]   LabelSmoothing Loss = 6.173169136047363\n",
      "[INFO: 2022-02-16 15:01:44,335] Iteration 720 (DataTime/BatchTime: 0.00177/0.484) losses = 5.8228, lr = [3.190819350104296e-06, 3.190819350104296e-05]\n",
      "[INFO: 2022-02-16 15:01:44,335]   LabelSmoothing Loss = 5.913756370544434\n",
      "[INFO: 2022-02-16 15:01:54,057] Iteration 740 (DataTime/BatchTime: 0.00365/0.486) losses = 5.6786, lr = [3.2792076977526143e-06, 3.279207697752614e-05]\n",
      "[INFO: 2022-02-16 15:01:54,057]   LabelSmoothing Loss = 5.2373576164245605\n",
      "[INFO: 2022-02-16 15:02:03,842] Iteration 760 (DataTime/BatchTime: 0.00161/0.489) losses = 5.6707, lr = [3.367596045400933e-06, 3.3675960454009326e-05]\n",
      "[INFO: 2022-02-16 15:02:03,842]   LabelSmoothing Loss = 5.88181209564209\n",
      "[INFO: 2022-02-16 15:02:13,586] Iteration 780 (DataTime/BatchTime: 0.0018/0.487) losses = 5.5815, lr = [3.4559843930492512e-06, 3.455984393049251e-05]\n",
      "[INFO: 2022-02-16 15:02:13,586]   LabelSmoothing Loss = 5.626064300537109\n",
      "[INFO: 2022-02-16 15:02:23,296] Iteration 800 (DataTime/BatchTime: 0.00177/0.486) losses = 5.4961, lr = [3.54437274069757e-06, 3.54437274069757e-05]\n",
      "[INFO: 2022-02-16 15:02:23,297]   LabelSmoothing Loss = 5.749449729919434\n",
      "[INFO: 2022-02-16 15:02:32,994] Iteration 820 (DataTime/BatchTime: 0.00272/0.485) losses = 5.5649, lr = [3.632761088345888e-06, 3.6327610883458876e-05]\n",
      "[INFO: 2022-02-16 15:02:32,994]   LabelSmoothing Loss = 5.627320766448975\n",
      "[INFO: 2022-02-16 15:02:42,676] Iteration 840 (DataTime/BatchTime: 0.0017/0.484) losses = 5.4074, lr = [3.7211494359942067e-06, 3.721149435994207e-05]\n",
      "[INFO: 2022-02-16 15:02:42,676]   LabelSmoothing Loss = 5.238982200622559\n",
      "[INFO: 2022-02-16 15:02:52,363] Iteration 860 (DataTime/BatchTime: 0.00184/0.484) losses = 5.3126, lr = [3.809537783642525e-06, 3.809537783642525e-05]\n",
      "[INFO: 2022-02-16 15:02:52,363]   LabelSmoothing Loss = 4.830008506774902\n",
      "[INFO: 2022-02-16 15:03:02,164] Iteration 880 (DataTime/BatchTime: 0.00173/0.49) losses = 5.2477, lr = [3.897926131290844e-06, 3.897926131290843e-05]\n",
      "[INFO: 2022-02-16 15:03:02,165]   LabelSmoothing Loss = 5.341434001922607\n",
      "[INFO: 2022-02-16 15:03:12,002] Iteration 900 (DataTime/BatchTime: 0.00261/0.492) losses = 5.4058, lr = [3.986314478939162e-06, 3.986314478939162e-05]\n",
      "[INFO: 2022-02-16 15:03:12,002]   LabelSmoothing Loss = 5.2718892097473145\n",
      "[INFO: 2022-02-16 15:03:21,704] Iteration 920 (DataTime/BatchTime: 0.00344/0.485) losses = 5.3097, lr = [4.074702826587481e-06, 4.0747028265874804e-05]\n",
      "[INFO: 2022-02-16 15:03:21,705]   LabelSmoothing Loss = 5.4042649269104\n",
      "[INFO: 2022-02-16 15:03:31,495] Iteration 940 (DataTime/BatchTime: 0.00177/0.49) losses = 5.2745, lr = [4.163091174235799e-06, 4.163091174235798e-05]\n",
      "[INFO: 2022-02-16 15:03:31,495]   LabelSmoothing Loss = 5.272697448730469\n",
      "[INFO: 2022-02-16 15:07:15,655] ######## Epoch (VAL)1 ########\n",
      "[INFO: 2022-02-16 15:07:15,655] {'Bleu_1': 0.03599053214421497, 'Bleu_2': 0.019354143062080532, 'Bleu_3': 0.010051681717282978, 'Bleu_4': 0.0036336721862897207, 'METEOR': 0.04151045728956936, 'ROUGE_L': 0.06993456866924995, 'CIDEr': 1.6714689863366942e-05}\n",
      "[INFO: 2022-02-16 15:10:55,463] ######## Epoch (TEST)1 ########\n",
      "[INFO: 2022-02-16 15:10:55,463] {'Bleu_1': 0.03555573824399796, 'Bleu_2': 0.019086384192299723, 'Bleu_3': 0.009943746207586784, 'Bleu_4': 0.003461828631336404, 'METEOR': 0.04030218369551406, 'ROUGE_L': 0.06823833168042216, 'CIDEr': 0.0010043294589451082}\n",
      "[INFO: 2022-02-16 15:10:59,516] Iteration 960 (DataTime/BatchTime: 0.161/0.675) losses = 5.2798, lr = [4.251479521884117e-06, 4.251479521884117e-05]\n",
      "[INFO: 2022-02-16 15:10:59,516]   LabelSmoothing Loss = 5.0752458572387695\n",
      "[INFO: 2022-02-16 15:11:09,188] Iteration 980 (DataTime/BatchTime: 0.00159/0.484) losses = 5.0702, lr = [4.339867869532436e-06, 4.339867869532436e-05]\n",
      "[INFO: 2022-02-16 15:11:09,188]   LabelSmoothing Loss = 4.351637363433838\n",
      "[INFO: 2022-02-16 15:11:18,955] Iteration 1000 (DataTime/BatchTime: 0.00149/0.488) losses = 5.1435, lr = [4.428256217180754e-06, 4.428256217180753e-05]\n",
      "[INFO: 2022-02-16 15:11:18,956]   LabelSmoothing Loss = 5.011819362640381\n",
      "[INFO: 2022-02-16 15:11:28,551] Iteration 1020 (DataTime/BatchTime: 0.00298/0.48) losses = 5.1308, lr = [4.516644564829073e-06, 4.5166445648290725e-05]\n",
      "[INFO: 2022-02-16 15:11:28,551]   LabelSmoothing Loss = 5.406157970428467\n",
      "[INFO: 2022-02-16 15:11:38,181] Iteration 1040 (DataTime/BatchTime: 0.00135/0.481) losses = 5.0415, lr = [4.605032912477391e-06, 4.605032912477391e-05]\n",
      "[INFO: 2022-02-16 15:11:38,181]   LabelSmoothing Loss = 5.094992160797119\n",
      "[INFO: 2022-02-16 15:11:47,764] Iteration 1060 (DataTime/BatchTime: 0.00135/0.479) losses = 4.892, lr = [4.69342126012571e-06, 4.6934212601257096e-05]\n",
      "[INFO: 2022-02-16 15:11:47,765]   LabelSmoothing Loss = 4.642026901245117\n",
      "[INFO: 2022-02-16 15:11:57,307] Iteration 1080 (DataTime/BatchTime: 0.00131/0.477) losses = 4.9824, lr = [4.7818096077740275e-06, 4.7818096077740275e-05]\n",
      "[INFO: 2022-02-16 15:11:57,307]   LabelSmoothing Loss = 4.993355751037598\n",
      "[INFO: 2022-02-16 15:12:06,871] Iteration 1100 (DataTime/BatchTime: 0.00131/0.478) losses = 4.9585, lr = [4.870197955422347e-06, 4.870197955422346e-05]\n",
      "[INFO: 2022-02-16 15:12:06,871]   LabelSmoothing Loss = 5.300565242767334\n",
      "[INFO: 2022-02-16 15:12:16,509] Iteration 1120 (DataTime/BatchTime: 0.00129/0.482) losses = 4.9524, lr = [4.958586303070665e-06, 4.9585863030706646e-05]\n",
      "[INFO: 2022-02-16 15:12:16,509]   LabelSmoothing Loss = 4.204442501068115\n",
      "[INFO: 2022-02-16 15:12:26,041] Iteration 1140 (DataTime/BatchTime: 0.00214/0.477) losses = 4.7321, lr = [5.046974650718984e-06, 5.046974650718983e-05]\n",
      "[INFO: 2022-02-16 15:12:26,042]   LabelSmoothing Loss = 4.500561237335205\n",
      "[INFO: 2022-02-16 15:12:35,614] Iteration 1160 (DataTime/BatchTime: 0.00133/0.479) losses = 4.812, lr = [5.135362998367303e-06, 5.135362998367302e-05]\n",
      "[INFO: 2022-02-16 15:12:35,614]   LabelSmoothing Loss = 4.443892955780029\n",
      "[INFO: 2022-02-16 15:12:45,151] Iteration 1180 (DataTime/BatchTime: 0.00131/0.477) losses = 4.6496, lr = [5.22375134601562e-06, 5.2237513460156196e-05]\n",
      "[INFO: 2022-02-16 15:12:45,151]   LabelSmoothing Loss = 5.191569805145264\n",
      "[INFO: 2022-02-16 15:12:54,718] Iteration 1200 (DataTime/BatchTime: 0.00134/0.478) losses = 4.8213, lr = [5.312139693663939e-06, 5.312139693663938e-05]\n",
      "[INFO: 2022-02-16 15:12:54,718]   LabelSmoothing Loss = 5.083878040313721\n",
      "[INFO: 2022-02-16 15:13:04,253] Iteration 1220 (DataTime/BatchTime: 0.00309/0.477) losses = 4.7043, lr = [5.400528041312258e-06, 5.400528041312257e-05]\n",
      "[INFO: 2022-02-16 15:13:04,253]   LabelSmoothing Loss = 5.166032791137695\n",
      "[INFO: 2022-02-16 15:13:13,746] Iteration 1240 (DataTime/BatchTime: 0.00131/0.475) losses = 4.6377, lr = [5.488916388960577e-06, 5.488916388960576e-05]\n",
      "[INFO: 2022-02-16 15:13:13,746]   LabelSmoothing Loss = 4.891032695770264\n",
      "[INFO: 2022-02-16 15:13:23,289] Iteration 1260 (DataTime/BatchTime: 0.00212/0.477) losses = 4.675, lr = [5.577304736608894e-06, 5.577304736608893e-05]\n",
      "[INFO: 2022-02-16 15:13:23,289]   LabelSmoothing Loss = 4.98713493347168\n",
      "[INFO: 2022-02-16 15:13:32,811] Iteration 1280 (DataTime/BatchTime: 0.00133/0.475) losses = 4.6017, lr = [5.665693084257213e-06, 5.6656930842572124e-05]\n",
      "[INFO: 2022-02-16 15:13:32,811]   LabelSmoothing Loss = 4.015947341918945\n",
      "[INFO: 2022-02-16 15:13:42,336] Iteration 1300 (DataTime/BatchTime: 0.00219/0.477) losses = 4.496, lr = [5.754081431905531e-06, 5.754081431905531e-05]\n",
      "[INFO: 2022-02-16 15:13:42,336]   LabelSmoothing Loss = 4.41774845123291\n",
      "[INFO: 2022-02-16 15:13:51,879] Iteration 1320 (DataTime/BatchTime: 0.00131/0.477) losses = 4.5796, lr = [5.84246977955385e-06, 5.8424697795538496e-05]\n",
      "[INFO: 2022-02-16 15:13:51,879]   LabelSmoothing Loss = 4.075285911560059\n",
      "[INFO: 2022-02-16 15:14:01,417] Iteration 1340 (DataTime/BatchTime: 0.00215/0.477) losses = 4.4284, lr = [5.930858127202168e-06, 5.9308581272021675e-05]\n",
      "[INFO: 2022-02-16 15:14:01,417]   LabelSmoothing Loss = 4.757450580596924\n",
      "[INFO: 2022-02-16 15:14:10,998] Iteration 1360 (DataTime/BatchTime: 0.00131/0.479) losses = 4.4364, lr = [6.019246474850487e-06, 6.019246474850486e-05]\n",
      "[INFO: 2022-02-16 15:14:10,998]   LabelSmoothing Loss = 4.184029579162598\n",
      "[INFO: 2022-02-16 15:14:20,673] Iteration 1380 (DataTime/BatchTime: 0.00127/0.484) losses = 4.407, lr = [6.107634822498805e-06, 6.107634822498805e-05]\n",
      "[INFO: 2022-02-16 15:14:20,673]   LabelSmoothing Loss = 4.530584335327148\n",
      "[INFO: 2022-02-16 15:14:30,151] Iteration 1400 (DataTime/BatchTime: 0.00125/0.474) losses = 4.2002, lr = [6.196023170147124e-06, 6.196023170147124e-05]\n",
      "[INFO: 2022-02-16 15:14:30,152]   LabelSmoothing Loss = 5.1031317710876465\n",
      "[INFO: 2022-02-16 15:14:39,782] Iteration 1420 (DataTime/BatchTime: 0.00327/0.482) losses = 4.1943, lr = [6.2844115177954415e-06, 6.284411517795441e-05]\n",
      "[INFO: 2022-02-16 15:14:39,782]   LabelSmoothing Loss = 4.159778594970703\n",
      "[INFO: 2022-02-16 15:14:49,311] Iteration 1440 (DataTime/BatchTime: 0.00207/0.476) losses = 4.2498, lr = [6.372799865443761e-06, 6.37279986544376e-05]\n",
      "[INFO: 2022-02-16 15:14:49,311]   LabelSmoothing Loss = 4.354249477386475\n",
      "[INFO: 2022-02-16 15:14:58,885] Iteration 1460 (DataTime/BatchTime: 0.00126/0.479) losses = 4.2412, lr = [6.461188213092079e-06, 6.461188213092078e-05]\n",
      "[INFO: 2022-02-16 15:14:58,885]   LabelSmoothing Loss = 3.70072078704834\n",
      "[INFO: 2022-02-16 15:15:08,436] Iteration 1480 (DataTime/BatchTime: 0.00128/0.478) losses = 4.3538, lr = [6.549576560740398e-06, 6.549576560740397e-05]\n",
      "[INFO: 2022-02-16 15:15:08,436]   LabelSmoothing Loss = 4.079784393310547\n",
      "[INFO: 2022-02-16 15:15:17,995] Iteration 1500 (DataTime/BatchTime: 0.00127/0.478) losses = 4.1083, lr = [6.637964908388715e-06, 6.637964908388715e-05]\n",
      "[INFO: 2022-02-16 15:15:17,995]   LabelSmoothing Loss = 3.5164425373077393\n",
      "[INFO: 2022-02-16 15:15:27,596] Iteration 1520 (DataTime/BatchTime: 0.00129/0.48) losses = 4.2008, lr = [6.726353256037034e-06, 6.726353256037034e-05]\n",
      "[INFO: 2022-02-16 15:15:27,597]   LabelSmoothing Loss = 3.3369147777557373\n",
      "[INFO: 2022-02-16 15:15:37,137] Iteration 1540 (DataTime/BatchTime: 0.0022/0.477) losses = 4.1661, lr = [6.8147416036853526e-06, 6.814741603685352e-05]\n",
      "[INFO: 2022-02-16 15:15:37,137]   LabelSmoothing Loss = 3.629849433898926\n",
      "[INFO: 2022-02-16 15:15:46,711] Iteration 1560 (DataTime/BatchTime: 0.00128/0.479) losses = 4.2551, lr = [6.903129951333672e-06, 6.903129951333671e-05]\n",
      "[INFO: 2022-02-16 15:15:46,711]   LabelSmoothing Loss = 4.677875518798828\n",
      "[INFO: 2022-02-16 15:15:56,357] Iteration 1580 (DataTime/BatchTime: 0.00129/0.482) losses = 4.1658, lr = [6.991518298981989e-06, 6.991518298981988e-05]\n",
      "[INFO: 2022-02-16 15:15:56,357]   LabelSmoothing Loss = 4.641299247741699\n",
      "[INFO: 2022-02-16 15:16:05,913] Iteration 1600 (DataTime/BatchTime: 0.00139/0.478) losses = 3.9698, lr = [7.079906646630308e-06, 7.079906646630307e-05]\n",
      "[INFO: 2022-02-16 15:16:05,914]   LabelSmoothing Loss = 4.622486114501953\n",
      "[INFO: 2022-02-16 15:16:15,464] Iteration 1620 (DataTime/BatchTime: 0.00127/0.478) losses = 4.1633, lr = [7.168294994278626e-06, 7.168294994278625e-05]\n",
      "[INFO: 2022-02-16 15:16:15,464]   LabelSmoothing Loss = 3.5070695877075195\n",
      "[INFO: 2022-02-16 15:16:25,012] Iteration 1640 (DataTime/BatchTime: 0.00218/0.477) losses = 4.0468, lr = [7.256683341926945e-06, 7.256683341926945e-05]\n",
      "[INFO: 2022-02-16 15:16:25,012]   LabelSmoothing Loss = 4.394255638122559\n",
      "[INFO: 2022-02-16 15:16:34,568] Iteration 1660 (DataTime/BatchTime: 0.00297/0.478) losses = 4.2627, lr = [7.345071689575263e-06, 7.345071689575262e-05]\n",
      "[INFO: 2022-02-16 15:16:34,568]   LabelSmoothing Loss = 3.835893392562866\n",
      "[INFO: 2022-02-16 15:16:44,183] Iteration 1680 (DataTime/BatchTime: 0.00223/0.481) losses = 4.1073, lr = [7.433460037223582e-06, 7.433460037223581e-05]\n",
      "[INFO: 2022-02-16 15:16:44,183]   LabelSmoothing Loss = 4.668341636657715\n",
      "[INFO: 2022-02-16 15:16:53,824] Iteration 1700 (DataTime/BatchTime: 0.00144/0.482) losses = 3.9286, lr = [7.521848384871901e-06, 7.5218483848719e-05]\n",
      "[INFO: 2022-02-16 15:16:53,825]   LabelSmoothing Loss = 3.1885740756988525\n",
      "[INFO: 2022-02-16 15:17:03,406] Iteration 1720 (DataTime/BatchTime: 0.00136/0.479) losses = 3.9162, lr = [7.610236732520219e-06, 7.610236732520218e-05]\n",
      "[INFO: 2022-02-16 15:17:03,407]   LabelSmoothing Loss = 3.991072416305542\n",
      "[INFO: 2022-02-16 15:17:12,990] Iteration 1740 (DataTime/BatchTime: 0.00134/0.479) losses = 4.0464, lr = [7.698625080168537e-06, 7.698625080168537e-05]\n",
      "[INFO: 2022-02-16 15:17:12,990]   LabelSmoothing Loss = 4.4105706214904785\n",
      "[INFO: 2022-02-16 15:17:22,600] Iteration 1760 (DataTime/BatchTime: 0.00132/0.481) losses = 3.8796, lr = [7.787013427816856e-06, 7.787013427816855e-05]\n",
      "[INFO: 2022-02-16 15:17:22,601]   LabelSmoothing Loss = 4.742086410522461\n",
      "[INFO: 2022-02-16 15:17:32,231] Iteration 1780 (DataTime/BatchTime: 0.00136/0.482) losses = 3.8566, lr = [7.875401775465174e-06, 7.875401775465174e-05]\n",
      "[INFO: 2022-02-16 15:17:32,231]   LabelSmoothing Loss = 3.3479270935058594\n",
      "[INFO: 2022-02-16 15:17:41,853] Iteration 1800 (DataTime/BatchTime: 0.00313/0.481) losses = 4.0822, lr = [7.963790123113494e-06, 7.963790123113492e-05]\n",
      "[INFO: 2022-02-16 15:17:41,853]   LabelSmoothing Loss = 3.878526449203491\n",
      "[INFO: 2022-02-16 15:17:51,491] Iteration 1820 (DataTime/BatchTime: 0.00136/0.482) losses = 3.9422, lr = [8.05217847076181e-06, 8.05217847076181e-05]\n",
      "[INFO: 2022-02-16 15:17:51,492]   LabelSmoothing Loss = 4.268080711364746\n",
      "[INFO: 2022-02-16 15:18:01,070] Iteration 1840 (DataTime/BatchTime: 0.00142/0.479) losses = 3.8245, lr = [8.14056681841013e-06, 8.140566818410128e-05]\n",
      "[INFO: 2022-02-16 15:18:01,070]   LabelSmoothing Loss = 2.8427047729492188\n",
      "[INFO: 2022-02-16 15:18:10,791] Iteration 1860 (DataTime/BatchTime: 0.00134/0.486) losses = 3.9933, lr = [8.228955166058448e-06, 8.228955166058447e-05]\n",
      "[INFO: 2022-02-16 15:18:10,792]   LabelSmoothing Loss = 4.488442420959473\n",
      "[INFO: 2022-02-16 15:18:20,352] Iteration 1880 (DataTime/BatchTime: 0.00133/0.478) losses = 3.7634, lr = [8.317343513706767e-06, 8.317343513706765e-05]\n",
      "[INFO: 2022-02-16 15:18:20,352]   LabelSmoothing Loss = 4.417946815490723\n",
      "[INFO: 2022-02-16 15:18:29,968] Iteration 1900 (DataTime/BatchTime: 0.00222/0.481) losses = 4.0082, lr = [8.405731861355085e-06, 8.405731861355084e-05]\n",
      "[INFO: 2022-02-16 15:18:29,968]   LabelSmoothing Loss = 4.881635665893555\n",
      "[INFO: 2022-02-16 15:22:09,695] ######## Epoch (VAL)2 ########\n",
      "[INFO: 2022-02-16 15:22:09,695] {'Bleu_1': 0.05049945786328811, 'Bleu_2': 0.03183225735496136, 'Bleu_3': 0.021074412779134837, 'Bleu_4': 0.01353795280698437, 'METEOR': 0.06785705005333549, 'ROUGE_L': 0.1048292641439479, 'CIDEr': 0.014917171196877597}\n",
      "[INFO: 2022-02-16 15:25:52,046] ######## Epoch (TEST)2 ########\n",
      "[INFO: 2022-02-16 15:25:52,047] {'Bleu_1': 0.05337919770348058, 'Bleu_2': 0.03203141999697107, 'Bleu_3': 0.021071301991496007, 'Bleu_4': 0.013527393311483924, 'METEOR': 0.0665785402547023, 'ROUGE_L': 0.11352427032340508, 'CIDEr': 0.012927409531943337}\n",
      "[INFO: 2022-02-16 15:25:58,383] Iteration 1920 (DataTime/BatchTime: 0.1/0.576) losses = 3.9356, lr = [8.494120209003403e-06, 8.494120209003402e-05]\n",
      "[INFO: 2022-02-16 15:25:58,383]   LabelSmoothing Loss = 2.8799233436584473\n",
      "[INFO: 2022-02-16 15:26:07,926] Iteration 1940 (DataTime/BatchTime: 0.00139/0.477) losses = 3.8989, lr = [8.582508556651721e-06, 8.582508556651721e-05]\n",
      "[INFO: 2022-02-16 15:26:07,926]   LabelSmoothing Loss = 3.625514507293701\n",
      "[INFO: 2022-02-16 15:26:17,339] Iteration 1960 (DataTime/BatchTime: 0.00224/0.471) losses = 3.9053, lr = [8.67089690430004e-06, 8.670896904300038e-05]\n",
      "[INFO: 2022-02-16 15:26:17,339]   LabelSmoothing Loss = 3.400012493133545\n",
      "[INFO: 2022-02-16 15:26:26,811] Iteration 1980 (DataTime/BatchTime: 0.00226/0.474) losses = 3.7424, lr = [8.759285251948358e-06, 8.759285251948357e-05]\n",
      "[INFO: 2022-02-16 15:26:26,811]   LabelSmoothing Loss = 4.041684150695801\n",
      "[INFO: 2022-02-16 15:26:36,200] Iteration 2000 (DataTime/BatchTime: 0.00111/0.469) losses = 3.7607, lr = [8.847673599596678e-06, 8.847673599596677e-05]\n",
      "[INFO: 2022-02-16 15:26:36,201]   LabelSmoothing Loss = 3.8697330951690674\n",
      "[INFO: 2022-02-16 15:26:45,663] Iteration 2020 (DataTime/BatchTime: 0.00255/0.473) losses = 3.8119, lr = [8.936061947244996e-06, 8.936061947244995e-05]\n",
      "[INFO: 2022-02-16 15:26:45,663]   LabelSmoothing Loss = 4.513585090637207\n",
      "[INFO: 2022-02-16 15:26:55,087] Iteration 2040 (DataTime/BatchTime: 0.00163/0.471) losses = 3.7139, lr = [9.024450294893314e-06, 9.024450294893314e-05]\n",
      "[INFO: 2022-02-16 15:26:55,087]   LabelSmoothing Loss = 2.991831064224243\n",
      "[INFO: 2022-02-16 15:27:04,495] Iteration 2060 (DataTime/BatchTime: 0.00108/0.47) losses = 3.7194, lr = [9.112838642541632e-06, 9.112838642541632e-05]\n",
      "[INFO: 2022-02-16 15:27:04,495]   LabelSmoothing Loss = 3.7353901863098145\n",
      "[INFO: 2022-02-16 15:27:14,007] Iteration 2080 (DataTime/BatchTime: 0.00108/0.476) losses = 3.5045, lr = [9.201226990189952e-06, 9.201226990189951e-05]\n",
      "[INFO: 2022-02-16 15:27:14,007]   LabelSmoothing Loss = 3.346282958984375\n",
      "[INFO: 2022-02-16 15:27:23,527] Iteration 2100 (DataTime/BatchTime: 0.00111/0.476) losses = 3.845, lr = [9.289615337838269e-06, 9.289615337838268e-05]\n",
      "[INFO: 2022-02-16 15:27:23,527]   LabelSmoothing Loss = 4.094332695007324\n",
      "[INFO: 2022-02-16 15:27:33,039] Iteration 2120 (DataTime/BatchTime: 0.002/0.476) losses = 3.892, lr = [9.378003685486587e-06, 9.378003685486587e-05]\n",
      "[INFO: 2022-02-16 15:27:33,039]   LabelSmoothing Loss = 3.674025297164917\n",
      "[INFO: 2022-02-16 15:27:42,559] Iteration 2140 (DataTime/BatchTime: 0.000986/0.476) losses = 3.6964, lr = [9.466392033134905e-06, 9.466392033134905e-05]\n",
      "[INFO: 2022-02-16 15:27:42,559]   LabelSmoothing Loss = 3.450680732727051\n",
      "[INFO: 2022-02-16 15:27:51,960] Iteration 2160 (DataTime/BatchTime: 0.00099/0.47) losses = 3.4587, lr = [9.554780380783225e-06, 9.554780380783224e-05]\n",
      "[INFO: 2022-02-16 15:27:51,961]   LabelSmoothing Loss = 3.215118169784546\n",
      "[INFO: 2022-02-16 15:28:01,386] Iteration 2180 (DataTime/BatchTime: 0.000997/0.471) losses = 3.5017, lr = [9.643168728431543e-06, 9.643168728431542e-05]\n",
      "[INFO: 2022-02-16 15:28:01,386]   LabelSmoothing Loss = 2.8795342445373535\n",
      "[INFO: 2022-02-16 15:28:10,955] Iteration 2200 (DataTime/BatchTime: 0.00109/0.478) losses = 3.8224, lr = [9.731557076079862e-06, 9.731557076079861e-05]\n",
      "[INFO: 2022-02-16 15:28:10,955]   LabelSmoothing Loss = 4.645954132080078\n",
      "[INFO: 2022-02-16 15:28:20,554] Iteration 2220 (DataTime/BatchTime: 0.00588/0.48) losses = 3.5774, lr = [9.819945423728181e-06, 9.81994542372818e-05]\n",
      "[INFO: 2022-02-16 15:28:20,555]   LabelSmoothing Loss = 4.199349880218506\n",
      "[INFO: 2022-02-16 15:28:30,070] Iteration 2240 (DataTime/BatchTime: 0.00316/0.476) losses = 3.5823, lr = [9.9083337713765e-06, 9.908333771376498e-05]\n",
      "[INFO: 2022-02-16 15:28:30,071]   LabelSmoothing Loss = 2.729726791381836\n",
      "[INFO: 2022-02-16 15:28:39,597] Iteration 2260 (DataTime/BatchTime: 0.00106/0.476) losses = 3.6998, lr = [9.996722119024816e-06, 9.996722119024815e-05]\n",
      "[INFO: 2022-02-16 15:28:39,597]   LabelSmoothing Loss = 2.681391477584839\n",
      "[INFO: 2022-02-16 15:28:49,007] Iteration 2280 (DataTime/BatchTime: 0.00103/0.47) losses = 3.741, lr = [1.0085110466673134e-05, 0.00010085110466673134]\n",
      "[INFO: 2022-02-16 15:28:49,008]   LabelSmoothing Loss = 2.6937599182128906\n",
      "[INFO: 2022-02-16 15:28:58,503] Iteration 2300 (DataTime/BatchTime: 0.0026/0.475) losses = 3.4486, lr = [1.0173498814321454e-05, 0.00010173498814321452]\n",
      "[INFO: 2022-02-16 15:28:58,503]   LabelSmoothing Loss = 3.072511672973633\n",
      "[INFO: 2022-02-16 15:29:08,131] Iteration 2320 (DataTime/BatchTime: 0.00193/0.481) losses = 3.8916, lr = [1.0261887161969773e-05, 0.00010261887161969771]\n",
      "[INFO: 2022-02-16 15:29:08,132]   LabelSmoothing Loss = 4.329995155334473\n",
      "[INFO: 2022-02-16 15:29:17,582] Iteration 2340 (DataTime/BatchTime: 0.00116/0.473) losses = 3.5477, lr = [1.035027550961809e-05, 0.0001035027550961809]\n",
      "[INFO: 2022-02-16 15:29:17,582]   LabelSmoothing Loss = 2.7900164127349854\n",
      "[INFO: 2022-02-16 15:29:27,244] Iteration 2360 (DataTime/BatchTime: 0.00214/0.483) losses = 3.4753, lr = [1.0438663857266409e-05, 0.00010438663857266408]\n",
      "[INFO: 2022-02-16 15:29:27,244]   LabelSmoothing Loss = 2.98593807220459\n",
      "[INFO: 2022-02-16 15:29:36,878] Iteration 2380 (DataTime/BatchTime: 0.00197/0.481) losses = 3.6802, lr = [1.0527052204914729e-05, 0.00010527052204914727]\n",
      "[INFO: 2022-02-16 15:29:36,878]   LabelSmoothing Loss = 3.1402320861816406\n",
      "[INFO: 2022-02-16 15:29:46,383] Iteration 2400 (DataTime/BatchTime: 0.0022/0.476) losses = 3.4831, lr = [1.0615440552563047e-05, 0.00010615440552563045]\n",
      "[INFO: 2022-02-16 15:29:46,383]   LabelSmoothing Loss = 4.142787933349609\n",
      "[INFO: 2022-02-16 15:29:55,898] Iteration 2420 (DataTime/BatchTime: 0.00201/0.476) losses = 3.7015, lr = [1.0703828900211364e-05, 0.00010703828900211362]\n",
      "[INFO: 2022-02-16 15:29:55,898]   LabelSmoothing Loss = 3.7337543964385986\n",
      "[INFO: 2022-02-16 15:30:05,467] Iteration 2440 (DataTime/BatchTime: 0.000975/0.478) losses = 3.5344, lr = [1.0792217247859682e-05, 0.00010792217247859681]\n",
      "[INFO: 2022-02-16 15:30:05,468]   LabelSmoothing Loss = 2.7418739795684814\n",
      "[INFO: 2022-02-16 15:30:14,949] Iteration 2460 (DataTime/BatchTime: 0.000946/0.474) losses = 3.5444, lr = [1.0880605595508002e-05, 0.00010880605595508]\n",
      "[INFO: 2022-02-16 15:30:14,949]   LabelSmoothing Loss = 3.28963041305542\n",
      "[INFO: 2022-02-16 15:30:24,392] Iteration 2480 (DataTime/BatchTime: 0.00177/0.472) losses = 3.3708, lr = [1.096899394315632e-05, 0.00010968993943156318]\n",
      "[INFO: 2022-02-16 15:30:24,392]   LabelSmoothing Loss = 3.0892319679260254\n",
      "[INFO: 2022-02-16 15:30:33,898] Iteration 2500 (DataTime/BatchTime: 0.00093/0.475) losses = 3.4666, lr = [1.1057382290804638e-05, 0.00011057382290804637]\n",
      "[INFO: 2022-02-16 15:30:33,898]   LabelSmoothing Loss = 3.8018639087677\n",
      "[INFO: 2022-02-16 15:30:43,411] Iteration 2520 (DataTime/BatchTime: 0.00205/0.476) losses = 3.4334, lr = [1.1145770638452956e-05, 0.00011145770638452956]\n",
      "[INFO: 2022-02-16 15:30:43,411]   LabelSmoothing Loss = 3.3254499435424805\n",
      "[INFO: 2022-02-16 15:30:53,008] Iteration 2540 (DataTime/BatchTime: 0.00343/0.48) losses = 3.6609, lr = [1.1234158986101276e-05, 0.00011234158986101275]\n",
      "[INFO: 2022-02-16 15:30:53,008]   LabelSmoothing Loss = 2.8129541873931885\n",
      "[INFO: 2022-02-16 15:31:02,523] Iteration 2560 (DataTime/BatchTime: 0.00227/0.476) losses = 3.5292, lr = [1.1322547333749595e-05, 0.00011322547333749594]\n",
      "[INFO: 2022-02-16 15:31:02,523]   LabelSmoothing Loss = 3.606640577316284\n",
      "[INFO: 2022-02-16 15:31:12,121] Iteration 2580 (DataTime/BatchTime: 0.00133/0.48) losses = 3.6479, lr = [1.1410935681397913e-05, 0.00011410935681397912]\n",
      "[INFO: 2022-02-16 15:31:12,121]   LabelSmoothing Loss = 2.8621826171875\n",
      "[INFO: 2022-02-16 15:31:21,675] Iteration 2600 (DataTime/BatchTime: 0.00139/0.478) losses = 3.5252, lr = [1.149932402904623e-05, 0.00011499324029046228]\n",
      "[INFO: 2022-02-16 15:31:21,675]   LabelSmoothing Loss = 3.8589019775390625\n",
      "[INFO: 2022-02-16 15:31:31,261] Iteration 2620 (DataTime/BatchTime: 0.00143/0.479) losses = 3.5363, lr = [1.158771237669455e-05, 0.00011587712376694548]\n",
      "[INFO: 2022-02-16 15:31:31,262]   LabelSmoothing Loss = 4.176918983459473\n",
      "[INFO: 2022-02-16 15:31:40,808] Iteration 2640 (DataTime/BatchTime: 0.00227/0.477) losses = 3.2589, lr = [1.1676100724342867e-05, 0.00011676100724342866]\n",
      "[INFO: 2022-02-16 15:31:40,808]   LabelSmoothing Loss = 3.014970541000366\n",
      "[INFO: 2022-02-16 15:31:50,396] Iteration 2660 (DataTime/BatchTime: 0.00308/0.479) losses = 3.5137, lr = [1.1764489071991186e-05, 0.00011764489071991185]\n",
      "[INFO: 2022-02-16 15:31:50,397]   LabelSmoothing Loss = 4.012062072753906\n",
      "[INFO: 2022-02-16 15:31:59,971] Iteration 2680 (DataTime/BatchTime: 0.00227/0.479) losses = 3.6294, lr = [1.1852877419639504e-05, 0.00011852877419639504]\n",
      "[INFO: 2022-02-16 15:31:59,971]   LabelSmoothing Loss = 4.027556896209717\n",
      "[INFO: 2022-02-16 15:32:09,517] Iteration 2700 (DataTime/BatchTime: 0.00135/0.477) losses = 3.5431, lr = [1.1941265767287824e-05, 0.00011941265767287822]\n",
      "[INFO: 2022-02-16 15:32:09,517]   LabelSmoothing Loss = 3.0029296875\n",
      "[INFO: 2022-02-16 15:32:19,098] Iteration 2720 (DataTime/BatchTime: 0.00141/0.478) losses = 3.366, lr = [1.2029654114936142e-05, 0.00012029654114936141]\n",
      "[INFO: 2022-02-16 15:32:19,099]   LabelSmoothing Loss = 3.3949315547943115\n",
      "[INFO: 2022-02-16 15:32:28,592] Iteration 2740 (DataTime/BatchTime: 0.00314/0.476) losses = 3.3672, lr = [1.211804246258446e-05, 0.00012118042462584459]\n",
      "[INFO: 2022-02-16 15:32:28,592]   LabelSmoothing Loss = 4.0269598960876465\n",
      "[INFO: 2022-02-16 15:32:38,177] Iteration 2760 (DataTime/BatchTime: 0.00128/0.479) losses = 3.3933, lr = [1.2206430810232777e-05, 0.00012206430810232776]\n",
      "[INFO: 2022-02-16 15:32:38,177]   LabelSmoothing Loss = 3.1154770851135254\n",
      "[INFO: 2022-02-16 15:32:47,720] Iteration 2780 (DataTime/BatchTime: 0.00225/0.477) losses = 3.3797, lr = [1.2294819157881097e-05, 0.00012294819157881095]\n",
      "[INFO: 2022-02-16 15:32:47,720]   LabelSmoothing Loss = 2.951436758041382\n",
      "[INFO: 2022-02-16 15:32:57,228] Iteration 2800 (DataTime/BatchTime: 0.00137/0.475) losses = 3.2991, lr = [1.2383207505529415e-05, 0.00012383207505529414]\n",
      "[INFO: 2022-02-16 15:32:57,228]   LabelSmoothing Loss = 4.499502658843994\n",
      "[INFO: 2022-02-16 15:33:06,818] Iteration 2820 (DataTime/BatchTime: 0.00144/0.479) losses = 3.5362, lr = [1.2471595853177733e-05, 0.00012471595853177732]\n",
      "[INFO: 2022-02-16 15:33:06,818]   LabelSmoothing Loss = 3.7641732692718506\n",
      "[INFO: 2022-02-16 15:33:16,411] Iteration 2840 (DataTime/BatchTime: 0.00256/0.48) losses = 3.4994, lr = [1.2559984200826053e-05, 0.0001255998420082605]\n",
      "[INFO: 2022-02-16 15:33:16,411]   LabelSmoothing Loss = 4.178830623626709\n",
      "[INFO: 2022-02-16 15:33:25,926] Iteration 2860 (DataTime/BatchTime: 0.00253/0.476) losses = 3.3265, lr = [1.2648372548474371e-05, 0.0001264837254847437]\n",
      "[INFO: 2022-02-16 15:33:25,926]   LabelSmoothing Loss = 3.55930757522583\n",
      "[INFO: 2022-02-16 15:37:05,878] ######## Epoch (VAL)3 ########\n",
      "[INFO: 2022-02-16 15:37:05,878] {'Bleu_1': 0.06919185584681489, 'Bleu_2': 0.043670778182192026, 'Bleu_3': 0.02770311364207306, 'Bleu_4': 0.017266426226323187, 'METEOR': 0.09615467068994439, 'ROUGE_L': 0.11983800695220521, 'CIDEr': 9.181789393904066e-64}\n",
      "[INFO: 2022-02-16 15:40:47,853] ######## Epoch (TEST)3 ########\n",
      "[INFO: 2022-02-16 15:40:47,854] {'Bleu_1': 0.06778353132297558, 'Bleu_2': 0.042079351689884185, 'Bleu_3': 0.02663017912475834, 'Bleu_4': 0.016447966372810843, 'METEOR': 0.09051799957358553, 'ROUGE_L': 0.11610490507136882, 'CIDEr': 3.8640275246475766e-33}\n",
      "[INFO: 2022-02-16 15:40:56,669] Iteration 2880 (DataTime/BatchTime: 0.0684/0.551) losses = 3.3803, lr = [1.273676089612269e-05, 0.00012736760896122688]\n",
      "[INFO: 2022-02-16 15:40:56,669]   LabelSmoothing Loss = 3.728729248046875\n",
      "[INFO: 2022-02-16 15:41:06,212] Iteration 2900 (DataTime/BatchTime: 0.00221/0.477) losses = 3.5066, lr = [1.2825149243771008e-05, 0.00012825149243771006]\n",
      "[INFO: 2022-02-16 15:41:06,212]   LabelSmoothing Loss = 2.5077316761016846\n",
      "[INFO: 2022-02-16 15:41:15,815] Iteration 2920 (DataTime/BatchTime: 0.00134/0.48) losses = 3.5021, lr = [1.2913537591419326e-05, 0.00012913537591419325]\n",
      "[INFO: 2022-02-16 15:41:15,816]   LabelSmoothing Loss = 3.2786433696746826\n",
      "[INFO: 2022-02-16 15:41:25,255] Iteration 2940 (DataTime/BatchTime: 0.00143/0.472) losses = 3.1837, lr = [1.3001925939067644e-05, 0.00013001925939067644]\n",
      "[INFO: 2022-02-16 15:41:25,256]   LabelSmoothing Loss = 3.1726133823394775\n",
      "[INFO: 2022-02-16 15:41:34,761] Iteration 2960 (DataTime/BatchTime: 0.00302/0.475) losses = 3.3913, lr = [1.3090314286715962e-05, 0.00013090314286715962]\n",
      "[INFO: 2022-02-16 15:41:34,761]   LabelSmoothing Loss = 3.7252564430236816\n",
      "[INFO: 2022-02-16 15:41:44,206] Iteration 2980 (DataTime/BatchTime: 0.00295/0.472) losses = 3.5027, lr = [1.317870263436428e-05, 0.0001317870263436428]\n",
      "[INFO: 2022-02-16 15:41:44,207]   LabelSmoothing Loss = 3.2197625637054443\n",
      "[INFO: 2022-02-16 15:41:53,756] Iteration 3000 (DataTime/BatchTime: 0.00295/0.477) losses = 3.4386, lr = [1.32670909820126e-05, 0.000132670909820126]\n",
      "[INFO: 2022-02-16 15:41:53,757]   LabelSmoothing Loss = 3.031618118286133\n",
      "[INFO: 2022-02-16 15:42:03,247] Iteration 3020 (DataTime/BatchTime: 0.00132/0.475) losses = 3.5215, lr = [1.3355479329660919e-05, 0.00013355479329660918]\n",
      "[INFO: 2022-02-16 15:42:03,247]   LabelSmoothing Loss = 2.3149731159210205\n",
      "[INFO: 2022-02-16 15:42:12,754] Iteration 3040 (DataTime/BatchTime: 0.00213/0.475) losses = 3.5235, lr = [1.3443867677309237e-05, 0.00013443867677309236]\n",
      "[INFO: 2022-02-16 15:42:12,754]   LabelSmoothing Loss = 3.8198230266571045\n",
      "[INFO: 2022-02-16 15:42:22,315] Iteration 3060 (DataTime/BatchTime: 0.00142/0.478) losses = 3.3289, lr = [1.3532256024957555e-05, 0.00013532256024957555]\n",
      "[INFO: 2022-02-16 15:42:22,315]   LabelSmoothing Loss = 3.6750800609588623\n",
      "[INFO: 2022-02-16 15:42:31,845] Iteration 3080 (DataTime/BatchTime: 0.00222/0.477) losses = 3.5246, lr = [1.3620644372605873e-05, 0.0001362064437260587]\n",
      "[INFO: 2022-02-16 15:42:31,845]   LabelSmoothing Loss = 3.7596182823181152\n",
      "[INFO: 2022-02-16 15:42:41,366] Iteration 3100 (DataTime/BatchTime: 0.00136/0.476) losses = 3.2718, lr = [1.3709032720254192e-05, 0.0001370903272025419]\n",
      "[INFO: 2022-02-16 15:42:41,366]   LabelSmoothing Loss = 4.469640731811523\n",
      "[INFO: 2022-02-16 15:42:50,850] Iteration 3120 (DataTime/BatchTime: 0.00135/0.474) losses = 3.3316, lr = [1.379742106790251e-05, 0.00013797421067902508]\n",
      "[INFO: 2022-02-16 15:42:50,850]   LabelSmoothing Loss = 2.528622627258301\n",
      "[INFO: 2022-02-16 15:43:00,459] Iteration 3140 (DataTime/BatchTime: 0.00215/0.48) losses = 3.5596, lr = [1.3885809415550828e-05, 0.00013885809415550826]\n",
      "[INFO: 2022-02-16 15:43:00,459]   LabelSmoothing Loss = 2.800168991088867\n",
      "[INFO: 2022-02-16 15:43:09,973] Iteration 3160 (DataTime/BatchTime: 0.00136/0.476) losses = 3.4214, lr = [1.3974197763199148e-05, 0.00013974197763199145]\n",
      "[INFO: 2022-02-16 15:43:09,973]   LabelSmoothing Loss = 3.3065710067749023\n",
      "[INFO: 2022-02-16 15:43:19,530] Iteration 3180 (DataTime/BatchTime: 0.00226/0.478) losses = 3.0517, lr = [1.4062586110847466e-05, 0.00014062586110847464]\n",
      "[INFO: 2022-02-16 15:43:19,530]   LabelSmoothing Loss = 3.894974708557129\n",
      "[INFO: 2022-02-16 15:43:29,202] Iteration 3200 (DataTime/BatchTime: 0.00298/0.484) losses = 3.4867, lr = [1.4150974458495784e-05, 0.00014150974458495782]\n",
      "[INFO: 2022-02-16 15:43:29,203]   LabelSmoothing Loss = 4.403285980224609\n",
      "[INFO: 2022-02-16 15:43:38,861] Iteration 3220 (DataTime/BatchTime: 0.00226/0.483) losses = 3.33, lr = [1.4239362806144104e-05, 0.000142393628061441]\n",
      "[INFO: 2022-02-16 15:43:38,861]   LabelSmoothing Loss = 3.1085968017578125\n",
      "[INFO: 2022-02-16 15:43:48,381] Iteration 3240 (DataTime/BatchTime: 0.00325/0.476) losses = 3.2725, lr = [1.4327751153792421e-05, 0.0001432775115379242]\n",
      "[INFO: 2022-02-16 15:43:48,381]   LabelSmoothing Loss = 3.6139252185821533\n",
      "[INFO: 2022-02-16 15:43:57,928] Iteration 3260 (DataTime/BatchTime: 0.00254/0.477) losses = 2.9979, lr = [1.4416139501440739e-05, 0.00014416139501440738]\n",
      "[INFO: 2022-02-16 15:43:57,928]   LabelSmoothing Loss = 3.7557785511016846\n",
      "[INFO: 2022-02-16 15:44:07,492] Iteration 3280 (DataTime/BatchTime: 0.00405/0.478) losses = 3.2321, lr = [1.4504527849089057e-05, 0.00014504527849089056]\n",
      "[INFO: 2022-02-16 15:44:07,492]   LabelSmoothing Loss = 3.700885057449341\n",
      "[INFO: 2022-02-16 15:44:17,052] Iteration 3300 (DataTime/BatchTime: 0.00311/0.478) losses = 3.2311, lr = [1.4592916196737376e-05, 0.00014592916196737375]\n",
      "[INFO: 2022-02-16 15:44:17,052]   LabelSmoothing Loss = 3.8616347312927246\n",
      "[INFO: 2022-02-16 15:44:26,664] Iteration 3320 (DataTime/BatchTime: 0.00228/0.481) losses = 2.9792, lr = [1.4681304544385696e-05, 0.00014681304544385693]\n",
      "[INFO: 2022-02-16 15:44:26,664]   LabelSmoothing Loss = 3.0117602348327637\n",
      "[INFO: 2022-02-16 15:44:36,424] Iteration 3340 (DataTime/BatchTime: 0.0024/0.488) losses = 3.1959, lr = [1.4769692892034014e-05, 0.00014769692892034012]\n",
      "[INFO: 2022-02-16 15:44:36,425]   LabelSmoothing Loss = 4.595926761627197\n",
      "[INFO: 2022-02-16 15:44:46,121] Iteration 3360 (DataTime/BatchTime: 0.00136/0.485) losses = 3.5405, lr = [1.4858081239682332e-05, 0.0001485808123968233]\n",
      "[INFO: 2022-02-16 15:44:46,121]   LabelSmoothing Loss = 1.875379204750061\n",
      "[INFO: 2022-02-16 15:44:55,687] Iteration 3380 (DataTime/BatchTime: 0.00137/0.478) losses = 3.2613, lr = [1.4946469587330652e-05, 0.0001494646958733065]\n",
      "[INFO: 2022-02-16 15:44:55,687]   LabelSmoothing Loss = 2.8166584968566895\n",
      "[INFO: 2022-02-16 15:45:05,288] Iteration 3400 (DataTime/BatchTime: 0.00138/0.48) losses = 3.2828, lr = [1.5034857934978968e-05, 0.00015034857934978965]\n",
      "[INFO: 2022-02-16 15:45:05,288]   LabelSmoothing Loss = 2.9163577556610107\n",
      "[INFO: 2022-02-16 15:45:15,024] Iteration 3420 (DataTime/BatchTime: 0.0016/0.487) losses = 3.1688, lr = [1.5123246282627287e-05, 0.00015123246282627284]\n",
      "[INFO: 2022-02-16 15:45:15,024]   LabelSmoothing Loss = 2.8010220527648926\n",
      "[INFO: 2022-02-16 15:45:24,640] Iteration 3440 (DataTime/BatchTime: 0.00232/0.481) losses = 3.2969, lr = [1.5211634630275605e-05, 0.00015211634630275605]\n",
      "[INFO: 2022-02-16 15:45:24,640]   LabelSmoothing Loss = 2.6663074493408203\n",
      "[INFO: 2022-02-16 15:45:34,221] Iteration 3460 (DataTime/BatchTime: 0.0022/0.479) losses = 3.0504, lr = [1.5300022977923925e-05, 0.00015300022977923923]\n",
      "[INFO: 2022-02-16 15:45:34,221]   LabelSmoothing Loss = 1.5626585483551025\n",
      "[INFO: 2022-02-16 15:45:43,785] Iteration 3480 (DataTime/BatchTime: 0.00159/0.478) losses = 3.1449, lr = [1.538841132557224e-05, 0.00015388411325572242]\n",
      "[INFO: 2022-02-16 15:45:43,786]   LabelSmoothing Loss = 2.723240613937378\n",
      "[INFO: 2022-02-16 15:45:53,375] Iteration 3500 (DataTime/BatchTime: 0.00142/0.479) losses = 3.1263, lr = [1.547679967322056e-05, 0.0001547679967322056]\n",
      "[INFO: 2022-02-16 15:45:53,375]   LabelSmoothing Loss = 3.38700532913208\n",
      "[INFO: 2022-02-16 15:46:02,931] Iteration 3520 (DataTime/BatchTime: 0.00323/0.478) losses = 3.2625, lr = [1.556518802086888e-05, 0.0001556518802086888]\n",
      "[INFO: 2022-02-16 15:46:02,932]   LabelSmoothing Loss = 3.506176233291626\n",
      "[INFO: 2022-02-16 15:46:12,475] Iteration 3540 (DataTime/BatchTime: 0.00134/0.477) losses = 3.2755, lr = [1.5653576368517198e-05, 0.00015653576368517198]\n",
      "[INFO: 2022-02-16 15:46:12,475]   LabelSmoothing Loss = 2.942957878112793\n",
      "[INFO: 2022-02-16 15:46:21,976] Iteration 3560 (DataTime/BatchTime: 0.00228/0.475) losses = 2.9988, lr = [1.5741964716165514e-05, 0.00015741964716165514]\n",
      "[INFO: 2022-02-16 15:46:21,977]   LabelSmoothing Loss = 2.5502991676330566\n",
      "[INFO: 2022-02-16 15:46:31,515] Iteration 3580 (DataTime/BatchTime: 0.00138/0.477) losses = 3.1275, lr = [1.5830353063813834e-05, 0.00015830353063813832]\n",
      "[INFO: 2022-02-16 15:46:31,515]   LabelSmoothing Loss = 1.8312890529632568\n",
      "[INFO: 2022-02-16 15:46:41,146] Iteration 3600 (DataTime/BatchTime: 0.00139/0.482) losses = 3.434, lr = [1.5918741411462154e-05, 0.0001591874141146215]\n",
      "[INFO: 2022-02-16 15:46:41,146]   LabelSmoothing Loss = 3.261647939682007\n",
      "[INFO: 2022-02-16 15:46:50,768] Iteration 3620 (DataTime/BatchTime: 0.00235/0.481) losses = 3.0311, lr = [1.600712975911047e-05, 0.0001600712975911047]\n",
      "[INFO: 2022-02-16 15:46:50,769]   LabelSmoothing Loss = 2.4158143997192383\n",
      "[INFO: 2022-02-16 15:47:00,357] Iteration 3640 (DataTime/BatchTime: 0.00137/0.479) losses = 3.0511, lr = [1.609551810675879e-05, 0.00016095518106758788]\n",
      "[INFO: 2022-02-16 15:47:00,357]   LabelSmoothing Loss = 2.975607395172119\n",
      "[INFO: 2022-02-16 15:47:10,058] Iteration 3660 (DataTime/BatchTime: 0.00149/0.485) losses = 3.2204, lr = [1.618390645440711e-05, 0.00016183906454407106]\n",
      "[INFO: 2022-02-16 15:47:10,058]   LabelSmoothing Loss = 4.46067476272583\n",
      "[INFO: 2022-02-16 15:47:19,608] Iteration 3680 (DataTime/BatchTime: 0.00305/0.477) losses = 3.0874, lr = [1.6272294802055427e-05, 0.00016272294802055425]\n",
      "[INFO: 2022-02-16 15:47:19,608]   LabelSmoothing Loss = 3.1012775897979736\n",
      "[INFO: 2022-02-16 15:47:29,238] Iteration 3700 (DataTime/BatchTime: 0.00141/0.481) losses = 3.5294, lr = [1.6360683149703747e-05, 0.00016360683149703743]\n",
      "[INFO: 2022-02-16 15:47:29,238]   LabelSmoothing Loss = 4.263655662536621\n",
      "[INFO: 2022-02-16 15:47:38,858] Iteration 3720 (DataTime/BatchTime: 0.00262/0.481) losses = 3.0636, lr = [1.6449071497352067e-05, 0.00016449071497352062]\n",
      "[INFO: 2022-02-16 15:47:38,858]   LabelSmoothing Loss = 2.43918514251709\n",
      "[INFO: 2022-02-16 15:47:48,455] Iteration 3740 (DataTime/BatchTime: 0.00233/0.48) losses = 3.2879, lr = [1.6537459845000383e-05, 0.0001653745984500038]\n",
      "[INFO: 2022-02-16 15:47:48,455]   LabelSmoothing Loss = 3.6227355003356934\n",
      "[INFO: 2022-02-16 15:47:58,065] Iteration 3760 (DataTime/BatchTime: 0.00233/0.481) losses = 3.3934, lr = [1.66258481926487e-05, 0.000166258481926487]\n",
      "[INFO: 2022-02-16 15:47:58,066]   LabelSmoothing Loss = 3.0922350883483887\n",
      "[INFO: 2022-02-16 15:48:07,604] Iteration 3780 (DataTime/BatchTime: 0.00231/0.477) losses = 3.2527, lr = [1.671423654029702e-05, 0.00016714236540297018]\n",
      "[INFO: 2022-02-16 15:48:07,604]   LabelSmoothing Loss = 3.7322816848754883\n",
      "[INFO: 2022-02-16 15:48:17,102] Iteration 3800 (DataTime/BatchTime: 0.00249/0.474) losses = 3.1097, lr = [1.6802624887945336e-05, 0.00016802624887945336]\n",
      "[INFO: 2022-02-16 15:48:17,102]   LabelSmoothing Loss = 2.6288559436798096\n",
      "[INFO: 2022-02-16 15:51:58,120] ######## Epoch (VAL)4 ########\n",
      "[INFO: 2022-02-16 15:51:58,121] {'Bleu_1': 0.3457203437116007, 'Bleu_2': 0.23088231800161152, 'Bleu_3': 0.15901441350856216, 'Bleu_4': 0.10496710196918183, 'METEOR': 0.18527603919703475, 'ROUGE_L': 0.29995064570617586, 'CIDEr': 0.15816083158463248}\n",
      "[INFO: 2022-02-16 15:55:34,816] ######## Epoch (TEST)4 ########\n",
      "[INFO: 2022-02-16 15:55:34,816] {'Bleu_1': 0.34085432639645774, 'Bleu_2': 0.22460455820080721, 'Bleu_3': 0.1536284550218421, 'Bleu_4': 0.10193740516303954, 'METEOR': 0.17433906068098615, 'ROUGE_L': 0.2909439311019202, 'CIDEr': 0.17697559798446535}\n",
      "[INFO: 2022-02-16 15:55:36,502] Iteration 3820 (DataTime/BatchTime: 1.14/1.69) losses = 3.0029, lr = [1.6891013235593656e-05, 0.00016891013235593655]\n",
      "[INFO: 2022-02-16 15:55:36,502]   LabelSmoothing Loss = 3.0028631687164307\n",
      "[INFO: 2022-02-16 15:55:45,945] Iteration 3840 (DataTime/BatchTime: 0.00113/0.472) losses = 3.1424, lr = [1.6979401583241976e-05, 0.00016979401583241973]\n",
      "[INFO: 2022-02-16 15:55:45,945]   LabelSmoothing Loss = 2.41767954826355\n",
      "[INFO: 2022-02-16 15:55:55,399] Iteration 3860 (DataTime/BatchTime: 0.00237/0.473) losses = 3.1031, lr = [1.7067789930890293e-05, 0.00017067789930890292]\n",
      "[INFO: 2022-02-16 15:55:55,399]   LabelSmoothing Loss = 2.583298444747925\n",
      "[INFO: 2022-02-16 15:56:05,088] Iteration 3880 (DataTime/BatchTime: 0.00333/0.484) losses = 3.2144, lr = [1.7156178278538613e-05, 0.0001715617827853861]\n",
      "[INFO: 2022-02-16 15:56:05,088]   LabelSmoothing Loss = 3.8642919063568115\n",
      "[INFO: 2022-02-16 15:56:14,730] Iteration 3900 (DataTime/BatchTime: 0.00208/0.482) losses = 3.2627, lr = [1.724456662618693e-05, 0.00017244566626186926]\n",
      "[INFO: 2022-02-16 15:56:14,730]   LabelSmoothing Loss = 2.9100914001464844\n",
      "[INFO: 2022-02-16 15:56:24,259] Iteration 3920 (DataTime/BatchTime: 0.00307/0.476) losses = 3.1942, lr = [1.733295497383525e-05, 0.00017332954973835248]\n",
      "[INFO: 2022-02-16 15:56:24,260]   LabelSmoothing Loss = 3.723944902420044\n",
      "[INFO: 2022-02-16 15:56:33,827] Iteration 3940 (DataTime/BatchTime: 0.00219/0.478) losses = 3.0825, lr = [1.742134332148357e-05, 0.00017421343321483566]\n",
      "[INFO: 2022-02-16 15:56:33,850]   LabelSmoothing Loss = 2.38969349861145\n",
      "[INFO: 2022-02-16 15:56:43,365] Iteration 3960 (DataTime/BatchTime: 0.00331/0.477) losses = 3.2117, lr = [1.750973166913189e-05, 0.00017509731669131885]\n",
      "[INFO: 2022-02-16 15:56:43,365]   LabelSmoothing Loss = 3.111088752746582\n",
      "[INFO: 2022-02-16 15:56:52,934] Iteration 3980 (DataTime/BatchTime: 0.00216/0.478) losses = 3.0629, lr = [1.7598120016780202e-05, 0.000175981200167802]\n",
      "[INFO: 2022-02-16 15:56:52,934]   LabelSmoothing Loss = 2.527440309524536\n",
      "[INFO: 2022-02-16 15:57:02,533] Iteration 4000 (DataTime/BatchTime: 0.00288/0.48) losses = 3.2435, lr = [1.7686508364428522e-05, 0.0001768650836442852]\n",
      "[INFO: 2022-02-16 15:57:02,533]   LabelSmoothing Loss = 3.9852757453918457\n",
      "[INFO: 2022-02-16 15:57:12,036] Iteration 4020 (DataTime/BatchTime: 0.00127/0.475) losses = 3.0184, lr = [1.777489671207684e-05, 0.00017774896712076838]\n",
      "[INFO: 2022-02-16 15:57:12,036]   LabelSmoothing Loss = 2.7025516033172607\n",
      "[INFO: 2022-02-16 15:57:21,642] Iteration 4040 (DataTime/BatchTime: 0.00218/0.48) losses = 3.1471, lr = [1.7863285059725158e-05, 0.00017863285059725156]\n",
      "[INFO: 2022-02-16 15:57:21,642]   LabelSmoothing Loss = 3.868553638458252\n",
      "[INFO: 2022-02-16 15:57:31,160] Iteration 4060 (DataTime/BatchTime: 0.00131/0.476) losses = 3.1123, lr = [1.7951673407373478e-05, 0.00017951673407373475]\n",
      "[INFO: 2022-02-16 15:57:31,161]   LabelSmoothing Loss = 3.3393609523773193\n",
      "[INFO: 2022-02-16 15:57:40,725] Iteration 4080 (DataTime/BatchTime: 0.00128/0.478) losses = 3.168, lr = [1.8040061755021795e-05, 0.00018040061755021793]\n",
      "[INFO: 2022-02-16 15:57:40,725]   LabelSmoothing Loss = 3.3440282344818115\n",
      "[INFO: 2022-02-16 15:57:50,261] Iteration 4100 (DataTime/BatchTime: 0.00222/0.477) losses = 2.996, lr = [1.8128450102670115e-05, 0.00018128450102670112]\n",
      "[INFO: 2022-02-16 15:57:50,261]   LabelSmoothing Loss = 2.5938329696655273\n",
      "[INFO: 2022-02-16 15:57:59,801] Iteration 4120 (DataTime/BatchTime: 0.00133/0.477) losses = 3.1331, lr = [1.8216838450318435e-05, 0.0001821683845031843]\n",
      "[INFO: 2022-02-16 15:57:59,802]   LabelSmoothing Loss = 3.415762424468994\n",
      "[INFO: 2022-02-16 15:58:09,438] Iteration 4140 (DataTime/BatchTime: 0.00144/0.482) losses = 2.8706, lr = [1.830522679796675e-05, 0.0001830522679796675]\n",
      "[INFO: 2022-02-16 15:58:09,439]   LabelSmoothing Loss = 2.735407829284668\n",
      "[INFO: 2022-02-16 15:58:18,928] Iteration 4160 (DataTime/BatchTime: 0.00215/0.474) losses = 3.1474, lr = [1.839361514561507e-05, 0.00018393615145615068]\n",
      "[INFO: 2022-02-16 15:58:18,928]   LabelSmoothing Loss = 3.23000431060791\n",
      "[INFO: 2022-02-16 15:58:28,474] Iteration 4180 (DataTime/BatchTime: 0.00129/0.477) losses = 3.1313, lr = [1.8482003493263388e-05, 0.00018482003493263386]\n",
      "[INFO: 2022-02-16 15:58:28,474]   LabelSmoothing Loss = 3.156125783920288\n",
      "[INFO: 2022-02-16 15:58:38,035] Iteration 4200 (DataTime/BatchTime: 0.00128/0.478) losses = 3.3167, lr = [1.8570391840911707e-05, 0.00018570391840911705]\n",
      "[INFO: 2022-02-16 15:58:38,035]   LabelSmoothing Loss = 3.0140743255615234\n",
      "[INFO: 2022-02-16 15:58:47,521] Iteration 4220 (DataTime/BatchTime: 0.00131/0.474) losses = 3.1081, lr = [1.8658780188560027e-05, 0.00018658780188560023]\n",
      "[INFO: 2022-02-16 15:58:47,521]   LabelSmoothing Loss = 3.709200620651245\n",
      "[INFO: 2022-02-16 15:58:57,139] Iteration 4240 (DataTime/BatchTime: 0.00131/0.481) losses = 3.1754, lr = [1.8747168536208344e-05, 0.00018747168536208342]\n",
      "[INFO: 2022-02-16 15:58:57,139]   LabelSmoothing Loss = 2.5699069499969482\n",
      "[INFO: 2022-02-16 15:59:06,672] Iteration 4260 (DataTime/BatchTime: 0.00229/0.477) losses = 3.0824, lr = [1.8835556883856664e-05, 0.0001883555688385666]\n",
      "[INFO: 2022-02-16 15:59:06,672]   LabelSmoothing Loss = 2.9499974250793457\n",
      "[INFO: 2022-02-16 15:59:16,308] Iteration 4280 (DataTime/BatchTime: 0.0013/0.482) losses = 3.1937, lr = [1.8923945231504984e-05, 0.00018923945231504982]\n",
      "[INFO: 2022-02-16 15:59:16,308]   LabelSmoothing Loss = 2.9779393672943115\n",
      "[INFO: 2022-02-16 15:59:25,811] Iteration 4300 (DataTime/BatchTime: 0.00129/0.475) losses = 3.0971, lr = [1.9012333579153297e-05, 0.00019012333579153295]\n",
      "[INFO: 2022-02-16 15:59:25,812]   LabelSmoothing Loss = 4.0299177169799805\n",
      "[INFO: 2022-02-16 15:59:35,446] Iteration 4320 (DataTime/BatchTime: 0.00129/0.482) losses = 3.0799, lr = [1.9100721926801617e-05, 0.00019100721926801613]\n",
      "[INFO: 2022-02-16 15:59:35,446]   LabelSmoothing Loss = 2.779228925704956\n",
      "[INFO: 2022-02-16 15:59:45,213] Iteration 4340 (DataTime/BatchTime: 0.00244/0.488) losses = 2.9192, lr = [1.9189110274449933e-05, 0.00019189110274449932]\n",
      "[INFO: 2022-02-16 15:59:45,214]   LabelSmoothing Loss = 3.3365049362182617\n",
      "[INFO: 2022-02-16 15:59:54,821] Iteration 4360 (DataTime/BatchTime: 0.00138/0.48) losses = 3.0439, lr = [1.9277498622098253e-05, 0.0001927749862209825]\n",
      "[INFO: 2022-02-16 15:59:54,822]   LabelSmoothing Loss = 3.3384816646575928\n",
      "[INFO: 2022-02-16 16:00:04,366] Iteration 4380 (DataTime/BatchTime: 0.00124/0.477) losses = 3.2352, lr = [1.9365886969746573e-05, 0.0001936588696974657]\n",
      "[INFO: 2022-02-16 16:00:04,366]   LabelSmoothing Loss = 3.531930685043335\n",
      "[INFO: 2022-02-16 16:00:13,906] Iteration 4400 (DataTime/BatchTime: 0.00214/0.477) losses = 3.1252, lr = [1.945427531739489e-05, 0.00019454275317394888]\n",
      "[INFO: 2022-02-16 16:00:13,906]   LabelSmoothing Loss = 3.4192938804626465\n",
      "[INFO: 2022-02-16 16:00:23,461] Iteration 4420 (DataTime/BatchTime: 0.0025/0.478) losses = 3.1926, lr = [1.954266366504321e-05, 0.00019542663665043206]\n",
      "[INFO: 2022-02-16 16:00:23,461]   LabelSmoothing Loss = 2.8067269325256348\n",
      "[INFO: 2022-02-16 16:00:33,002] Iteration 4440 (DataTime/BatchTime: 0.0031/0.477) losses = 3.0117, lr = [1.963105201269153e-05, 0.00019631052012691525]\n",
      "[INFO: 2022-02-16 16:00:33,002]   LabelSmoothing Loss = 2.3837974071502686\n",
      "[INFO: 2022-02-16 16:00:42,519] Iteration 4460 (DataTime/BatchTime: 0.00212/0.476) losses = 3.1207, lr = [1.9719440360339846e-05, 0.00019719440360339843]\n",
      "[INFO: 2022-02-16 16:00:42,520]   LabelSmoothing Loss = 2.0411031246185303\n",
      "[INFO: 2022-02-16 16:00:52,122] Iteration 4480 (DataTime/BatchTime: 0.00218/0.48) losses = 2.8964, lr = [1.9807828707988166e-05, 0.00019807828707988165]\n",
      "[INFO: 2022-02-16 16:00:52,122]   LabelSmoothing Loss = 4.052136421203613\n",
      "[INFO: 2022-02-16 16:01:01,699] Iteration 4500 (DataTime/BatchTime: 0.0013/0.479) losses = 3.4207, lr = [1.9896217055636486e-05, 0.00019896217055636483]\n",
      "[INFO: 2022-02-16 16:01:01,699]   LabelSmoothing Loss = 3.879138469696045\n",
      "[INFO: 2022-02-16 16:01:11,279] Iteration 4520 (DataTime/BatchTime: 0.0029/0.479) losses = 2.7102, lr = [1.9984605403284802e-05, 0.00019984605403284802]\n",
      "[INFO: 2022-02-16 16:01:11,279]   LabelSmoothing Loss = 2.57523775100708\n",
      "[INFO: 2022-02-16 16:01:20,859] Iteration 4540 (DataTime/BatchTime: 0.00127/0.479) losses = 3.0175, lr = [2.0072993750933122e-05, 0.0002007299375093312]\n",
      "[INFO: 2022-02-16 16:01:20,860]   LabelSmoothing Loss = 2.7389187812805176\n",
      "[INFO: 2022-02-16 16:01:30,427] Iteration 4560 (DataTime/BatchTime: 0.00131/0.478) losses = 2.94, lr = [2.016138209858144e-05, 0.0002016138209858144]\n",
      "[INFO: 2022-02-16 16:01:30,427]   LabelSmoothing Loss = 3.2591209411621094\n",
      "[INFO: 2022-02-16 16:01:39,973] Iteration 4580 (DataTime/BatchTime: 0.00128/0.477) losses = 3.0969, lr = [2.024977044622976e-05, 0.00020249770446229757]\n",
      "[INFO: 2022-02-16 16:01:39,973]   LabelSmoothing Loss = 4.1078643798828125\n",
      "[INFO: 2022-02-16 16:01:49,589] Iteration 4600 (DataTime/BatchTime: 0.00133/0.481) losses = 2.9691, lr = [2.033815879387808e-05, 0.00020338158793878076]\n",
      "[INFO: 2022-02-16 16:01:49,589]   LabelSmoothing Loss = 2.1097190380096436\n",
      "[INFO: 2022-02-16 16:01:59,183] Iteration 4620 (DataTime/BatchTime: 0.00132/0.48) losses = 2.979, lr = [2.0426547141526392e-05, 0.0002042654714152639]\n",
      "[INFO: 2022-02-16 16:01:59,184]   LabelSmoothing Loss = 3.0093636512756348\n",
      "[INFO: 2022-02-16 16:02:08,688] Iteration 4640 (DataTime/BatchTime: 0.0021/0.475) losses = 3.1771, lr = [2.0514935489174712e-05, 0.00020514935489174708]\n",
      "[INFO: 2022-02-16 16:02:08,689]   LabelSmoothing Loss = 2.2966411113739014\n",
      "[INFO: 2022-02-16 16:02:18,309] Iteration 4660 (DataTime/BatchTime: 0.0013/0.481) losses = 3.1462, lr = [2.060332383682303e-05, 0.0002060332383682303]\n",
      "[INFO: 2022-02-16 16:02:18,309]   LabelSmoothing Loss = 3.227713108062744\n",
      "[INFO: 2022-02-16 16:02:27,856] Iteration 4680 (DataTime/BatchTime: 0.00211/0.477) losses = 2.9739, lr = [2.0691712184471348e-05, 0.00020691712184471348]\n",
      "[INFO: 2022-02-16 16:02:27,856]   LabelSmoothing Loss = 3.563966989517212\n",
      "[INFO: 2022-02-16 16:02:37,379] Iteration 4700 (DataTime/BatchTime: 0.00207/0.476) losses = 2.9735, lr = [2.0780100532119668e-05, 0.00020780100532119666]\n",
      "[INFO: 2022-02-16 16:02:37,379]   LabelSmoothing Loss = 3.6548683643341064\n",
      "[INFO: 2022-02-16 16:02:46,932] Iteration 4720 (DataTime/BatchTime: 0.00166/0.478) losses = 3.0635, lr = [2.0868488879767985e-05, 0.00020868488879767985]\n",
      "[INFO: 2022-02-16 16:02:46,932]   LabelSmoothing Loss = 3.1441078186035156\n",
      "[INFO: 2022-02-16 16:02:56,545] Iteration 4740 (DataTime/BatchTime: 0.00128/0.481) losses = 2.9636, lr = [2.0956877227416305e-05, 0.00020956877227416303]\n",
      "[INFO: 2022-02-16 16:02:56,545]   LabelSmoothing Loss = 3.292285680770874\n",
      "[INFO: 2022-02-16 16:03:06,294] Iteration 4760 (DataTime/BatchTime: 0.00151/0.487) losses = 2.8639, lr = [2.1045265575064624e-05, 0.00021045265575064622]\n",
      "[INFO: 2022-02-16 16:03:06,294]   LabelSmoothing Loss = 3.067974328994751\n",
      "[INFO: 2022-02-16 16:06:45,039] ######## Epoch (VAL)5 ########\n",
      "[INFO: 2022-02-16 16:06:45,039] {'Bleu_1': 0.39030345826915486, 'Bleu_2': 0.2591248172813358, 'Bleu_3': 0.17566854044793923, 'Bleu_4': 0.11637108499867088, 'METEOR': 0.19144645288716286, 'ROUGE_L': 0.33135292836041086, 'CIDEr': 0.23135928710403342}\n",
      "[INFO: 2022-02-16 16:10:24,285] ######## Epoch (TEST)5 ########\n",
      "[INFO: 2022-02-16 16:10:24,285] {'Bleu_1': 0.3680644483094619, 'Bleu_2': 0.24385228584364407, 'Bleu_3': 0.16664479717593889, 'Bleu_4': 0.11132765886952835, 'METEOR': 0.18039774971743303, 'ROUGE_L': 0.32054140667665165, 'CIDEr': 0.2537625409708473}\n",
      "[INFO: 2022-02-16 16:10:28,279] Iteration 4780 (DataTime/BatchTime: 0.164/0.666) losses = 3.1075, lr = [2.113365392271294e-05, 0.0002113365392271294]\n",
      "[INFO: 2022-02-16 16:10:28,280]   LabelSmoothing Loss = 2.6871540546417236\n",
      "[INFO: 2022-02-16 16:10:37,987] Iteration 4800 (DataTime/BatchTime: 0.00139/0.485) losses = 2.9895, lr = [2.122204227036126e-05, 0.0002122204227036126]\n",
      "[INFO: 2022-02-16 16:10:37,987]   LabelSmoothing Loss = 2.77036452293396\n",
      "[INFO: 2022-02-16 16:10:47,596] Iteration 4820 (DataTime/BatchTime: 0.00132/0.48) losses = 3.0329, lr = [2.131043061800958e-05, 0.00021310430618009577]\n",
      "[INFO: 2022-02-16 16:10:47,596]   LabelSmoothing Loss = 2.504862070083618\n",
      "[INFO: 2022-02-16 16:10:57,305] Iteration 4840 (DataTime/BatchTime: 0.00514/0.486) losses = 3.2241, lr = [2.1398818965657897e-05, 0.00021398818965657896]\n",
      "[INFO: 2022-02-16 16:10:57,305]   LabelSmoothing Loss = 3.4920108318328857\n",
      "[INFO: 2022-02-16 16:11:06,951] Iteration 4860 (DataTime/BatchTime: 0.00348/0.482) losses = 3.0033, lr = [2.1487207313306217e-05, 0.00021487207313306215]\n",
      "[INFO: 2022-02-16 16:11:06,951]   LabelSmoothing Loss = 2.1619629859924316\n",
      "[INFO: 2022-02-16 16:11:16,536] Iteration 4880 (DataTime/BatchTime: 0.00266/0.479) losses = 2.9968, lr = [2.1575595660954537e-05, 0.00021575595660954533]\n",
      "[INFO: 2022-02-16 16:11:16,537]   LabelSmoothing Loss = 2.721367120742798\n",
      "[INFO: 2022-02-16 16:11:26,132] Iteration 4900 (DataTime/BatchTime: 0.00428/0.48) losses = 2.7403, lr = [2.1663984008602854e-05, 0.00021663984008602852]\n",
      "[INFO: 2022-02-16 16:11:26,132]   LabelSmoothing Loss = 2.3172245025634766\n",
      "[INFO: 2022-02-16 16:11:35,912] Iteration 4920 (DataTime/BatchTime: 0.00329/0.489) losses = 3.025, lr = [2.1752372356251174e-05, 0.0002175237235625117]\n",
      "[INFO: 2022-02-16 16:11:35,912]   LabelSmoothing Loss = 3.385585308074951\n",
      "[INFO: 2022-02-16 16:11:45,693] Iteration 4940 (DataTime/BatchTime: 0.00146/0.489) losses = 3.0364, lr = [2.1840760703899487e-05, 0.00021840760703899486]\n",
      "[INFO: 2022-02-16 16:11:45,694]   LabelSmoothing Loss = 3.19590163230896\n",
      "[INFO: 2022-02-16 16:11:55,197] Iteration 4960 (DataTime/BatchTime: 0.00227/0.475) losses = 3.0869, lr = [2.1929149051547807e-05, 0.00021929149051547805]\n",
      "[INFO: 2022-02-16 16:11:55,198]   LabelSmoothing Loss = 3.4814937114715576\n",
      "[INFO: 2022-02-16 16:12:04,877] Iteration 4980 (DataTime/BatchTime: 0.00243/0.484) losses = 2.7642, lr = [2.2017537399196127e-05, 0.00022017537399196123]\n",
      "[INFO: 2022-02-16 16:12:04,877]   LabelSmoothing Loss = 2.2879478931427\n",
      "[INFO: 2022-02-16 16:12:14,458] Iteration 5000 (DataTime/BatchTime: 0.00131/0.479) losses = 2.7944, lr = [2.2105925746844443e-05, 0.00022105925746844442]\n",
      "[INFO: 2022-02-16 16:12:14,458]   LabelSmoothing Loss = 1.3753520250320435\n",
      "[INFO: 2022-02-16 16:12:23,965] Iteration 5020 (DataTime/BatchTime: 0.0023/0.475) losses = 3.0352, lr = [2.2194314094492763e-05, 0.0002219431409449276]\n",
      "[INFO: 2022-02-16 16:12:23,965]   LabelSmoothing Loss = 3.9355833530426025\n",
      "[INFO: 2022-02-16 16:12:33,585] Iteration 5040 (DataTime/BatchTime: 0.00362/0.481) losses = 3.0758, lr = [2.2282702442141083e-05, 0.0002228270244214108]\n",
      "[INFO: 2022-02-16 16:12:33,585]   LabelSmoothing Loss = 3.3131933212280273\n",
      "[INFO: 2022-02-16 16:12:43,198] Iteration 5060 (DataTime/BatchTime: 0.00323/0.481) losses = 2.8166, lr = [2.23710907897894e-05, 0.00022371090789789397]\n",
      "[INFO: 2022-02-16 16:12:43,199]   LabelSmoothing Loss = 2.478614091873169\n",
      "[INFO: 2022-02-16 16:12:52,734] Iteration 5080 (DataTime/BatchTime: 0.00375/0.477) losses = 2.9403, lr = [2.245947913743772e-05, 0.00022459479137437716]\n",
      "[INFO: 2022-02-16 16:12:52,734]   LabelSmoothing Loss = 3.3189587593078613\n",
      "[INFO: 2022-02-16 16:13:02,243] Iteration 5100 (DataTime/BatchTime: 0.00213/0.475) losses = 2.9022, lr = [2.2547867485086036e-05, 0.00022547867485086035]\n",
      "[INFO: 2022-02-16 16:13:02,243]   LabelSmoothing Loss = 2.0092267990112305\n",
      "[INFO: 2022-02-16 16:13:11,749] Iteration 5120 (DataTime/BatchTime: 0.00196/0.475) losses = 2.9228, lr = [2.2636255832734356e-05, 0.00022636255832734353]\n",
      "[INFO: 2022-02-16 16:13:11,749]   LabelSmoothing Loss = 2.813471794128418\n",
      "[INFO: 2022-02-16 16:13:21,319] Iteration 5140 (DataTime/BatchTime: 0.00316/0.479) losses = 2.802, lr = [2.2724644180382676e-05, 0.00022724644180382672]\n",
      "[INFO: 2022-02-16 16:13:21,320]   LabelSmoothing Loss = 3.4204623699188232\n",
      "[INFO: 2022-02-16 16:13:30,893] Iteration 5160 (DataTime/BatchTime: 0.00386/0.479) losses = 2.8119, lr = [2.2813032528030992e-05, 0.0002281303252803099]\n",
      "[INFO: 2022-02-16 16:13:30,894]   LabelSmoothing Loss = 2.4017999172210693\n",
      "[INFO: 2022-02-16 16:13:40,359] Iteration 5180 (DataTime/BatchTime: 0.00115/0.473) losses = 2.9298, lr = [2.2901420875679312e-05, 0.0002290142087567931]\n",
      "[INFO: 2022-02-16 16:13:40,359]   LabelSmoothing Loss = 2.6983070373535156\n",
      "[INFO: 2022-02-16 16:13:49,966] Iteration 5200 (DataTime/BatchTime: 0.00108/0.48) losses = 3.1044, lr = [2.2989809223327632e-05, 0.00022989809223327627]\n",
      "[INFO: 2022-02-16 16:13:49,966]   LabelSmoothing Loss = 2.06585955619812\n",
      "[INFO: 2022-02-16 16:13:59,421] Iteration 5220 (DataTime/BatchTime: 0.0019/0.473) losses = 2.8944, lr = [2.307819757097595e-05, 0.00023078197570975946]\n",
      "[INFO: 2022-02-16 16:13:59,422]   LabelSmoothing Loss = 3.328137159347534\n",
      "[INFO: 2022-02-16 16:14:08,868] Iteration 5240 (DataTime/BatchTime: 0.00105/0.472) losses = 3.0534, lr = [2.316658591862427e-05, 0.00023166585918624265]\n",
      "[INFO: 2022-02-16 16:14:08,868]   LabelSmoothing Loss = 2.570061445236206\n",
      "[INFO: 2022-02-16 16:14:18,427] Iteration 5260 (DataTime/BatchTime: 0.00117/0.478) losses = 2.8397, lr = [2.325497426627259e-05, 0.00023254974266272583]\n",
      "[INFO: 2022-02-16 16:14:18,427]   LabelSmoothing Loss = 2.675884246826172\n",
      "[INFO: 2022-02-16 16:14:27,980] Iteration 5280 (DataTime/BatchTime: 0.00233/0.478) losses = 2.6868, lr = [2.33433626139209e-05, 0.000233433626139209]\n",
      "[INFO: 2022-02-16 16:14:27,980]   LabelSmoothing Loss = 3.089635133743286\n",
      "[INFO: 2022-02-16 16:14:37,505] Iteration 5300 (DataTime/BatchTime: 0.00122/0.476) losses = 2.9091, lr = [2.343175096156922e-05, 0.00023431750961569217]\n",
      "[INFO: 2022-02-16 16:14:37,505]   LabelSmoothing Loss = 2.0580055713653564\n",
      "[INFO: 2022-02-16 16:14:46,989] Iteration 5320 (DataTime/BatchTime: 0.0012/0.474) losses = 2.7834, lr = [2.3520139309217538e-05, 0.00023520139309217536]\n",
      "[INFO: 2022-02-16 16:14:46,989]   LabelSmoothing Loss = 2.8194899559020996\n",
      "[INFO: 2022-02-16 16:14:56,616] Iteration 5340 (DataTime/BatchTime: 0.00126/0.481) losses = 3.0767, lr = [2.3608527656865858e-05, 0.00023608527656865855]\n",
      "[INFO: 2022-02-16 16:14:56,616]   LabelSmoothing Loss = 4.281657695770264\n",
      "[INFO: 2022-02-16 16:15:06,124] Iteration 5360 (DataTime/BatchTime: 0.00163/0.475) losses = 2.8859, lr = [2.3696916004514178e-05, 0.00023696916004514173]\n",
      "[INFO: 2022-02-16 16:15:06,124]   LabelSmoothing Loss = 2.260965347290039\n",
      "[INFO: 2022-02-16 16:15:15,713] Iteration 5380 (DataTime/BatchTime: 0.00128/0.479) losses = 3.0848, lr = [2.3785304352162494e-05, 0.00023785304352162492]\n",
      "[INFO: 2022-02-16 16:15:15,713]   LabelSmoothing Loss = 3.8283846378326416\n",
      "[INFO: 2022-02-16 16:15:25,270] Iteration 5400 (DataTime/BatchTime: 0.00385/0.478) losses = 3.0074, lr = [2.3873692699810814e-05, 0.0002387369269981081]\n",
      "[INFO: 2022-02-16 16:15:25,270]   LabelSmoothing Loss = 3.123328685760498\n",
      "[INFO: 2022-02-16 16:15:34,975] Iteration 5420 (DataTime/BatchTime: 0.00306/0.485) losses = 3.0627, lr = [2.396208104745913e-05, 0.0002396208104745913]\n",
      "[INFO: 2022-02-16 16:15:34,975]   LabelSmoothing Loss = 3.8246910572052\n",
      "[INFO: 2022-02-16 16:15:44,640] Iteration 5440 (DataTime/BatchTime: 0.0022/0.483) losses = 3.0221, lr = [2.405046939510745e-05, 0.00024050469395107447]\n",
      "[INFO: 2022-02-16 16:15:44,640]   LabelSmoothing Loss = 3.20628023147583\n",
      "[INFO: 2022-02-16 16:15:54,221] Iteration 5460 (DataTime/BatchTime: 0.00133/0.479) losses = 2.9401, lr = [2.413885774275577e-05, 0.00024138857742755766]\n",
      "[INFO: 2022-02-16 16:15:54,221]   LabelSmoothing Loss = 1.9412715435028076\n",
      "[INFO: 2022-02-16 16:16:03,713] Iteration 5480 (DataTime/BatchTime: 0.0013/0.475) losses = 2.8565, lr = [2.4227246090404087e-05, 0.00024227246090404085]\n",
      "[INFO: 2022-02-16 16:16:03,713]   LabelSmoothing Loss = 3.696598529815674\n",
      "[INFO: 2022-02-16 16:16:13,338] Iteration 5500 (DataTime/BatchTime: 0.00129/0.481) losses = 3.0125, lr = [2.4315634438052407e-05, 0.00024315634438052403]\n",
      "[INFO: 2022-02-16 16:16:13,338]   LabelSmoothing Loss = 3.5627410411834717\n",
      "[INFO: 2022-02-16 16:16:22,903] Iteration 5520 (DataTime/BatchTime: 0.00126/0.478) losses = 3.1686, lr = [2.4404022785700727e-05, 0.00024404022785700724]\n",
      "[INFO: 2022-02-16 16:16:22,903]   LabelSmoothing Loss = 2.3058342933654785\n",
      "[INFO: 2022-02-16 16:16:32,455] Iteration 5540 (DataTime/BatchTime: 0.00127/0.478) losses = 2.7783, lr = [2.4492411133349044e-05, 0.00024492411133349043]\n",
      "[INFO: 2022-02-16 16:16:32,455]   LabelSmoothing Loss = 2.272197961807251\n",
      "[INFO: 2022-02-16 16:16:41,990] Iteration 5560 (DataTime/BatchTime: 0.00134/0.476) losses = 2.8815, lr = [2.4580799480997364e-05, 0.0002458079948099736]\n",
      "[INFO: 2022-02-16 16:16:41,991]   LabelSmoothing Loss = 3.019794225692749\n",
      "[INFO: 2022-02-16 16:16:51,705] Iteration 5580 (DataTime/BatchTime: 0.00443/0.487) losses = 2.9828, lr = [2.4669187828645683e-05, 0.0002466918782864568]\n",
      "[INFO: 2022-02-16 16:16:51,705]   LabelSmoothing Loss = 2.9237890243530273\n",
      "[INFO: 2022-02-16 16:17:01,414] Iteration 5600 (DataTime/BatchTime: 0.00144/0.485) losses = 2.9182, lr = [2.4757576176293997e-05, 0.00024757576176293993]\n",
      "[INFO: 2022-02-16 16:17:01,415]   LabelSmoothing Loss = 2.7608120441436768\n",
      "[INFO: 2022-02-16 16:17:11,038] Iteration 5620 (DataTime/BatchTime: 0.00441/0.481) losses = 2.8754, lr = [2.4845964523942316e-05, 0.0002484596452394231]\n",
      "[INFO: 2022-02-16 16:17:11,039]   LabelSmoothing Loss = 2.0393097400665283\n",
      "[INFO: 2022-02-16 16:17:20,635] Iteration 5640 (DataTime/BatchTime: 0.00143/0.48) losses = 2.855, lr = [2.4934352871590633e-05, 0.0002493435287159063]\n",
      "[INFO: 2022-02-16 16:17:20,636]   LabelSmoothing Loss = 1.626598596572876\n",
      "[INFO: 2022-02-16 16:17:30,208] Iteration 5660 (DataTime/BatchTime: 0.00323/0.479) losses = 2.9338, lr = [2.5022741219238953e-05, 0.0002502274121923895]\n",
      "[INFO: 2022-02-16 16:17:30,208]   LabelSmoothing Loss = 3.6312108039855957\n",
      "[INFO: 2022-02-16 16:17:39,861] Iteration 5680 (DataTime/BatchTime: 0.0024/0.483) losses = 2.8223, lr = [2.5111129566887273e-05, 0.0002511112956688727]\n",
      "[INFO: 2022-02-16 16:17:39,861]   LabelSmoothing Loss = 2.25593900680542\n",
      "[INFO: 2022-02-16 16:17:49,477] Iteration 5700 (DataTime/BatchTime: 0.00138/0.481) losses = 3.0403, lr = [2.519951791453559e-05, 0.00025199517914535586]\n",
      "[INFO: 2022-02-16 16:17:49,477]   LabelSmoothing Loss = 4.215945243835449\n",
      "[INFO: 2022-02-16 16:17:59,136] Iteration 5720 (DataTime/BatchTime: 0.00439/0.483) losses = 3.1026, lr = [2.528790626218391e-05, 0.00025287906262183905]\n",
      "[INFO: 2022-02-16 16:17:59,136]   LabelSmoothing Loss = 2.362861394882202\n",
      "[INFO: 2022-02-16 16:21:35,887] ######## Epoch (VAL)6 ########\n",
      "[INFO: 2022-02-16 16:21:35,887] {'Bleu_1': 0.32051874928487445, 'Bleu_2': 0.21748120436163404, 'Bleu_3': 0.14781147366682343, 'Bleu_4': 0.0978908966596941, 'METEOR': 0.17524307109288323, 'ROUGE_L': 0.340375952055344, 'CIDEr': 0.21755164201905738}\n",
      "[INFO: 2022-02-16 16:25:13,570] ######## Epoch (TEST)6 ########\n",
      "[INFO: 2022-02-16 16:25:13,571] {'Bleu_1': 0.29655632610832455, 'Bleu_2': 0.19887097543157928, 'Bleu_3': 0.13462901965082344, 'Bleu_4': 0.09071897479752747, 'METEOR': 0.16572124898504756, 'ROUGE_L': 0.31730771317758366, 'CIDEr': 0.23765886592249547}\n",
      "[INFO: 2022-02-16 16:25:19,847] Iteration 5740 (DataTime/BatchTime: 0.0861/0.57) losses = 3.2506, lr = [2.537629460983223e-05, 0.00025376294609832223]\n",
      "[INFO: 2022-02-16 16:25:19,847]   LabelSmoothing Loss = 3.16939115524292\n",
      "[INFO: 2022-02-16 16:25:29,416] Iteration 5760 (DataTime/BatchTime: 0.00129/0.478) losses = 3.2162, lr = [2.5464682957480546e-05, 0.0002546468295748054]\n",
      "[INFO: 2022-02-16 16:25:29,416]   LabelSmoothing Loss = 2.779269218444824\n",
      "[INFO: 2022-02-16 16:25:38,746] Iteration 5780 (DataTime/BatchTime: 0.00202/0.466) losses = 2.9002, lr = [2.5553071305128866e-05, 0.0002555307130512886]\n",
      "[INFO: 2022-02-16 16:25:38,746]   LabelSmoothing Loss = 3.0549426078796387\n",
      "[INFO: 2022-02-16 16:25:48,157] Iteration 5800 (DataTime/BatchTime: 0.002/0.471) losses = 3.0099, lr = [2.5641459652777182e-05, 0.0002564145965277718]\n",
      "[INFO: 2022-02-16 16:25:48,157]   LabelSmoothing Loss = 3.597712516784668\n",
      "[INFO: 2022-02-16 16:25:57,696] Iteration 5820 (DataTime/BatchTime: 0.0036/0.477) losses = 2.7655, lr = [2.5729848000425502e-05, 0.000257298480004255]\n",
      "[INFO: 2022-02-16 16:25:57,697]   LabelSmoothing Loss = 4.073167324066162\n",
      "[INFO: 2022-02-16 16:26:07,308] Iteration 5840 (DataTime/BatchTime: 0.00206/0.481) losses = 2.9437, lr = [2.5818236348073822e-05, 0.00025818236348073816]\n",
      "[INFO: 2022-02-16 16:26:07,309]   LabelSmoothing Loss = 3.7858383655548096\n",
      "[INFO: 2022-02-16 16:26:16,795] Iteration 5860 (DataTime/BatchTime: 0.00121/0.474) losses = 2.6982, lr = [2.590662469572214e-05, 0.00025906624695722134]\n",
      "[INFO: 2022-02-16 16:26:16,795]   LabelSmoothing Loss = 3.1317825317382812\n",
      "[INFO: 2022-02-16 16:26:26,210] Iteration 5880 (DataTime/BatchTime: 0.00121/0.471) losses = 2.9346, lr = [2.599501304337046e-05, 0.00025995013043370453]\n",
      "[INFO: 2022-02-16 16:26:26,211]   LabelSmoothing Loss = 2.973461866378784\n",
      "[INFO: 2022-02-16 16:26:35,721] Iteration 5900 (DataTime/BatchTime: 0.00241/0.476) losses = 2.7274, lr = [2.608340139101878e-05, 0.0002608340139101877]\n",
      "[INFO: 2022-02-16 16:26:35,721]   LabelSmoothing Loss = 2.856247901916504\n",
      "[INFO: 2022-02-16 16:26:45,206] Iteration 5920 (DataTime/BatchTime: 0.00187/0.474) losses = 2.9275, lr = [2.617178973866709e-05, 0.0002617178973866709]\n",
      "[INFO: 2022-02-16 16:26:45,207]   LabelSmoothing Loss = 2.986046314239502\n",
      "[INFO: 2022-02-16 16:26:54,669] Iteration 5940 (DataTime/BatchTime: 0.00218/0.473) losses = 2.8578, lr = [2.626017808631541e-05, 0.0002626017808631541]\n",
      "[INFO: 2022-02-16 16:26:54,670]   LabelSmoothing Loss = 3.0200276374816895\n",
      "[INFO: 2022-02-16 16:27:04,251] Iteration 5960 (DataTime/BatchTime: 0.00124/0.479) losses = 2.7327, lr = [2.6348566433963728e-05, 0.00026348566433963727]\n",
      "[INFO: 2022-02-16 16:27:04,251]   LabelSmoothing Loss = 3.2014644145965576\n",
      "[INFO: 2022-02-16 16:27:13,725] Iteration 5980 (DataTime/BatchTime: 0.00117/0.474) losses = 2.7962, lr = [2.6436954781612048e-05, 0.00026436954781612046]\n",
      "[INFO: 2022-02-16 16:27:13,725]   LabelSmoothing Loss = 2.6613998413085938\n",
      "[INFO: 2022-02-16 16:27:23,153] Iteration 6000 (DataTime/BatchTime: 0.00124/0.471) losses = 2.9039, lr = [2.6525343129260368e-05, 0.00026525343129260364]\n",
      "[INFO: 2022-02-16 16:27:23,153]   LabelSmoothing Loss = 2.704866886138916\n",
      "[INFO: 2022-02-16 16:27:32,660] Iteration 6020 (DataTime/BatchTime: 0.00219/0.475) losses = 2.9067, lr = [2.6613731476908684e-05, 0.00026613731476908683]\n",
      "[INFO: 2022-02-16 16:27:32,661]   LabelSmoothing Loss = 2.6576285362243652\n",
      "[INFO: 2022-02-16 16:27:42,037] Iteration 6040 (DataTime/BatchTime: 0.00113/0.469) losses = 2.7702, lr = [2.6702119824557004e-05, 0.00026702119824557]\n",
      "[INFO: 2022-02-16 16:27:42,037]   LabelSmoothing Loss = 2.156606435775757\n",
      "[INFO: 2022-02-16 16:27:51,565] Iteration 6060 (DataTime/BatchTime: 0.00217/0.476) losses = 2.7033, lr = [2.6790508172205324e-05, 0.0002679050817220532]\n",
      "[INFO: 2022-02-16 16:27:51,566]   LabelSmoothing Loss = 2.955331802368164\n",
      "[INFO: 2022-02-16 16:28:01,053] Iteration 6080 (DataTime/BatchTime: 0.00112/0.474) losses = 2.8658, lr = [2.687889651985364e-05, 0.0002687889651985364]\n",
      "[INFO: 2022-02-16 16:28:01,054]   LabelSmoothing Loss = 3.6303791999816895\n",
      "[INFO: 2022-02-16 16:28:10,561] Iteration 6100 (DataTime/BatchTime: 0.00118/0.475) losses = 2.857, lr = [2.696728486750196e-05, 0.00026967284867501957]\n",
      "[INFO: 2022-02-16 16:28:10,561]   LabelSmoothing Loss = 3.4944777488708496\n",
      "[INFO: 2022-02-16 16:28:20,158] Iteration 6120 (DataTime/BatchTime: 0.00235/0.48) losses = 2.5531, lr = [2.705567321515028e-05, 0.00027055673215150276]\n",
      "[INFO: 2022-02-16 16:28:20,158]   LabelSmoothing Loss = 3.133172035217285\n",
      "[INFO: 2022-02-16 16:28:29,763] Iteration 6140 (DataTime/BatchTime: 0.00449/0.48) losses = 2.711, lr = [2.7144061562798597e-05, 0.00027144061562798594]\n",
      "[INFO: 2022-02-16 16:28:29,763]   LabelSmoothing Loss = 3.590662717819214\n",
      "[INFO: 2022-02-16 16:28:39,340] Iteration 6160 (DataTime/BatchTime: 0.00238/0.479) losses = 2.8593, lr = [2.7232449910446917e-05, 0.00027232449910446913]\n",
      "[INFO: 2022-02-16 16:28:39,340]   LabelSmoothing Loss = 2.374124050140381\n",
      "[INFO: 2022-02-16 16:28:48,997] Iteration 6180 (DataTime/BatchTime: 0.00142/0.483) losses = 2.8468, lr = [2.7320838258095233e-05, 0.0002732083825809523]\n",
      "[INFO: 2022-02-16 16:28:48,998]   LabelSmoothing Loss = 3.7185754776000977\n",
      "[INFO: 2022-02-16 16:28:58,667] Iteration 6200 (DataTime/BatchTime: 0.00259/0.483) losses = 2.8587, lr = [2.7409226605743553e-05, 0.0002740922660574355]\n",
      "[INFO: 2022-02-16 16:28:58,667]   LabelSmoothing Loss = 2.1677699089050293\n",
      "[INFO: 2022-02-16 16:29:08,255] Iteration 6220 (DataTime/BatchTime: 0.00325/0.479) losses = 2.8731, lr = [2.7497614953391873e-05, 0.0002749761495339187]\n",
      "[INFO: 2022-02-16 16:29:08,255]   LabelSmoothing Loss = 2.7885639667510986\n",
      "[INFO: 2022-02-16 16:29:17,903] Iteration 6240 (DataTime/BatchTime: 0.00152/0.482) losses = 2.8509, lr = [2.7586003301040186e-05, 0.0002758600330104018]\n",
      "[INFO: 2022-02-16 16:29:17,904]   LabelSmoothing Loss = 2.3485774993896484\n",
      "[INFO: 2022-02-16 16:29:27,578] Iteration 6260 (DataTime/BatchTime: 0.00231/0.484) losses = 2.7427, lr = [2.7674391648688506e-05, 0.000276743916486885]\n",
      "[INFO: 2022-02-16 16:29:27,578]   LabelSmoothing Loss = 3.073404312133789\n",
      "[INFO: 2022-02-16 16:29:37,238] Iteration 6280 (DataTime/BatchTime: 0.00546/0.483) losses = 2.8156, lr = [2.7762779996336826e-05, 0.0002776277999633682]\n",
      "[INFO: 2022-02-16 16:29:37,238]   LabelSmoothing Loss = 4.555657863616943\n",
      "[INFO: 2022-02-16 16:29:46,786] Iteration 6300 (DataTime/BatchTime: 0.00142/0.477) losses = 2.8096, lr = [2.7851168343985143e-05, 0.0002785116834398514]\n",
      "[INFO: 2022-02-16 16:29:46,786]   LabelSmoothing Loss = 2.2663893699645996\n",
      "[INFO: 2022-02-16 16:29:56,407] Iteration 6320 (DataTime/BatchTime: 0.00146/0.481) losses = 3.0159, lr = [2.7939556691633463e-05, 0.0002793955669163346]\n",
      "[INFO: 2022-02-16 16:29:56,407]   LabelSmoothing Loss = 2.325357675552368\n",
      "[INFO: 2022-02-16 16:30:05,984] Iteration 6340 (DataTime/BatchTime: 0.00227/0.479) losses = 2.7703, lr = [2.802794503928178e-05, 0.0002802794503928178]\n",
      "[INFO: 2022-02-16 16:30:05,985]   LabelSmoothing Loss = 3.335622787475586\n",
      "[INFO: 2022-02-16 16:30:15,606] Iteration 6360 (DataTime/BatchTime: 0.0023/0.481) losses = 2.7391, lr = [2.81163333869301e-05, 0.000281163333869301]\n",
      "[INFO: 2022-02-16 16:30:15,607]   LabelSmoothing Loss = 3.043410062789917\n",
      "[INFO: 2022-02-16 16:30:25,271] Iteration 6380 (DataTime/BatchTime: 0.00154/0.483) losses = 2.7105, lr = [2.820472173457842e-05, 0.00028204721734578417]\n",
      "[INFO: 2022-02-16 16:30:25,272]   LabelSmoothing Loss = 3.218270778656006\n",
      "[INFO: 2022-02-16 16:30:34,881] Iteration 6400 (DataTime/BatchTime: 0.00323/0.48) losses = 2.8588, lr = [2.8293110082226736e-05, 0.00028293110082226736]\n",
      "[INFO: 2022-02-16 16:30:34,882]   LabelSmoothing Loss = 2.5531859397888184\n",
      "[INFO: 2022-02-16 16:30:44,732] Iteration 6420 (DataTime/BatchTime: 0.00341/0.493) losses = 2.9437, lr = [2.8381498429875056e-05, 0.00028381498429875054]\n",
      "[INFO: 2022-02-16 16:30:44,732]   LabelSmoothing Loss = 3.1414082050323486\n",
      "[INFO: 2022-02-16 16:30:54,387] Iteration 6440 (DataTime/BatchTime: 0.00147/0.483) losses = 2.7553, lr = [2.8469886777523375e-05, 0.00028469886777523373]\n",
      "[INFO: 2022-02-16 16:30:54,388]   LabelSmoothing Loss = 2.930757761001587\n",
      "[INFO: 2022-02-16 16:31:04,025] Iteration 6460 (DataTime/BatchTime: 0.00322/0.482) losses = 3.0501, lr = [2.8558275125171692e-05, 0.0002855827512517169]\n",
      "[INFO: 2022-02-16 16:31:04,025]   LabelSmoothing Loss = 3.406937599182129\n",
      "[INFO: 2022-02-16 16:31:13,749] Iteration 6480 (DataTime/BatchTime: 0.00273/0.486) losses = 2.8728, lr = [2.8646663472820012e-05, 0.0002864666347282001]\n",
      "[INFO: 2022-02-16 16:31:13,749]   LabelSmoothing Loss = 2.519566774368286\n",
      "[INFO: 2022-02-16 16:31:23,547] Iteration 6500 (DataTime/BatchTime: 0.00266/0.49) losses = 2.6528, lr = [2.8735051820468332e-05, 0.0002873505182046833]\n",
      "[INFO: 2022-02-16 16:31:23,547]   LabelSmoothing Loss = 3.4628584384918213\n",
      "[INFO: 2022-02-16 16:31:33,161] Iteration 6520 (DataTime/BatchTime: 0.00154/0.481) losses = 2.7744, lr = [2.882344016811665e-05, 0.00028823440168116647]\n",
      "[INFO: 2022-02-16 16:31:33,161]   LabelSmoothing Loss = 3.3594279289245605\n",
      "[INFO: 2022-02-16 16:31:42,786] Iteration 6540 (DataTime/BatchTime: 0.00418/0.481) losses = 2.7062, lr = [2.8911828515764968e-05, 0.00028911828515764966]\n",
      "[INFO: 2022-02-16 16:31:42,786]   LabelSmoothing Loss = 2.533334255218506\n",
      "[INFO: 2022-02-16 16:31:52,327] Iteration 6560 (DataTime/BatchTime: 0.00235/0.477) losses = 2.7624, lr = [2.9000216863413285e-05, 0.00029000216863413284]\n",
      "[INFO: 2022-02-16 16:31:52,327]   LabelSmoothing Loss = 2.226630449295044\n",
      "[INFO: 2022-02-16 16:32:02,053] Iteration 6580 (DataTime/BatchTime: 0.00229/0.486) losses = 2.8393, lr = [2.90886052110616e-05, 0.00029088605211061597]\n",
      "[INFO: 2022-02-16 16:32:02,053]   LabelSmoothing Loss = 3.7893970012664795\n",
      "[INFO: 2022-02-16 16:32:11,716] Iteration 6600 (DataTime/BatchTime: 0.00148/0.483) losses = 2.7533, lr = [2.917699355870992e-05, 0.00029176993558709916]\n",
      "[INFO: 2022-02-16 16:32:11,717]   LabelSmoothing Loss = 3.1024205684661865\n",
      "[INFO: 2022-02-16 16:32:21,305] Iteration 6620 (DataTime/BatchTime: 0.00334/0.479) losses = 2.866, lr = [2.9265381906358238e-05, 0.00029265381906358234]\n",
      "[INFO: 2022-02-16 16:32:21,305]   LabelSmoothing Loss = 3.300147771835327\n",
      "[INFO: 2022-02-16 16:32:30,905] Iteration 6640 (DataTime/BatchTime: 0.0033/0.48) losses = 2.7829, lr = [2.9353770254006558e-05, 0.00029353770254006553]\n",
      "[INFO: 2022-02-16 16:32:30,905]   LabelSmoothing Loss = 2.3824474811553955\n",
      "[INFO: 2022-02-16 16:32:40,635] Iteration 6660 (DataTime/BatchTime: 0.00151/0.486) losses = 3.0367, lr = [2.9442158601654878e-05, 0.0002944215860165487]\n",
      "[INFO: 2022-02-16 16:32:40,635]   LabelSmoothing Loss = 2.2082090377807617\n",
      "[INFO: 2022-02-16 16:32:50,302] Iteration 6680 (DataTime/BatchTime: 0.00265/0.483) losses = 2.9113, lr = [2.9530546949303194e-05, 0.0002953054694930319]\n",
      "[INFO: 2022-02-16 16:32:50,302]   LabelSmoothing Loss = 2.4862613677978516\n",
      "[INFO: 2022-02-16 16:36:27,662] ######## Epoch (VAL)7 ########\n",
      "[INFO: 2022-02-16 16:36:27,662] {'Bleu_1': 0.368059865831697, 'Bleu_2': 0.2340078090547708, 'Bleu_3': 0.15032728185303904, 'Bleu_4': 0.09872867871888813, 'METEOR': 0.18914375836815325, 'ROUGE_L': 0.35201489092411614, 'CIDEr': 0.2738442586461069}\n",
      "[INFO: 2022-02-16 16:40:07,254] ######## Epoch (TEST)7 ########\n",
      "[INFO: 2022-02-16 16:40:07,255] {'Bleu_1': 0.34101944799483624, 'Bleu_2': 0.21931750571713557, 'Bleu_3': 0.1447035292143456, 'Bleu_4': 0.09655396518769772, 'METEOR': 0.17907455313043216, 'ROUGE_L': 0.33623002472891755, 'CIDEr': 0.3226128142862051}\n",
      "[INFO: 2022-02-16 16:40:15,889] Iteration 6700 (DataTime/BatchTime: 0.0614/0.54) losses = 2.9382, lr = [2.9618935296951514e-05, 0.0002961893529695151]\n",
      "[INFO: 2022-02-16 16:40:15,889]   LabelSmoothing Loss = 2.2894623279571533\n",
      "[INFO: 2022-02-16 16:40:25,360] Iteration 6720 (DataTime/BatchTime: 0.00221/0.474) losses = 2.6159, lr = [2.970732364459983e-05, 0.00029707323644599827]\n",
      "[INFO: 2022-02-16 16:40:25,360]   LabelSmoothing Loss = 2.6127238273620605\n",
      "[INFO: 2022-02-16 16:40:34,794] Iteration 6740 (DataTime/BatchTime: 0.0013/0.472) losses = 2.7033, lr = [2.979571199224815e-05, 0.00029795711992248146]\n",
      "[INFO: 2022-02-16 16:40:34,794]   LabelSmoothing Loss = 2.0713717937469482\n",
      "[INFO: 2022-02-16 16:40:44,277] Iteration 6760 (DataTime/BatchTime: 0.00223/0.474) losses = 2.6475, lr = [2.988410033989647e-05, 0.00029884100339896464]\n",
      "[INFO: 2022-02-16 16:40:44,277]   LabelSmoothing Loss = 3.0918796062469482\n",
      "[INFO: 2022-02-16 16:40:53,762] Iteration 6780 (DataTime/BatchTime: 0.00431/0.474) losses = 2.6401, lr = [2.9972488687544787e-05, 0.00029972488687544783]\n",
      "[INFO: 2022-02-16 16:40:53,762]   LabelSmoothing Loss = 2.1809468269348145\n",
      "[INFO: 2022-02-16 16:41:03,242] Iteration 6800 (DataTime/BatchTime: 0.00136/0.474) losses = 2.6752, lr = [3.0060877035193107e-05, 0.000300608770351931]\n",
      "[INFO: 2022-02-16 16:41:03,258]   LabelSmoothing Loss = 2.3511946201324463\n",
      "[INFO: 2022-02-16 16:41:12,802] Iteration 6820 (DataTime/BatchTime: 0.00295/0.478) losses = 2.8207, lr = [3.0149265382841427e-05, 0.0003014926538284142]\n",
      "[INFO: 2022-02-16 16:41:12,802]   LabelSmoothing Loss = 4.254510879516602\n",
      "[INFO: 2022-02-16 16:41:22,296] Iteration 6840 (DataTime/BatchTime: 0.00211/0.475) losses = 2.7218, lr = [3.0237653730489743e-05, 0.0003023765373048974]\n",
      "[INFO: 2022-02-16 16:41:22,297]   LabelSmoothing Loss = 2.5726001262664795\n",
      "[INFO: 2022-02-16 16:41:31,955] Iteration 6860 (DataTime/BatchTime: 0.00138/0.483) losses = 2.7762, lr = [3.0326042078138063e-05, 0.00030326042078138057]\n",
      "[INFO: 2022-02-16 16:41:31,956]   LabelSmoothing Loss = 3.4410910606384277\n",
      "[INFO: 2022-02-16 16:41:41,577] Iteration 6880 (DataTime/BatchTime: 0.00301/0.481) losses = 2.9035, lr = [3.0414430425786383e-05, 0.00030414430425786376]\n",
      "[INFO: 2022-02-16 16:41:41,577]   LabelSmoothing Loss = 3.731011152267456\n",
      "[INFO: 2022-02-16 16:41:51,108] Iteration 6900 (DataTime/BatchTime: 0.00218/0.477) losses = 2.6241, lr = [3.0502818773434696e-05, 0.00030502818773434694]\n",
      "[INFO: 2022-02-16 16:41:51,108]   LabelSmoothing Loss = 2.71091890335083\n",
      "[INFO: 2022-02-16 16:42:00,661] Iteration 6920 (DataTime/BatchTime: 0.00131/0.478) losses = 2.8162, lr = [3.059120712108301e-05, 0.00030591207121083013]\n",
      "[INFO: 2022-02-16 16:42:00,661]   LabelSmoothing Loss = 3.8088221549987793\n",
      "[INFO: 2022-02-16 16:42:10,249] Iteration 6940 (DataTime/BatchTime: 0.00293/0.479) losses = 2.963, lr = [3.067959546873133e-05, 0.0003067959546873133]\n",
      "[INFO: 2022-02-16 16:42:10,249]   LabelSmoothing Loss = 3.7031378746032715\n",
      "[INFO: 2022-02-16 16:42:19,861] Iteration 6960 (DataTime/BatchTime: 0.00214/0.481) losses = 2.7758, lr = [3.076798381637965e-05, 0.0003076798381637965]\n",
      "[INFO: 2022-02-16 16:42:19,861]   LabelSmoothing Loss = 1.8060662746429443\n",
      "[INFO: 2022-02-16 16:42:29,485] Iteration 6980 (DataTime/BatchTime: 0.00135/0.481) losses = 2.777, lr = [3.085637216402797e-05, 0.0003085637216402797]\n",
      "[INFO: 2022-02-16 16:42:29,485]   LabelSmoothing Loss = 1.8133999109268188\n",
      "[INFO: 2022-02-16 16:42:39,090] Iteration 7000 (DataTime/BatchTime: 0.00213/0.48) losses = 2.7346, lr = [3.094476051167629e-05, 0.00030944760511676287]\n",
      "[INFO: 2022-02-16 16:42:39,090]   LabelSmoothing Loss = 3.081979751586914\n",
      "[INFO: 2022-02-16 16:42:48,627] Iteration 7020 (DataTime/BatchTime: 0.00132/0.477) losses = 2.6541, lr = [3.1033148859324606e-05, 0.00031033148859324606]\n",
      "[INFO: 2022-02-16 16:42:48,627]   LabelSmoothing Loss = 3.2924671173095703\n",
      "[INFO: 2022-02-16 16:42:58,131] Iteration 7040 (DataTime/BatchTime: 0.00215/0.475) losses = 2.7901, lr = [3.1121537206972926e-05, 0.00031121537206972924]\n",
      "[INFO: 2022-02-16 16:42:58,131]   LabelSmoothing Loss = 2.139063596725464\n",
      "[INFO: 2022-02-16 16:43:07,660] Iteration 7060 (DataTime/BatchTime: 0.00127/0.476) losses = 2.592, lr = [3.1209925554621245e-05, 0.00031209925554621243]\n",
      "[INFO: 2022-02-16 16:43:07,661]   LabelSmoothing Loss = 2.264697790145874\n",
      "[INFO: 2022-02-16 16:43:17,215] Iteration 7080 (DataTime/BatchTime: 0.0013/0.478) losses = 2.7464, lr = [3.1298313902269565e-05, 0.0003129831390226956]\n",
      "[INFO: 2022-02-16 16:43:17,216]   LabelSmoothing Loss = 2.9387199878692627\n",
      "[INFO: 2022-02-16 16:43:26,756] Iteration 7100 (DataTime/BatchTime: 0.00223/0.477) losses = 2.8215, lr = [3.1386702249917885e-05, 0.0003138670224991788]\n",
      "[INFO: 2022-02-16 16:43:26,756]   LabelSmoothing Loss = 3.4736809730529785\n",
      "[INFO: 2022-02-16 16:43:36,350] Iteration 7120 (DataTime/BatchTime: 0.00134/0.48) losses = 2.7501, lr = [3.1475090597566205e-05, 0.000314750905975662]\n",
      "[INFO: 2022-02-16 16:43:36,351]   LabelSmoothing Loss = 2.551992416381836\n",
      "[INFO: 2022-02-16 16:43:45,871] Iteration 7140 (DataTime/BatchTime: 0.00209/0.476) losses = 2.7173, lr = [3.156347894521452e-05, 0.00031563478945214517]\n",
      "[INFO: 2022-02-16 16:43:45,871]   LabelSmoothing Loss = 2.3625693321228027\n",
      "[INFO: 2022-02-16 16:43:55,444] Iteration 7160 (DataTime/BatchTime: 0.00126/0.479) losses = 2.5841, lr = [3.165186729286284e-05, 0.00031651867292862836]\n",
      "[INFO: 2022-02-16 16:43:55,444]   LabelSmoothing Loss = 2.9304049015045166\n",
      "[INFO: 2022-02-16 16:44:05,056] Iteration 7180 (DataTime/BatchTime: 0.00128/0.481) losses = 2.8892, lr = [3.174025564051116e-05, 0.00031740255640511154]\n",
      "[INFO: 2022-02-16 16:44:05,056]   LabelSmoothing Loss = 3.4678807258605957\n",
      "[INFO: 2022-02-16 16:44:14,620] Iteration 7200 (DataTime/BatchTime: 0.00131/0.478) losses = 2.8561, lr = [3.182864398815948e-05, 0.0003182864398815947]\n",
      "[INFO: 2022-02-16 16:44:14,621]   LabelSmoothing Loss = 4.015294551849365\n",
      "[INFO: 2022-02-16 16:44:24,099] Iteration 7220 (DataTime/BatchTime: 0.0013/0.474) losses = 2.4768, lr = [3.191703233580779e-05, 0.00031917032335807786]\n",
      "[INFO: 2022-02-16 16:44:24,099]   LabelSmoothing Loss = 1.725108027458191\n",
      "[INFO: 2022-02-16 16:44:33,595] Iteration 7240 (DataTime/BatchTime: 0.00128/0.475) losses = 2.7362, lr = [3.200542068345611e-05, 0.00032005420683456104]\n",
      "[INFO: 2022-02-16 16:44:33,595]   LabelSmoothing Loss = 3.370103597640991\n",
      "[INFO: 2022-02-16 16:44:43,076] Iteration 7260 (DataTime/BatchTime: 0.00208/0.474) losses = 2.6964, lr = [3.209380903110443e-05, 0.00032093809031104423]\n",
      "[INFO: 2022-02-16 16:44:43,076]   LabelSmoothing Loss = 3.14160418510437\n",
      "[INFO: 2022-02-16 16:44:52,645] Iteration 7280 (DataTime/BatchTime: 0.00137/0.478) losses = 2.9786, lr = [3.218219737875275e-05, 0.0003218219737875274]\n",
      "[INFO: 2022-02-16 16:44:52,645]   LabelSmoothing Loss = 2.5407843589782715\n",
      "[INFO: 2022-02-16 16:45:02,165] Iteration 7300 (DataTime/BatchTime: 0.00208/0.476) losses = 2.7743, lr = [3.2270585726401064e-05, 0.0003227058572640106]\n",
      "[INFO: 2022-02-16 16:45:02,165]   LabelSmoothing Loss = 3.3469886779785156\n",
      "[INFO: 2022-02-16 16:45:11,644] Iteration 7320 (DataTime/BatchTime: 0.0021/0.474) losses = 2.7471, lr = [3.2358974074049384e-05, 0.0003235897407404938]\n",
      "[INFO: 2022-02-16 16:45:11,644]   LabelSmoothing Loss = 2.8910861015319824\n",
      "[INFO: 2022-02-16 16:45:21,130] Iteration 7340 (DataTime/BatchTime: 0.00305/0.474) losses = 2.934, lr = [3.2447362421697704e-05, 0.00032447362421697697]\n",
      "[INFO: 2022-02-16 16:45:21,130]   LabelSmoothing Loss = 1.672936201095581\n",
      "[INFO: 2022-02-16 16:45:30,651] Iteration 7360 (DataTime/BatchTime: 0.00129/0.476) losses = 2.798, lr = [3.2535750769346024e-05, 0.0003253575076934602]\n",
      "[INFO: 2022-02-16 16:45:30,651]   LabelSmoothing Loss = 3.3142518997192383\n",
      "[INFO: 2022-02-16 16:45:40,161] Iteration 7380 (DataTime/BatchTime: 0.00129/0.475) losses = 2.6689, lr = [3.2624139116994344e-05, 0.0003262413911699434]\n",
      "[INFO: 2022-02-16 16:45:40,161]   LabelSmoothing Loss = 2.1202149391174316\n",
      "[INFO: 2022-02-16 16:45:49,722] Iteration 7400 (DataTime/BatchTime: 0.00221/0.478) losses = 2.7585, lr = [3.271252746464266e-05, 0.0003271252746464266]\n",
      "[INFO: 2022-02-16 16:45:49,722]   LabelSmoothing Loss = 2.2042598724365234\n",
      "[INFO: 2022-02-16 16:45:59,267] Iteration 7420 (DataTime/BatchTime: 0.00209/0.477) losses = 2.7148, lr = [3.280091581229098e-05, 0.00032800915812290977]\n",
      "[INFO: 2022-02-16 16:45:59,267]   LabelSmoothing Loss = 2.358375310897827\n",
      "[INFO: 2022-02-16 16:46:08,803] Iteration 7440 (DataTime/BatchTime: 0.0013/0.477) losses = 2.8569, lr = [3.28893041599393e-05, 0.00032889304159939295]\n",
      "[INFO: 2022-02-16 16:46:08,803]   LabelSmoothing Loss = 2.425031900405884\n",
      "[INFO: 2022-02-16 16:46:18,346] Iteration 7460 (DataTime/BatchTime: 0.00129/0.477) losses = 2.8565, lr = [3.297769250758762e-05, 0.00032977692507587614]\n",
      "[INFO: 2022-02-16 16:46:18,346]   LabelSmoothing Loss = 3.778574228286743\n",
      "[INFO: 2022-02-16 16:46:27,900] Iteration 7480 (DataTime/BatchTime: 0.00128/0.478) losses = 2.7933, lr = [3.3066080855235937e-05, 0.0003306608085523593]\n",
      "[INFO: 2022-02-16 16:46:27,900]   LabelSmoothing Loss = 2.334660053253174\n",
      "[INFO: 2022-02-16 16:46:37,531] Iteration 7500 (DataTime/BatchTime: 0.00135/0.482) losses = 2.7362, lr = [3.3154469202884256e-05, 0.0003315446920288425]\n",
      "[INFO: 2022-02-16 16:46:37,531]   LabelSmoothing Loss = 4.263830184936523\n",
      "[INFO: 2022-02-16 16:46:47,106] Iteration 7520 (DataTime/BatchTime: 0.00222/0.479) losses = 2.6672, lr = [3.324285755053257e-05, 0.0003324285755053257]\n",
      "[INFO: 2022-02-16 16:46:47,106]   LabelSmoothing Loss = 2.407029390335083\n",
      "[INFO: 2022-02-16 16:46:56,661] Iteration 7540 (DataTime/BatchTime: 0.0012/0.478) losses = 2.9307, lr = [3.333124589818089e-05, 0.00033331245898180883]\n",
      "[INFO: 2022-02-16 16:46:56,661]   LabelSmoothing Loss = 2.788032293319702\n",
      "[INFO: 2022-02-16 16:47:06,279] Iteration 7560 (DataTime/BatchTime: 0.00306/0.481) losses = 2.6554, lr = [3.34196342458292e-05, 0.000334196342458292]\n",
      "[INFO: 2022-02-16 16:47:06,279]   LabelSmoothing Loss = 3.2534990310668945\n",
      "[INFO: 2022-02-16 16:47:15,914] Iteration 7580 (DataTime/BatchTime: 0.0013/0.482) losses = 2.8502, lr = [3.350802259347752e-05, 0.0003350802259347752]\n",
      "[INFO: 2022-02-16 16:47:15,915]   LabelSmoothing Loss = 2.0955560207366943\n",
      "[INFO: 2022-02-16 16:47:25,559] Iteration 7600 (DataTime/BatchTime: 0.00222/0.482) losses = 2.7539, lr = [3.359641094112584e-05, 0.0003359641094112584]\n",
      "[INFO: 2022-02-16 16:47:25,559]   LabelSmoothing Loss = 2.9029393196105957\n",
      "[INFO: 2022-02-16 16:47:35,201] Iteration 7620 (DataTime/BatchTime: 0.00219/0.482) losses = 2.6197, lr = [3.368479928877416e-05, 0.00033684799288774157]\n",
      "[INFO: 2022-02-16 16:47:35,201]   LabelSmoothing Loss = 2.464813232421875\n",
      "[INFO: 2022-02-16 16:51:15,234] ######## Epoch (VAL)8 ########\n",
      "[INFO: 2022-02-16 16:51:15,234] {'Bleu_1': 0.4026710308045643, 'Bleu_2': 0.2687196545073892, 'Bleu_3': 0.18395829452764553, 'Bleu_4': 0.12317318445337318, 'METEOR': 0.19615253354693182, 'ROUGE_L': 0.34878870893407976, 'CIDEr': 0.29508307263825007}\n",
      "[INFO: 2022-02-16 16:54:49,647] ######## Epoch (TEST)8 ########\n",
      "[INFO: 2022-02-16 16:54:49,647] {'Bleu_1': 0.38176894088747104, 'Bleu_2': 0.24962313897637917, 'Bleu_3': 0.16700279252562814, 'Bleu_4': 0.11000113830496684, 'METEOR': 0.18517935718605116, 'ROUGE_L': 0.33013967217209184, 'CIDEr': 0.3460842781828871}\n",
      "[INFO: 2022-02-16 16:54:51,175] Iteration 7640 (DataTime/BatchTime: 0.951/1.53) losses = 3.7694, lr = [3.377318763642248e-05, 0.00033773187636422476]\n",
      "[INFO: 2022-02-16 16:54:51,175]   LabelSmoothing Loss = 3.769421100616455\n",
      "[INFO: 2022-02-16 16:55:00,667] Iteration 7660 (DataTime/BatchTime: 0.00125/0.475) losses = 2.7306, lr = [3.3861575984070795e-05, 0.00033861575984070794]\n",
      "[INFO: 2022-02-16 16:55:00,667]   LabelSmoothing Loss = 2.780266523361206\n",
      "[INFO: 2022-02-16 16:55:10,150] Iteration 7680 (DataTime/BatchTime: 0.00384/0.474) losses = 2.6494, lr = [3.3949964331719115e-05, 0.0003394996433171911]\n",
      "[INFO: 2022-02-16 16:55:10,150]   LabelSmoothing Loss = 2.993286371231079\n",
      "[INFO: 2022-02-16 16:55:19,663] Iteration 7700 (DataTime/BatchTime: 0.00213/0.476) losses = 2.8383, lr = [3.4038352679367435e-05, 0.0003403835267936743]\n",
      "[INFO: 2022-02-16 16:55:19,664]   LabelSmoothing Loss = 3.3062379360198975\n",
      "[INFO: 2022-02-16 16:55:29,176] Iteration 7720 (DataTime/BatchTime: 0.0013/0.476) losses = 2.6043, lr = [3.4126741027015755e-05, 0.0003412674102701575]\n",
      "[INFO: 2022-02-16 16:55:29,176]   LabelSmoothing Loss = 2.4141557216644287\n",
      "[INFO: 2022-02-16 16:55:38,707] Iteration 7740 (DataTime/BatchTime: 0.0013/0.477) losses = 2.6882, lr = [3.4215129374664075e-05, 0.0003421512937466407]\n",
      "[INFO: 2022-02-16 16:55:38,707]   LabelSmoothing Loss = 3.5931618213653564\n",
      "[INFO: 2022-02-16 16:55:48,154] Iteration 7760 (DataTime/BatchTime: 0.0021/0.472) losses = 2.6275, lr = [3.4303517722312395e-05, 0.00034303517722312387]\n",
      "[INFO: 2022-02-16 16:55:48,155]   LabelSmoothing Loss = 3.213223695755005\n",
      "[INFO: 2022-02-16 16:55:57,767] Iteration 7780 (DataTime/BatchTime: 0.00124/0.481) losses = 2.9623, lr = [3.439190606996071e-05, 0.00034391906069960705]\n",
      "[INFO: 2022-02-16 16:55:57,767]   LabelSmoothing Loss = 2.651960611343384\n",
      "[INFO: 2022-02-16 16:56:07,346] Iteration 7800 (DataTime/BatchTime: 0.00128/0.479) losses = 2.6065, lr = [3.448029441760903e-05, 0.00034480294417609024]\n",
      "[INFO: 2022-02-16 16:56:07,346]   LabelSmoothing Loss = 3.0759706497192383\n",
      "[INFO: 2022-02-16 16:56:16,821] Iteration 7820 (DataTime/BatchTime: 0.00128/0.474) losses = 2.5425, lr = [3.456868276525734e-05, 0.0003456868276525734]\n",
      "[INFO: 2022-02-16 16:56:16,821]   LabelSmoothing Loss = 2.6494369506835938\n",
      "[INFO: 2022-02-16 16:56:26,398] Iteration 7840 (DataTime/BatchTime: 0.00128/0.479) losses = 2.8438, lr = [3.465707111290567e-05, 0.0003465707111290566]\n",
      "[INFO: 2022-02-16 16:56:26,398]   LabelSmoothing Loss = 2.7279837131500244\n",
      "[INFO: 2022-02-16 16:56:35,893] Iteration 7860 (DataTime/BatchTime: 0.00128/0.475) losses = 2.5725, lr = [3.474545946055398e-05, 0.0003474545946055398]\n",
      "[INFO: 2022-02-16 16:56:35,893]   LabelSmoothing Loss = 2.2739336490631104\n",
      "[INFO: 2022-02-16 16:56:45,353] Iteration 7880 (DataTime/BatchTime: 0.00209/0.473) losses = 2.4872, lr = [3.483384780820231e-05, 0.000348338478082023]\n",
      "[INFO: 2022-02-16 16:56:45,353]   LabelSmoothing Loss = 2.627610683441162\n",
      "[INFO: 2022-02-16 16:56:54,939] Iteration 7900 (DataTime/BatchTime: 0.00127/0.479) losses = 2.7773, lr = [3.492223615585062e-05, 0.00034922236155850617]\n",
      "[INFO: 2022-02-16 16:56:54,939]   LabelSmoothing Loss = 1.4502291679382324\n",
      "[INFO: 2022-02-16 16:57:04,466] Iteration 7920 (DataTime/BatchTime: 0.00128/0.476) losses = 2.8217, lr = [3.501062450349894e-05, 0.00035010624503498935]\n",
      "[INFO: 2022-02-16 16:57:04,466]   LabelSmoothing Loss = 3.0743308067321777\n",
      "[INFO: 2022-02-16 16:57:13,989] Iteration 7940 (DataTime/BatchTime: 0.00127/0.476) losses = 2.7616, lr = [3.5099012851147254e-05, 0.00035099012851147254]\n",
      "[INFO: 2022-02-16 16:57:13,989]   LabelSmoothing Loss = 2.530730962753296\n",
      "[INFO: 2022-02-16 16:57:23,480] Iteration 7960 (DataTime/BatchTime: 0.00126/0.475) losses = 2.5333, lr = [3.518740119879558e-05, 0.0003518740119879557]\n",
      "[INFO: 2022-02-16 16:57:23,480]   LabelSmoothing Loss = 2.4701449871063232\n",
      "[INFO: 2022-02-16 16:57:33,016] Iteration 7980 (DataTime/BatchTime: 0.00128/0.477) losses = 2.7327, lr = [3.5275789546443894e-05, 0.0003527578954644389]\n",
      "[INFO: 2022-02-16 16:57:33,016]   LabelSmoothing Loss = 4.32602071762085\n",
      "[INFO: 2022-02-16 16:57:42,525] Iteration 8000 (DataTime/BatchTime: 0.00127/0.475) losses = 2.812, lr = [3.5364177894092214e-05, 0.00035364177894092215]\n",
      "[INFO: 2022-02-16 16:57:42,525]   LabelSmoothing Loss = 2.923539400100708\n",
      "[INFO: 2022-02-16 16:57:52,027] Iteration 8020 (DataTime/BatchTime: 0.00128/0.475) losses = 2.5814, lr = [3.5452566241740534e-05, 0.0003545256624174053]\n",
      "[INFO: 2022-02-16 16:57:52,027]   LabelSmoothing Loss = 2.5736703872680664\n",
      "[INFO: 2022-02-16 16:58:01,515] Iteration 8040 (DataTime/BatchTime: 0.00127/0.474) losses = 2.6311, lr = [3.554095458938885e-05, 0.0003554095458938884]\n",
      "[INFO: 2022-02-16 16:58:01,515]   LabelSmoothing Loss = 2.6093502044677734\n",
      "[INFO: 2022-02-16 16:58:11,031] Iteration 8060 (DataTime/BatchTime: 0.00125/0.476) losses = 2.7704, lr = [3.562934293703717e-05, 0.00035629342937037165]\n",
      "[INFO: 2022-02-16 16:58:11,031]   LabelSmoothing Loss = 2.062544345855713\n",
      "[INFO: 2022-02-16 16:58:20,645] Iteration 8080 (DataTime/BatchTime: 0.00138/0.481) losses = 2.7404, lr = [3.571773128468549e-05, 0.0003571773128468548]\n",
      "[INFO: 2022-02-16 16:58:20,645]   LabelSmoothing Loss = 2.11110520362854\n",
      "[INFO: 2022-02-16 16:58:30,241] Iteration 8100 (DataTime/BatchTime: 0.00129/0.48) losses = 2.7443, lr = [3.5806119632333807e-05, 0.000358061196323338]\n",
      "[INFO: 2022-02-16 16:58:30,242]   LabelSmoothing Loss = 3.669001579284668\n",
      "[INFO: 2022-02-16 16:58:39,934] Iteration 8120 (DataTime/BatchTime: 0.00303/0.485) losses = 2.4729, lr = [3.589450797998212e-05, 0.00035894507979982116]\n",
      "[INFO: 2022-02-16 16:58:39,934]   LabelSmoothing Loss = 1.5307706594467163\n",
      "[INFO: 2022-02-16 16:58:49,513] Iteration 8140 (DataTime/BatchTime: 0.00128/0.479) losses = 2.6376, lr = [3.5982896327630446e-05, 0.0003598289632763044]\n",
      "[INFO: 2022-02-16 16:58:49,514]   LabelSmoothing Loss = 2.3399240970611572\n",
      "[INFO: 2022-02-16 16:58:59,075] Iteration 8160 (DataTime/BatchTime: 0.00133/0.478) losses = 2.4056, lr = [3.607128467527876e-05, 0.00036071284675278753]\n",
      "[INFO: 2022-02-16 16:58:59,075]   LabelSmoothing Loss = 1.3224998712539673\n",
      "[INFO: 2022-02-16 16:59:08,684] Iteration 8180 (DataTime/BatchTime: 0.00128/0.48) losses = 2.8, lr = [3.615967302292708e-05, 0.00036159673022927077]\n",
      "[INFO: 2022-02-16 16:59:08,684]   LabelSmoothing Loss = 2.6679744720458984\n",
      "[INFO: 2022-02-16 16:59:18,307] Iteration 8200 (DataTime/BatchTime: 0.00132/0.481) losses = 2.8551, lr = [3.624806137057539e-05, 0.0003624806137057539]\n",
      "[INFO: 2022-02-16 16:59:18,307]   LabelSmoothing Loss = 3.095167636871338\n",
      "[INFO: 2022-02-16 16:59:28,028] Iteration 8220 (DataTime/BatchTime: 0.00133/0.486) losses = 2.9086, lr = [3.633644971822372e-05, 0.00036336449718223714]\n",
      "[INFO: 2022-02-16 16:59:28,028]   LabelSmoothing Loss = 3.761596202850342\n",
      "[INFO: 2022-02-16 16:59:37,706] Iteration 8240 (DataTime/BatchTime: 0.0013/0.484) losses = 2.6998, lr = [3.642483806587203e-05, 0.00036424838065872027]\n",
      "[INFO: 2022-02-16 16:59:37,706]   LabelSmoothing Loss = 1.966551661491394\n",
      "[INFO: 2022-02-16 16:59:47,260] Iteration 8260 (DataTime/BatchTime: 0.00211/0.478) losses = 2.5194, lr = [3.651322641352035e-05, 0.0003651322641352035]\n",
      "[INFO: 2022-02-16 16:59:47,260]   LabelSmoothing Loss = 2.696676254272461\n",
      "[INFO: 2022-02-16 16:59:56,768] Iteration 8280 (DataTime/BatchTime: 0.00126/0.475) losses = 2.669, lr = [3.660161476116867e-05, 0.00036601614761168664]\n",
      "[INFO: 2022-02-16 16:59:56,768]   LabelSmoothing Loss = 2.8650074005126953\n",
      "[INFO: 2022-02-16 17:00:06,404] Iteration 8300 (DataTime/BatchTime: 0.00127/0.482) losses = 2.6467, lr = [3.669000310881699e-05, 0.0003669000310881699]\n",
      "[INFO: 2022-02-16 17:00:06,404]   LabelSmoothing Loss = 3.2930636405944824\n",
      "[INFO: 2022-02-16 17:00:15,944] Iteration 8320 (DataTime/BatchTime: 0.0013/0.477) losses = 2.665, lr = [3.6778391456465305e-05, 0.000367783914564653]\n",
      "[INFO: 2022-02-16 17:00:15,945]   LabelSmoothing Loss = 2.529287099838257\n",
      "[INFO: 2022-02-16 17:00:25,465] Iteration 8340 (DataTime/BatchTime: 0.00132/0.476) losses = 2.6506, lr = [3.686677980411363e-05, 0.00036866779804113625]\n",
      "[INFO: 2022-02-16 17:00:25,465]   LabelSmoothing Loss = 2.528395175933838\n",
      "[INFO: 2022-02-16 17:00:35,142] Iteration 8360 (DataTime/BatchTime: 0.00138/0.484) losses = 2.6389, lr = [3.6955168151761945e-05, 0.0003695516815176194]\n",
      "[INFO: 2022-02-16 17:00:35,142]   LabelSmoothing Loss = 2.368473768234253\n",
      "[INFO: 2022-02-16 17:00:44,721] Iteration 8380 (DataTime/BatchTime: 0.00133/0.479) losses = 2.8654, lr = [3.704355649941026e-05, 0.00037043556499410257]\n",
      "[INFO: 2022-02-16 17:00:44,722]   LabelSmoothing Loss = 3.8152360916137695\n",
      "[INFO: 2022-02-16 17:00:54,312] Iteration 8400 (DataTime/BatchTime: 0.00208/0.48) losses = 2.9274, lr = [3.7131944847058585e-05, 0.0003713194484705858]\n",
      "[INFO: 2022-02-16 17:00:54,312]   LabelSmoothing Loss = 3.7196311950683594\n",
      "[INFO: 2022-02-16 17:01:03,925] Iteration 8420 (DataTime/BatchTime: 0.00131/0.48) losses = 2.5519, lr = [3.72203331947069e-05, 0.00037220333194706894]\n",
      "[INFO: 2022-02-16 17:01:03,925]   LabelSmoothing Loss = 1.8989568948745728\n",
      "[INFO: 2022-02-16 17:01:13,433] Iteration 8440 (DataTime/BatchTime: 0.00209/0.476) losses = 2.6921, lr = [3.730872154235522e-05, 0.0003730872154235522]\n",
      "[INFO: 2022-02-16 17:01:13,433]   LabelSmoothing Loss = 2.348146677017212\n",
      "[INFO: 2022-02-16 17:01:22,976] Iteration 8460 (DataTime/BatchTime: 0.00116/0.477) losses = 2.549, lr = [3.739710989000354e-05, 0.0003739710989000353]\n",
      "[INFO: 2022-02-16 17:01:22,977]   LabelSmoothing Loss = 2.0047473907470703\n",
      "[INFO: 2022-02-16 17:01:32,615] Iteration 8480 (DataTime/BatchTime: 0.00294/0.482) losses = 2.5797, lr = [3.748549823765186e-05, 0.00037485498237651855]\n",
      "[INFO: 2022-02-16 17:01:32,616]   LabelSmoothing Loss = 1.8763903379440308\n",
      "[INFO: 2022-02-16 17:01:42,186] Iteration 8500 (DataTime/BatchTime: 0.00128/0.479) losses = 2.6686, lr = [3.757388658530017e-05, 0.0003757388658530017]\n",
      "[INFO: 2022-02-16 17:01:42,186]   LabelSmoothing Loss = 1.911690592765808\n",
      "[INFO: 2022-02-16 17:01:51,751] Iteration 8520 (DataTime/BatchTime: 0.00133/0.478) losses = 2.6112, lr = [3.76622749329485e-05, 0.0003766227493294849]\n",
      "[INFO: 2022-02-16 17:01:51,751]   LabelSmoothing Loss = 2.068093776702881\n",
      "[INFO: 2022-02-16 17:02:01,392] Iteration 8540 (DataTime/BatchTime: 0.0013/0.482) losses = 2.6045, lr = [3.775066328059681e-05, 0.00037750663280596805]\n",
      "[INFO: 2022-02-16 17:02:01,392]   LabelSmoothing Loss = 2.1997976303100586\n",
      "[INFO: 2022-02-16 17:02:10,924] Iteration 8560 (DataTime/BatchTime: 0.00129/0.477) losses = 2.5403, lr = [3.783905162824513e-05, 0.0003783905162824513]\n",
      "[INFO: 2022-02-16 17:02:10,924]   LabelSmoothing Loss = 1.5790873765945435\n",
      "[INFO: 2022-02-16 17:02:20,435] Iteration 8580 (DataTime/BatchTime: 0.00128/0.476) losses = 2.5696, lr = [3.7927439975893444e-05, 0.0003792743997589344]\n",
      "[INFO: 2022-02-16 17:02:20,436]   LabelSmoothing Loss = 2.2451586723327637\n",
      "[INFO: 2022-02-16 17:06:01,607] ######## Epoch (VAL)9 ########\n",
      "[INFO: 2022-02-16 17:06:01,607] {'Bleu_1': 0.34877288622891744, 'Bleu_2': 0.2201564626503559, 'Bleu_3': 0.14940499850039626, 'Bleu_4': 0.10361994210539348, 'METEOR': 0.19050392909971398, 'ROUGE_L': 0.3501853468387843, 'CIDEr': 0.28180210923916055}\n",
      "[INFO: 2022-02-16 17:09:42,947] ######## Epoch (TEST)9 ########\n",
      "[INFO: 2022-02-16 17:09:42,947] {'Bleu_1': 0.3246772574500357, 'Bleu_2': 0.2019694261365944, 'Bleu_3': 0.13673893869956544, 'Bleu_4': 0.0940873795119763, 'METEOR': 0.17990967947346997, 'ROUGE_L': 0.33151342611771967, 'CIDEr': 0.31321985772720995}\n",
      "[INFO: 2022-02-16 17:09:47,049] Iteration 8600 (DataTime/BatchTime: 0.191/0.684) losses = 2.3502, lr = [3.801582832354177e-05, 0.00038015828323541767]\n",
      "[INFO: 2022-02-16 17:09:47,050]   LabelSmoothing Loss = 3.2984070777893066\n",
      "[INFO: 2022-02-16 17:09:56,594] Iteration 8620 (DataTime/BatchTime: 0.0012/0.477) losses = 2.4301, lr = [3.8104216671190084e-05, 0.0003810421667119008]\n",
      "[INFO: 2022-02-16 17:09:56,594]   LabelSmoothing Loss = 3.359658718109131\n",
      "[INFO: 2022-02-16 17:10:06,146] Iteration 8640 (DataTime/BatchTime: 0.00388/0.478) losses = 2.3451, lr = [3.8192605018838404e-05, 0.00038192605018838404]\n",
      "[INFO: 2022-02-16 17:10:06,146]   LabelSmoothing Loss = 2.244032859802246\n",
      "[INFO: 2022-02-16 17:10:15,730] Iteration 8660 (DataTime/BatchTime: 0.00289/0.479) losses = 2.3688, lr = [3.8280993366486724e-05, 0.00038280993366486717]\n",
      "[INFO: 2022-02-16 17:10:15,730]   LabelSmoothing Loss = 1.7944244146347046\n",
      "[INFO: 2022-02-16 17:10:25,376] Iteration 8680 (DataTime/BatchTime: 0.00236/0.482) losses = 2.6031, lr = [3.836938171413504e-05, 0.0003836938171413503]\n",
      "[INFO: 2022-02-16 17:10:25,376]   LabelSmoothing Loss = 3.550248384475708\n",
      "[INFO: 2022-02-16 17:10:34,908] Iteration 8700 (DataTime/BatchTime: 0.00198/0.477) losses = 2.5457, lr = [3.8457770061783357e-05, 0.00038457770061783354]\n",
      "[INFO: 2022-02-16 17:10:34,909]   LabelSmoothing Loss = 3.113337993621826\n",
      "[INFO: 2022-02-16 17:10:44,542] Iteration 8720 (DataTime/BatchTime: 0.00133/0.482) losses = 2.4428, lr = [3.8546158409431677e-05, 0.00038546158409431667]\n",
      "[INFO: 2022-02-16 17:10:44,542]   LabelSmoothing Loss = 2.35164213180542\n",
      "[INFO: 2022-02-16 17:10:54,196] Iteration 8740 (DataTime/BatchTime: 0.00225/0.483) losses = 2.6631, lr = [3.8634546757079996e-05, 0.0003863454675707999]\n",
      "[INFO: 2022-02-16 17:10:54,196]   LabelSmoothing Loss = 2.868353843688965\n",
      "[INFO: 2022-02-16 17:11:03,804] Iteration 8760 (DataTime/BatchTime: 0.00135/0.48) losses = 2.6252, lr = [3.872293510472831e-05, 0.00038722935104728304]\n",
      "[INFO: 2022-02-16 17:11:03,804]   LabelSmoothing Loss = 2.1279120445251465\n",
      "[INFO: 2022-02-16 17:11:13,400] Iteration 8780 (DataTime/BatchTime: 0.0012/0.48) losses = 2.7053, lr = [3.8811323452376636e-05, 0.0003881132345237663]\n",
      "[INFO: 2022-02-16 17:11:13,400]   LabelSmoothing Loss = 3.643552780151367\n",
      "[INFO: 2022-02-16 17:11:22,942] Iteration 8800 (DataTime/BatchTime: 0.00202/0.477) losses = 2.5383, lr = [3.889971180002495e-05, 0.00038899711800024947]\n",
      "[INFO: 2022-02-16 17:11:22,942]   LabelSmoothing Loss = 2.7206993103027344\n",
      "[INFO: 2022-02-16 17:11:32,469] Iteration 8820 (DataTime/BatchTime: 0.00118/0.476) losses = 2.5598, lr = [3.898810014767327e-05, 0.00038988100147673265]\n",
      "[INFO: 2022-02-16 17:11:32,469]   LabelSmoothing Loss = 2.8513107299804688\n",
      "[INFO: 2022-02-16 17:11:42,070] Iteration 8840 (DataTime/BatchTime: 0.00308/0.48) losses = 2.7357, lr = [3.907648849532159e-05, 0.00039076488495321584]\n",
      "[INFO: 2022-02-16 17:11:42,070]   LabelSmoothing Loss = 3.283573865890503\n",
      "[INFO: 2022-02-16 17:11:51,627] Iteration 8860 (DataTime/BatchTime: 0.00123/0.478) losses = 2.6617, lr = [3.916487684296991e-05, 0.000391648768429699]\n",
      "[INFO: 2022-02-16 17:11:51,627]   LabelSmoothing Loss = 3.318634271621704\n",
      "[INFO: 2022-02-16 17:12:01,236] Iteration 8880 (DataTime/BatchTime: 0.00139/0.48) losses = 2.6569, lr = [3.925326519061822e-05, 0.0003925326519061822]\n",
      "[INFO: 2022-02-16 17:12:01,236]   LabelSmoothing Loss = 2.657611846923828\n",
      "[INFO: 2022-02-16 17:12:10,903] Iteration 8900 (DataTime/BatchTime: 0.00224/0.483) losses = 2.6663, lr = [3.934165353826655e-05, 0.0003934165353826654]\n",
      "[INFO: 2022-02-16 17:12:10,903]   LabelSmoothing Loss = 2.329099655151367\n",
      "[INFO: 2022-02-16 17:12:20,438] Iteration 8920 (DataTime/BatchTime: 0.00203/0.477) losses = 2.663, lr = [3.943004188591486e-05, 0.0003943004188591486]\n",
      "[INFO: 2022-02-16 17:12:20,438]   LabelSmoothing Loss = 2.761997699737549\n",
      "[INFO: 2022-02-16 17:12:30,089] Iteration 8940 (DataTime/BatchTime: 0.00123/0.483) losses = 2.9278, lr = [3.951843023356318e-05, 0.00039518430233563177]\n",
      "[INFO: 2022-02-16 17:12:30,089]   LabelSmoothing Loss = 2.9897735118865967\n",
      "[INFO: 2022-02-16 17:12:39,687] Iteration 8960 (DataTime/BatchTime: 0.0021/0.48) losses = 2.445, lr = [3.9606818581211495e-05, 0.00039606818581211495]\n",
      "[INFO: 2022-02-16 17:12:39,688]   LabelSmoothing Loss = 2.0202643871307373\n",
      "[INFO: 2022-02-16 17:12:49,323] Iteration 8980 (DataTime/BatchTime: 0.00203/0.482) losses = 2.611, lr = [3.969520692885982e-05, 0.00039695206928859814]\n",
      "[INFO: 2022-02-16 17:12:49,323]   LabelSmoothing Loss = 2.882101058959961\n",
      "[INFO: 2022-02-16 17:12:58,861] Iteration 9000 (DataTime/BatchTime: 0.00202/0.477) losses = 2.5186, lr = [3.9783595276508135e-05, 0.0003978359527650813]\n",
      "[INFO: 2022-02-16 17:12:58,861]   LabelSmoothing Loss = 1.7485580444335938\n",
      "[INFO: 2022-02-16 17:13:08,445] Iteration 9020 (DataTime/BatchTime: 0.00442/0.479) losses = 2.4278, lr = [3.987198362415645e-05, 0.00039871983624156445]\n",
      "[INFO: 2022-02-16 17:13:08,445]   LabelSmoothing Loss = 2.053490161895752\n",
      "[INFO: 2022-02-16 17:13:17,994] Iteration 9040 (DataTime/BatchTime: 0.00205/0.477) losses = 2.5082, lr = [3.9960371971804775e-05, 0.0003996037197180477]\n",
      "[INFO: 2022-02-16 17:13:17,994]   LabelSmoothing Loss = 2.18642520904541\n",
      "[INFO: 2022-02-16 17:13:27,558] Iteration 9060 (DataTime/BatchTime: 0.0012/0.478) losses = 2.7547, lr = [4.004876031945309e-05, 0.0004004876031945308]\n",
      "[INFO: 2022-02-16 17:13:27,558]   LabelSmoothing Loss = 3.105238199234009\n",
      "[INFO: 2022-02-16 17:13:37,093] Iteration 9080 (DataTime/BatchTime: 0.00124/0.477) losses = 2.5183, lr = [4.013714866710141e-05, 0.00040137148667101407]\n",
      "[INFO: 2022-02-16 17:13:37,094]   LabelSmoothing Loss = 2.3012914657592773\n",
      "[INFO: 2022-02-16 17:13:46,630] Iteration 9100 (DataTime/BatchTime: 0.00149/0.477) losses = 2.4437, lr = [4.022553701474973e-05, 0.0004022553701474972]\n",
      "[INFO: 2022-02-16 17:13:46,630]   LabelSmoothing Loss = 1.7325994968414307\n",
      "[INFO: 2022-02-16 17:13:56,206] Iteration 9120 (DataTime/BatchTime: 0.00205/0.479) losses = 2.4968, lr = [4.031392536239805e-05, 0.00040313925362398044]\n",
      "[INFO: 2022-02-16 17:13:56,206]   LabelSmoothing Loss = 3.0530717372894287\n",
      "[INFO: 2022-02-16 17:14:05,886] Iteration 9140 (DataTime/BatchTime: 0.00125/0.483) losses = 2.7038, lr = [4.040231371004636e-05, 0.00040402313710046357]\n",
      "[INFO: 2022-02-16 17:14:05,887]   LabelSmoothing Loss = 2.330308675765991\n",
      "[INFO: 2022-02-16 17:14:15,451] Iteration 9160 (DataTime/BatchTime: 0.00222/0.479) losses = 2.6542, lr = [4.049070205769469e-05, 0.0004049070205769468]\n",
      "[INFO: 2022-02-16 17:14:15,451]   LabelSmoothing Loss = 1.3436342477798462\n",
      "[INFO: 2022-02-16 17:14:24,972] Iteration 9180 (DataTime/BatchTime: 0.00338/0.476) losses = 2.2906, lr = [4.0579090405343e-05, 0.00040579090405342994]\n",
      "[INFO: 2022-02-16 17:14:24,972]   LabelSmoothing Loss = 2.2890164852142334\n",
      "[INFO: 2022-02-16 17:14:34,559] Iteration 9200 (DataTime/BatchTime: 0.00122/0.479) losses = 2.8746, lr = [4.066747875299132e-05, 0.0004066747875299132]\n",
      "[INFO: 2022-02-16 17:14:34,559]   LabelSmoothing Loss = 2.6942403316497803\n",
      "[INFO: 2022-02-16 17:14:44,139] Iteration 9220 (DataTime/BatchTime: 0.00212/0.479) losses = 2.7258, lr = [4.075586710063964e-05, 0.0004075586710063963]\n",
      "[INFO: 2022-02-16 17:14:44,140]   LabelSmoothing Loss = 2.176731824874878\n",
      "[INFO: 2022-02-16 17:14:53,855] Iteration 9240 (DataTime/BatchTime: 0.00131/0.486) losses = 2.7196, lr = [4.084425544828796e-05, 0.00040844255448287955]\n",
      "[INFO: 2022-02-16 17:14:53,855]   LabelSmoothing Loss = 3.7758212089538574\n",
      "[INFO: 2022-02-16 17:15:03,325] Iteration 9260 (DataTime/BatchTime: 0.00129/0.474) losses = 2.3802, lr = [4.0932643795936274e-05, 0.0004093264379593627]\n",
      "[INFO: 2022-02-16 17:15:03,325]   LabelSmoothing Loss = 2.007514476776123\n",
      "[INFO: 2022-02-16 17:15:12,881] Iteration 9280 (DataTime/BatchTime: 0.00123/0.478) losses = 2.6311, lr = [4.10210321435846e-05, 0.0004102103214358459]\n",
      "[INFO: 2022-02-16 17:15:12,881]   LabelSmoothing Loss = 2.883523464202881\n",
      "[INFO: 2022-02-16 17:15:22,397] Iteration 9300 (DataTime/BatchTime: 0.00128/0.476) losses = 2.4637, lr = [4.1109420491232913e-05, 0.00041109420491232905]\n",
      "[INFO: 2022-02-16 17:15:22,398]   LabelSmoothing Loss = 3.051989793777466\n",
      "[INFO: 2022-02-16 17:15:32,127] Iteration 9320 (DataTime/BatchTime: 0.00148/0.486) losses = 2.6663, lr = [4.119780883888123e-05, 0.0004119780883888123]\n",
      "[INFO: 2022-02-16 17:15:32,127]   LabelSmoothing Loss = 2.745166063308716\n",
      "[INFO: 2022-02-16 17:15:41,862] Iteration 9340 (DataTime/BatchTime: 0.00246/0.487) losses = 2.8454, lr = [4.1286197186529546e-05, 0.0004128619718652954]\n",
      "[INFO: 2022-02-16 17:15:41,862]   LabelSmoothing Loss = 3.2568981647491455\n",
      "[INFO: 2022-02-16 17:15:51,380] Iteration 9360 (DataTime/BatchTime: 0.00128/0.476) losses = 2.6336, lr = [4.1374585534177866e-05, 0.0004137458553417786]\n",
      "[INFO: 2022-02-16 17:15:51,380]   LabelSmoothing Loss = 2.679344892501831\n",
      "[INFO: 2022-02-16 17:16:00,904] Iteration 9380 (DataTime/BatchTime: 0.00127/0.476) losses = 2.6489, lr = [4.1462973881826186e-05, 0.0004146297388182618]\n",
      "[INFO: 2022-02-16 17:16:00,904]   LabelSmoothing Loss = 2.3848876953125\n",
      "[INFO: 2022-02-16 17:16:10,429] Iteration 9400 (DataTime/BatchTime: 0.00253/0.476) losses = 2.6237, lr = [4.15513622294745e-05, 0.000415513622294745]\n",
      "[INFO: 2022-02-16 17:16:10,429]   LabelSmoothing Loss = 2.2650673389434814\n",
      "[INFO: 2022-02-16 17:16:20,008] Iteration 9420 (DataTime/BatchTime: 0.00212/0.479) losses = 2.7063, lr = [4.1639750577122826e-05, 0.0004163975057712282]\n",
      "[INFO: 2022-02-16 17:16:20,008]   LabelSmoothing Loss = 3.4606869220733643\n",
      "[INFO: 2022-02-16 17:16:29,598] Iteration 9440 (DataTime/BatchTime: 0.00128/0.48) losses = 2.8949, lr = [4.172813892477114e-05, 0.00041728138924771135]\n",
      "[INFO: 2022-02-16 17:16:29,598]   LabelSmoothing Loss = 4.075643062591553\n",
      "[INFO: 2022-02-16 17:16:39,108] Iteration 9460 (DataTime/BatchTime: 0.00127/0.475) losses = 2.5898, lr = [4.181652727241946e-05, 0.0004181652727241946]\n",
      "[INFO: 2022-02-16 17:16:39,108]   LabelSmoothing Loss = 2.3628346920013428\n",
      "[INFO: 2022-02-16 17:16:48,675] Iteration 9480 (DataTime/BatchTime: 0.00217/0.478) losses = 2.7064, lr = [4.190491562006778e-05, 0.0004190491562006777]\n",
      "[INFO: 2022-02-16 17:16:48,675]   LabelSmoothing Loss = 3.2905900478363037\n",
      "[INFO: 2022-02-16 17:16:58,216] Iteration 9500 (DataTime/BatchTime: 0.00127/0.477) losses = 2.5223, lr = [4.19933039677161e-05, 0.00041993303967716096]\n",
      "[INFO: 2022-02-16 17:16:58,216]   LabelSmoothing Loss = 2.364924192428589\n",
      "[INFO: 2022-02-16 17:17:07,764] Iteration 9520 (DataTime/BatchTime: 0.00126/0.477) losses = 2.826, lr = [4.208169231536441e-05, 0.0004208169231536441]\n",
      "[INFO: 2022-02-16 17:17:07,765]   LabelSmoothing Loss = 2.6055595874786377\n",
      "[INFO: 2022-02-16 17:17:17,356] Iteration 9540 (DataTime/BatchTime: 0.00326/0.48) losses = 2.7652, lr = [4.217008066301274e-05, 0.00042170080663012733]\n",
      "[INFO: 2022-02-16 17:17:17,356]   LabelSmoothing Loss = 3.116097927093506\n",
      "[INFO: 2022-02-16 17:20:52,151] ######## Epoch (VAL)10 ########\n",
      "[INFO: 2022-02-16 17:20:52,151] {'Bleu_1': 0.29650475147210525, 'Bleu_2': 0.19364070052688123, 'Bleu_3': 0.1366099210530055, 'Bleu_4': 0.09585553009791765, 'METEOR': 0.1757550886202129, 'ROUGE_L': 0.3486559561408683, 'CIDEr': 0.26137310241530803}\n",
      "[INFO: 2022-02-16 17:24:30,441] ######## Epoch (TEST)10 ########\n",
      "[INFO: 2022-02-16 17:24:30,442] {'Bleu_1': 0.2757722237434221, 'Bleu_2': 0.1755455296965636, 'Bleu_3': 0.12182955797185967, 'Bleu_4': 0.0847959782866886, 'METEOR': 0.16724224038146993, 'ROUGE_L': 0.33064972996395403, 'CIDEr': 0.23922764456815257}\n",
      "[INFO: 2022-02-16 17:24:36,927] Iteration 9560 (DataTime/BatchTime: 0.109/0.59) losses = 2.5179, lr = [4.225846901066105e-05, 0.00042258469010661047]\n",
      "[INFO: 2022-02-16 17:24:36,927]   LabelSmoothing Loss = 2.7137577533721924\n",
      "[INFO: 2022-02-16 17:24:46,558] Iteration 9580 (DataTime/BatchTime: 0.00369/0.482) losses = 2.5249, lr = [4.234685735830937e-05, 0.0004234685735830937]\n",
      "[INFO: 2022-02-16 17:24:46,558]   LabelSmoothing Loss = 2.6480958461761475\n",
      "[INFO: 2022-02-16 17:24:56,102] Iteration 9600 (DataTime/BatchTime: 0.0023/0.477) losses = 2.6092, lr = [4.243524570595769e-05, 0.00042435245705957684]\n",
      "[INFO: 2022-02-16 17:24:56,103]   LabelSmoothing Loss = 2.422800302505493\n",
      "[INFO: 2022-02-16 17:25:05,668] Iteration 9620 (DataTime/BatchTime: 0.0036/0.478) losses = 2.4909, lr = [4.252363405360601e-05, 0.0004252363405360601]\n",
      "[INFO: 2022-02-16 17:25:05,668]   LabelSmoothing Loss = 2.332101345062256\n",
      "[INFO: 2022-02-16 17:25:15,132] Iteration 9640 (DataTime/BatchTime: 0.00241/0.473) losses = 2.5761, lr = [4.2612022401254325e-05, 0.0004261202240125432]\n",
      "[INFO: 2022-02-16 17:25:15,132]   LabelSmoothing Loss = 2.899345636367798\n",
      "[INFO: 2022-02-16 17:25:24,582] Iteration 9660 (DataTime/BatchTime: 0.00348/0.473) losses = 2.4539, lr = [4.270041074890264e-05, 0.00042700410748902634]\n",
      "[INFO: 2022-02-16 17:25:24,582]   LabelSmoothing Loss = 2.567004442214966\n",
      "[INFO: 2022-02-16 17:25:34,101] Iteration 9680 (DataTime/BatchTime: 0.000972/0.475) losses = 2.573, lr = [4.2788799096550965e-05, 0.0004278879909655096]\n",
      "[INFO: 2022-02-16 17:25:34,102]   LabelSmoothing Loss = 2.10325288772583\n",
      "[INFO: 2022-02-16 17:25:43,653] Iteration 9700 (DataTime/BatchTime: 0.00184/0.478) losses = 2.5838, lr = [4.287718744419928e-05, 0.0004287718744419927]\n",
      "[INFO: 2022-02-16 17:25:43,654]   LabelSmoothing Loss = 1.3406037092208862\n",
      "[INFO: 2022-02-16 17:25:53,175] Iteration 9720 (DataTime/BatchTime: 0.00123/0.476) losses = 2.5407, lr = [4.29655757918476e-05, 0.00042965575791847595]\n",
      "[INFO: 2022-02-16 17:25:53,175]   LabelSmoothing Loss = 2.5284037590026855\n",
      "[INFO: 2022-02-16 17:26:02,553] Iteration 9740 (DataTime/BatchTime: 0.0012/0.469) losses = 2.579, lr = [4.305396413949592e-05, 0.0004305396413949591]\n",
      "[INFO: 2022-02-16 17:26:02,553]   LabelSmoothing Loss = 3.255537271499634\n",
      "[INFO: 2022-02-16 17:26:12,007] Iteration 9760 (DataTime/BatchTime: 0.00202/0.473) losses = 2.392, lr = [4.314235248714424e-05, 0.0004314235248714423]\n",
      "[INFO: 2022-02-16 17:26:12,007]   LabelSmoothing Loss = 2.872579336166382\n",
      "[INFO: 2022-02-16 17:26:21,503] Iteration 9780 (DataTime/BatchTime: 0.00119/0.475) losses = 2.4928, lr = [4.323074083479255e-05, 0.00043230740834792545]\n",
      "[INFO: 2022-02-16 17:26:21,503]   LabelSmoothing Loss = 2.564744234085083\n",
      "[INFO: 2022-02-16 17:26:30,981] Iteration 9800 (DataTime/BatchTime: 0.00116/0.474) losses = 2.4296, lr = [4.331912918244088e-05, 0.0004331912918244087]\n",
      "[INFO: 2022-02-16 17:26:30,981]   LabelSmoothing Loss = 2.6530652046203613\n",
      "[INFO: 2022-02-16 17:26:40,583] Iteration 9820 (DataTime/BatchTime: 0.00116/0.48) losses = 2.748, lr = [4.340751753008919e-05, 0.0004340751753008919]\n",
      "[INFO: 2022-02-16 17:26:40,583]   LabelSmoothing Loss = 1.9359815120697021\n",
      "[INFO: 2022-02-16 17:26:50,123] Iteration 9840 (DataTime/BatchTime: 0.00123/0.477) losses = 2.2679, lr = [4.349590587773751e-05, 0.00043495905877737506]\n",
      "[INFO: 2022-02-16 17:26:50,123]   LabelSmoothing Loss = 2.856792688369751\n",
      "[INFO: 2022-02-16 17:26:59,673] Iteration 9860 (DataTime/BatchTime: 0.00197/0.477) losses = 2.7448, lr = [4.358429422538583e-05, 0.00043584294225385825]\n",
      "[INFO: 2022-02-16 17:26:59,673]   LabelSmoothing Loss = 2.4610679149627686\n",
      "[INFO: 2022-02-16 17:27:09,208] Iteration 9880 (DataTime/BatchTime: 0.00194/0.477) losses = 2.4271, lr = [4.367268257303415e-05, 0.00043672682573034144]\n",
      "[INFO: 2022-02-16 17:27:09,208]   LabelSmoothing Loss = 1.699183702468872\n",
      "[INFO: 2022-02-16 17:27:18,745] Iteration 9900 (DataTime/BatchTime: 0.00115/0.477) losses = 2.7136, lr = [4.3761070920682463e-05, 0.0004376107092068246]\n",
      "[INFO: 2022-02-16 17:27:18,745]   LabelSmoothing Loss = 3.83024525642395\n",
      "[INFO: 2022-02-16 17:27:28,219] Iteration 9920 (DataTime/BatchTime: 0.00205/0.474) losses = 2.5268, lr = [4.384945926833079e-05, 0.0004384945926833078]\n",
      "[INFO: 2022-02-16 17:27:28,219]   LabelSmoothing Loss = 3.1407108306884766\n",
      "[INFO: 2022-02-16 17:27:37,695] Iteration 9940 (DataTime/BatchTime: 0.00118/0.474) losses = 2.3476, lr = [4.39378476159791e-05, 0.000439378476159791]\n",
      "[INFO: 2022-02-16 17:27:37,695]   LabelSmoothing Loss = 1.9419349431991577\n",
      "[INFO: 2022-02-16 17:27:47,223] Iteration 9960 (DataTime/BatchTime: 0.00296/0.476) losses = 2.494, lr = [4.402623596362742e-05, 0.0004402623596362742]\n",
      "[INFO: 2022-02-16 17:27:47,224]   LabelSmoothing Loss = 2.949148416519165\n",
      "[INFO: 2022-02-16 17:27:56,990] Iteration 9980 (DataTime/BatchTime: 0.00114/0.488) losses = 2.7198, lr = [4.411462431127574e-05, 0.00044114624311275736]\n",
      "[INFO: 2022-02-16 17:27:56,990]   LabelSmoothing Loss = 3.5181121826171875\n",
      "[INFO: 2022-02-16 17:28:06,625] Iteration 10000 (DataTime/BatchTime: 0.0021/0.482) losses = 2.6667, lr = [4.418975506957895e-05, 0.00044189755069578944]\n",
      "[INFO: 2022-02-16 17:28:06,625]   LabelSmoothing Loss = 2.2650866508483887\n",
      "[INFO: 2022-02-16 17:28:16,087] Iteration 10020 (DataTime/BatchTime: 0.00122/0.473) losses = 2.4444, lr = [4.4145640298604554e-05, 0.0004414564029860455]\n",
      "[INFO: 2022-02-16 17:28:16,087]   LabelSmoothing Loss = 1.6127263307571411\n",
      "[INFO: 2022-02-16 17:28:25,575] Iteration 10040 (DataTime/BatchTime: 0.00119/0.474) losses = 2.5326, lr = [4.410165738412885e-05, 0.0004410165738412884]\n",
      "[INFO: 2022-02-16 17:28:25,576]   LabelSmoothing Loss = 3.3180272579193115\n",
      "[INFO: 2022-02-16 17:28:35,102] Iteration 10060 (DataTime/BatchTime: 0.00207/0.476) losses = 2.5429, lr = [4.405780567060559e-05, 0.0004405780567060558]\n",
      "[INFO: 2022-02-16 17:28:35,102]   LabelSmoothing Loss = 2.5163674354553223\n",
      "[INFO: 2022-02-16 17:28:44,662] Iteration 10080 (DataTime/BatchTime: 0.00126/0.478) losses = 2.4039, lr = [4.401408450704226e-05, 0.0004401408450704226]\n",
      "[INFO: 2022-02-16 17:28:44,662]   LabelSmoothing Loss = 2.1052260398864746\n",
      "[INFO: 2022-02-16 17:28:54,234] Iteration 10100 (DataTime/BatchTime: 0.0013/0.479) losses = 2.4217, lr = [4.397049324695955e-05, 0.0004397049324695954]\n",
      "[INFO: 2022-02-16 17:28:54,234]   LabelSmoothing Loss = 3.2016677856445312\n",
      "[INFO: 2022-02-16 17:29:03,760] Iteration 10120 (DataTime/BatchTime: 0.00129/0.476) losses = 2.4798, lr = [4.392703124835115e-05, 0.00043927031248351147]\n",
      "[INFO: 2022-02-16 17:29:03,761]   LabelSmoothing Loss = 2.1756529808044434\n",
      "[INFO: 2022-02-16 17:29:13,332] Iteration 10140 (DataTime/BatchTime: 0.00129/0.479) losses = 2.471, lr = [4.388369787364407e-05, 0.0004388369787364407]\n",
      "[INFO: 2022-02-16 17:29:13,333]   LabelSmoothing Loss = 2.987283945083618\n",
      "[INFO: 2022-02-16 17:29:22,876] Iteration 10160 (DataTime/BatchTime: 0.00127/0.477) losses = 2.6001, lr = [4.3840492489659365e-05, 0.0004384049248965936]\n",
      "[INFO: 2022-02-16 17:29:22,877]   LabelSmoothing Loss = 2.2289483547210693\n",
      "[INFO: 2022-02-16 17:29:32,369] Iteration 10180 (DataTime/BatchTime: 0.00291/0.475) losses = 2.5911, lr = [4.379741446757323e-05, 0.00043797414467573227]\n",
      "[INFO: 2022-02-16 17:29:32,369]   LabelSmoothing Loss = 1.5644887685775757\n",
      "[INFO: 2022-02-16 17:29:41,885] Iteration 10200 (DataTime/BatchTime: 0.00128/0.476) losses = 2.5476, lr = [4.3754463182878596e-05, 0.00043754463182878596]\n",
      "[INFO: 2022-02-16 17:29:41,885]   LabelSmoothing Loss = 3.4252681732177734\n",
      "[INFO: 2022-02-16 17:29:51,449] Iteration 10220 (DataTime/BatchTime: 0.00127/0.478) losses = 2.8296, lr = [4.371163801534712e-05, 0.00043711638015347113]\n",
      "[INFO: 2022-02-16 17:29:51,449]   LabelSmoothing Loss = 2.6099209785461426\n",
      "[INFO: 2022-02-16 17:30:00,929] Iteration 10240 (DataTime/BatchTime: 0.00127/0.474) losses = 2.6698, lr = [4.366893834899153e-05, 0.0004366893834899152]\n",
      "[INFO: 2022-02-16 17:30:00,929]   LabelSmoothing Loss = 3.267847776412964\n",
      "[INFO: 2022-02-16 17:30:10,411] Iteration 10260 (DataTime/BatchTime: 0.00127/0.474) losses = 2.4883, lr = [4.362636357202842e-05, 0.00043626363572028413]\n",
      "[INFO: 2022-02-16 17:30:10,411]   LabelSmoothing Loss = 2.694568157196045\n",
      "[INFO: 2022-02-16 17:30:19,955] Iteration 10280 (DataTime/BatchTime: 0.00127/0.477) losses = 2.5543, lr = [4.3583913076841464e-05, 0.0004358391307684146]\n",
      "[INFO: 2022-02-16 17:30:19,955]   LabelSmoothing Loss = 1.763619065284729\n",
      "[INFO: 2022-02-16 17:30:29,439] Iteration 10300 (DataTime/BatchTime: 0.00127/0.474) losses = 2.496, lr = [4.354158625994496e-05, 0.00043541586259944953]\n",
      "[INFO: 2022-02-16 17:30:29,439]   LabelSmoothing Loss = 2.1104936599731445\n",
      "[INFO: 2022-02-16 17:30:38,997] Iteration 10320 (DataTime/BatchTime: 0.00126/0.478) losses = 2.5707, lr = [4.349938252194782e-05, 0.0004349938252194781]\n",
      "[INFO: 2022-02-16 17:30:38,997]   LabelSmoothing Loss = 2.3423144817352295\n",
      "[INFO: 2022-02-16 17:30:48,589] Iteration 10340 (DataTime/BatchTime: 0.00125/0.48) losses = 2.9513, lr = [4.345730126751789e-05, 0.0004345730126751789]\n",
      "[INFO: 2022-02-16 17:30:48,589]   LabelSmoothing Loss = 2.5923354625701904\n",
      "[INFO: 2022-02-16 17:30:58,105] Iteration 10360 (DataTime/BatchTime: 0.00128/0.476) losses = 2.6395, lr = [4.3415341905346724e-05, 0.00043415341905346717]\n",
      "[INFO: 2022-02-16 17:30:58,105]   LabelSmoothing Loss = 2.3044447898864746\n",
      "[INFO: 2022-02-16 17:31:07,566] Iteration 10380 (DataTime/BatchTime: 0.00126/0.473) losses = 2.3126, lr = [4.337350384811465e-05, 0.00043373503848114647]\n",
      "[INFO: 2022-02-16 17:31:07,566]   LabelSmoothing Loss = 2.4498560428619385\n",
      "[INFO: 2022-02-16 17:31:17,080] Iteration 10400 (DataTime/BatchTime: 0.00126/0.476) losses = 2.5553, lr = [4.333178651245625e-05, 0.0004333178651245624]\n",
      "[INFO: 2022-02-16 17:31:17,080]   LabelSmoothing Loss = 2.0837674140930176\n",
      "[INFO: 2022-02-16 17:31:26,644] Iteration 10420 (DataTime/BatchTime: 0.0021/0.478) losses = 2.5106, lr = [4.329018931892619e-05, 0.0004329018931892619]\n",
      "[INFO: 2022-02-16 17:31:26,644]   LabelSmoothing Loss = 1.8372851610183716\n",
      "[INFO: 2022-02-16 17:31:36,271] Iteration 10440 (DataTime/BatchTime: 0.00126/0.481) losses = 2.7078, lr = [4.324871169196545e-05, 0.0004324871169196544]\n",
      "[INFO: 2022-02-16 17:31:36,271]   LabelSmoothing Loss = 2.344026565551758\n",
      "[INFO: 2022-02-16 17:31:45,816] Iteration 10460 (DataTime/BatchTime: 0.00128/0.477) losses = 2.4231, lr = [4.320735305986783e-05, 0.0004320735305986782]\n",
      "[INFO: 2022-02-16 17:31:45,816]   LabelSmoothing Loss = 2.9721169471740723\n",
      "[INFO: 2022-02-16 17:31:55,297] Iteration 10480 (DataTime/BatchTime: 0.00127/0.474) losses = 2.4505, lr = [4.3166112854746876e-05, 0.0004316611285474687]\n",
      "[INFO: 2022-02-16 17:31:55,297]   LabelSmoothing Loss = 2.201262950897217\n",
      "[INFO: 2022-02-16 17:32:04,687] Iteration 10500 (DataTime/BatchTime: 0.002/0.469) losses = 2.5033, lr = [4.3124990512503143e-05, 0.0004312499051250314]\n",
      "[INFO: 2022-02-16 17:32:04,687]   LabelSmoothing Loss = 3.5608279705047607\n",
      "[INFO: 2022-02-16 17:35:37,677] ######## Epoch (VAL)11 ########\n",
      "[INFO: 2022-02-16 17:35:37,678] {'Bleu_1': 0.31156636062254633, 'Bleu_2': 0.19067079334339762, 'Bleu_3': 0.12790615478509734, 'Bleu_4': 0.09048089881467675, 'METEOR': 0.17410910851952466, 'ROUGE_L': 0.33212122116946136, 'CIDEr': 0.34671497668134876}\n",
      "[INFO: 2022-02-16 17:39:17,616] ######## Epoch (TEST)11 ########\n",
      "[INFO: 2022-02-16 17:39:17,617] {'Bleu_1': 0.28551832626906126, 'Bleu_2': 0.16508137779635412, 'Bleu_3': 0.10551119432317832, 'Bleu_4': 0.06944513454036848, 'METEOR': 0.1619008871617653, 'ROUGE_L': 0.3019118559677144, 'CIDEr': 0.21220425854303585}\n",
      "[INFO: 2022-02-16 17:39:26,366] Iteration 10520 (DataTime/BatchTime: 0.06/0.547) losses = 2.4939, lr = [4.308398547279175e-05, 0.0004308398547279175]\n",
      "[INFO: 2022-02-16 17:39:26,367]   LabelSmoothing Loss = 1.9377562999725342\n",
      "[INFO: 2022-02-16 17:39:35,944] Iteration 10540 (DataTime/BatchTime: 0.00331/0.479) losses = 2.2532, lr = [4.304309717899037e-05, 0.0004304309717899036]\n",
      "[INFO: 2022-02-16 17:39:35,944]   LabelSmoothing Loss = 3.2873311042785645\n",
      "[INFO: 2022-02-16 17:39:45,524] Iteration 10560 (DataTime/BatchTime: 0.00146/0.479) losses = 2.4621, lr = [4.30023250781674e-05, 0.000430023250781674]\n",
      "[INFO: 2022-02-16 17:39:45,524]   LabelSmoothing Loss = 2.590857744216919\n",
      "[INFO: 2022-02-16 17:39:55,124] Iteration 10580 (DataTime/BatchTime: 0.00332/0.48) losses = 2.627, lr = [4.296166862105069e-05, 0.00042961668621050683]\n",
      "[INFO: 2022-02-16 17:39:55,125]   LabelSmoothing Loss = 2.189291477203369\n",
      "[INFO: 2022-02-16 17:40:04,763] Iteration 10600 (DataTime/BatchTime: 0.00146/0.482) losses = 2.3202, lr = [4.2921127261996315e-05, 0.00042921127261996315]\n",
      "[INFO: 2022-02-16 17:40:04,763]   LabelSmoothing Loss = 2.130950689315796\n",
      "[INFO: 2022-02-16 17:40:14,359] Iteration 10620 (DataTime/BatchTime: 0.00145/0.48) losses = 2.4032, lr = [4.288070045895795e-05, 0.00042880700458957944]\n",
      "[INFO: 2022-02-16 17:40:14,359]   LabelSmoothing Loss = 2.1748499870300293\n",
      "[INFO: 2022-02-16 17:40:23,963] Iteration 10640 (DataTime/BatchTime: 0.00228/0.48) losses = 2.7294, lr = [4.284038767345632e-05, 0.0004284038767345632]\n",
      "[INFO: 2022-02-16 17:40:23,964]   LabelSmoothing Loss = 2.03613018989563\n",
      "[INFO: 2022-02-16 17:40:33,585] Iteration 10660 (DataTime/BatchTime: 0.00141/0.481) losses = 2.3011, lr = [4.280018837054918e-05, 0.0004280018837054917]\n",
      "[INFO: 2022-02-16 17:40:33,585]   LabelSmoothing Loss = 2.071225166320801\n",
      "[INFO: 2022-02-16 17:40:43,193] Iteration 10680 (DataTime/BatchTime: 0.00231/0.48) losses = 2.5397, lr = [4.276010201880141e-05, 0.000427601020188014]\n",
      "[INFO: 2022-02-16 17:40:43,193]   LabelSmoothing Loss = 2.795119524002075\n",
      "[INFO: 2022-02-16 17:40:52,787] Iteration 10700 (DataTime/BatchTime: 0.00238/0.48) losses = 2.4807, lr = [4.272012809025556e-05, 0.00042720128090255555]\n",
      "[INFO: 2022-02-16 17:40:52,787]   LabelSmoothing Loss = 2.1359949111938477\n",
      "[INFO: 2022-02-16 17:41:02,446] Iteration 10720 (DataTime/BatchTime: 0.00237/0.483) losses = 2.5748, lr = [4.268026606040263e-05, 0.0004268026606040263]\n",
      "[INFO: 2022-02-16 17:41:02,446]   LabelSmoothing Loss = 2.329045057296753\n",
      "[INFO: 2022-02-16 17:41:12,075] Iteration 10740 (DataTime/BatchTime: 0.00317/0.481) losses = 2.4617, lr = [4.2640515408153173e-05, 0.0004264051540815317]\n",
      "[INFO: 2022-02-16 17:41:12,075]   LabelSmoothing Loss = 2.227994441986084\n",
      "[INFO: 2022-02-16 17:41:21,677] Iteration 10760 (DataTime/BatchTime: 0.00315/0.48) losses = 2.4448, lr = [4.260087561580865e-05, 0.0004260087561580865]\n",
      "[INFO: 2022-02-16 17:41:21,677]   LabelSmoothing Loss = 2.124817132949829\n",
      "[INFO: 2022-02-16 17:41:31,258] Iteration 10780 (DataTime/BatchTime: 0.00145/0.479) losses = 2.5806, lr = [4.256134616903318e-05, 0.0004256134616903317]\n",
      "[INFO: 2022-02-16 17:41:31,258]   LabelSmoothing Loss = 2.9860427379608154\n",
      "[INFO: 2022-02-16 17:41:40,862] Iteration 10800 (DataTime/BatchTime: 0.00236/0.48) losses = 2.3504, lr = [4.252192655682543e-05, 0.0004252192655682542]\n",
      "[INFO: 2022-02-16 17:41:40,862]   LabelSmoothing Loss = 2.328930139541626\n",
      "[INFO: 2022-02-16 17:41:50,535] Iteration 10820 (DataTime/BatchTime: 0.00237/0.484) losses = 2.6772, lr = [4.248261627149092e-05, 0.0004248261627149092]\n",
      "[INFO: 2022-02-16 17:41:50,535]   LabelSmoothing Loss = 3.575775623321533\n",
      "[INFO: 2022-02-16 17:42:00,246] Iteration 10840 (DataTime/BatchTime: 0.00162/0.486) losses = 2.4068, lr = [4.2443414808614574e-05, 0.00042443414808614573]\n",
      "[INFO: 2022-02-16 17:42:00,247]   LabelSmoothing Loss = 1.331313967704773\n",
      "[INFO: 2022-02-16 17:42:09,906] Iteration 10860 (DataTime/BatchTime: 0.00154/0.483) losses = 2.4425, lr = [4.2404321667033486e-05, 0.0004240432166703348]\n",
      "[INFO: 2022-02-16 17:42:09,906]   LabelSmoothing Loss = 3.5873310565948486\n",
      "[INFO: 2022-02-16 17:42:19,491] Iteration 10880 (DataTime/BatchTime: 0.0023/0.479) losses = 2.6314, lr = [4.236533634881003e-05, 0.00042365336348810026]\n",
      "[INFO: 2022-02-16 17:42:19,491]   LabelSmoothing Loss = 3.125944137573242\n",
      "[INFO: 2022-02-16 17:42:29,049] Iteration 10900 (DataTime/BatchTime: 0.0016/0.478) losses = 2.3837, lr = [4.2326458359205254e-05, 0.00042326458359205247]\n",
      "[INFO: 2022-02-16 17:42:29,049]   LabelSmoothing Loss = 2.8058464527130127\n",
      "[INFO: 2022-02-16 17:42:38,656] Iteration 10920 (DataTime/BatchTime: 0.0024/0.48) losses = 2.5133, lr = [4.228768720665245e-05, 0.0004228768720665244]\n",
      "[INFO: 2022-02-16 17:42:38,656]   LabelSmoothing Loss = 1.5359127521514893\n",
      "[INFO: 2022-02-16 17:42:48,248] Iteration 10940 (DataTime/BatchTime: 0.00232/0.48) losses = 2.4073, lr = [4.22490224027311e-05, 0.00042249022402731095]\n",
      "[INFO: 2022-02-16 17:42:48,248]   LabelSmoothing Loss = 1.9459660053253174\n",
      "[INFO: 2022-02-16 17:42:57,822] Iteration 10960 (DataTime/BatchTime: 0.00234/0.479) losses = 2.363, lr = [4.221046346214104e-05, 0.00042210463462141035]\n",
      "[INFO: 2022-02-16 17:42:57,822]   LabelSmoothing Loss = 2.225186824798584\n",
      "[INFO: 2022-02-16 17:43:07,423] Iteration 10980 (DataTime/BatchTime: 0.00155/0.48) losses = 2.4095, lr = [4.2172009902676805e-05, 0.000421720099026768]\n",
      "[INFO: 2022-02-16 17:43:07,423]   LabelSmoothing Loss = 1.75931978225708\n",
      "[INFO: 2022-02-16 17:43:16,958] Iteration 11000 (DataTime/BatchTime: 0.0023/0.477) losses = 2.3466, lr = [4.213366124520238e-05, 0.00042133661245202374]\n",
      "[INFO: 2022-02-16 17:43:16,958]   LabelSmoothing Loss = 3.750647783279419\n",
      "[INFO: 2022-02-16 17:43:26,505] Iteration 11020 (DataTime/BatchTime: 0.00144/0.476) losses = 2.5891, lr = [4.209541701362609e-05, 0.0004209541701362608]\n",
      "[INFO: 2022-02-16 17:43:26,505]   LabelSmoothing Loss = 2.5418949127197266\n",
      "[INFO: 2022-02-16 17:43:36,102] Iteration 11040 (DataTime/BatchTime: 0.00265/0.481) losses = 2.4678, lr = [4.2057276734875765e-05, 0.0004205727673487576]\n",
      "[INFO: 2022-02-16 17:43:36,102]   LabelSmoothing Loss = 2.185476541519165\n",
      "[INFO: 2022-02-16 17:43:45,734] Iteration 11060 (DataTime/BatchTime: 0.00149/0.482) losses = 2.3698, lr = [4.2019239938874195e-05, 0.0004201923993887419]\n",
      "[INFO: 2022-02-16 17:43:45,734]   LabelSmoothing Loss = 2.630047559738159\n",
      "[INFO: 2022-02-16 17:43:55,347] Iteration 11080 (DataTime/BatchTime: 0.00147/0.481) losses = 2.4802, lr = [4.198130615851478e-05, 0.00041981306158514773]\n",
      "[INFO: 2022-02-16 17:43:55,348]   LabelSmoothing Loss = 2.5311732292175293\n",
      "[INFO: 2022-02-16 17:44:04,883] Iteration 11100 (DataTime/BatchTime: 0.00146/0.477) losses = 2.6658, lr = [4.1943474929637414e-05, 0.00041943474929637413]\n",
      "[INFO: 2022-02-16 17:44:04,883]   LabelSmoothing Loss = 3.309486150741577\n",
      "[INFO: 2022-02-16 17:44:14,523] Iteration 11120 (DataTime/BatchTime: 0.00147/0.482) losses = 2.3684, lr = [4.1905745791004676e-05, 0.0004190574579100467]\n",
      "[INFO: 2022-02-16 17:44:14,523]   LabelSmoothing Loss = 2.265577554702759\n",
      "[INFO: 2022-02-16 17:44:23,934] Iteration 11140 (DataTime/BatchTime: 0.00294/0.471) losses = 2.5465, lr = [4.186811828427817e-05, 0.00041868118284278167]\n",
      "[INFO: 2022-02-16 17:44:23,934]   LabelSmoothing Loss = 2.620441198348999\n",
      "[INFO: 2022-02-16 17:44:33,533] Iteration 11160 (DataTime/BatchTime: 0.0013/0.48) losses = 2.4034, lr = [4.183059195399517e-05, 0.00041830591953995167]\n",
      "[INFO: 2022-02-16 17:44:33,533]   LabelSmoothing Loss = 2.2692975997924805\n",
      "[INFO: 2022-02-16 17:44:43,059] Iteration 11180 (DataTime/BatchTime: 0.00115/0.476) losses = 2.6746, lr = [4.1793166347545443e-05, 0.0004179316634754544]\n",
      "[INFO: 2022-02-16 17:44:43,060]   LabelSmoothing Loss = 1.8131963014602661\n",
      "[INFO: 2022-02-16 17:44:52,701] Iteration 11200 (DataTime/BatchTime: 0.00112/0.482) losses = 2.7536, lr = [4.175584101514833e-05, 0.0004175584101514832]\n",
      "[INFO: 2022-02-16 17:44:52,701]   LabelSmoothing Loss = 4.014029502868652\n",
      "[INFO: 2022-02-16 17:45:02,194] Iteration 11220 (DataTime/BatchTime: 0.00111/0.475) losses = 2.4768, lr = [4.171861550983004e-05, 0.0004171861550983003]\n",
      "[INFO: 2022-02-16 17:45:02,194]   LabelSmoothing Loss = 2.57414174079895\n",
      "[INFO: 2022-02-16 17:45:11,758] Iteration 11240 (DataTime/BatchTime: 0.00119/0.478) losses = 2.5184, lr = [4.1681489387401185e-05, 0.0004168148938740118]\n",
      "[INFO: 2022-02-16 17:45:11,758]   LabelSmoothing Loss = 2.861461639404297\n",
      "[INFO: 2022-02-16 17:45:21,328] Iteration 11260 (DataTime/BatchTime: 0.00397/0.478) losses = 2.3318, lr = [4.164446220643449e-05, 0.0004164446220643449]\n",
      "[INFO: 2022-02-16 17:45:21,328]   LabelSmoothing Loss = 2.1681907176971436\n",
      "[INFO: 2022-02-16 17:45:30,919] Iteration 11280 (DataTime/BatchTime: 0.00213/0.48) losses = 2.6339, lr = [4.160753352824278e-05, 0.00041607533528242776]\n",
      "[INFO: 2022-02-16 17:45:30,919]   LabelSmoothing Loss = 3.8583459854125977\n",
      "[INFO: 2022-02-16 17:45:40,615] Iteration 11300 (DataTime/BatchTime: 0.00119/0.485) losses = 2.6875, lr = [4.157070291685712e-05, 0.0004157070291685712]\n",
      "[INFO: 2022-02-16 17:45:40,615]   LabelSmoothing Loss = 1.6156489849090576\n",
      "[INFO: 2022-02-16 17:45:50,147] Iteration 11320 (DataTime/BatchTime: 0.00111/0.477) losses = 2.4539, lr = [4.1533969939005215e-05, 0.00041533969939005214]\n",
      "[INFO: 2022-02-16 17:45:50,148]   LabelSmoothing Loss = 1.2443803548812866\n",
      "[INFO: 2022-02-16 17:45:59,718] Iteration 11340 (DataTime/BatchTime: 0.00112/0.479) losses = 2.5093, lr = [4.149733416409e-05, 0.00041497334164089994]\n",
      "[INFO: 2022-02-16 17:45:59,719]   LabelSmoothing Loss = 2.0223910808563232\n",
      "[INFO: 2022-02-16 17:46:09,219] Iteration 11360 (DataTime/BatchTime: 0.0022/0.475) losses = 2.5221, lr = [4.1460795164168444e-05, 0.0004146079516416844]\n",
      "[INFO: 2022-02-16 17:46:09,219]   LabelSmoothing Loss = 1.9096730947494507\n",
      "[INFO: 2022-02-16 17:46:18,619] Iteration 11380 (DataTime/BatchTime: 0.000973/0.469) losses = 2.496, lr = [4.1424352513930544e-05, 0.0004142435251393054]\n",
      "[INFO: 2022-02-16 17:46:18,620]   LabelSmoothing Loss = 2.288590669631958\n",
      "[INFO: 2022-02-16 17:46:28,023] Iteration 11400 (DataTime/BatchTime: 0.00193/0.471) losses = 2.393, lr = [4.138800579067855e-05, 0.0004138800579067855]\n",
      "[INFO: 2022-02-16 17:46:28,024]   LabelSmoothing Loss = 2.525480031967163\n",
      "[INFO: 2022-02-16 17:46:37,491] Iteration 11420 (DataTime/BatchTime: 0.00193/0.473) losses = 2.5389, lr = [4.135175457430634e-05, 0.0004135175457430634]\n",
      "[INFO: 2022-02-16 17:46:37,491]   LabelSmoothing Loss = 2.7244861125946045\n",
      "[INFO: 2022-02-16 17:46:46,995] Iteration 11440 (DataTime/BatchTime: 0.00184/0.475) losses = 2.1536, lr = [4.131559844727907e-05, 0.0004131559844727907]\n",
      "[INFO: 2022-02-16 17:46:46,996]   LabelSmoothing Loss = 1.819403052330017\n",
      "[INFO: 2022-02-16 17:50:29,818] ######## Epoch (VAL)12 ########\n",
      "[INFO: 2022-02-16 17:50:29,818] {'Bleu_1': 0.33851598510566655, 'Bleu_2': 0.20905704518873774, 'Bleu_3': 0.1395018538239687, 'Bleu_4': 0.0964650685752548, 'METEOR': 0.17657972815094491, 'ROUGE_L': 0.3330921085420392, 'CIDEr': 0.3192607719616489}\n",
      "[INFO: 2022-02-16 17:54:10,675] ######## Epoch (TEST)12 ########\n",
      "[INFO: 2022-02-16 17:54:10,676] {'Bleu_1': 0.31296679562229063, 'Bleu_2': 0.18628622439752723, 'Bleu_3': 0.11975080588338692, 'Bleu_4': 0.08056440746778099, 'METEOR': 0.16482532652466525, 'ROUGE_L': 0.3094169022873763, 'CIDEr': 0.27078650505213414}\n",
      "[INFO: 2022-02-16 17:54:12,200] Iteration 11460 (DataTime/BatchTime: 0.93/1.52) losses = 2.6037, lr = [4.127953699461294e-05, 0.0004127953699461294]\n",
      "[INFO: 2022-02-16 17:54:12,200]   LabelSmoothing Loss = 2.603715658187866\n",
      "[INFO: 2022-02-16 17:54:21,803] Iteration 11480 (DataTime/BatchTime: 0.00228/0.48) losses = 2.4131, lr = [4.124356980385521e-05, 0.000412435698038552]\n",
      "[INFO: 2022-02-16 17:54:21,803]   LabelSmoothing Loss = 1.573885202407837\n",
      "[INFO: 2022-02-16 17:54:31,372] Iteration 11500 (DataTime/BatchTime: 0.00509/0.478) losses = 2.591, lr = [4.120769646506436e-05, 0.0004120769646506436]\n",
      "[INFO: 2022-02-16 17:54:31,372]   LabelSmoothing Loss = 3.5804264545440674\n",
      "[INFO: 2022-02-16 17:54:40,902] Iteration 11520 (DataTime/BatchTime: 0.00224/0.477) losses = 2.3395, lr = [4.117191657079051e-05, 0.00041171916570790503]\n",
      "[INFO: 2022-02-16 17:54:40,903]   LabelSmoothing Loss = 2.263791561126709\n",
      "[INFO: 2022-02-16 17:54:50,595] Iteration 11540 (DataTime/BatchTime: 0.00423/0.485) losses = 2.61, lr = [4.113622971605594e-05, 0.0004113622971605593]\n",
      "[INFO: 2022-02-16 17:54:50,595]   LabelSmoothing Loss = 2.564633369445801\n",
      "[INFO: 2022-02-16 17:55:00,296] Iteration 11560 (DataTime/BatchTime: 0.00232/0.485) losses = 2.3619, lr = [4.110063549833585e-05, 0.00041100635498335846]\n",
      "[INFO: 2022-02-16 17:55:00,296]   LabelSmoothing Loss = 3.101609706878662\n",
      "[INFO: 2022-02-16 17:55:09,928] Iteration 11580 (DataTime/BatchTime: 0.00228/0.482) losses = 2.4122, lr = [4.1065133517539324e-05, 0.0004106513351753932]\n",
      "[INFO: 2022-02-16 17:55:09,928]   LabelSmoothing Loss = 3.252455949783325\n",
      "[INFO: 2022-02-16 17:55:19,599] Iteration 11600 (DataTime/BatchTime: 0.00141/0.484) losses = 2.3652, lr = [4.1029723375990384e-05, 0.0004102972337599038]\n",
      "[INFO: 2022-02-16 17:55:19,599]   LabelSmoothing Loss = 2.6708264350891113\n",
      "[INFO: 2022-02-16 17:55:29,264] Iteration 11620 (DataTime/BatchTime: 0.00229/0.483) losses = 2.5313, lr = [4.099440467840933e-05, 0.00040994404678409323]\n",
      "[INFO: 2022-02-16 17:55:29,264]   LabelSmoothing Loss = 2.849217414855957\n",
      "[INFO: 2022-02-16 17:55:39,010] Iteration 11640 (DataTime/BatchTime: 0.00221/0.487) losses = 2.3815, lr = [4.0959177031894175e-05, 0.00040959177031894167]\n",
      "[INFO: 2022-02-16 17:55:39,011]   LabelSmoothing Loss = 2.1922519207000732\n",
      "[INFO: 2022-02-16 17:55:48,782] Iteration 11660 (DataTime/BatchTime: 0.00159/0.489) losses = 2.538, lr = [4.09240400459023e-05, 0.00040924040045902294]\n",
      "[INFO: 2022-02-16 17:55:48,782]   LabelSmoothing Loss = 2.518178939819336\n",
      "[INFO: 2022-02-16 17:55:58,306] Iteration 11680 (DataTime/BatchTime: 0.00219/0.476) losses = 2.467, lr = [4.0888993332232284e-05, 0.00040888993332232276]\n",
      "[INFO: 2022-02-16 17:55:58,306]   LabelSmoothing Loss = 2.0940475463867188\n",
      "[INFO: 2022-02-16 17:56:07,830] Iteration 11700 (DataTime/BatchTime: 0.00216/0.476) losses = 2.4356, lr = [4.085403650500585e-05, 0.0004085403650500584]\n",
      "[INFO: 2022-02-16 17:56:07,830]   LabelSmoothing Loss = 2.74633526802063\n",
      "[INFO: 2022-02-16 17:56:17,477] Iteration 11720 (DataTime/BatchTime: 0.00306/0.482) losses = 2.4733, lr = [4.081916918065008e-05, 0.0004081916918065007]\n",
      "[INFO: 2022-02-16 17:56:17,477]   LabelSmoothing Loss = 2.305759906768799\n",
      "[INFO: 2022-02-16 17:56:27,084] Iteration 11740 (DataTime/BatchTime: 0.00127/0.48) losses = 2.3485, lr = [4.078439097787968e-05, 0.0004078439097787967]\n",
      "[INFO: 2022-02-16 17:56:27,084]   LabelSmoothing Loss = 3.2614243030548096\n",
      "[INFO: 2022-02-16 17:56:36,799] Iteration 11760 (DataTime/BatchTime: 0.0021/0.486) losses = 2.3904, lr = [4.074970151767948e-05, 0.0004074970151767948]\n",
      "[INFO: 2022-02-16 17:56:36,799]   LabelSmoothing Loss = 0.9389351010322571\n",
      "[INFO: 2022-02-16 17:56:46,518] Iteration 11780 (DataTime/BatchTime: 0.00212/0.486) losses = 2.6076, lr = [4.071510042328715e-05, 0.00040715100423287145]\n",
      "[INFO: 2022-02-16 17:56:46,518]   LabelSmoothing Loss = 1.9131269454956055\n",
      "[INFO: 2022-02-16 17:56:56,094] Iteration 11800 (DataTime/BatchTime: 0.00192/0.479) losses = 2.4788, lr = [4.0680587320175895e-05, 0.0004068058732017589]\n",
      "[INFO: 2022-02-16 17:56:56,094]   LabelSmoothing Loss = 2.1634116172790527\n",
      "[INFO: 2022-02-16 17:57:05,705] Iteration 11820 (DataTime/BatchTime: 0.00221/0.481) losses = 2.5327, lr = [4.064616183603753e-05, 0.00040646161836037527]\n",
      "[INFO: 2022-02-16 17:57:05,705]   LabelSmoothing Loss = 1.964662790298462\n",
      "[INFO: 2022-02-16 17:57:15,202] Iteration 11840 (DataTime/BatchTime: 0.00222/0.475) losses = 2.0735, lr = [4.061182360076558e-05, 0.0004061182360076557]\n",
      "[INFO: 2022-02-16 17:57:15,202]   LabelSmoothing Loss = 2.1194798946380615\n",
      "[INFO: 2022-02-16 17:57:24,716] Iteration 11860 (DataTime/BatchTime: 0.00302/0.476) losses = 2.4312, lr = [4.0577572246438536e-05, 0.00040577572246438534]\n",
      "[INFO: 2022-02-16 17:57:24,716]   LabelSmoothing Loss = 2.875352621078491\n",
      "[INFO: 2022-02-16 17:57:34,345] Iteration 11880 (DataTime/BatchTime: 0.00113/0.481) losses = 2.3554, lr = [4.0543407407303356e-05, 0.00040543407407303355]\n",
      "[INFO: 2022-02-16 17:57:34,345]   LabelSmoothing Loss = 2.550786018371582\n",
      "[INFO: 2022-02-16 17:57:43,819] Iteration 11900 (DataTime/BatchTime: 0.00258/0.474) losses = 2.0713, lr = [4.050932871975901e-05, 0.00040509328719759007]\n",
      "[INFO: 2022-02-16 17:57:43,820]   LabelSmoothing Loss = 1.8856053352355957\n",
      "[INFO: 2022-02-16 17:57:53,391] Iteration 11920 (DataTime/BatchTime: 0.00108/0.479) losses = 2.5638, lr = [4.0475335822340254e-05, 0.0004047533582234025]\n",
      "[INFO: 2022-02-16 17:57:53,391]   LabelSmoothing Loss = 2.414733409881592\n",
      "[INFO: 2022-02-16 17:58:02,948] Iteration 11940 (DataTime/BatchTime: 0.00138/0.478) losses = 2.0705, lr = [4.044142835570152e-05, 0.00040441428355701513]\n",
      "[INFO: 2022-02-16 17:58:02,948]   LabelSmoothing Loss = 1.772694706916809\n",
      "[INFO: 2022-02-16 17:58:12,526] Iteration 11960 (DataTime/BatchTime: 0.00116/0.479) losses = 2.3354, lr = [4.040760596260097e-05, 0.0004040760596260096]\n",
      "[INFO: 2022-02-16 17:58:12,526]   LabelSmoothing Loss = 2.6898369789123535\n",
      "[INFO: 2022-02-16 17:58:22,123] Iteration 11980 (DataTime/BatchTime: 0.00137/0.48) losses = 2.6058, lr = [4.0373868287884654e-05, 0.0004037386828788465]\n",
      "[INFO: 2022-02-16 17:58:22,123]   LabelSmoothing Loss = 2.7741284370422363\n",
      "[INFO: 2022-02-16 17:58:31,700] Iteration 12000 (DataTime/BatchTime: 0.00142/0.479) losses = 2.3124, lr = [4.0340214978470914e-05, 0.0004034021497847091]\n",
      "[INFO: 2022-02-16 17:58:31,700]   LabelSmoothing Loss = 2.3534576892852783\n",
      "[INFO: 2022-02-16 17:58:41,317] Iteration 12020 (DataTime/BatchTime: 0.00115/0.481) losses = 2.4861, lr = [4.0306645683334785e-05, 0.0004030664568333478]\n",
      "[INFO: 2022-02-16 17:58:41,318]   LabelSmoothing Loss = 2.293982982635498\n",
      "[INFO: 2022-02-16 17:58:50,874] Iteration 12040 (DataTime/BatchTime: 0.00118/0.478) losses = 2.5074, lr = [4.027316005349267e-05, 0.0004027316005349266]\n",
      "[INFO: 2022-02-16 17:58:50,874]   LabelSmoothing Loss = 3.04671573638916\n",
      "[INFO: 2022-02-16 17:59:00,433] Iteration 12060 (DataTime/BatchTime: 0.002/0.478) losses = 2.2849, lr = [4.023975774198708e-05, 0.00040239757741987074]\n",
      "[INFO: 2022-02-16 17:59:00,434]   LabelSmoothing Loss = 3.1604411602020264\n",
      "[INFO: 2022-02-16 17:59:09,995] Iteration 12080 (DataTime/BatchTime: 0.00197/0.478) losses = 2.1849, lr = [4.020643840387156e-05, 0.00040206438403871553]\n",
      "[INFO: 2022-02-16 17:59:09,996]   LabelSmoothing Loss = 2.8630549907684326\n",
      "[INFO: 2022-02-16 17:59:19,510] Iteration 12100 (DataTime/BatchTime: 0.00295/0.476) losses = 2.1406, lr = [4.0173201696195685e-05, 0.00040173201696195676]\n",
      "[INFO: 2022-02-16 17:59:19,510]   LabelSmoothing Loss = 1.4603161811828613\n",
      "[INFO: 2022-02-16 17:59:29,049] Iteration 12120 (DataTime/BatchTime: 0.00147/0.477) losses = 2.3605, lr = [4.014004727799028e-05, 0.00040140047277990274]\n",
      "[INFO: 2022-02-16 17:59:29,050]   LabelSmoothing Loss = 2.7432878017425537\n",
      "[INFO: 2022-02-16 17:59:38,558] Iteration 12140 (DataTime/BatchTime: 0.00116/0.475) losses = 2.2052, lr = [4.010697481025267e-05, 0.0004010697481025267]\n",
      "[INFO: 2022-02-16 17:59:38,558]   LabelSmoothing Loss = 2.684751272201538\n",
      "[INFO: 2022-02-16 17:59:48,160] Iteration 12160 (DataTime/BatchTime: 0.00133/0.48) losses = 2.4564, lr = [4.0073983955932216e-05, 0.00040073983955932213]\n",
      "[INFO: 2022-02-16 17:59:48,160]   LabelSmoothing Loss = 3.807158946990967\n",
      "[INFO: 2022-02-16 17:59:57,680] Iteration 12180 (DataTime/BatchTime: 0.00127/0.476) losses = 2.327, lr = [4.0041074379915785e-05, 0.0004004107437991578]\n",
      "[INFO: 2022-02-16 17:59:57,680]   LabelSmoothing Loss = 2.0067670345306396\n",
      "[INFO: 2022-02-16 18:00:07,227] Iteration 12200 (DataTime/BatchTime: 0.00203/0.477) losses = 2.7392, lr = [4.0008245749013506e-05, 0.00040008245749013503]\n",
      "[INFO: 2022-02-16 18:00:07,227]   LabelSmoothing Loss = 3.6521105766296387\n",
      "[INFO: 2022-02-16 18:00:16,848] Iteration 12220 (DataTime/BatchTime: 0.00116/0.481) losses = 2.4145, lr = [3.9975497731944604e-05, 0.00039975497731944596]\n",
      "[INFO: 2022-02-16 18:00:16,849]   LabelSmoothing Loss = 1.6235787868499756\n",
      "[INFO: 2022-02-16 18:00:26,396] Iteration 12240 (DataTime/BatchTime: 0.00223/0.477) losses = 2.4572, lr = [3.994282999932334e-05, 0.00039942829999323334]\n",
      "[INFO: 2022-02-16 18:00:26,397]   LabelSmoothing Loss = 3.1202585697174072\n",
      "[INFO: 2022-02-16 18:00:35,985] Iteration 12260 (DataTime/BatchTime: 0.00114/0.479) losses = 2.5163, lr = [3.9910242223645115e-05, 0.00039910242223645107]\n",
      "[INFO: 2022-02-16 18:00:35,985]   LabelSmoothing Loss = 1.52781343460083\n",
      "[INFO: 2022-02-16 18:00:45,572] Iteration 12280 (DataTime/BatchTime: 0.00212/0.479) losses = 2.4169, lr = [3.9877734079272654e-05, 0.0003987773407927265]\n",
      "[INFO: 2022-02-16 18:00:45,572]   LabelSmoothing Loss = 2.984930992126465\n",
      "[INFO: 2022-02-16 18:00:55,154] Iteration 12300 (DataTime/BatchTime: 0.00123/0.479) losses = 2.7098, lr = [3.984530524242237e-05, 0.00039845305242422366]\n",
      "[INFO: 2022-02-16 18:00:55,154]   LabelSmoothing Loss = 2.7594475746154785\n",
      "[INFO: 2022-02-16 18:01:04,659] Iteration 12320 (DataTime/BatchTime: 0.00214/0.475) losses = 2.4169, lr = [3.9812955391150806e-05, 0.000398129553911508]\n",
      "[INFO: 2022-02-16 18:01:04,659]   LabelSmoothing Loss = 1.886704921722412\n",
      "[INFO: 2022-02-16 18:01:14,184] Iteration 12340 (DataTime/BatchTime: 0.00215/0.476) losses = 2.3043, lr = [3.978068420534119e-05, 0.00039780684205341187]\n",
      "[INFO: 2022-02-16 18:01:14,184]   LabelSmoothing Loss = 2.640681266784668\n",
      "[INFO: 2022-02-16 18:01:23,783] Iteration 12360 (DataTime/BatchTime: 0.00121/0.479) losses = 2.8589, lr = [3.974849136669018e-05, 0.00039748491366690177]\n",
      "[INFO: 2022-02-16 18:01:23,783]   LabelSmoothing Loss = 2.396076202392578\n",
      "[INFO: 2022-02-16 18:01:33,345] Iteration 12380 (DataTime/BatchTime: 0.00204/0.479) losses = 2.5805, lr = [3.9716376558694623e-05, 0.0003971637655869462]\n",
      "[INFO: 2022-02-16 18:01:33,345]   LabelSmoothing Loss = 3.057343006134033\n",
      "[INFO: 2022-02-16 18:01:42,910] Iteration 12400 (DataTime/BatchTime: 0.00118/0.478) losses = 2.4562, lr = [3.968433946663852e-05, 0.0003968433946663851]\n",
      "[INFO: 2022-02-16 18:01:42,910]   LabelSmoothing Loss = 3.629894971847534\n",
      "[INFO: 2022-02-16 18:05:16,322] ######## Epoch (VAL)13 ########\n",
      "[INFO: 2022-02-16 18:05:16,322] {'Bleu_1': 0.32760169480705803, 'Bleu_2': 0.20970915348932903, 'Bleu_3': 0.14178929122537873, 'Bleu_4': 0.09559279909683363, 'METEOR': 0.18063868717989262, 'ROUGE_L': 0.3283817984876917, 'CIDEr': 0.22503895852843148}\n",
      "[INFO: 2022-02-16 18:08:51,640] ######## Epoch (TEST)13 ########\n",
      "[INFO: 2022-02-16 18:08:51,641] {'Bleu_1': 0.30322014429268873, 'Bleu_2': 0.19556017108204338, 'Bleu_3': 0.13496219959951408, 'Bleu_4': 0.09395243652411793, 'METEOR': 0.17150646552999427, 'ROUGE_L': 0.3173908866944552, 'CIDEr': 0.28433413055983797}\n",
      "[INFO: 2022-02-16 18:08:55,635] Iteration 12420 (DataTime/BatchTime: 0.173/0.666) losses = 2.1571, lr = [3.965237977758005e-05, 0.00039652379777580047]\n",
      "[INFO: 2022-02-16 18:08:55,636]   LabelSmoothing Loss = 2.0977694988250732\n",
      "[INFO: 2022-02-16 18:09:05,219] Iteration 12440 (DataTime/BatchTime: 0.00111/0.479) losses = 2.6123, lr = [3.962049718033877e-05, 0.00039620497180338764]\n",
      "[INFO: 2022-02-16 18:09:05,219]   LabelSmoothing Loss = 3.1057562828063965\n",
      "[INFO: 2022-02-16 18:09:14,774] Iteration 12460 (DataTime/BatchTime: 0.00267/0.478) losses = 2.2562, lr = [3.958869136548285e-05, 0.00039588691365482847]\n",
      "[INFO: 2022-02-16 18:09:14,774]   LabelSmoothing Loss = 1.749379277229309\n",
      "[INFO: 2022-02-16 18:09:24,220] Iteration 12480 (DataTime/BatchTime: 0.00109/0.472) losses = 2.4003, lr = [3.955696202531646e-05, 0.00039556962025316455]\n",
      "[INFO: 2022-02-16 18:09:24,220]   LabelSmoothing Loss = 2.652550220489502\n",
      "[INFO: 2022-02-16 18:09:33,675] Iteration 12500 (DataTime/BatchTime: 0.00186/0.472) losses = 2.4577, lr = [3.952530885386731e-05, 0.00039525308853867306]\n",
      "[INFO: 2022-02-16 18:09:33,675]   LabelSmoothing Loss = 1.6268925666809082\n",
      "[INFO: 2022-02-16 18:09:43,306] Iteration 12520 (DataTime/BatchTime: 0.00166/0.482) losses = 2.5139, lr = [3.949373154687421e-05, 0.000394937315468742]\n",
      "[INFO: 2022-02-16 18:09:43,306]   LabelSmoothing Loss = 2.1845943927764893\n",
      "[INFO: 2022-02-16 18:09:52,859] Iteration 12540 (DataTime/BatchTime: 0.00202/0.478) losses = 2.6795, lr = [3.946222980177479e-05, 0.0003946222980177478]\n",
      "[INFO: 2022-02-16 18:09:52,859]   LabelSmoothing Loss = 2.869835376739502\n",
      "[INFO: 2022-02-16 18:10:02,413] Iteration 12560 (DataTime/BatchTime: 0.00128/0.478) losses = 2.3275, lr = [3.943080331769337e-05, 0.00039430803317693365]\n",
      "[INFO: 2022-02-16 18:10:02,413]   LabelSmoothing Loss = 2.5301096439361572\n",
      "[INFO: 2022-02-16 18:10:12,045] Iteration 12580 (DataTime/BatchTime: 0.00445/0.482) losses = 2.5108, lr = [3.939945179542885e-05, 0.00039399451795428845]\n",
      "[INFO: 2022-02-16 18:10:12,046]   LabelSmoothing Loss = 2.900087833404541\n",
      "[INFO: 2022-02-16 18:10:21,589] Iteration 12600 (DataTime/BatchTime: 0.00118/0.477) losses = 2.31, lr = [3.9368174937442746e-05, 0.0003936817493744274]\n",
      "[INFO: 2022-02-16 18:10:21,589]   LabelSmoothing Loss = 1.906100869178772\n",
      "[INFO: 2022-02-16 18:10:31,034] Iteration 12620 (DataTime/BatchTime: 0.00112/0.472) losses = 2.2583, lr = [3.9336972447847335e-05, 0.00039336972447847333]\n",
      "[INFO: 2022-02-16 18:10:31,034]   LabelSmoothing Loss = 2.765986680984497\n",
      "[INFO: 2022-02-16 18:10:40,565] Iteration 12640 (DataTime/BatchTime: 0.00299/0.477) losses = 2.3306, lr = [3.930584403239393e-05, 0.00039305844032393926]\n",
      "[INFO: 2022-02-16 18:10:40,566]   LabelSmoothing Loss = 2.496044158935547\n",
      "[INFO: 2022-02-16 18:10:50,078] Iteration 12660 (DataTime/BatchTime: 0.00115/0.476) losses = 2.3452, lr = [3.927478939846116e-05, 0.0003927478939846116]\n",
      "[INFO: 2022-02-16 18:10:50,078]   LabelSmoothing Loss = 1.9452860355377197\n",
      "[INFO: 2022-02-16 18:10:59,640] Iteration 12680 (DataTime/BatchTime: 0.00122/0.478) losses = 2.2648, lr = [3.9243808255043484e-05, 0.0003924380825504348]\n",
      "[INFO: 2022-02-16 18:10:59,641]   LabelSmoothing Loss = 2.8002145290374756\n",
      "[INFO: 2022-02-16 18:11:09,138] Iteration 12700 (DataTime/BatchTime: 0.00113/0.475) losses = 2.1989, lr = [3.9212900312739694e-05, 0.00039212900312739695]\n",
      "[INFO: 2022-02-16 18:11:09,139]   LabelSmoothing Loss = 0.9557749629020691\n",
      "[INFO: 2022-02-16 18:11:18,717] Iteration 12720 (DataTime/BatchTime: 0.00201/0.479) losses = 2.2416, lr = [3.918206528374159e-05, 0.0003918206528374158]\n",
      "[INFO: 2022-02-16 18:11:18,717]   LabelSmoothing Loss = 2.6878833770751953\n",
      "[INFO: 2022-02-16 18:11:28,263] Iteration 12740 (DataTime/BatchTime: 0.00178/0.477) losses = 2.2973, lr = [3.9151302881822675e-05, 0.0003915130288182267]\n",
      "[INFO: 2022-02-16 18:11:28,263]   LabelSmoothing Loss = 2.6922171115875244\n",
      "[INFO: 2022-02-16 18:11:37,821] Iteration 12760 (DataTime/BatchTime: 0.00221/0.478) losses = 2.4643, lr = [3.9120612822327075e-05, 0.0003912061282232707]\n",
      "[INFO: 2022-02-16 18:11:37,822]   LabelSmoothing Loss = 3.416889190673828\n",
      "[INFO: 2022-02-16 18:11:47,322] Iteration 12780 (DataTime/BatchTime: 0.00112/0.475) losses = 2.1905, lr = [3.90899948221584e-05, 0.00039089994822158393]\n",
      "[INFO: 2022-02-16 18:11:47,322]   LabelSmoothing Loss = 2.701993942260742\n",
      "[INFO: 2022-02-16 18:11:56,834] Iteration 12800 (DataTime/BatchTime: 0.00196/0.476) losses = 2.1958, lr = [3.9059448599768816e-05, 0.00039059448599768813]\n",
      "[INFO: 2022-02-16 18:11:56,835]   LabelSmoothing Loss = 2.5312438011169434\n",
      "[INFO: 2022-02-16 18:12:06,429] Iteration 12820 (DataTime/BatchTime: 0.00116/0.48) losses = 2.6009, lr = [3.902897387514816e-05, 0.0003902897387514816]\n",
      "[INFO: 2022-02-16 18:12:06,430]   LabelSmoothing Loss = 2.8463706970214844\n",
      "[INFO: 2022-02-16 18:12:16,086] Iteration 12840 (DataTime/BatchTime: 0.00237/0.483) losses = 2.1824, lr = [3.8998570369813176e-05, 0.00038998570369813175]\n",
      "[INFO: 2022-02-16 18:12:16,086]   LabelSmoothing Loss = 2.580994129180908\n",
      "[INFO: 2022-02-16 18:12:25,657] Iteration 12860 (DataTime/BatchTime: 0.00155/0.479) losses = 2.4628, lr = [3.896823780679679e-05, 0.00038968237806796786]\n",
      "[INFO: 2022-02-16 18:12:25,657]   LabelSmoothing Loss = 3.118006467819214\n",
      "[INFO: 2022-02-16 18:12:35,187] Iteration 12880 (DataTime/BatchTime: 0.00156/0.476) losses = 2.2374, lr = [3.8937975910637536e-05, 0.00038937975910637533]\n",
      "[INFO: 2022-02-16 18:12:35,187]   LabelSmoothing Loss = 1.9276103973388672\n",
      "[INFO: 2022-02-16 18:12:44,790] Iteration 12900 (DataTime/BatchTime: 0.00458/0.48) losses = 2.4186, lr = [3.8907784407369075e-05, 0.0003890778440736907]\n",
      "[INFO: 2022-02-16 18:12:44,791]   LabelSmoothing Loss = 2.303248167037964\n",
      "[INFO: 2022-02-16 18:12:54,513] Iteration 12920 (DataTime/BatchTime: 0.00248/0.486) losses = 2.2533, lr = [3.8877663024509726e-05, 0.00038877663024509723]\n",
      "[INFO: 2022-02-16 18:12:54,513]   LabelSmoothing Loss = 1.7495136260986328\n",
      "[INFO: 2022-02-16 18:13:04,161] Iteration 12940 (DataTime/BatchTime: 0.00442/0.482) losses = 2.3762, lr = [3.8847611491052166e-05, 0.00038847611491052165]\n",
      "[INFO: 2022-02-16 18:13:04,161]   LabelSmoothing Loss = 2.9737699031829834\n",
      "[INFO: 2022-02-16 18:13:13,730] Iteration 12960 (DataTime/BatchTime: 0.00355/0.478) losses = 2.2599, lr = [3.8817629537453205e-05, 0.00038817629537453197]\n",
      "[INFO: 2022-02-16 18:13:13,730]   LabelSmoothing Loss = 2.198837995529175\n",
      "[INFO: 2022-02-16 18:13:23,361] Iteration 12980 (DataTime/BatchTime: 0.00361/0.482) losses = 2.506, lr = [3.878771689562358e-05, 0.0003878771689562358]\n",
      "[INFO: 2022-02-16 18:13:23,361]   LabelSmoothing Loss = 1.9324016571044922\n",
      "[INFO: 2022-02-16 18:13:32,992] Iteration 13000 (DataTime/BatchTime: 0.00339/0.482) losses = 2.1553, lr = [3.8757873298917944e-05, 0.0003875787329891794]\n",
      "[INFO: 2022-02-16 18:13:32,993]   LabelSmoothing Loss = 2.674794912338257\n",
      "[INFO: 2022-02-16 18:13:42,634] Iteration 13020 (DataTime/BatchTime: 0.00327/0.482) losses = 2.5814, lr = [3.872809848212486e-05, 0.0003872809848212485]\n",
      "[INFO: 2022-02-16 18:13:42,634]   LabelSmoothing Loss = 2.122690200805664\n",
      "[INFO: 2022-02-16 18:13:52,260] Iteration 13040 (DataTime/BatchTime: 0.00164/0.481) losses = 2.579, lr = [3.869839218145688e-05, 0.0003869839218145687]\n",
      "[INFO: 2022-02-16 18:13:52,260]   LabelSmoothing Loss = 2.337218999862671\n",
      "[INFO: 2022-02-16 18:14:01,942] Iteration 13060 (DataTime/BatchTime: 0.00523/0.484) losses = 2.3709, lr = [3.866875413454076e-05, 0.00038668754134540755]\n",
      "[INFO: 2022-02-16 18:14:01,942]   LabelSmoothing Loss = 2.182803153991699\n",
      "[INFO: 2022-02-16 18:14:11,779] Iteration 13080 (DataTime/BatchTime: 0.00249/0.492) losses = 2.6209, lr = [3.8639184080407724e-05, 0.00038639184080407717]\n",
      "[INFO: 2022-02-16 18:14:11,780]   LabelSmoothing Loss = 2.5303304195404053\n",
      "[INFO: 2022-02-16 18:14:21,590] Iteration 13100 (DataTime/BatchTime: 0.00185/0.491) losses = 2.5617, lr = [3.8609681759483803e-05, 0.00038609681759483797]\n",
      "[INFO: 2022-02-16 18:14:21,590]   LabelSmoothing Loss = 2.672910451889038\n",
      "[INFO: 2022-02-16 18:14:31,253] Iteration 13120 (DataTime/BatchTime: 0.00273/0.483) losses = 2.233, lr = [3.858024691358025e-05, 0.0003858024691358025]\n",
      "[INFO: 2022-02-16 18:14:31,253]   LabelSmoothing Loss = 2.641584873199463\n",
      "[INFO: 2022-02-16 18:14:41,078] Iteration 13140 (DataTime/BatchTime: 0.00254/0.491) losses = 2.3278, lr = [3.85508792858841e-05, 0.000385508792858841]\n",
      "[INFO: 2022-02-16 18:14:41,078]   LabelSmoothing Loss = 2.891855001449585\n",
      "[INFO: 2022-02-16 18:14:50,819] Iteration 13160 (DataTime/BatchTime: 0.00431/0.487) losses = 2.3549, lr = [3.85215786209487e-05, 0.00038521578620948695]\n",
      "[INFO: 2022-02-16 18:14:50,820]   LabelSmoothing Loss = 1.9224128723144531\n",
      "[INFO: 2022-02-16 18:15:00,499] Iteration 13180 (DataTime/BatchTime: 0.00247/0.484) losses = 2.3748, lr = [3.849234466468442e-05, 0.0003849234466468441]\n",
      "[INFO: 2022-02-16 18:15:00,499]   LabelSmoothing Loss = 2.701038360595703\n",
      "[INFO: 2022-02-16 18:15:10,208] Iteration 13200 (DataTime/BatchTime: 0.0033/0.485) losses = 2.5982, lr = [3.8463177164349354e-05, 0.0003846317716434935]\n",
      "[INFO: 2022-02-16 18:15:10,209]   LabelSmoothing Loss = 3.9349968433380127\n",
      "[INFO: 2022-02-16 18:15:19,848] Iteration 13220 (DataTime/BatchTime: 0.00255/0.482) losses = 2.3614, lr = [3.84340758685402e-05, 0.00038434075868540193]\n",
      "[INFO: 2022-02-16 18:15:19,848]   LabelSmoothing Loss = 3.283874034881592\n",
      "[INFO: 2022-02-16 18:15:29,416] Iteration 13240 (DataTime/BatchTime: 0.00319/0.478) losses = 2.4107, lr = [3.840504052718313e-05, 0.0003840504052718312]\n",
      "[INFO: 2022-02-16 18:15:29,417]   LabelSmoothing Loss = 1.4519214630126953\n",
      "[INFO: 2022-02-16 18:15:39,008] Iteration 13260 (DataTime/BatchTime: 0.00267/0.48) losses = 2.5656, lr = [3.837607089152474e-05, 0.00038376070891524733]\n",
      "[INFO: 2022-02-16 18:15:39,008]   LabelSmoothing Loss = 3.3462026119232178\n",
      "[INFO: 2022-02-16 18:15:48,641] Iteration 13280 (DataTime/BatchTime: 0.00322/0.482) losses = 2.3686, lr = [3.8347166714123135e-05, 0.00038347166714123134]\n",
      "[INFO: 2022-02-16 18:15:48,641]   LabelSmoothing Loss = 3.010676145553589\n",
      "[INFO: 2022-02-16 18:15:58,248] Iteration 13300 (DataTime/BatchTime: 0.0034/0.48) losses = 2.5023, lr = [3.831832774883905e-05, 0.00038318327748839044]\n",
      "[INFO: 2022-02-16 18:15:58,249]   LabelSmoothing Loss = 1.8606419563293457\n",
      "[INFO: 2022-02-16 18:16:07,834] Iteration 13320 (DataTime/BatchTime: 0.00241/0.479) losses = 2.2292, lr = [3.828955375082703e-05, 0.0003828955375082702]\n",
      "[INFO: 2022-02-16 18:16:07,835]   LabelSmoothing Loss = 2.0384440422058105\n",
      "[INFO: 2022-02-16 18:16:17,480] Iteration 13340 (DataTime/BatchTime: 0.00259/0.482) losses = 2.2439, lr = [3.82608444765267e-05, 0.000382608444765267]\n",
      "[INFO: 2022-02-16 18:16:17,480]   LabelSmoothing Loss = 1.5802383422851562\n",
      "[INFO: 2022-02-16 18:16:27,075] Iteration 13360 (DataTime/BatchTime: 0.00247/0.48) losses = 2.3491, lr = [3.823219968365411e-05, 0.000382321996836541]\n",
      "[INFO: 2022-02-16 18:16:27,075]   LabelSmoothing Loss = 2.2532401084899902\n",
      "[INFO: 2022-02-16 18:20:05,766] ######## Epoch (VAL)14 ########\n",
      "[INFO: 2022-02-16 18:20:05,767] {'Bleu_1': 0.32860671584673945, 'Bleu_2': 0.20961021572804275, 'Bleu_3': 0.14532447696361792, 'Bleu_4': 0.10318615378739704, 'METEOR': 0.17886944444657424, 'ROUGE_L': 0.33384675829722976, 'CIDEr': 0.21483070599718163}\n",
      "[INFO: 2022-02-16 18:23:44,698] ######## Epoch (TEST)14 ########\n",
      "[INFO: 2022-02-16 18:23:44,699] {'Bleu_1': 0.3163141009925444, 'Bleu_2': 0.1925237553130506, 'Bleu_3': 0.1280970227193625, 'Bleu_4': 0.08736648439886895, 'METEOR': 0.17231738657584686, 'ROUGE_L': 0.31507772613697166, 'CIDEr': 0.2446624029735795}\n",
      "[INFO: 2022-02-16 18:23:51,060] Iteration 13380 (DataTime/BatchTime: 0.099/0.578) losses = 2.1867, lr = [3.820361913119316e-05, 0.0003820361913119315]\n",
      "[INFO: 2022-02-16 18:23:51,061]   LabelSmoothing Loss = 2.7373616695404053\n",
      "[INFO: 2022-02-16 18:24:00,474] Iteration 13400 (DataTime/BatchTime: 0.00139/0.471) losses = 2.2621, lr = [3.817510257938707e-05, 0.0003817510257938706]\n",
      "[INFO: 2022-02-16 18:24:00,474]   LabelSmoothing Loss = 3.659235954284668\n",
      "[INFO: 2022-02-16 18:24:09,967] Iteration 13420 (DataTime/BatchTime: 0.0013/0.475) losses = 2.254, lr = [3.8146649789729914e-05, 0.0003814664978972991]\n",
      "[INFO: 2022-02-16 18:24:09,967]   LabelSmoothing Loss = 1.730095386505127\n",
      "[INFO: 2022-02-16 18:24:19,567] Iteration 13440 (DataTime/BatchTime: 0.00329/0.48) losses = 2.5524, lr = [3.8118260524958306e-05, 0.000381182605249583]\n",
      "[INFO: 2022-02-16 18:24:19,567]   LabelSmoothing Loss = 2.985100030899048\n",
      "[INFO: 2022-02-16 18:24:29,184] Iteration 13460 (DataTime/BatchTime: 0.00139/0.481) losses = 2.3662, lr = [3.808993454904299e-05, 0.0003808993454904299]\n",
      "[INFO: 2022-02-16 18:24:29,184]   LabelSmoothing Loss = 2.448162078857422\n",
      "[INFO: 2022-02-16 18:24:38,775] Iteration 13480 (DataTime/BatchTime: 0.00242/0.48) losses = 1.9988, lr = [3.806167162718072e-05, 0.0003806167162718071]\n",
      "[INFO: 2022-02-16 18:24:38,775]   LabelSmoothing Loss = 1.413167953491211\n",
      "[INFO: 2022-02-16 18:24:48,317] Iteration 13500 (DataTime/BatchTime: 0.00214/0.477) losses = 2.5059, lr = [3.803347152578595e-05, 0.00038033471525785947]\n",
      "[INFO: 2022-02-16 18:24:48,317]   LabelSmoothing Loss = 1.972231149673462\n",
      "[INFO: 2022-02-16 18:24:57,829] Iteration 13520 (DataTime/BatchTime: 0.00211/0.476) losses = 2.271, lr = [3.8005334012482846e-05, 0.0003800533401248284]\n",
      "[INFO: 2022-02-16 18:24:57,829]   LabelSmoothing Loss = 1.8870303630828857\n",
      "[INFO: 2022-02-16 18:25:07,333] Iteration 13540 (DataTime/BatchTime: 0.00287/0.475) losses = 2.4399, lr = [3.797725885609717e-05, 0.0003797725885609716]\n",
      "[INFO: 2022-02-16 18:25:07,333]   LabelSmoothing Loss = 3.1075589656829834\n",
      "[INFO: 2022-02-16 18:25:16,869] Iteration 13560 (DataTime/BatchTime: 0.00121/0.477) losses = 2.4102, lr = [3.794924582664832e-05, 0.0003794924582664832]\n",
      "[INFO: 2022-02-16 18:25:16,869]   LabelSmoothing Loss = 2.418926954269409\n",
      "[INFO: 2022-02-16 18:25:26,387] Iteration 13580 (DataTime/BatchTime: 0.0012/0.476) losses = 2.3632, lr = [3.7921294695341465e-05, 0.00037921294695341464]\n",
      "[INFO: 2022-02-16 18:25:26,387]   LabelSmoothing Loss = 1.1488900184631348\n",
      "[INFO: 2022-02-16 18:25:35,887] Iteration 13600 (DataTime/BatchTime: 0.00411/0.475) losses = 2.2716, lr = [3.7893405234559604e-05, 0.000378934052345596]\n",
      "[INFO: 2022-02-16 18:25:35,887]   LabelSmoothing Loss = 2.0939998626708984\n",
      "[INFO: 2022-02-16 18:25:45,484] Iteration 13620 (DataTime/BatchTime: 0.00147/0.48) losses = 2.578, lr = [3.7865577217855853e-05, 0.0003786557721785585]\n",
      "[INFO: 2022-02-16 18:25:45,484]   LabelSmoothing Loss = 2.867253303527832\n",
      "[INFO: 2022-02-16 18:25:55,033] Iteration 13640 (DataTime/BatchTime: 0.00118/0.477) losses = 2.5177, lr = [3.783781041994571e-05, 0.000378378104199457]\n",
      "[INFO: 2022-02-16 18:25:55,034]   LabelSmoothing Loss = 1.9979006052017212\n",
      "[INFO: 2022-02-16 18:26:04,559] Iteration 13660 (DataTime/BatchTime: 0.00112/0.476) losses = 2.4103, lr = [3.781010461669936e-05, 0.0003781010461669936]\n",
      "[INFO: 2022-02-16 18:26:04,559]   LabelSmoothing Loss = 2.376295566558838\n",
      "[INFO: 2022-02-16 18:26:14,147] Iteration 13680 (DataTime/BatchTime: 0.0012/0.479) losses = 2.4535, lr = [3.7782459585134155e-05, 0.0003778245958513415]\n",
      "[INFO: 2022-02-16 18:26:14,147]   LabelSmoothing Loss = 1.141228199005127\n",
      "[INFO: 2022-02-16 18:26:23,680] Iteration 13700 (DataTime/BatchTime: 0.0012/0.477) losses = 2.2623, lr = [3.775487510340695e-05, 0.0003775487510340695]\n",
      "[INFO: 2022-02-16 18:26:23,681]   LabelSmoothing Loss = 2.39550518989563\n",
      "[INFO: 2022-02-16 18:26:33,238] Iteration 13720 (DataTime/BatchTime: 0.00129/0.478) losses = 2.4883, lr = [3.772735095080677e-05, 0.0003772735095080677]\n",
      "[INFO: 2022-02-16 18:26:33,238]   LabelSmoothing Loss = 3.0030195713043213\n",
      "[INFO: 2022-02-16 18:26:42,789] Iteration 13740 (DataTime/BatchTime: 0.00126/0.478) losses = 2.3438, lr = [3.769988690774729e-05, 0.0003769988690774729]\n",
      "[INFO: 2022-02-16 18:26:42,789]   LabelSmoothing Loss = 1.4637336730957031\n",
      "[INFO: 2022-02-16 18:26:52,291] Iteration 13760 (DataTime/BatchTime: 0.00215/0.475) losses = 2.4235, lr = [3.76724827557595e-05, 0.00037672482755759504]\n",
      "[INFO: 2022-02-16 18:26:52,291]   LabelSmoothing Loss = 1.6203147172927856\n",
      "[INFO: 2022-02-16 18:27:01,772] Iteration 13780 (DataTime/BatchTime: 0.00127/0.474) losses = 2.132, lr = [3.764513827748445e-05, 0.00037645138277484446]\n",
      "[INFO: 2022-02-16 18:27:01,773]   LabelSmoothing Loss = 1.8438994884490967\n",
      "[INFO: 2022-02-16 18:27:11,293] Iteration 13800 (DataTime/BatchTime: 0.00128/0.476) losses = 2.1563, lr = [3.761785325666594e-05, 0.0003761785325666594]\n",
      "[INFO: 2022-02-16 18:27:11,293]   LabelSmoothing Loss = 1.4132053852081299\n",
      "[INFO: 2022-02-16 18:27:20,774] Iteration 13820 (DataTime/BatchTime: 0.00208/0.473) losses = 2.4192, lr = [3.759062747814341e-05, 0.00037590627478143406]\n",
      "[INFO: 2022-02-16 18:27:20,774]   LabelSmoothing Loss = 1.9266294240951538\n",
      "[INFO: 2022-02-16 18:27:30,288] Iteration 13840 (DataTime/BatchTime: 0.00209/0.477) losses = 2.374, lr = [3.7563460727844737e-05, 0.0003756346072784473]\n",
      "[INFO: 2022-02-16 18:27:30,288]   LabelSmoothing Loss = 2.9874963760375977\n",
      "[INFO: 2022-02-16 18:27:39,768] Iteration 13860 (DataTime/BatchTime: 0.00128/0.474) losses = 2.2246, lr = [3.753635279277924e-05, 0.00037536352792779233]\n",
      "[INFO: 2022-02-16 18:27:39,768]   LabelSmoothing Loss = 2.4856200218200684\n",
      "[INFO: 2022-02-16 18:27:49,298] Iteration 13880 (DataTime/BatchTime: 0.00129/0.477) losses = 2.2193, lr = [3.750930346103059e-05, 0.0003750930346103059]\n",
      "[INFO: 2022-02-16 18:27:49,298]   LabelSmoothing Loss = 2.287912368774414\n",
      "[INFO: 2022-02-16 18:27:58,822] Iteration 13900 (DataTime/BatchTime: 0.0013/0.476) losses = 2.3652, lr = [3.748231252174995e-05, 0.0003748231252174995]\n",
      "[INFO: 2022-02-16 18:27:58,822]   LabelSmoothing Loss = 2.496431350708008\n",
      "[INFO: 2022-02-16 18:28:08,370] Iteration 13920 (DataTime/BatchTime: 0.0021/0.477) losses = 2.0822, lr = [3.745537976514897e-05, 0.00037455379765148964]\n",
      "[INFO: 2022-02-16 18:28:08,370]   LabelSmoothing Loss = 2.642324447631836\n",
      "[INFO: 2022-02-16 18:28:17,842] Iteration 13940 (DataTime/BatchTime: 0.00127/0.474) losses = 2.2471, lr = [3.742850498249298e-05, 0.00037428504982492974]\n",
      "[INFO: 2022-02-16 18:28:17,843]   LabelSmoothing Loss = 2.5964736938476562\n",
      "[INFO: 2022-02-16 18:28:27,370] Iteration 13960 (DataTime/BatchTime: 0.0021/0.476) losses = 2.5264, lr = [3.7401687966094245e-05, 0.00037401687966094236]\n",
      "[INFO: 2022-02-16 18:28:27,370]   LabelSmoothing Loss = 1.8479715585708618\n",
      "[INFO: 2022-02-16 18:28:36,901] Iteration 13980 (DataTime/BatchTime: 0.00128/0.477) losses = 2.306, lr = [3.7374928509305126e-05, 0.0003737492850930512]\n",
      "[INFO: 2022-02-16 18:28:36,901]   LabelSmoothing Loss = 2.7653558254241943\n",
      "[INFO: 2022-02-16 18:28:46,371] Iteration 14000 (DataTime/BatchTime: 0.00128/0.473) losses = 2.245, lr = [3.734822640651148e-05, 0.0003734822640651148]\n",
      "[INFO: 2022-02-16 18:28:46,371]   LabelSmoothing Loss = 1.3021268844604492\n",
      "[INFO: 2022-02-16 18:28:55,949] Iteration 14020 (DataTime/BatchTime: 0.00212/0.479) losses = 2.4763, lr = [3.732158145312598e-05, 0.00037321581453125975]\n",
      "[INFO: 2022-02-16 18:28:55,950]   LabelSmoothing Loss = 3.59175705909729\n",
      "[INFO: 2022-02-16 18:29:05,478] Iteration 14040 (DataTime/BatchTime: 0.00135/0.476) losses = 2.3402, lr = [3.729499344558152e-05, 0.00037294993445581516]\n",
      "[INFO: 2022-02-16 18:29:05,478]   LabelSmoothing Loss = 2.013381004333496\n",
      "[INFO: 2022-02-16 18:29:14,960] Iteration 14060 (DataTime/BatchTime: 0.00212/0.474) losses = 2.2445, lr = [3.726846218132472e-05, 0.0003726846218132472]\n",
      "[INFO: 2022-02-16 18:29:14,961]   LabelSmoothing Loss = 2.538689136505127\n",
      "[INFO: 2022-02-16 18:29:24,503] Iteration 14080 (DataTime/BatchTime: 0.0013/0.477) losses = 2.4851, lr = [3.724198745880944e-05, 0.00037241987458809436]\n",
      "[INFO: 2022-02-16 18:29:24,503]   LabelSmoothing Loss = 2.651784896850586\n",
      "[INFO: 2022-02-16 18:29:33,999] Iteration 14100 (DataTime/BatchTime: 0.00128/0.475) losses = 2.4402, lr = [3.721556907749031e-05, 0.00037215569077490303]\n",
      "[INFO: 2022-02-16 18:29:33,999]   LabelSmoothing Loss = 2.6840014457702637\n",
      "[INFO: 2022-02-16 18:29:43,487] Iteration 14120 (DataTime/BatchTime: 0.00129/0.474) losses = 2.2605, lr = [3.7189206837816385e-05, 0.00037189206837816383]\n",
      "[INFO: 2022-02-16 18:29:43,488]   LabelSmoothing Loss = 1.0396506786346436\n",
      "[INFO: 2022-02-16 18:29:52,995] Iteration 14140 (DataTime/BatchTime: 0.00136/0.475) losses = 2.2185, lr = [3.7162900541224823e-05, 0.00037162900541224823]\n",
      "[INFO: 2022-02-16 18:29:52,995]   LabelSmoothing Loss = 2.106153964996338\n",
      "[INFO: 2022-02-16 18:30:02,471] Iteration 14160 (DataTime/BatchTime: 0.00144/0.474) losses = 2.4389, lr = [3.713664999013457e-05, 0.00037136649990134567]\n",
      "[INFO: 2022-02-16 18:30:02,471]   LabelSmoothing Loss = 3.1522483825683594\n",
      "[INFO: 2022-02-16 18:30:11,963] Iteration 14180 (DataTime/BatchTime: 0.00129/0.475) losses = 2.3675, lr = [3.711045498794014e-05, 0.0003711045498794014]\n",
      "[INFO: 2022-02-16 18:30:11,963]   LabelSmoothing Loss = 2.3220558166503906\n",
      "[INFO: 2022-02-16 18:30:21,452] Iteration 14200 (DataTime/BatchTime: 0.00129/0.474) losses = 2.2839, lr = [3.708431533900544e-05, 0.0003708431533900544]\n",
      "[INFO: 2022-02-16 18:30:21,452]   LabelSmoothing Loss = 2.0374014377593994\n",
      "[INFO: 2022-02-16 18:30:31,055] Iteration 14220 (DataTime/BatchTime: 0.00126/0.48) losses = 2.282, lr = [3.7058230848657644e-05, 0.0003705823084865764]\n",
      "[INFO: 2022-02-16 18:30:31,055]   LabelSmoothing Loss = 1.571202278137207\n",
      "[INFO: 2022-02-16 18:30:40,704] Iteration 14240 (DataTime/BatchTime: 0.00239/0.482) losses = 2.2031, lr = [3.7032201323181054e-05, 0.00037032201323181053]\n",
      "[INFO: 2022-02-16 18:30:40,704]   LabelSmoothing Loss = 2.5402464866638184\n",
      "[INFO: 2022-02-16 18:30:50,363] Iteration 14260 (DataTime/BatchTime: 0.00203/0.483) losses = 2.1586, lr = [3.700622656981112e-05, 0.00037006226569811113]\n",
      "[INFO: 2022-02-16 18:30:50,363]   LabelSmoothing Loss = 1.430064082145691\n",
      "[INFO: 2022-02-16 18:31:00,075] Iteration 14280 (DataTime/BatchTime: 0.00165/0.486) losses = 2.2039, lr = [3.69803063967284e-05, 0.0003698030639672839]\n",
      "[INFO: 2022-02-16 18:31:00,075]   LabelSmoothing Loss = 2.3386623859405518\n",
      "[INFO: 2022-02-16 18:31:09,660] Iteration 14300 (DataTime/BatchTime: 0.00131/0.479) losses = 2.4417, lr = [3.695444061305263e-05, 0.00036954440613052626]\n",
      "[INFO: 2022-02-16 18:31:09,660]   LabelSmoothing Loss = 2.689213514328003\n",
      "[INFO: 2022-02-16 18:31:19,239] Iteration 14320 (DataTime/BatchTime: 0.00127/0.479) losses = 2.3411, lr = [3.692862902883681e-05, 0.00036928629028836813]\n",
      "[INFO: 2022-02-16 18:31:19,239]   LabelSmoothing Loss = 3.1799073219299316\n",
      "[INFO: 2022-02-16 18:34:52,938] ######## Epoch (VAL)15 ########\n",
      "[INFO: 2022-02-16 18:34:52,939] {'Bleu_1': 0.3684988506779151, 'Bleu_2': 0.22665556132258446, 'Bleu_3': 0.15029522867378334, 'Bleu_4': 0.10208961437929659, 'METEOR': 0.18531006155709495, 'ROUGE_L': 0.33357720414186687, 'CIDEr': 0.3156354736735075}\n",
      "[INFO: 2022-02-16 18:38:34,187] ######## Epoch (TEST)15 ########\n",
      "[INFO: 2022-02-16 18:38:34,188] {'Bleu_1': 0.3420254940562698, 'Bleu_2': 0.2049566508264836, 'Bleu_3': 0.1328029533539528, 'Bleu_4': 0.08960638874807035, 'METEOR': 0.17415731244266688, 'ROUGE_L': 0.3082530447653692, 'CIDEr': 0.3113433973118467}\n",
      "[INFO: 2022-02-16 18:38:42,839] Iteration 14340 (DataTime/BatchTime: 0.0595/0.541) losses = 2.2833, lr = [3.6902871455061366e-05, 0.00036902871455061364]\n",
      "[INFO: 2022-02-16 18:38:42,839]   LabelSmoothing Loss = 1.2674221992492676\n",
      "[INFO: 2022-02-16 18:38:52,639] Iteration 14360 (DataTime/BatchTime: 0.00152/0.49) losses = 2.4763, lr = [3.687716770362831e-05, 0.00036877167703628304]\n",
      "[INFO: 2022-02-16 18:38:52,639]   LabelSmoothing Loss = 2.3229124546051025\n",
      "[INFO: 2022-02-16 18:39:02,189] Iteration 14380 (DataTime/BatchTime: 0.00146/0.477) losses = 2.2782, lr = [3.685151758735548e-05, 0.00036851517587355474]\n",
      "[INFO: 2022-02-16 18:39:02,189]   LabelSmoothing Loss = 2.7474629878997803\n",
      "[INFO: 2022-02-16 18:39:11,876] Iteration 14400 (DataTime/BatchTime: 0.00241/0.484) losses = 2.3587, lr = [3.682592091997082e-05, 0.00036825920919970813]\n",
      "[INFO: 2022-02-16 18:39:11,876]   LabelSmoothing Loss = 1.7149083614349365\n",
      "[INFO: 2022-02-16 18:39:21,542] Iteration 14420 (DataTime/BatchTime: 0.0025/0.483) losses = 2.4053, lr = [3.68003775161067e-05, 0.00036800377516106695]\n",
      "[INFO: 2022-02-16 18:39:21,543]   LabelSmoothing Loss = 2.773381471633911\n",
      "[INFO: 2022-02-16 18:39:31,267] Iteration 14440 (DataTime/BatchTime: 0.00163/0.486) losses = 2.2218, lr = [3.677488719129428e-05, 0.0003677488719129427]\n",
      "[INFO: 2022-02-16 18:39:31,267]   LabelSmoothing Loss = 1.5880247354507446\n",
      "[INFO: 2022-02-16 18:39:40,935] Iteration 14460 (DataTime/BatchTime: 0.00158/0.483) losses = 2.2693, lr = [3.6749449761957885e-05, 0.0003674944976195788]\n",
      "[INFO: 2022-02-16 18:39:40,935]   LabelSmoothing Loss = 2.5777738094329834\n",
      "[INFO: 2022-02-16 18:39:50,593] Iteration 14480 (DataTime/BatchTime: 0.00237/0.483) losses = 2.3349, lr = [3.672406504540949e-05, 0.0003672406504540949]\n",
      "[INFO: 2022-02-16 18:39:50,593]   LabelSmoothing Loss = 2.5490286350250244\n",
      "[INFO: 2022-02-16 18:40:00,235] Iteration 14500 (DataTime/BatchTime: 0.00235/0.482) losses = 2.3898, lr = [3.669873285984321e-05, 0.0003669873285984321]\n",
      "[INFO: 2022-02-16 18:40:00,235]   LabelSmoothing Loss = 1.1677144765853882\n",
      "[INFO: 2022-02-16 18:40:09,911] Iteration 14520 (DataTime/BatchTime: 0.00422/0.484) losses = 2.2959, lr = [3.6673453024329793e-05, 0.0003667345302432979]\n",
      "[INFO: 2022-02-16 18:40:09,911]   LabelSmoothing Loss = 2.375805616378784\n",
      "[INFO: 2022-02-16 18:40:19,537] Iteration 14540 (DataTime/BatchTime: 0.00238/0.481) losses = 2.3638, lr = [3.664822535881122e-05, 0.00036648225358811216]\n",
      "[INFO: 2022-02-16 18:40:19,537]   LabelSmoothing Loss = 2.276885747909546\n",
      "[INFO: 2022-02-16 18:40:29,268] Iteration 14560 (DataTime/BatchTime: 0.00155/0.487) losses = 2.2776, lr = [3.6623049684095323e-05, 0.0003662304968409532]\n",
      "[INFO: 2022-02-16 18:40:29,268]   LabelSmoothing Loss = 2.519390821456909\n",
      "[INFO: 2022-02-16 18:40:38,942] Iteration 14580 (DataTime/BatchTime: 0.00149/0.484) losses = 2.2861, lr = [3.659792582185042e-05, 0.00036597925821850414]\n",
      "[INFO: 2022-02-16 18:40:38,942]   LabelSmoothing Loss = 3.144176483154297\n",
      "[INFO: 2022-02-16 18:40:48,601] Iteration 14600 (DataTime/BatchTime: 0.00237/0.483) losses = 2.528, lr = [3.657285359460003e-05, 0.00036572853594600026]\n",
      "[INFO: 2022-02-16 18:40:48,601]   LabelSmoothing Loss = 2.4699509143829346\n",
      "[INFO: 2022-02-16 18:40:58,241] Iteration 14620 (DataTime/BatchTime: 0.00335/0.482) losses = 2.1872, lr = [3.654783282571759e-05, 0.00036547832825717586]\n",
      "[INFO: 2022-02-16 18:40:58,241]   LabelSmoothing Loss = 1.8450058698654175\n",
      "[INFO: 2022-02-16 18:41:07,938] Iteration 14640 (DataTime/BatchTime: 0.00238/0.485) losses = 2.6165, lr = [3.652286333942124e-05, 0.0003652286333942124]\n",
      "[INFO: 2022-02-16 18:41:07,939]   LabelSmoothing Loss = 2.162724256515503\n",
      "[INFO: 2022-02-16 18:41:17,655] Iteration 14660 (DataTime/BatchTime: 0.00241/0.486) losses = 2.2237, lr = [3.649794496076863e-05, 0.0003649794496076863]\n",
      "[INFO: 2022-02-16 18:41:17,655]   LabelSmoothing Loss = 2.000694513320923\n",
      "[INFO: 2022-02-16 18:41:27,317] Iteration 14680 (DataTime/BatchTime: 0.00323/0.483) losses = 2.0742, lr = [3.647307751565179e-05, 0.0003647307751565178]\n",
      "[INFO: 2022-02-16 18:41:27,318]   LabelSmoothing Loss = 2.5746662616729736\n",
      "[INFO: 2022-02-16 18:41:36,922] Iteration 14700 (DataTime/BatchTime: 0.00237/0.48) losses = 2.2416, lr = [3.644826083079196e-05, 0.0003644826083079196]\n",
      "[INFO: 2022-02-16 18:41:36,922]   LabelSmoothing Loss = 2.2133660316467285\n",
      "[INFO: 2022-02-16 18:41:46,733] Iteration 14720 (DataTime/BatchTime: 0.00156/0.491) losses = 2.2656, lr = [3.642349473373464e-05, 0.00036423494733734633]\n",
      "[INFO: 2022-02-16 18:41:46,733]   LabelSmoothing Loss = 2.334385633468628\n",
      "[INFO: 2022-02-16 18:41:56,282] Iteration 14740 (DataTime/BatchTime: 0.00137/0.477) losses = 2.4386, lr = [3.63987790528444e-05, 0.0003639877905284439]\n",
      "[INFO: 2022-02-16 18:41:56,282]   LabelSmoothing Loss = 1.6513206958770752\n",
      "[INFO: 2022-02-16 18:42:05,819] Iteration 14760 (DataTime/BatchTime: 0.00131/0.477) losses = 2.1648, lr = [3.63741136173e-05, 0.0003637411361729999]\n",
      "[INFO: 2022-02-16 18:42:05,819]   LabelSmoothing Loss = 2.3760826587677\n",
      "[INFO: 2022-02-16 18:42:15,374] Iteration 14780 (DataTime/BatchTime: 0.00124/0.478) losses = 2.174, lr = [3.634949825708941e-05, 0.0003634949825708941]\n",
      "[INFO: 2022-02-16 18:42:15,374]   LabelSmoothing Loss = 2.8574750423431396\n",
      "[INFO: 2022-02-16 18:42:24,962] Iteration 14800 (DataTime/BatchTime: 0.00262/0.479) losses = 2.2464, lr = [3.632493280300487e-05, 0.0003632493280300486]\n",
      "[INFO: 2022-02-16 18:42:24,963]   LabelSmoothing Loss = 2.4330265522003174\n",
      "[INFO: 2022-02-16 18:42:34,543] Iteration 14820 (DataTime/BatchTime: 0.00125/0.479) losses = 2.4397, lr = [3.630041708663798e-05, 0.00036300417086637974]\n",
      "[INFO: 2022-02-16 18:42:34,543]   LabelSmoothing Loss = 3.659433364868164\n",
      "[INFO: 2022-02-16 18:42:44,088] Iteration 14840 (DataTime/BatchTime: 0.00208/0.477) losses = 2.32, lr = [3.627595094037491e-05, 0.000362759509403749]\n",
      "[INFO: 2022-02-16 18:42:44,088]   LabelSmoothing Loss = 3.1819064617156982\n",
      "[INFO: 2022-02-16 18:42:53,674] Iteration 14860 (DataTime/BatchTime: 0.00127/0.479) losses = 2.1872, lr = [3.6251534197391545e-05, 0.00036251534197391543]\n",
      "[INFO: 2022-02-16 18:42:53,674]   LabelSmoothing Loss = 2.4756557941436768\n",
      "[INFO: 2022-02-16 18:43:03,249] Iteration 14880 (DataTime/BatchTime: 0.0012/0.479) losses = 2.2683, lr = [3.6227166691648715e-05, 0.00036227166691648715]\n",
      "[INFO: 2022-02-16 18:43:03,249]   LabelSmoothing Loss = 3.11331844329834\n",
      "[INFO: 2022-02-16 18:43:12,772] Iteration 14900 (DataTime/BatchTime: 0.00206/0.476) losses = 2.1117, lr = [3.620284825788748e-05, 0.0003620284825788748]\n",
      "[INFO: 2022-02-16 18:43:12,772]   LabelSmoothing Loss = 2.0012564659118652\n",
      "[INFO: 2022-02-16 18:43:22,291] Iteration 14920 (DataTime/BatchTime: 0.00208/0.476) losses = 2.3632, lr = [3.6178578731624375e-05, 0.0003617857873162437]\n",
      "[INFO: 2022-02-16 18:43:22,291]   LabelSmoothing Loss = 1.6599385738372803\n",
      "[INFO: 2022-02-16 18:43:31,875] Iteration 14940 (DataTime/BatchTime: 0.00243/0.479) losses = 2.1221, lr = [3.615435794914677e-05, 0.00036154357949146765]\n",
      "[INFO: 2022-02-16 18:43:31,875]   LabelSmoothing Loss = 1.3468379974365234\n",
      "[INFO: 2022-02-16 18:43:41,448] Iteration 14960 (DataTime/BatchTime: 0.00111/0.479) losses = 2.3373, lr = [3.6130185747508217e-05, 0.0003613018574750821]\n",
      "[INFO: 2022-02-16 18:43:41,448]   LabelSmoothing Loss = 2.042109727859497\n",
      "[INFO: 2022-02-16 18:43:50,907] Iteration 14980 (DataTime/BatchTime: 0.00114/0.473) losses = 2.3771, lr = [3.610606196452387e-05, 0.0003610606196452386]\n",
      "[INFO: 2022-02-16 18:43:50,908]   LabelSmoothing Loss = 2.3569962978363037\n",
      "[INFO: 2022-02-16 18:44:00,357] Iteration 15000 (DataTime/BatchTime: 0.00106/0.472) losses = 2.2192, lr = [3.608198643876588e-05, 0.00036081986438765874]\n",
      "[INFO: 2022-02-16 18:44:00,357]   LabelSmoothing Loss = 2.112400531768799\n",
      "[INFO: 2022-02-16 18:44:09,756] Iteration 15020 (DataTime/BatchTime: 0.0011/0.47) losses = 2.3683, lr = [3.6057959009558896e-05, 0.0003605795900955889]\n",
      "[INFO: 2022-02-16 18:44:09,756]   LabelSmoothing Loss = 2.7904179096221924\n",
      "[INFO: 2022-02-16 18:44:19,342] Iteration 15040 (DataTime/BatchTime: 0.00117/0.479) losses = 2.1773, lr = [3.603397951697551e-05, 0.000360339795169755]\n",
      "[INFO: 2022-02-16 18:44:19,342]   LabelSmoothing Loss = 2.6708743572235107\n",
      "[INFO: 2022-02-16 18:44:28,879] Iteration 15060 (DataTime/BatchTime: 0.00235/0.477) losses = 2.2828, lr = [3.6010047801831845e-05, 0.0003601004780183184]\n",
      "[INFO: 2022-02-16 18:44:28,879]   LabelSmoothing Loss = 2.997649908065796\n",
      "[INFO: 2022-02-16 18:44:38,389] Iteration 15080 (DataTime/BatchTime: 0.00127/0.475) losses = 2.3695, lr = [3.5986163705683074e-05, 0.0003598616370568307]\n",
      "[INFO: 2022-02-16 18:44:38,389]   LabelSmoothing Loss = 3.074260950088501\n",
      "[INFO: 2022-02-16 18:44:48,034] Iteration 15100 (DataTime/BatchTime: 0.00299/0.482) losses = 2.4082, lr = [3.5962327070819036e-05, 0.0003596232707081903]\n",
      "[INFO: 2022-02-16 18:44:48,034]   LabelSmoothing Loss = 2.6952619552612305\n",
      "[INFO: 2022-02-16 18:44:57,466] Iteration 15120 (DataTime/BatchTime: 0.00205/0.472) losses = 2.3637, lr = [3.5938537740259846e-05, 0.0003593853774025984]\n",
      "[INFO: 2022-02-16 18:44:57,467]   LabelSmoothing Loss = 2.0959813594818115\n",
      "[INFO: 2022-02-16 18:45:07,008] Iteration 15140 (DataTime/BatchTime: 0.00115/0.477) losses = 2.3525, lr = [3.5914795557751575e-05, 0.0003591479555775157]\n",
      "[INFO: 2022-02-16 18:45:07,008]   LabelSmoothing Loss = 2.4023797512054443\n",
      "[INFO: 2022-02-16 18:45:16,512] Iteration 15160 (DataTime/BatchTime: 0.00112/0.475) losses = 2.17, lr = [3.589110036776191e-05, 0.0003589110036776191]\n",
      "[INFO: 2022-02-16 18:45:16,512]   LabelSmoothing Loss = 2.6886441707611084\n",
      "[INFO: 2022-02-16 18:45:26,152] Iteration 15180 (DataTime/BatchTime: 0.00194/0.482) losses = 2.3581, lr = [3.58674520154759e-05, 0.00035867452015475896]\n",
      "[INFO: 2022-02-16 18:45:26,152]   LabelSmoothing Loss = 2.6207754611968994\n",
      "[INFO: 2022-02-16 18:45:35,655] Iteration 15200 (DataTime/BatchTime: 0.00133/0.475) losses = 2.2917, lr = [3.584385034679171e-05, 0.00035843850346791703]\n",
      "[INFO: 2022-02-16 18:45:35,655]   LabelSmoothing Loss = 1.854669451713562\n",
      "[INFO: 2022-02-16 18:45:45,324] Iteration 15220 (DataTime/BatchTime: 0.00123/0.483) losses = 2.2392, lr = [3.582029520831636e-05, 0.00035820295208316357]\n",
      "[INFO: 2022-02-16 18:45:45,324]   LabelSmoothing Loss = 2.537673234939575\n",
      "[INFO: 2022-02-16 18:45:54,811] Iteration 15240 (DataTime/BatchTime: 0.00199/0.474) losses = 1.9144, lr = [3.57967864473616e-05, 0.00035796786447361595]\n",
      "[INFO: 2022-02-16 18:45:54,811]   LabelSmoothing Loss = 1.768950343132019\n",
      "[INFO: 2022-02-16 18:46:04,243] Iteration 15260 (DataTime/BatchTime: 0.00195/0.472) losses = 2.4154, lr = [3.5773323911939715e-05, 0.0003577332391193971]\n",
      "[INFO: 2022-02-16 18:46:04,243]   LabelSmoothing Loss = 2.745720624923706\n",
      "[INFO: 2022-02-16 18:49:43,653] ######## Epoch (VAL)16 ########\n",
      "[INFO: 2022-02-16 18:49:43,653] {'Bleu_1': 0.4001582114418587, 'Bleu_2': 0.24955807316557005, 'Bleu_3': 0.1681754502097059, 'Bleu_4': 0.11481700944614888, 'METEOR': 0.20062113594255288, 'ROUGE_L': 0.32101775711644454, 'CIDEr': 0.28290377425074564}\n",
      "[INFO: 2022-02-16 18:53:19,784] ######## Epoch (TEST)16 ########\n",
      "[INFO: 2022-02-16 18:53:19,784] {'Bleu_1': 0.37991029580744, 'Bleu_2': 0.23207960469152178, 'Bleu_3': 0.1536430110786039, 'Bleu_4': 0.10335688964443332, 'METEOR': 0.19231743253816663, 'ROUGE_L': 0.3095690514432706, 'CIDEr': 0.31083708412799577}\n",
      "[INFO: 2022-02-16 18:53:21,395] Iteration 15280 (DataTime/BatchTime: 1.04/1.61) losses = 2.4088, lr = [3.574990745075939e-05, 0.0003574990745075939]\n",
      "[INFO: 2022-02-16 18:53:21,395]   LabelSmoothing Loss = 2.4088313579559326\n",
      "[INFO: 2022-02-16 18:53:30,832] Iteration 15300 (DataTime/BatchTime: 0.00124/0.472) losses = 2.042, lr = [3.5726536913221656e-05, 0.00035726536913221655]\n",
      "[INFO: 2022-02-16 18:53:30,832]   LabelSmoothing Loss = 1.579896092414856\n",
      "[INFO: 2022-02-16 18:53:40,200] Iteration 15320 (DataTime/BatchTime: 0.00206/0.468) losses = 2.391, lr = [3.570321214941578e-05, 0.00035703212149415774]\n",
      "[INFO: 2022-02-16 18:53:40,201]   LabelSmoothing Loss = 2.63923978805542\n",
      "[INFO: 2022-02-16 18:53:49,917] Iteration 15340 (DataTime/BatchTime: 0.00414/0.486) losses = 2.2701, lr = [3.567993301011522e-05, 0.0003567993301011522]\n",
      "[INFO: 2022-02-16 18:53:49,917]   LabelSmoothing Loss = 1.6179064512252808\n",
      "[INFO: 2022-02-16 18:53:59,427] Iteration 15360 (DataTime/BatchTime: 0.00327/0.476) losses = 2.2003, lr = [3.565669934677368e-05, 0.00035656699346773673]\n",
      "[INFO: 2022-02-16 18:53:59,427]   LabelSmoothing Loss = 2.0814998149871826\n",
      "[INFO: 2022-02-16 18:54:08,938] Iteration 15380 (DataTime/BatchTime: 0.0033/0.476) losses = 2.2109, lr = [3.563351101152105e-05, 0.0003563351101152105]\n",
      "[INFO: 2022-02-16 18:54:08,939]   LabelSmoothing Loss = 1.672243356704712\n",
      "[INFO: 2022-02-16 18:54:18,483] Iteration 15400 (DataTime/BatchTime: 0.00277/0.477) losses = 2.1697, lr = [3.5610367857159494e-05, 0.00035610367857159494]\n",
      "[INFO: 2022-02-16 18:54:18,483]   LabelSmoothing Loss = 2.7609245777130127\n",
      "[INFO: 2022-02-16 18:54:27,956] Iteration 15420 (DataTime/BatchTime: 0.00103/0.474) losses = 2.3616, lr = [3.558726973715954e-05, 0.00035587269737159534]\n",
      "[INFO: 2022-02-16 18:54:27,956]   LabelSmoothing Loss = 1.9698154926300049\n",
      "[INFO: 2022-02-16 18:54:37,427] Iteration 15440 (DataTime/BatchTime: 0.00191/0.474) losses = 2.2285, lr = [3.5564216505656136e-05, 0.00035564216505656134]\n",
      "[INFO: 2022-02-16 18:54:37,428]   LabelSmoothing Loss = 2.0184407234191895\n",
      "[INFO: 2022-02-16 18:54:47,063] Iteration 15460 (DataTime/BatchTime: 0.00103/0.482) losses = 2.2961, lr = [3.554120801744482e-05, 0.0003554120801744481]\n",
      "[INFO: 2022-02-16 18:54:47,063]   LabelSmoothing Loss = 2.4711859226226807\n",
      "[INFO: 2022-02-16 18:54:56,582] Iteration 15480 (DataTime/BatchTime: 0.00195/0.476) losses = 2.1002, lr = [3.5518244127977864e-05, 0.0003551824412797786]\n",
      "[INFO: 2022-02-16 18:54:56,582]   LabelSmoothing Loss = 1.49639892578125\n",
      "[INFO: 2022-02-16 18:55:06,128] Iteration 15500 (DataTime/BatchTime: 0.00264/0.477) losses = 2.269, lr = [3.549532469336048e-05, 0.0003549532469336047]\n",
      "[INFO: 2022-02-16 18:55:06,128]   LabelSmoothing Loss = 2.786393880844116\n",
      "[INFO: 2022-02-16 18:55:15,680] Iteration 15520 (DataTime/BatchTime: 0.00198/0.478) losses = 2.2883, lr = [3.5472449570346975e-05, 0.0003547244957034697]\n",
      "[INFO: 2022-02-16 18:55:15,680]   LabelSmoothing Loss = 1.6345562934875488\n",
      "[INFO: 2022-02-16 18:55:25,126] Iteration 15540 (DataTime/BatchTime: 0.000863/0.472) losses = 2.2085, lr = [3.544961861633708e-05, 0.0003544961861633708]\n",
      "[INFO: 2022-02-16 18:55:25,127]   LabelSmoothing Loss = 2.38860821723938\n",
      "[INFO: 2022-02-16 18:55:34,587] Iteration 15560 (DataTime/BatchTime: 0.00291/0.473) losses = 2.2363, lr = [3.5426831689372146e-05, 0.0003542683168937214]\n",
      "[INFO: 2022-02-16 18:55:34,587]   LabelSmoothing Loss = 2.800802707672119\n",
      "[INFO: 2022-02-16 18:55:44,082] Iteration 15580 (DataTime/BatchTime: 0.000839/0.475) losses = 2.2566, lr = [3.540408864813144e-05, 0.00035404088648131437]\n",
      "[INFO: 2022-02-16 18:55:44,082]   LabelSmoothing Loss = 1.552615761756897\n",
      "[INFO: 2022-02-16 18:55:53,604] Iteration 15600 (DataTime/BatchTime: 0.000849/0.476) losses = 2.3456, lr = [3.538138935192851e-05, 0.00035381389351928506]\n",
      "[INFO: 2022-02-16 18:55:53,605]   LabelSmoothing Loss = 2.8873636722564697\n",
      "[INFO: 2022-02-16 18:56:03,051] Iteration 15620 (DataTime/BatchTime: 0.0019/0.472) losses = 2.2068, lr = [3.535873366070749e-05, 0.00035358733660707494]\n",
      "[INFO: 2022-02-16 18:56:03,051]   LabelSmoothing Loss = 3.0029819011688232\n",
      "[INFO: 2022-02-16 18:56:12,692] Iteration 15640 (DataTime/BatchTime: 0.00198/0.482) losses = 2.3997, lr = [3.53361214350395e-05, 0.00035336121435039497]\n",
      "[INFO: 2022-02-16 18:56:12,692]   LabelSmoothing Loss = 3.2260215282440186\n",
      "[INFO: 2022-02-16 18:56:22,280] Iteration 15660 (DataTime/BatchTime: 0.0011/0.479) losses = 2.357, lr = [3.5313552536119e-05, 0.00035313552536118996]\n",
      "[INFO: 2022-02-16 18:56:22,280]   LabelSmoothing Loss = 3.643352508544922\n",
      "[INFO: 2022-02-16 18:56:31,904] Iteration 15680 (DataTime/BatchTime: 0.002/0.481) losses = 2.3817, lr = [3.529102682576024e-05, 0.00035291026825760234]\n",
      "[INFO: 2022-02-16 18:56:31,904]   LabelSmoothing Loss = 1.9081276655197144\n",
      "[INFO: 2022-02-16 18:56:41,386] Iteration 15700 (DataTime/BatchTime: 0.00287/0.474) losses = 2.2368, lr = [3.526854416639372e-05, 0.00035268544166393713]\n",
      "[INFO: 2022-02-16 18:56:41,386]   LabelSmoothing Loss = 2.686831474304199\n",
      "[INFO: 2022-02-16 18:56:50,894] Iteration 15720 (DataTime/BatchTime: 0.0011/0.475) losses = 2.0468, lr = [3.524610442106264e-05, 0.0003524610442106263]\n",
      "[INFO: 2022-02-16 18:56:50,894]   LabelSmoothing Loss = 2.6027934551239014\n",
      "[INFO: 2022-02-16 18:57:00,431] Iteration 15740 (DataTime/BatchTime: 0.00147/0.476) losses = 2.1391, lr = [3.5223707453419365e-05, 0.0003522370745341936]\n",
      "[INFO: 2022-02-16 18:57:00,432]   LabelSmoothing Loss = 2.4937474727630615\n",
      "[INFO: 2022-02-16 18:57:09,958] Iteration 15760 (DataTime/BatchTime: 0.00305/0.477) losses = 2.1078, lr = [3.520135312772204e-05, 0.0003520135312772204]\n",
      "[INFO: 2022-02-16 18:57:09,958]   LabelSmoothing Loss = 1.6615099906921387\n",
      "[INFO: 2022-02-16 18:57:19,533] Iteration 15780 (DataTime/BatchTime: 0.00199/0.479) losses = 2.3734, lr = [3.517904130883104e-05, 0.00035179041308831035]\n",
      "[INFO: 2022-02-16 18:57:19,533]   LabelSmoothing Loss = 2.131647825241089\n",
      "[INFO: 2022-02-16 18:57:28,988] Iteration 15800 (DataTime/BatchTime: 0.00112/0.473) losses = 2.1962, lr = [3.515677186220556e-05, 0.0003515677186220556]\n",
      "[INFO: 2022-02-16 18:57:28,988]   LabelSmoothing Loss = 2.085798978805542\n",
      "[INFO: 2022-02-16 18:57:38,441] Iteration 15820 (DataTime/BatchTime: 0.00115/0.473) losses = 2.2297, lr = [3.5134544653900254e-05, 0.00035134544653900253]\n",
      "[INFO: 2022-02-16 18:57:38,441]   LabelSmoothing Loss = 2.626706123352051\n",
      "[INFO: 2022-02-16 18:57:48,026] Iteration 15840 (DataTime/BatchTime: 0.00116/0.479) losses = 2.3779, lr = [3.51123595505618e-05, 0.00035112359550561797]\n",
      "[INFO: 2022-02-16 18:57:48,026]   LabelSmoothing Loss = 2.5401012897491455\n",
      "[INFO: 2022-02-16 18:57:57,417] Iteration 15860 (DataTime/BatchTime: 0.000869/0.47) losses = 2.1926, lr = [3.5090216419425564e-05, 0.0003509021641942556]\n",
      "[INFO: 2022-02-16 18:57:57,417]   LabelSmoothing Loss = 1.9405663013458252\n",
      "[INFO: 2022-02-16 18:58:06,814] Iteration 15880 (DataTime/BatchTime: 0.00152/0.47) losses = 2.1397, lr = [3.506811512831226e-05, 0.00035068115128312257]\n",
      "[INFO: 2022-02-16 18:58:06,815]   LabelSmoothing Loss = 2.5785531997680664\n",
      "[INFO: 2022-02-16 18:58:16,238] Iteration 15900 (DataTime/BatchTime: 0.00079/0.471) losses = 2.3044, lr = [3.5046055545624615e-05, 0.00035046055545624613]\n",
      "[INFO: 2022-02-16 18:58:16,238]   LabelSmoothing Loss = 2.0597734451293945\n",
      "[INFO: 2022-02-16 18:58:25,708] Iteration 15920 (DataTime/BatchTime: 0.00164/0.474) losses = 2.1624, lr = [3.502403754034412e-05, 0.00035024037540344117]\n",
      "[INFO: 2022-02-16 18:58:25,708]   LabelSmoothing Loss = 3.327188730239868\n",
      "[INFO: 2022-02-16 18:58:35,327] Iteration 15940 (DataTime/BatchTime: 0.00117/0.481) losses = 2.5084, lr = [3.5002060982027724e-05, 0.0003500206098202772]\n",
      "[INFO: 2022-02-16 18:58:35,327]   LabelSmoothing Loss = 2.430154800415039\n",
      "[INFO: 2022-02-16 18:58:44,968] Iteration 15960 (DataTime/BatchTime: 0.00143/0.482) losses = 2.4618, lr = [3.498012574080461e-05, 0.00034980125740804606]\n",
      "[INFO: 2022-02-16 18:58:44,969]   LabelSmoothing Loss = 2.50399112701416\n",
      "[INFO: 2022-02-16 18:58:54,517] Iteration 15980 (DataTime/BatchTime: 0.00139/0.477) losses = 2.2076, lr = [3.495823168737297e-05, 0.0003495823168737296]\n",
      "[INFO: 2022-02-16 18:58:54,517]   LabelSmoothing Loss = 3.5333828926086426\n",
      "[INFO: 2022-02-16 18:59:04,097] Iteration 16000 (DataTime/BatchTime: 0.00255/0.479) losses = 2.464, lr = [3.493637869299675e-05, 0.00034936378692996753]\n",
      "[INFO: 2022-02-16 18:59:04,097]   LabelSmoothing Loss = 1.516951560974121\n",
      "[INFO: 2022-02-16 18:59:13,656] Iteration 16020 (DataTime/BatchTime: 0.00391/0.478) losses = 2.2499, lr = [3.4914566629502614e-05, 0.0003491456662950261]\n",
      "[INFO: 2022-02-16 18:59:13,657]   LabelSmoothing Loss = 2.8116509914398193\n",
      "[INFO: 2022-02-16 18:59:23,135] Iteration 16040 (DataTime/BatchTime: 0.00138/0.474) losses = 2.3415, lr = [3.489279536927659e-05, 0.00034892795369276583]\n",
      "[INFO: 2022-02-16 18:59:23,135]   LabelSmoothing Loss = 2.899348020553589\n",
      "[INFO: 2022-02-16 18:59:32,680] Iteration 16060 (DataTime/BatchTime: 0.00146/0.477) losses = 2.2752, lr = [3.487106478526109e-05, 0.00034871064785261087]\n",
      "[INFO: 2022-02-16 18:59:32,680]   LabelSmoothing Loss = 2.211909055709839\n",
      "[INFO: 2022-02-16 18:59:42,221] Iteration 16080 (DataTime/BatchTime: 0.00311/0.477) losses = 1.9405, lr = [3.484937475095174e-05, 0.00034849374750951735]\n",
      "[INFO: 2022-02-16 18:59:42,221]   LabelSmoothing Loss = 1.682669997215271\n",
      "[INFO: 2022-02-16 18:59:51,820] Iteration 16100 (DataTime/BatchTime: 0.00315/0.48) losses = 2.426, lr = [3.482772514039427e-05, 0.0003482772514039426]\n",
      "[INFO: 2022-02-16 18:59:51,821]   LabelSmoothing Loss = 2.72930908203125\n",
      "[INFO: 2022-02-16 19:00:01,454] Iteration 16120 (DataTime/BatchTime: 0.00142/0.482) losses = 2.3785, lr = [3.4806115828181456e-05, 0.0003480611582818145]\n",
      "[INFO: 2022-02-16 19:00:01,454]   LabelSmoothing Loss = 1.972403883934021\n",
      "[INFO: 2022-02-16 19:00:11,010] Iteration 16140 (DataTime/BatchTime: 0.00235/0.478) losses = 2.1133, lr = [3.478454668945011e-05, 0.0003478454668945011]\n",
      "[INFO: 2022-02-16 19:00:11,010]   LabelSmoothing Loss = 1.2139618396759033\n",
      "[INFO: 2022-02-16 19:00:20,561] Iteration 16160 (DataTime/BatchTime: 0.00146/0.478) losses = 2.282, lr = [3.476301759987796e-05, 0.00034763017599877955]\n",
      "[INFO: 2022-02-16 19:00:20,561]   LabelSmoothing Loss = 1.914778232574463\n",
      "[INFO: 2022-02-16 19:00:30,185] Iteration 16180 (DataTime/BatchTime: 0.00232/0.481) losses = 2.1785, lr = [3.4741528435680744e-05, 0.00034741528435680737]\n",
      "[INFO: 2022-02-16 19:00:30,185]   LabelSmoothing Loss = 2.7523488998413086\n",
      "[INFO: 2022-02-16 19:00:39,687] Iteration 16200 (DataTime/BatchTime: 0.00148/0.475) losses = 2.2017, lr = [3.4720079073609124e-05, 0.00034720079073609117]\n",
      "[INFO: 2022-02-16 19:00:39,687]   LabelSmoothing Loss = 2.0925238132476807\n",
      "[INFO: 2022-02-16 19:00:49,248] Iteration 16220 (DataTime/BatchTime: 0.00142/0.478) losses = 2.402, lr = [3.469866939094579e-05, 0.00034698669390945786]\n",
      "[INFO: 2022-02-16 19:00:49,248]   LabelSmoothing Loss = 2.10899019241333\n",
      "[INFO: 2022-02-16 19:04:31,033] ######## Epoch (VAL)17 ########\n",
      "[INFO: 2022-02-16 19:04:31,033] {'Bleu_1': 0.4154249451910944, 'Bleu_2': 0.2698694455765327, 'Bleu_3': 0.18568100883066874, 'Bleu_4': 0.12758405351940771, 'METEOR': 0.2057821049217111, 'ROUGE_L': 0.32203287271764, 'CIDEr': 0.29954418981399517}\n",
      "[INFO: 2022-02-16 19:08:10,591] ######## Epoch (TEST)17 ########\n",
      "[INFO: 2022-02-16 19:08:10,592] {'Bleu_1': 0.3893778207269174, 'Bleu_2': 0.24080397147920735, 'Bleu_3': 0.15998458178584835, 'Bleu_4': 0.10636726205039133, 'METEOR': 0.19284346483272913, 'ROUGE_L': 0.3046960543756504, 'CIDEr': 0.3171912415850091}\n",
      "[INFO: 2022-02-16 19:08:14,555] Iteration 16240 (DataTime/BatchTime: 0.154/0.66) losses = 1.8575, lr = [3.4677299265502475e-05, 0.0003467729926550247]\n",
      "[INFO: 2022-02-16 19:08:14,555]   LabelSmoothing Loss = 0.8018730878829956\n",
      "[INFO: 2022-02-16 19:08:24,332] Iteration 16260 (DataTime/BatchTime: 0.00393/0.489) losses = 1.951, lr = [3.465596857561705e-05, 0.0003465596857561704]\n",
      "[INFO: 2022-02-16 19:08:24,333]   LabelSmoothing Loss = 1.5801340341567993\n",
      "[INFO: 2022-02-16 19:08:33,996] Iteration 16280 (DataTime/BatchTime: 0.00261/0.483) losses = 2.3879, lr = [3.463467720015057e-05, 0.00034634677200150567]\n",
      "[INFO: 2022-02-16 19:08:33,997]   LabelSmoothing Loss = 2.433849811553955\n",
      "[INFO: 2022-02-16 19:08:43,664] Iteration 16300 (DataTime/BatchTime: 0.00139/0.483) losses = 2.0254, lr = [3.461342501848444e-05, 0.0003461342501848443]\n",
      "[INFO: 2022-02-16 19:08:43,664]   LabelSmoothing Loss = 1.770951509475708\n",
      "[INFO: 2022-02-16 19:08:53,326] Iteration 16320 (DataTime/BatchTime: 0.00399/0.483) losses = 2.0486, lr = [3.459221191051751e-05, 0.0003459221191051751]\n",
      "[INFO: 2022-02-16 19:08:53,327]   LabelSmoothing Loss = 2.217719793319702\n",
      "[INFO: 2022-02-16 19:09:02,933] Iteration 16340 (DataTime/BatchTime: 0.00228/0.48) losses = 2.0352, lr = [3.457103775666324e-05, 0.00034571037756663236]\n",
      "[INFO: 2022-02-16 19:09:02,933]   LabelSmoothing Loss = 1.559145450592041\n",
      "[INFO: 2022-02-16 19:09:12,755] Iteration 16360 (DataTime/BatchTime: 0.00305/0.491) losses = 2.301, lr = [3.4549902437846846e-05, 0.00034549902437846846]\n",
      "[INFO: 2022-02-16 19:09:12,755]   LabelSmoothing Loss = 1.8090753555297852\n",
      "[INFO: 2022-02-16 19:09:22,381] Iteration 16380 (DataTime/BatchTime: 0.00226/0.481) losses = 2.3421, lr = [3.452880583550253e-05, 0.00034528805835502526]\n",
      "[INFO: 2022-02-16 19:09:22,381]   LabelSmoothing Loss = 2.4661219120025635\n",
      "[INFO: 2022-02-16 19:09:31,918] Iteration 16400 (DataTime/BatchTime: 0.0013/0.477) losses = 1.9567, lr = [3.4507747831570635e-05, 0.00034507747831570633]\n",
      "[INFO: 2022-02-16 19:09:31,918]   LabelSmoothing Loss = 1.4800904989242554\n",
      "[INFO: 2022-02-16 19:09:41,484] Iteration 16420 (DataTime/BatchTime: 0.00208/0.478) losses = 2.228, lr = [3.448672830849491e-05, 0.00034486728308494904]\n",
      "[INFO: 2022-02-16 19:09:41,484]   LabelSmoothing Loss = 2.1500985622406006\n",
      "[INFO: 2022-02-16 19:09:51,112] Iteration 16440 (DataTime/BatchTime: 0.00134/0.481) losses = 2.2656, lr = [3.446574714921973e-05, 0.00034465747149219723]\n",
      "[INFO: 2022-02-16 19:09:51,112]   LabelSmoothing Loss = 3.1318001747131348\n",
      "[INFO: 2022-02-16 19:10:00,707] Iteration 16460 (DataTime/BatchTime: 0.00234/0.48) losses = 2.2368, lr = [3.444480423718737e-05, 0.00034444804237187366]\n",
      "[INFO: 2022-02-16 19:10:00,707]   LabelSmoothing Loss = 1.9661507606506348\n",
      "[INFO: 2022-02-16 19:10:10,329] Iteration 16480 (DataTime/BatchTime: 0.00219/0.481) losses = 2.3285, lr = [3.44238994563353e-05, 0.0003442389945633529]\n",
      "[INFO: 2022-02-16 19:10:10,329]   LabelSmoothing Loss = 1.9374215602874756\n",
      "[INFO: 2022-02-16 19:10:19,881] Iteration 16500 (DataTime/BatchTime: 0.00211/0.478) losses = 2.317, lr = [3.440303269109343e-05, 0.0003440303269109343]\n",
      "[INFO: 2022-02-16 19:10:19,881]   LabelSmoothing Loss = 2.823439121246338\n",
      "[INFO: 2022-02-16 19:10:29,361] Iteration 16520 (DataTime/BatchTime: 0.00128/0.474) losses = 1.8858, lr = [3.4382203826381504e-05, 0.000343822038263815]\n",
      "[INFO: 2022-02-16 19:10:29,361]   LabelSmoothing Loss = 1.989609718322754\n",
      "[INFO: 2022-02-16 19:10:38,810] Iteration 16540 (DataTime/BatchTime: 0.0013/0.472) losses = 1.9986, lr = [3.436141274760637e-05, 0.0003436141274760636]\n",
      "[INFO: 2022-02-16 19:10:38,810]   LabelSmoothing Loss = 2.1756932735443115\n",
      "[INFO: 2022-02-16 19:10:48,306] Iteration 16560 (DataTime/BatchTime: 0.00128/0.475) losses = 2.1352, lr = [3.434065934065935e-05, 0.00034340659340659343]\n",
      "[INFO: 2022-02-16 19:10:48,306]   LabelSmoothing Loss = 2.711648941040039\n",
      "[INFO: 2022-02-16 19:10:57,770] Iteration 16580 (DataTime/BatchTime: 0.00126/0.473) losses = 2.2234, lr = [3.4319943491913626e-05, 0.0003431994349191362]\n",
      "[INFO: 2022-02-16 19:10:57,770]   LabelSmoothing Loss = 2.0306575298309326\n",
      "[INFO: 2022-02-16 19:11:07,248] Iteration 16600 (DataTime/BatchTime: 0.00128/0.474) losses = 2.1367, lr = [3.429926508822161e-05, 0.0003429926508822161]\n",
      "[INFO: 2022-02-16 19:11:07,248]   LabelSmoothing Loss = 2.5477006435394287\n",
      "[INFO: 2022-02-16 19:11:16,734] Iteration 16620 (DataTime/BatchTime: 0.00127/0.474) losses = 2.2021, lr = [3.427862401691237e-05, 0.0003427862401691236]\n",
      "[INFO: 2022-02-16 19:11:16,734]   LabelSmoothing Loss = 2.4562361240386963\n",
      "[INFO: 2022-02-16 19:11:26,223] Iteration 16640 (DataTime/BatchTime: 0.00126/0.474) losses = 2.3869, lr = [3.425802016578901e-05, 0.00034258020165789003]\n",
      "[INFO: 2022-02-16 19:11:26,223]   LabelSmoothing Loss = 2.5311522483825684\n",
      "[INFO: 2022-02-16 19:11:35,658] Iteration 16660 (DataTime/BatchTime: 0.00126/0.472) losses = 2.0133, lr = [3.423745342312615e-05, 0.0003423745342312615]\n",
      "[INFO: 2022-02-16 19:11:35,658]   LabelSmoothing Loss = 2.886232852935791\n",
      "[INFO: 2022-02-16 19:11:45,190] Iteration 16680 (DataTime/BatchTime: 0.00127/0.477) losses = 2.1749, lr = [3.421692367766737e-05, 0.0003421692367766737]\n",
      "[INFO: 2022-02-16 19:11:45,190]   LabelSmoothing Loss = 2.03731632232666\n",
      "[INFO: 2022-02-16 19:11:54,729] Iteration 16700 (DataTime/BatchTime: 0.00208/0.477) losses = 2.1118, lr = [3.4196430818622675e-05, 0.00034196430818622675]\n",
      "[INFO: 2022-02-16 19:11:54,729]   LabelSmoothing Loss = 1.8921406269073486\n",
      "[INFO: 2022-02-16 19:12:04,195] Iteration 16720 (DataTime/BatchTime: 0.00126/0.473) losses = 2.2947, lr = [3.417597473566598e-05, 0.00034175974735665976]\n",
      "[INFO: 2022-02-16 19:12:04,195]   LabelSmoothing Loss = 2.0418593883514404\n",
      "[INFO: 2022-02-16 19:12:13,749] Iteration 16740 (DataTime/BatchTime: 0.00125/0.478) losses = 2.193, lr = [3.4155555318932623e-05, 0.0003415555531893262]\n",
      "[INFO: 2022-02-16 19:12:13,749]   LabelSmoothing Loss = 3.4376301765441895\n",
      "[INFO: 2022-02-16 19:12:23,286] Iteration 16760 (DataTime/BatchTime: 0.00124/0.477) losses = 2.39, lr = [3.413517245901689e-05, 0.0003413517245901689]\n",
      "[INFO: 2022-02-16 19:12:23,286]   LabelSmoothing Loss = 1.3876594305038452\n",
      "[INFO: 2022-02-16 19:12:32,779] Iteration 16780 (DataTime/BatchTime: 0.00126/0.475) losses = 2.2503, lr = [3.411482604696956e-05, 0.00034114826046969556]\n",
      "[INFO: 2022-02-16 19:12:32,779]   LabelSmoothing Loss = 2.6063895225524902\n",
      "[INFO: 2022-02-16 19:12:42,358] Iteration 16800 (DataTime/BatchTime: 0.00125/0.479) losses = 2.4643, lr = [3.4094515974295424e-05, 0.0003409451597429542]\n",
      "[INFO: 2022-02-16 19:12:42,358]   LabelSmoothing Loss = 2.408684730529785\n",
      "[INFO: 2022-02-16 19:12:51,848] Iteration 16820 (DataTime/BatchTime: 0.00123/0.474) losses = 2.3881, lr = [3.40742421329509e-05, 0.000340742421329509]\n",
      "[INFO: 2022-02-16 19:12:51,848]   LabelSmoothing Loss = 1.4125922918319702\n",
      "[INFO: 2022-02-16 19:13:01,371] Iteration 16840 (DataTime/BatchTime: 0.00125/0.476) losses = 2.3974, lr = [3.4054004415341597e-05, 0.0003405400441534159]\n",
      "[INFO: 2022-02-16 19:13:01,371]   LabelSmoothing Loss = 2.2172813415527344\n",
      "[INFO: 2022-02-16 19:13:10,831] Iteration 16860 (DataTime/BatchTime: 0.00124/0.473) losses = 2.1687, lr = [3.40338027143199e-05, 0.00034033802714319896]\n",
      "[INFO: 2022-02-16 19:13:10,832]   LabelSmoothing Loss = 2.055417776107788\n",
      "[INFO: 2022-02-16 19:13:20,322] Iteration 16880 (DataTime/BatchTime: 0.00126/0.475) losses = 2.2323, lr = [3.4013636923182626e-05, 0.0003401363692318262]\n",
      "[INFO: 2022-02-16 19:13:20,322]   LabelSmoothing Loss = 2.7785563468933105\n",
      "[INFO: 2022-02-16 19:13:29,850] Iteration 16900 (DataTime/BatchTime: 0.00126/0.476) losses = 2.2247, lr = [3.399350693566863e-05, 0.0003399350693566863]\n",
      "[INFO: 2022-02-16 19:13:29,850]   LabelSmoothing Loss = 2.4568135738372803\n",
      "[INFO: 2022-02-16 19:13:39,353] Iteration 16920 (DataTime/BatchTime: 0.00125/0.475) losses = 2.1264, lr = [3.3973412645956455e-05, 0.0003397341264595645]\n",
      "[INFO: 2022-02-16 19:13:39,353]   LabelSmoothing Loss = 1.7420365810394287\n",
      "[INFO: 2022-02-16 19:13:48,891] Iteration 16940 (DataTime/BatchTime: 0.00126/0.477) losses = 2.2246, lr = [3.3953353948662004e-05, 0.00033953353948661997]\n",
      "[INFO: 2022-02-16 19:13:48,891]   LabelSmoothing Loss = 2.659679412841797\n",
      "[INFO: 2022-02-16 19:13:58,399] Iteration 16960 (DataTime/BatchTime: 0.00125/0.475) losses = 2.2609, lr = [3.3933330738836216e-05, 0.0003393333073883621]\n",
      "[INFO: 2022-02-16 19:13:58,399]   LabelSmoothing Loss = 1.6884844303131104\n",
      "[INFO: 2022-02-16 19:14:07,985] Iteration 16980 (DataTime/BatchTime: 0.00125/0.479) losses = 2.453, lr = [3.3913342911962753e-05, 0.0003391334291196275]\n",
      "[INFO: 2022-02-16 19:14:07,985]   LabelSmoothing Loss = 2.4271349906921387\n",
      "[INFO: 2022-02-16 19:14:17,465] Iteration 17000 (DataTime/BatchTime: 0.00127/0.474) losses = 2.3461, lr = [3.389339036395573e-05, 0.00033893390363955725]\n",
      "[INFO: 2022-02-16 19:14:17,465]   LabelSmoothing Loss = 2.4147236347198486\n",
      "[INFO: 2022-02-16 19:14:26,982] Iteration 17020 (DataTime/BatchTime: 0.00125/0.476) losses = 2.5555, lr = [3.38734729911574e-05, 0.000338734729911574]\n",
      "[INFO: 2022-02-16 19:14:26,983]   LabelSmoothing Loss = 1.9979403018951416\n",
      "[INFO: 2022-02-16 19:14:36,556] Iteration 17040 (DataTime/BatchTime: 0.00128/0.479) losses = 2.4109, lr = [3.3853590690335935e-05, 0.0003385359069033593]\n",
      "[INFO: 2022-02-16 19:14:36,556]   LabelSmoothing Loss = 1.9958901405334473\n",
      "[INFO: 2022-02-16 19:14:46,083] Iteration 17060 (DataTime/BatchTime: 0.00126/0.476) losses = 2.3205, lr = [3.383374335868315e-05, 0.00033833743358683145]\n",
      "[INFO: 2022-02-16 19:14:46,083]   LabelSmoothing Loss = 1.5464695692062378\n",
      "[INFO: 2022-02-16 19:14:55,561] Iteration 17080 (DataTime/BatchTime: 0.00127/0.474) losses = 2.0948, lr = [3.381393089381227e-05, 0.0003381393089381227]\n",
      "[INFO: 2022-02-16 19:14:55,561]   LabelSmoothing Loss = 2.4723973274230957\n",
      "[INFO: 2022-02-16 19:15:05,006] Iteration 17100 (DataTime/BatchTime: 0.00126/0.472) losses = 1.9115, lr = [3.3794153193755745e-05, 0.00033794153193755745]\n",
      "[INFO: 2022-02-16 19:15:05,007]   LabelSmoothing Loss = 3.2552897930145264\n",
      "[INFO: 2022-02-16 19:15:14,514] Iteration 17120 (DataTime/BatchTime: 0.00127/0.475) losses = 2.2729, lr = [3.3774410156963005e-05, 0.00033774410156963]\n",
      "[INFO: 2022-02-16 19:15:14,514]   LabelSmoothing Loss = 2.4936182498931885\n",
      "[INFO: 2022-02-16 19:15:24,033] Iteration 17140 (DataTime/BatchTime: 0.00127/0.476) losses = 2.2419, lr = [3.375470168229828e-05, 0.00033754701682298273]\n",
      "[INFO: 2022-02-16 19:15:24,033]   LabelSmoothing Loss = 2.362426280975342\n",
      "[INFO: 2022-02-16 19:15:33,583] Iteration 17160 (DataTime/BatchTime: 0.00124/0.477) losses = 2.4888, lr = [3.373502766903844e-05, 0.0003373502766903844]\n",
      "[INFO: 2022-02-16 19:15:33,583]   LabelSmoothing Loss = 2.991203546524048\n",
      "[INFO: 2022-02-16 19:15:43,075] Iteration 17180 (DataTime/BatchTime: 0.00127/0.475) losses = 2.2295, lr = [3.3715388016870836e-05, 0.00033715388016870835]\n",
      "[INFO: 2022-02-16 19:15:43,076]   LabelSmoothing Loss = 2.754347562789917\n",
      "[INFO: 2022-02-16 19:19:17,610] ######## Epoch (VAL)18 ########\n",
      "[INFO: 2022-02-16 19:19:17,611] {'Bleu_1': 0.3515433062027791, 'Bleu_2': 0.22374017144510008, 'Bleu_3': 0.1538022036655399, 'Bleu_4': 0.10739484169937422, 'METEOR': 0.18591926047768673, 'ROUGE_L': 0.3176537809820055, 'CIDEr': 0.25187931888214204}\n",
      "[INFO: 2022-02-16 19:22:56,435] ######## Epoch (TEST)18 ########\n",
      "[INFO: 2022-02-16 19:22:56,435] {'Bleu_1': 0.331490634931352, 'Bleu_2': 0.20417526687356533, 'Bleu_3': 0.1373753180529791, 'Bleu_4': 0.09359324645026054, 'METEOR': 0.17838528598123835, 'ROUGE_L': 0.3025729554123366, 'CIDEr': 0.28809633855446115}\n",
      "[INFO: 2022-02-16 19:23:02,837] Iteration 17200 (DataTime/BatchTime: 0.0911/0.582) losses = 2.1866, lr = [3.3695782625891125e-05, 0.0003369578262589112]\n",
      "[INFO: 2022-02-16 19:23:02,838]   LabelSmoothing Loss = 2.828425645828247\n",
      "[INFO: 2022-02-16 19:23:12,387] Iteration 17220 (DataTime/BatchTime: 0.00233/0.477) losses = 1.8507, lr = [3.367621139660114e-05, 0.0003367621139660114]\n",
      "[INFO: 2022-02-16 19:23:12,387]   LabelSmoothing Loss = 1.6881849765777588\n",
      "[INFO: 2022-02-16 19:23:22,218] Iteration 17240 (DataTime/BatchTime: 0.00437/0.492) losses = 2.2331, lr = [3.36566742299068e-05, 0.000336566742299068]\n",
      "[INFO: 2022-02-16 19:23:22,218]   LabelSmoothing Loss = 1.7211095094680786\n",
      "[INFO: 2022-02-16 19:23:32,026] Iteration 17260 (DataTime/BatchTime: 0.00159/0.49) losses = 2.2636, lr = [3.3637171027115975e-05, 0.00033637171027115967]\n",
      "[INFO: 2022-02-16 19:23:32,026]   LabelSmoothing Loss = 2.2156596183776855\n",
      "[INFO: 2022-02-16 19:23:41,700] Iteration 17280 (DataTime/BatchTime: 0.00327/0.484) losses = 2.193, lr = [3.361770168993639e-05, 0.00033617701689936386]\n",
      "[INFO: 2022-02-16 19:23:41,700]   LabelSmoothing Loss = 2.515469551086426\n",
      "[INFO: 2022-02-16 19:23:51,377] Iteration 17300 (DataTime/BatchTime: 0.00246/0.484) losses = 2.1115, lr = [3.359826612047357e-05, 0.0003359826612047356]\n",
      "[INFO: 2022-02-16 19:23:51,377]   LabelSmoothing Loss = 2.7004947662353516\n",
      "[INFO: 2022-02-16 19:24:01,285] Iteration 17320 (DataTime/BatchTime: 0.00158/0.495) losses = 2.1955, lr = [3.3578864221228736e-05, 0.0003357886422122873]\n",
      "[INFO: 2022-02-16 19:24:01,285]   LabelSmoothing Loss = 2.6256954669952393\n",
      "[INFO: 2022-02-16 19:24:11,034] Iteration 17340 (DataTime/BatchTime: 0.00153/0.487) losses = 2.3978, lr = [3.355949589509679e-05, 0.0003355949589509679]\n",
      "[INFO: 2022-02-16 19:24:11,034]   LabelSmoothing Loss = 2.1551787853240967\n",
      "[INFO: 2022-02-16 19:24:20,764] Iteration 17360 (DataTime/BatchTime: 0.00244/0.487) losses = 1.9166, lr = [3.3540161045364247e-05, 0.0003354016104536424]\n",
      "[INFO: 2022-02-16 19:24:20,764]   LabelSmoothing Loss = 1.246167778968811\n",
      "[INFO: 2022-02-16 19:24:30,630] Iteration 17380 (DataTime/BatchTime: 0.00245/0.492) losses = 2.3767, lr = [3.3520859575707214e-05, 0.00033520859575707207]\n",
      "[INFO: 2022-02-16 19:24:30,631]   LabelSmoothing Loss = 1.4076569080352783\n",
      "[INFO: 2022-02-16 19:24:40,415] Iteration 17400 (DataTime/BatchTime: 0.0035/0.489) losses = 2.0121, lr = [3.3501591390189366e-05, 0.0003350159139018936]\n",
      "[INFO: 2022-02-16 19:24:40,415]   LabelSmoothing Loss = 1.938450813293457\n",
      "[INFO: 2022-02-16 19:24:50,321] Iteration 17420 (DataTime/BatchTime: 0.00257/0.496) losses = 2.3156, lr = [3.3482356393259965e-05, 0.0003348235639325996]\n",
      "[INFO: 2022-02-16 19:24:50,321]   LabelSmoothing Loss = 2.4331185817718506\n",
      "[INFO: 2022-02-16 19:25:00,171] Iteration 17440 (DataTime/BatchTime: 0.00289/0.492) losses = 2.2073, lr = [3.346315448975186e-05, 0.00033463154489751855]\n",
      "[INFO: 2022-02-16 19:25:00,171]   LabelSmoothing Loss = 1.803572654724121\n",
      "[INFO: 2022-02-16 19:25:09,957] Iteration 17460 (DataTime/BatchTime: 0.00253/0.489) losses = 2.1908, lr = [3.344398558487948e-05, 0.0003344398558487948]\n",
      "[INFO: 2022-02-16 19:25:09,957]   LabelSmoothing Loss = 1.873502492904663\n",
      "[INFO: 2022-02-16 19:25:19,570] Iteration 17480 (DataTime/BatchTime: 0.00437/0.481) losses = 2.218, lr = [3.342484958423694e-05, 0.0003342484958423694]\n",
      "[INFO: 2022-02-16 19:25:19,570]   LabelSmoothing Loss = 2.136293411254883\n",
      "[INFO: 2022-02-16 19:25:29,301] Iteration 17500 (DataTime/BatchTime: 0.00341/0.487) losses = 2.3371, lr = [3.3405746393796e-05, 0.00033405746393795995]\n",
      "[INFO: 2022-02-16 19:25:29,302]   LabelSmoothing Loss = 2.0053179264068604\n",
      "[INFO: 2022-02-16 19:25:39,231] Iteration 17520 (DataTime/BatchTime: 0.00174/0.496) losses = 2.2689, lr = [3.338667591990419e-05, 0.00033386675919904184]\n",
      "[INFO: 2022-02-16 19:25:39,231]   LabelSmoothing Loss = 2.7016751766204834\n",
      "[INFO: 2022-02-16 19:25:48,936] Iteration 17540 (DataTime/BatchTime: 0.00152/0.485) losses = 2.3417, lr = [3.3367638069282856e-05, 0.00033367638069282853]\n",
      "[INFO: 2022-02-16 19:25:48,936]   LabelSmoothing Loss = 3.0947961807250977\n",
      "[INFO: 2022-02-16 19:25:58,773] Iteration 17560 (DataTime/BatchTime: 0.00268/0.492) losses = 2.2959, lr = [3.334863274902525e-05, 0.00033348632749025244]\n",
      "[INFO: 2022-02-16 19:25:58,773]   LabelSmoothing Loss = 2.072519063949585\n",
      "[INFO: 2022-02-16 19:26:08,427] Iteration 17580 (DataTime/BatchTime: 0.0034/0.483) losses = 1.992, lr = [3.332965986659461e-05, 0.0003332965986659461]\n",
      "[INFO: 2022-02-16 19:26:08,428]   LabelSmoothing Loss = 2.333904981613159\n",
      "[INFO: 2022-02-16 19:26:18,233] Iteration 17600 (DataTime/BatchTime: 0.00265/0.49) losses = 2.2132, lr = [3.33107193298223e-05, 0.00033310719329822294]\n",
      "[INFO: 2022-02-16 19:26:18,233]   LabelSmoothing Loss = 2.6353352069854736\n",
      "[INFO: 2022-02-16 19:26:27,981] Iteration 17620 (DataTime/BatchTime: 0.00176/0.487) losses = 2.2474, lr = [3.3291811046905895e-05, 0.00033291811046905895]\n",
      "[INFO: 2022-02-16 19:26:27,981]   LabelSmoothing Loss = 2.4262373447418213\n",
      "[INFO: 2022-02-16 19:26:37,598] Iteration 17640 (DataTime/BatchTime: 0.00235/0.481) losses = 2.0607, lr = [3.327293492640734e-05, 0.0003327293492640733]\n",
      "[INFO: 2022-02-16 19:26:37,598]   LabelSmoothing Loss = 1.5041025876998901\n",
      "[INFO: 2022-02-16 19:26:47,360] Iteration 17660 (DataTime/BatchTime: 0.00333/0.488) losses = 2.112, lr = [3.325409087725106e-05, 0.0003325409087725106]\n",
      "[INFO: 2022-02-16 19:26:47,361]   LabelSmoothing Loss = 2.2124695777893066\n",
      "[INFO: 2022-02-16 19:26:57,123] Iteration 17680 (DataTime/BatchTime: 0.00356/0.488) losses = 2.1951, lr = [3.3235278808722165e-05, 0.00033235278808722157]\n",
      "[INFO: 2022-02-16 19:26:57,123]   LabelSmoothing Loss = 1.9676008224487305\n",
      "[INFO: 2022-02-16 19:27:06,709] Iteration 17700 (DataTime/BatchTime: 0.00145/0.479) losses = 2.3826, lr = [3.321649863046456e-05, 0.0003321649863046455]\n",
      "[INFO: 2022-02-16 19:27:06,710]   LabelSmoothing Loss = 1.9801533222198486\n",
      "[INFO: 2022-02-16 19:27:16,481] Iteration 17720 (DataTime/BatchTime: 0.00155/0.489) losses = 2.0713, lr = [3.319775025247915e-05, 0.00033197750252479143]\n",
      "[INFO: 2022-02-16 19:27:16,481]   LabelSmoothing Loss = 1.4472764730453491\n",
      "[INFO: 2022-02-16 19:27:26,084] Iteration 17740 (DataTime/BatchTime: 0.00156/0.48) losses = 2.2711, lr = [3.317903358512204e-05, 0.00033179033585122036]\n",
      "[INFO: 2022-02-16 19:27:26,084]   LabelSmoothing Loss = 1.8031227588653564\n",
      "[INFO: 2022-02-16 19:27:35,861] Iteration 17760 (DataTime/BatchTime: 0.00157/0.489) losses = 2.2334, lr = [3.316034853910271e-05, 0.0003316034853910271]\n",
      "[INFO: 2022-02-16 19:27:35,861]   LabelSmoothing Loss = 1.2805635929107666\n",
      "[INFO: 2022-02-16 19:27:45,495] Iteration 17780 (DataTime/BatchTime: 0.0015/0.482) losses = 2.2035, lr = [3.314169502548224e-05, 0.0003314169502548224]\n",
      "[INFO: 2022-02-16 19:27:45,495]   LabelSmoothing Loss = 1.4589565992355347\n",
      "[INFO: 2022-02-16 19:27:55,081] Iteration 17800 (DataTime/BatchTime: 0.00145/0.479) losses = 2.0333, lr = [3.3123072955671534e-05, 0.0003312307295567153]\n",
      "[INFO: 2022-02-16 19:27:55,081]   LabelSmoothing Loss = 1.9188162088394165\n",
      "[INFO: 2022-02-16 19:28:04,778] Iteration 17820 (DataTime/BatchTime: 0.00151/0.485) losses = 1.9838, lr = [3.3104482241429535e-05, 0.0003310448224142953]\n",
      "[INFO: 2022-02-16 19:28:04,778]   LabelSmoothing Loss = 1.4888418912887573\n",
      "[INFO: 2022-02-16 19:28:14,499] Iteration 17840 (DataTime/BatchTime: 0.00145/0.486) losses = 2.3167, lr = [3.308592279486149e-05, 0.0003308592279486149]\n",
      "[INFO: 2022-02-16 19:28:14,499]   LabelSmoothing Loss = 1.0939760208129883\n",
      "[INFO: 2022-02-16 19:28:24,029] Iteration 17860 (DataTime/BatchTime: 0.00315/0.476) losses = 2.1518, lr = [3.3067394528417206e-05, 0.00033067394528417203]\n",
      "[INFO: 2022-02-16 19:28:24,029]   LabelSmoothing Loss = 2.4495010375976562\n",
      "[INFO: 2022-02-16 19:28:33,664] Iteration 17880 (DataTime/BatchTime: 0.00139/0.482) losses = 2.2617, lr = [3.304889735488928e-05, 0.00033048897354889274]\n",
      "[INFO: 2022-02-16 19:28:33,664]   LabelSmoothing Loss = 2.437004566192627\n",
      "[INFO: 2022-02-16 19:28:43,332] Iteration 17900 (DataTime/BatchTime: 0.00315/0.483) losses = 2.4011, lr = [3.3030431187411426e-05, 0.0003303043118741142]\n",
      "[INFO: 2022-02-16 19:28:43,333]   LabelSmoothing Loss = 2.196831464767456\n",
      "[INFO: 2022-02-16 19:28:52,940] Iteration 17920 (DataTime/BatchTime: 0.00134/0.48) losses = 2.0738, lr = [3.3011995939456725e-05, 0.0003301199593945672]\n",
      "[INFO: 2022-02-16 19:28:52,940]   LabelSmoothing Loss = 1.7462425231933594\n",
      "[INFO: 2022-02-16 19:29:02,541] Iteration 17940 (DataTime/BatchTime: 0.00142/0.48) losses = 2.0894, lr = [3.299359152483593e-05, 0.00032993591524835926]\n",
      "[INFO: 2022-02-16 19:29:02,541]   LabelSmoothing Loss = 3.0335943698883057\n",
      "[INFO: 2022-02-16 19:29:12,235] Iteration 17960 (DataTime/BatchTime: 0.00254/0.485) losses = 2.445, lr = [3.2975217857695786e-05, 0.00032975217857695785]\n",
      "[INFO: 2022-02-16 19:29:12,235]   LabelSmoothing Loss = 2.0919082164764404\n",
      "[INFO: 2022-02-16 19:29:21,854] Iteration 17980 (DataTime/BatchTime: 0.00129/0.481) losses = 2.2429, lr = [3.2956874852517335e-05, 0.0003295687485251733]\n",
      "[INFO: 2022-02-16 19:29:21,854]   LabelSmoothing Loss = 2.7033183574676514\n",
      "[INFO: 2022-02-16 19:29:31,542] Iteration 18000 (DataTime/BatchTime: 0.00156/0.484) losses = 2.2043, lr = [3.293856242411424e-05, 0.00032938562424114236]\n",
      "[INFO: 2022-02-16 19:29:31,542]   LabelSmoothing Loss = 2.089822292327881\n",
      "[INFO: 2022-02-16 19:29:41,101] Iteration 18020 (DataTime/BatchTime: 0.00214/0.478) losses = 2.2956, lr = [3.292028048763116e-05, 0.0003292028048763115]\n",
      "[INFO: 2022-02-16 19:29:41,101]   LabelSmoothing Loss = 2.5218870639801025\n",
      "[INFO: 2022-02-16 19:29:50,750] Iteration 18040 (DataTime/BatchTime: 0.0043/0.482) losses = 2.1788, lr = [3.2902028958542024e-05, 0.00032902028958542017]\n",
      "[INFO: 2022-02-16 19:29:50,750]   LabelSmoothing Loss = 2.459993839263916\n",
      "[INFO: 2022-02-16 19:30:00,291] Iteration 18060 (DataTime/BatchTime: 0.00127/0.477) losses = 2.2646, lr = [3.288380775264848e-05, 0.0003288380775264847]\n",
      "[INFO: 2022-02-16 19:30:00,291]   LabelSmoothing Loss = 1.4183176755905151\n",
      "[INFO: 2022-02-16 19:30:09,885] Iteration 18080 (DataTime/BatchTime: 0.00128/0.48) losses = 2.172, lr = [3.286561678607819e-05, 0.00032865616786078184]\n",
      "[INFO: 2022-02-16 19:30:09,885]   LabelSmoothing Loss = 3.4253809452056885\n",
      "[INFO: 2022-02-16 19:30:19,493] Iteration 18100 (DataTime/BatchTime: 0.00126/0.48) losses = 2.2226, lr = [3.284745597528326e-05, 0.00032847455975283256]\n",
      "[INFO: 2022-02-16 19:30:19,493]   LabelSmoothing Loss = 1.4789698123931885\n",
      "[INFO: 2022-02-16 19:30:29,111] Iteration 18120 (DataTime/BatchTime: 0.00129/0.481) losses = 2.2471, lr = [3.282932523703859e-05, 0.00032829325237038583]\n",
      "[INFO: 2022-02-16 19:30:29,111]   LabelSmoothing Loss = 2.6174027919769287\n",
      "[INFO: 2022-02-16 19:30:38,657] Iteration 18140 (DataTime/BatchTime: 0.0014/0.477) losses = 2.1065, lr = [3.281122448844029e-05, 0.0003281122448844029]\n",
      "[INFO: 2022-02-16 19:30:38,658]   LabelSmoothing Loss = 1.3950591087341309\n",
      "[INFO: 2022-02-16 19:34:14,902] ######## Epoch (VAL)19 ########\n",
      "[INFO: 2022-02-16 19:34:14,902] {'Bleu_1': 0.3846037108465745, 'Bleu_2': 0.23865879158643022, 'Bleu_3': 0.16101800325444746, 'Bleu_4': 0.11215367555726673, 'METEOR': 0.19184418082675855, 'ROUGE_L': 0.31907214922059396, 'CIDEr': 0.31608659297697833}\n",
      "[INFO: 2022-02-16 19:37:54,926] ######## Epoch (TEST)19 ########\n",
      "[INFO: 2022-02-16 19:37:54,927] {'Bleu_1': 0.3613994878991019, 'Bleu_2': 0.21420124656042674, 'Bleu_3': 0.13760617077161627, 'Bleu_4': 0.0905411161847295, 'METEOR': 0.18092464204975447, 'ROUGE_L': 0.30240276166545016, 'CIDEr': 0.2715624652670599}\n",
      "[INFO: 2022-02-16 19:38:03,741] Iteration 18160 (DataTime/BatchTime: 0.077/0.551) losses = 1.9269, lr = [3.27931536469041e-05, 0.00032793153646904096]\n",
      "[INFO: 2022-02-16 19:38:03,742]   LabelSmoothing Loss = 2.504728078842163\n",
      "[INFO: 2022-02-16 19:38:13,327] Iteration 18180 (DataTime/BatchTime: 0.00128/0.479) losses = 2.4347, lr = [3.277511263016378e-05, 0.00032775112630163775]\n",
      "[INFO: 2022-02-16 19:38:13,327]   LabelSmoothing Loss = 2.210120439529419\n",
      "[INFO: 2022-02-16 19:38:22,862] Iteration 18200 (DataTime/BatchTime: 0.00128/0.477) losses = 2.1037, lr = [3.275710135626955e-05, 0.0003275710135626954]\n",
      "[INFO: 2022-02-16 19:38:22,862]   LabelSmoothing Loss = 2.1570053100585938\n",
      "[INFO: 2022-02-16 19:38:32,418] Iteration 18220 (DataTime/BatchTime: 0.0013/0.478) losses = 2.0738, lr = [3.273911974358653e-05, 0.0003273911974358653]\n",
      "[INFO: 2022-02-16 19:38:32,418]   LabelSmoothing Loss = 1.7283586263656616\n",
      "[INFO: 2022-02-16 19:38:41,927] Iteration 18240 (DataTime/BatchTime: 0.00247/0.475) losses = 2.0619, lr = [3.2721167710793204e-05, 0.000327211677107932]\n",
      "[INFO: 2022-02-16 19:38:41,927]   LabelSmoothing Loss = 2.416980504989624\n",
      "[INFO: 2022-02-16 19:38:51,470] Iteration 18260 (DataTime/BatchTime: 0.00482/0.477) losses = 2.1775, lr = [3.270324517687982e-05, 0.00032703245176879815]\n",
      "[INFO: 2022-02-16 19:38:51,470]   LabelSmoothing Loss = 3.645404577255249\n",
      "[INFO: 2022-02-16 19:39:01,080] Iteration 18280 (DataTime/BatchTime: 0.00125/0.48) losses = 2.4115, lr = [3.2685352061146915e-05, 0.0003268535206114691]\n",
      "[INFO: 2022-02-16 19:39:01,080]   LabelSmoothing Loss = 2.433438777923584\n",
      "[INFO: 2022-02-16 19:39:10,629] Iteration 18300 (DataTime/BatchTime: 0.00304/0.477) losses = 2.0579, lr = [3.266748828320374e-05, 0.00032667488283203734]\n",
      "[INFO: 2022-02-16 19:39:10,629]   LabelSmoothing Loss = 2.1248104572296143\n",
      "[INFO: 2022-02-16 19:39:20,101] Iteration 18320 (DataTime/BatchTime: 0.00131/0.474) losses = 2.1578, lr = [3.264965376296679e-05, 0.00032649653762966785]\n",
      "[INFO: 2022-02-16 19:39:20,101]   LabelSmoothing Loss = 3.076549530029297\n",
      "[INFO: 2022-02-16 19:39:29,655] Iteration 18340 (DataTime/BatchTime: 0.00222/0.478) losses = 2.0531, lr = [3.2631848420658265e-05, 0.00032631848420658263]\n",
      "[INFO: 2022-02-16 19:39:29,655]   LabelSmoothing Loss = 2.0220048427581787\n",
      "[INFO: 2022-02-16 19:39:39,247] Iteration 18360 (DataTime/BatchTime: 0.00128/0.48) losses = 2.0893, lr = [3.261407217680457e-05, 0.00032614072176804566]\n",
      "[INFO: 2022-02-16 19:39:39,247]   LabelSmoothing Loss = 1.7411824464797974\n",
      "[INFO: 2022-02-16 19:39:48,794] Iteration 18380 (DataTime/BatchTime: 0.00117/0.477) losses = 2.2953, lr = [3.259632495223484e-05, 0.0003259632495223484]\n",
      "[INFO: 2022-02-16 19:39:48,794]   LabelSmoothing Loss = 1.388403058052063\n",
      "[INFO: 2022-02-16 19:39:58,515] Iteration 18400 (DataTime/BatchTime: 0.0023/0.486) losses = 2.2771, lr = [3.257860666807946e-05, 0.00032578606668079457]\n",
      "[INFO: 2022-02-16 19:39:58,516]   LabelSmoothing Loss = 2.78684401512146\n",
      "[INFO: 2022-02-16 19:40:08,105] Iteration 18420 (DataTime/BatchTime: 0.00301/0.479) losses = 2.1183, lr = [3.256091724576857e-05, 0.00032560917245768564]\n",
      "[INFO: 2022-02-16 19:40:08,105]   LabelSmoothing Loss = 1.8371354341506958\n",
      "[INFO: 2022-02-16 19:40:17,717] Iteration 18440 (DataTime/BatchTime: 0.00212/0.481) losses = 2.1524, lr = [3.2543256607030624e-05, 0.00032543256607030625]\n",
      "[INFO: 2022-02-16 19:40:17,717]   LabelSmoothing Loss = 1.8858122825622559\n",
      "[INFO: 2022-02-16 19:40:27,369] Iteration 18460 (DataTime/BatchTime: 0.00216/0.483) losses = 2.1005, lr = [3.252562467389094e-05, 0.00032525624673890936]\n",
      "[INFO: 2022-02-16 19:40:27,369]   LabelSmoothing Loss = 2.208564281463623\n",
      "[INFO: 2022-02-16 19:40:36,953] Iteration 18480 (DataTime/BatchTime: 0.00126/0.479) losses = 2.1832, lr = [3.250802136867022e-05, 0.0003250802136867022]\n",
      "[INFO: 2022-02-16 19:40:36,954]   LabelSmoothing Loss = 2.9320662021636963\n",
      "[INFO: 2022-02-16 19:40:46,556] Iteration 18500 (DataTime/BatchTime: 0.00236/0.48) losses = 2.1193, lr = [3.249044661398316e-05, 0.00032490446613983153]\n",
      "[INFO: 2022-02-16 19:40:46,556]   LabelSmoothing Loss = 2.97109317779541\n",
      "[INFO: 2022-02-16 19:40:56,125] Iteration 18520 (DataTime/BatchTime: 0.00237/0.478) losses = 2.2074, lr = [3.247290033273697e-05, 0.00032472900332736963]\n",
      "[INFO: 2022-02-16 19:40:56,125]   LabelSmoothing Loss = 2.1147093772888184\n",
      "[INFO: 2022-02-16 19:41:05,810] Iteration 18540 (DataTime/BatchTime: 0.00223/0.484) losses = 2.136, lr = [3.245538244813e-05, 0.00032455382448129996]\n",
      "[INFO: 2022-02-16 19:41:05,810]   LabelSmoothing Loss = 1.2102787494659424\n",
      "[INFO: 2022-02-16 19:41:15,354] Iteration 18560 (DataTime/BatchTime: 0.00267/0.477) losses = 2.214, lr = [3.243789288365031e-05, 0.0003243789288365031]\n",
      "[INFO: 2022-02-16 19:41:15,354]   LabelSmoothing Loss = 0.932060956954956\n",
      "[INFO: 2022-02-16 19:41:24,879] Iteration 18580 (DataTime/BatchTime: 0.00398/0.476) losses = 2.1869, lr = [3.2420431563074256e-05, 0.0003242043156307425]\n",
      "[INFO: 2022-02-16 19:41:24,879]   LabelSmoothing Loss = 2.5381217002868652\n",
      "[INFO: 2022-02-16 19:41:34,332] Iteration 18600 (DataTime/BatchTime: 0.00181/0.473) losses = 2.2357, lr = [3.24029984104651e-05, 0.00032402998410465094]\n",
      "[INFO: 2022-02-16 19:41:34,332]   LabelSmoothing Loss = 3.1366782188415527\n",
      "[INFO: 2022-02-16 19:41:43,839] Iteration 18620 (DataTime/BatchTime: 0.00108/0.475) losses = 2.0524, lr = [3.238559335017163e-05, 0.0003238559335017163]\n",
      "[INFO: 2022-02-16 19:41:43,840]   LabelSmoothing Loss = 2.1211154460906982\n",
      "[INFO: 2022-02-16 19:41:53,458] Iteration 18640 (DataTime/BatchTime: 0.00101/0.481) losses = 2.4077, lr = [3.236821630682679e-05, 0.00032368216306826787]\n",
      "[INFO: 2022-02-16 19:41:53,458]   LabelSmoothing Loss = 2.0309455394744873\n",
      "[INFO: 2022-02-16 19:42:03,060] Iteration 18660 (DataTime/BatchTime: 0.00124/0.48) losses = 2.3845, lr = [3.235086720534628e-05, 0.0003235086720534627]\n",
      "[INFO: 2022-02-16 19:42:03,060]   LabelSmoothing Loss = 2.538517951965332\n",
      "[INFO: 2022-02-16 19:42:12,796] Iteration 18680 (DataTime/BatchTime: 0.00243/0.487) losses = 2.2403, lr = [3.233354597092721e-05, 0.00032333545970927207]\n",
      "[INFO: 2022-02-16 19:42:12,796]   LabelSmoothing Loss = 2.4031550884246826\n",
      "[INFO: 2022-02-16 19:42:22,424] Iteration 18700 (DataTime/BatchTime: 0.00123/0.481) losses = 2.2413, lr = [3.231625252904676e-05, 0.0003231625252904676]\n",
      "[INFO: 2022-02-16 19:42:22,424]   LabelSmoothing Loss = 1.9186897277832031\n",
      "[INFO: 2022-02-16 19:42:31,990] Iteration 18720 (DataTime/BatchTime: 0.00218/0.478) losses = 2.0813, lr = [3.229898680546081e-05, 0.0003229898680546081]\n",
      "[INFO: 2022-02-16 19:42:31,990]   LabelSmoothing Loss = 2.4762299060821533\n",
      "[INFO: 2022-02-16 19:42:41,577] Iteration 18740 (DataTime/BatchTime: 0.00239/0.479) losses = 2.2842, lr = [3.228174872620262e-05, 0.0003228174872620261]\n",
      "[INFO: 2022-02-16 19:42:41,577]   LabelSmoothing Loss = 2.445935010910034\n",
      "[INFO: 2022-02-16 19:42:51,125] Iteration 18760 (DataTime/BatchTime: 0.00111/0.477) losses = 2.1441, lr = [3.2264538217581466e-05, 0.00032264538217581463]\n",
      "[INFO: 2022-02-16 19:42:51,125]   LabelSmoothing Loss = 2.231051206588745\n",
      "[INFO: 2022-02-16 19:43:00,684] Iteration 18780 (DataTime/BatchTime: 0.00121/0.478) losses = 2.0476, lr = [3.224735520618137e-05, 0.0003224735520618136]\n",
      "[INFO: 2022-02-16 19:43:00,684]   LabelSmoothing Loss = 1.4788284301757812\n",
      "[INFO: 2022-02-16 19:43:10,079] Iteration 18800 (DataTime/BatchTime: 0.00184/0.47) losses = 2.0911, lr = [3.223019961885973e-05, 0.0003223019961885973]\n",
      "[INFO: 2022-02-16 19:43:10,079]   LabelSmoothing Loss = 1.5461506843566895\n",
      "[INFO: 2022-02-16 19:43:19,686] Iteration 18820 (DataTime/BatchTime: 0.00122/0.48) losses = 2.2276, lr = [3.221307138274606e-05, 0.00032213071382746053]\n",
      "[INFO: 2022-02-16 19:43:19,687]   LabelSmoothing Loss = 2.9881484508514404\n",
      "[INFO: 2022-02-16 19:43:29,202] Iteration 18840 (DataTime/BatchTime: 0.00285/0.476) losses = 2.097, lr = [3.2195970425240646e-05, 0.0003219597042524064]\n",
      "[INFO: 2022-02-16 19:43:29,202]   LabelSmoothing Loss = 2.987884283065796\n",
      "[INFO: 2022-02-16 19:43:38,809] Iteration 18860 (DataTime/BatchTime: 0.00288/0.48) losses = 2.2697, lr = [3.217889667401329e-05, 0.00032178896674013287]\n",
      "[INFO: 2022-02-16 19:43:38,809]   LabelSmoothing Loss = 2.2620368003845215\n",
      "[INFO: 2022-02-16 19:43:48,350] Iteration 18880 (DataTime/BatchTime: 0.00129/0.477) losses = 2.0456, lr = [3.216185005700201e-05, 0.00032161850057002003]\n",
      "[INFO: 2022-02-16 19:43:48,350]   LabelSmoothing Loss = 1.9681823253631592\n",
      "[INFO: 2022-02-16 19:43:57,860] Iteration 18900 (DataTime/BatchTime: 0.00117/0.475) losses = 1.9876, lr = [3.2144830502411744e-05, 0.0003214483050241174]\n",
      "[INFO: 2022-02-16 19:43:57,860]   LabelSmoothing Loss = 1.674538016319275\n",
      "[INFO: 2022-02-16 19:44:07,366] Iteration 18920 (DataTime/BatchTime: 0.00112/0.475) losses = 1.9779, lr = [3.2127837938713126e-05, 0.0003212783793871312]\n",
      "[INFO: 2022-02-16 19:44:07,366]   LabelSmoothing Loss = 2.1846868991851807\n",
      "[INFO: 2022-02-16 19:44:16,907] Iteration 18940 (DataTime/BatchTime: 0.00107/0.477) losses = 2.1312, lr = [3.211087229464117e-05, 0.0003211087229464117]\n",
      "[INFO: 2022-02-16 19:44:16,907]   LabelSmoothing Loss = 2.429439067840576\n",
      "[INFO: 2022-02-16 19:44:26,393] Iteration 18960 (DataTime/BatchTime: 0.00145/0.474) losses = 2.1433, lr = [3.209393349919407e-05, 0.00032093933499194067]\n",
      "[INFO: 2022-02-16 19:44:26,393]   LabelSmoothing Loss = 2.4596805572509766\n",
      "[INFO: 2022-02-16 19:44:36,097] Iteration 18980 (DataTime/BatchTime: 0.00202/0.485) losses = 2.424, lr = [3.207702148163189e-05, 0.0003207702148163189]\n",
      "[INFO: 2022-02-16 19:44:36,097]   LabelSmoothing Loss = 1.7510452270507812\n",
      "[INFO: 2022-02-16 19:44:45,734] Iteration 19000 (DataTime/BatchTime: 0.00129/0.482) losses = 2.2583, lr = [3.206013617147538e-05, 0.0003206013617147538]\n",
      "[INFO: 2022-02-16 19:44:45,734]   LabelSmoothing Loss = 2.977591037750244\n",
      "[INFO: 2022-02-16 19:44:55,312] Iteration 19020 (DataTime/BatchTime: 0.00219/0.479) losses = 2.0663, lr = [3.2043277498504716e-05, 0.0003204327749850471]\n",
      "[INFO: 2022-02-16 19:44:55,312]   LabelSmoothing Loss = 1.828776240348816\n",
      "[INFO: 2022-02-16 19:45:04,909] Iteration 19040 (DataTime/BatchTime: 0.00117/0.48) losses = 2.3026, lr = [3.202644539275825e-05, 0.0003202644539275825]\n",
      "[INFO: 2022-02-16 19:45:04,909]   LabelSmoothing Loss = 1.8414374589920044\n",
      "[INFO: 2022-02-16 19:45:14,388] Iteration 19060 (DataTime/BatchTime: 0.00301/0.474) losses = 2.0779, lr = [3.200963978453137e-05, 0.0003200963978453136]\n",
      "[INFO: 2022-02-16 19:45:14,388]   LabelSmoothing Loss = 1.6329495906829834\n",
      "[INFO: 2022-02-16 19:45:23,891] Iteration 19080 (DataTime/BatchTime: 0.00324/0.475) losses = 1.9753, lr = [3.1992860604375166e-05, 0.0003199286060437516]\n",
      "[INFO: 2022-02-16 19:45:23,891]   LabelSmoothing Loss = 2.6153454780578613\n",
      "[INFO: 2022-02-16 19:49:01,316] ######## Epoch (VAL)20 ########\n",
      "[INFO: 2022-02-16 19:49:01,316] {'Bleu_1': 0.3358513762441915, 'Bleu_2': 0.20895686803551303, 'Bleu_3': 0.14045736526670075, 'Bleu_4': 0.09858120183032462, 'METEOR': 0.18145521491607708, 'ROUGE_L': 0.3111206640885505, 'CIDEr': 0.20777535048638374}\n",
      "[INFO: 2022-02-16 19:52:36,399] ######## Epoch (TEST)20 ########\n",
      "[INFO: 2022-02-16 19:52:36,400] {'Bleu_1': 0.3053890297907663, 'Bleu_2': 0.17919791225516404, 'Bleu_3': 0.11109355048427134, 'Bleu_4': 0.0695851304928692, 'METEOR': 0.1679153908072285, 'ROUGE_L': 0.28171750309366145, 'CIDEr': 0.19980866546476717}\n",
      "[INFO: 2022-02-16 19:52:37,973] Iteration 19100 (DataTime/BatchTime: 0.982/1.57) losses = 1.3176, lr = [3.197610778309534e-05, 0.00031976107783095344]\n",
      "[INFO: 2022-02-16 19:52:37,973]   LabelSmoothing Loss = 1.317615270614624\n",
      "[INFO: 2022-02-16 19:52:47,625] Iteration 19120 (DataTime/BatchTime: 0.00231/0.483) losses = 2.1631, lr = [3.1959381251750964e-05, 0.00031959381251750956]\n",
      "[INFO: 2022-02-16 19:52:47,625]   LabelSmoothing Loss = 1.5113372802734375\n",
      "[INFO: 2022-02-16 19:52:57,176] Iteration 19140 (DataTime/BatchTime: 0.00127/0.478) losses = 1.9339, lr = [3.194268094165324e-05, 0.00031942680941653243]\n",
      "[INFO: 2022-02-16 19:52:57,176]   LabelSmoothing Loss = 2.44126558303833\n",
      "[INFO: 2022-02-16 19:53:06,747] Iteration 19160 (DataTime/BatchTime: 0.00137/0.479) losses = 2.0038, lr = [3.192600678436442e-05, 0.00031926006784364414]\n",
      "[INFO: 2022-02-16 19:53:06,747]   LabelSmoothing Loss = 2.1203625202178955\n",
      "[INFO: 2022-02-16 19:53:16,396] Iteration 19180 (DataTime/BatchTime: 0.00304/0.482) losses = 1.8867, lr = [3.190935871169651e-05, 0.0003190935871169651]\n",
      "[INFO: 2022-02-16 19:53:16,396]   LabelSmoothing Loss = 1.366579532623291\n",
      "[INFO: 2022-02-16 19:53:25,991] Iteration 19200 (DataTime/BatchTime: 0.00206/0.48) losses = 2.2629, lr = [3.189273665571019e-05, 0.0003189273665571019]\n",
      "[INFO: 2022-02-16 19:53:25,991]   LabelSmoothing Loss = 2.5864956378936768\n",
      "[INFO: 2022-02-16 19:53:35,530] Iteration 19220 (DataTime/BatchTime: 0.00271/0.477) losses = 1.9228, lr = [3.187614054871362e-05, 0.0003187614054871362]\n",
      "[INFO: 2022-02-16 19:53:35,530]   LabelSmoothing Loss = 1.2747688293457031\n",
      "[INFO: 2022-02-16 19:53:45,056] Iteration 19240 (DataTime/BatchTime: 0.00172/0.476) losses = 2.1003, lr = [3.185957032326126e-05, 0.00031859570323261257]\n",
      "[INFO: 2022-02-16 19:53:45,057]   LabelSmoothing Loss = 2.379737377166748\n",
      "[INFO: 2022-02-16 19:53:54,602] Iteration 19260 (DataTime/BatchTime: 0.00131/0.477) losses = 2.2696, lr = [3.184302591215275e-05, 0.00031843025912152743]\n",
      "[INFO: 2022-02-16 19:53:54,602]   LabelSmoothing Loss = 3.0804247856140137\n",
      "[INFO: 2022-02-16 19:54:04,253] Iteration 19280 (DataTime/BatchTime: 0.00235/0.483) losses = 2.1085, lr = [3.182650724843174e-05, 0.00031826507248431735]\n",
      "[INFO: 2022-02-16 19:54:04,253]   LabelSmoothing Loss = 2.194610834121704\n",
      "[INFO: 2022-02-16 19:54:13,947] Iteration 19300 (DataTime/BatchTime: 0.00228/0.485) losses = 2.0386, lr = [3.181001426538478e-05, 0.0003181001426538478]\n",
      "[INFO: 2022-02-16 19:54:13,947]   LabelSmoothing Loss = 2.598714828491211\n",
      "[INFO: 2022-02-16 19:54:23,552] Iteration 19320 (DataTime/BatchTime: 0.00138/0.48) losses = 2.2771, lr = [3.179354689654017e-05, 0.00031793546896540165]\n",
      "[INFO: 2022-02-16 19:54:23,552]   LabelSmoothing Loss = 2.60587477684021\n",
      "[INFO: 2022-02-16 19:54:33,304] Iteration 19340 (DataTime/BatchTime: 0.00217/0.488) losses = 2.2379, lr = [3.177710507566683e-05, 0.00031777105075666824]\n",
      "[INFO: 2022-02-16 19:54:33,304]   LabelSmoothing Loss = 0.991685688495636\n",
      "[INFO: 2022-02-16 19:54:42,924] Iteration 19360 (DataTime/BatchTime: 0.00137/0.481) losses = 1.9742, lr = [3.176068873677318e-05, 0.0003176068873677318]\n",
      "[INFO: 2022-02-16 19:54:42,924]   LabelSmoothing Loss = 3.4658472537994385\n",
      "[INFO: 2022-02-16 19:54:52,576] Iteration 19380 (DataTime/BatchTime: 0.00224/0.483) losses = 2.2534, lr = [3.174429781410607e-05, 0.0003174429781410607]\n",
      "[INFO: 2022-02-16 19:54:52,576]   LabelSmoothing Loss = 1.3714090585708618\n",
      "[INFO: 2022-02-16 19:55:02,353] Iteration 19400 (DataTime/BatchTime: 0.00141/0.489) losses = 2.3641, lr = [3.1727932242149615e-05, 0.00031727932242149614]\n",
      "[INFO: 2022-02-16 19:55:02,354]   LabelSmoothing Loss = 2.619706153869629\n",
      "[INFO: 2022-02-16 19:55:11,997] Iteration 19420 (DataTime/BatchTime: 0.00142/0.482) losses = 2.1847, lr = [3.171159195562412e-05, 0.0003171159195562412]\n",
      "[INFO: 2022-02-16 19:55:11,997]   LabelSmoothing Loss = 2.5395238399505615\n",
      "[INFO: 2022-02-16 19:55:21,732] Iteration 19440 (DataTime/BatchTime: 0.00141/0.487) losses = 2.1199, lr = [3.1695276889484994e-05, 0.0003169527688948499]\n",
      "[INFO: 2022-02-16 19:55:21,732]   LabelSmoothing Loss = 3.267923593521118\n",
      "[INFO: 2022-02-16 19:55:31,328] Iteration 19460 (DataTime/BatchTime: 0.00135/0.48) losses = 2.3176, lr = [3.167898697892166e-05, 0.00031678986978921655]\n",
      "[INFO: 2022-02-16 19:55:31,328]   LabelSmoothing Loss = 2.188361406326294\n",
      "[INFO: 2022-02-16 19:55:40,907] Iteration 19480 (DataTime/BatchTime: 0.00132/0.478) losses = 2.2663, lr = [3.1662722159356446e-05, 0.00031662722159356445]\n",
      "[INFO: 2022-02-16 19:55:40,907]   LabelSmoothing Loss = 1.5991193056106567\n",
      "[INFO: 2022-02-16 19:55:50,477] Iteration 19500 (DataTime/BatchTime: 0.00323/0.479) losses = 2.1182, lr = [3.164648236644357e-05, 0.00031646482366443567]\n",
      "[INFO: 2022-02-16 19:55:50,478]   LabelSmoothing Loss = 0.998880922794342\n",
      "[INFO: 2022-02-16 19:56:00,079] Iteration 19520 (DataTime/BatchTime: 0.0013/0.48) losses = 2.0101, lr = [3.163026753606801e-05, 0.00031630267536068005]\n",
      "[INFO: 2022-02-16 19:56:00,079]   LabelSmoothing Loss = 1.7337318658828735\n",
      "[INFO: 2022-02-16 19:56:09,661] Iteration 19540 (DataTime/BatchTime: 0.00131/0.479) losses = 2.2656, lr = [3.161407760434446e-05, 0.00031614077604344453]\n",
      "[INFO: 2022-02-16 19:56:09,661]   LabelSmoothing Loss = 2.6120617389678955\n",
      "[INFO: 2022-02-16 19:56:19,470] Iteration 19560 (DataTime/BatchTime: 0.00331/0.49) losses = 2.0862, lr = [3.159791250761629e-05, 0.00031597912507616284]\n",
      "[INFO: 2022-02-16 19:56:19,471]   LabelSmoothing Loss = 2.4069366455078125\n",
      "[INFO: 2022-02-16 19:56:29,024] Iteration 19580 (DataTime/BatchTime: 0.00143/0.478) losses = 2.1818, lr = [3.158177218245448e-05, 0.0003158177218245447]\n",
      "[INFO: 2022-02-16 19:56:29,024]   LabelSmoothing Loss = 2.8576653003692627\n",
      "[INFO: 2022-02-16 19:56:38,646] Iteration 19600 (DataTime/BatchTime: 0.00238/0.481) losses = 2.0837, lr = [3.156565656565657e-05, 0.0003156565656565657]\n",
      "[INFO: 2022-02-16 19:56:38,646]   LabelSmoothing Loss = 2.6270222663879395\n",
      "[INFO: 2022-02-16 19:56:48,353] Iteration 19620 (DataTime/BatchTime: 0.00142/0.485) losses = 2.2014, lr = [3.1549565594245645e-05, 0.0003154956559424564]\n",
      "[INFO: 2022-02-16 19:56:48,353]   LabelSmoothing Loss = 1.9877851009368896\n",
      "[INFO: 2022-02-16 19:56:57,943] Iteration 19640 (DataTime/BatchTime: 0.00343/0.48) losses = 1.8883, lr = [3.153349920546925e-05, 0.0003153349920546925]\n",
      "[INFO: 2022-02-16 19:56:57,943]   LabelSmoothing Loss = 1.9057523012161255\n",
      "[INFO: 2022-02-16 19:57:07,584] Iteration 19660 (DataTime/BatchTime: 0.00141/0.482) losses = 2.3302, lr = [3.151745733679845e-05, 0.0003151745733679844]\n",
      "[INFO: 2022-02-16 19:57:07,584]   LabelSmoothing Loss = 1.6833864450454712\n",
      "[INFO: 2022-02-16 19:57:17,135] Iteration 19680 (DataTime/BatchTime: 0.00228/0.478) losses = 1.9608, lr = [3.150143992592669e-05, 0.00031501439925926683]\n",
      "[INFO: 2022-02-16 19:57:17,135]   LabelSmoothing Loss = 1.3779606819152832\n",
      "[INFO: 2022-02-16 19:57:26,959] Iteration 19700 (DataTime/BatchTime: 0.00333/0.491) losses = 2.2838, lr = [3.1485446910768884e-05, 0.00031485446910768883]\n",
      "[INFO: 2022-02-16 19:57:26,960]   LabelSmoothing Loss = 2.516995668411255\n",
      "[INFO: 2022-02-16 19:57:36,525] Iteration 19720 (DataTime/BatchTime: 0.00311/0.478) losses = 2.1816, lr = [3.146947822946036e-05, 0.0003146947822946036]\n",
      "[INFO: 2022-02-16 19:57:36,525]   LabelSmoothing Loss = 2.887336492538452\n",
      "[INFO: 2022-02-16 19:57:46,215] Iteration 19740 (DataTime/BatchTime: 0.00139/0.485) losses = 2.2283, lr = [3.1453533820355844e-05, 0.00031453533820355843]\n",
      "[INFO: 2022-02-16 19:57:46,215]   LabelSmoothing Loss = 1.914204716682434\n",
      "[INFO: 2022-02-16 19:57:55,836] Iteration 19760 (DataTime/BatchTime: 0.00143/0.481) losses = 2.0661, lr = [3.1437613622028485e-05, 0.0003143761362202848]\n",
      "[INFO: 2022-02-16 19:57:55,836]   LabelSmoothing Loss = 1.6448171138763428\n",
      "[INFO: 2022-02-16 19:58:05,558] Iteration 19780 (DataTime/BatchTime: 0.00307/0.486) losses = 2.2598, lr = [3.142171757326884e-05, 0.0003142171757326884]\n",
      "[INFO: 2022-02-16 19:58:05,558]   LabelSmoothing Loss = 2.026057243347168\n",
      "[INFO: 2022-02-16 19:58:15,111] Iteration 19800 (DataTime/BatchTime: 0.0023/0.478) losses = 2.2218, lr = [3.1405845613083904e-05, 0.000314058456130839]\n",
      "[INFO: 2022-02-16 19:58:15,111]   LabelSmoothing Loss = 2.721440076828003\n",
      "[INFO: 2022-02-16 19:58:24,659] Iteration 19820 (DataTime/BatchTime: 0.00141/0.477) losses = 2.3144, lr = [3.138999768069612e-05, 0.0003138999768069612]\n",
      "[INFO: 2022-02-16 19:58:24,659]   LabelSmoothing Loss = 2.5863451957702637\n",
      "[INFO: 2022-02-16 19:58:34,313] Iteration 19840 (DataTime/BatchTime: 0.00142/0.483) losses = 2.2936, lr = [3.137417371554239e-05, 0.0003137417371554239]\n",
      "[INFO: 2022-02-16 19:58:34,314]   LabelSmoothing Loss = 2.7117888927459717\n",
      "[INFO: 2022-02-16 19:58:43,968] Iteration 19860 (DataTime/BatchTime: 0.00141/0.483) losses = 2.3359, lr = [3.135837365727313e-05, 0.0003135837365727313]\n",
      "[INFO: 2022-02-16 19:58:43,968]   LabelSmoothing Loss = 2.558223009109497\n",
      "[INFO: 2022-02-16 19:58:53,706] Iteration 19880 (DataTime/BatchTime: 0.00258/0.487) losses = 2.2054, lr = [3.134259744575127e-05, 0.00031342597445751266]\n",
      "[INFO: 2022-02-16 19:58:53,706]   LabelSmoothing Loss = 2.783936023712158\n",
      "[INFO: 2022-02-16 19:59:03,362] Iteration 19900 (DataTime/BatchTime: 0.00235/0.483) losses = 2.1259, lr = [3.132684502105132e-05, 0.00031326845021051314]\n",
      "[INFO: 2022-02-16 19:59:03,362]   LabelSmoothing Loss = 2.3575916290283203\n",
      "[INFO: 2022-02-16 19:59:12,971] Iteration 19920 (DataTime/BatchTime: 0.00138/0.48) losses = 2.0947, lr = [3.13111163234584e-05, 0.0003131111632345839]\n",
      "[INFO: 2022-02-16 19:59:12,971]   LabelSmoothing Loss = 2.4085495471954346\n",
      "[INFO: 2022-02-16 19:59:22,659] Iteration 19940 (DataTime/BatchTime: 0.00139/0.484) losses = 2.4197, lr = [3.129541129346728e-05, 0.0003129541129346728]\n",
      "[INFO: 2022-02-16 19:59:22,659]   LabelSmoothing Loss = 1.8856953382492065\n",
      "[INFO: 2022-02-16 19:59:32,285] Iteration 19960 (DataTime/BatchTime: 0.00242/0.481) losses = 2.1408, lr = [3.127972987178148e-05, 0.0003127972987178147]\n",
      "[INFO: 2022-02-16 19:59:32,285]   LabelSmoothing Loss = 1.4357855319976807\n",
      "[INFO: 2022-02-16 19:59:41,900] Iteration 19980 (DataTime/BatchTime: 0.00232/0.481) losses = 1.9887, lr = [3.126407199931226e-05, 0.0003126407199931225]\n",
      "[INFO: 2022-02-16 19:59:41,900]   LabelSmoothing Loss = 1.3074222803115845\n",
      "[INFO: 2022-02-16 19:59:51,547] Iteration 20000 (DataTime/BatchTime: 0.0016/0.482) losses = 1.9862, lr = [3.124843761717774e-05, 0.0003124843761717774]\n",
      "[INFO: 2022-02-16 19:59:51,547]   LabelSmoothing Loss = 2.5190742015838623\n",
      "[INFO: 2022-02-16 20:00:01,181] Iteration 20020 (DataTime/BatchTime: 0.00144/0.482) losses = 2.035, lr = [3.123282666670196e-05, 0.00031232826666701953]\n",
      "[INFO: 2022-02-16 20:00:01,181]   LabelSmoothing Loss = 2.4767258167266846\n",
      "[INFO: 2022-02-16 20:00:10,830] Iteration 20040 (DataTime/BatchTime: 0.00154/0.482) losses = 2.2003, lr = [3.121723908941392e-05, 0.0003121723908941392]\n",
      "[INFO: 2022-02-16 20:00:10,830]   LabelSmoothing Loss = 1.914473056793213\n",
      "[INFO: 2022-02-16 20:03:51,321] ######## Epoch (VAL)21 ########\n",
      "[INFO: 2022-02-16 20:03:51,321] {'Bleu_1': 0.3117483730449823, 'Bleu_2': 0.19244981399541639, 'Bleu_3': 0.12968541155651037, 'Bleu_4': 0.09251345165528846, 'METEOR': 0.1721414336063794, 'ROUGE_L': 0.3119978702166016, 'CIDEr': 0.41030528530742727}\n",
      "[INFO: 2022-02-16 20:07:28,812] ######## Epoch (TEST)21 ########\n",
      "[INFO: 2022-02-16 20:07:28,812] {'Bleu_1': 0.2892343527793005, 'Bleu_2': 0.1652033642901737, 'Bleu_3': 0.1043777687806194, 'Bleu_4': 0.06976158373618223, 'METEOR': 0.15983690141900606, 'ROUGE_L': 0.28841342211893567, 'CIDEr': 0.2722761211617019}\n",
      "[INFO: 2022-02-16 20:07:32,858] Iteration 20060 (DataTime/BatchTime: 0.185/0.674) losses = 1.7001, lr = [3.1201674827046716e-05, 0.00031201674827046716]\n",
      "[INFO: 2022-02-16 20:07:32,858]   LabelSmoothing Loss = 0.7139063477516174\n",
      "[INFO: 2022-02-16 20:07:42,454] Iteration 20080 (DataTime/BatchTime: 0.00231/0.48) losses = 2.221, lr = [3.118613382153658e-05, 0.00031186133821536574]\n",
      "[INFO: 2022-02-16 20:07:42,454]   LabelSmoothing Loss = 2.97417950630188\n",
      "[INFO: 2022-02-16 20:07:52,004] Iteration 20100 (DataTime/BatchTime: 0.00395/0.476) losses = 2.0167, lr = [3.117061601502199e-05, 0.00031170616015021983]\n",
      "[INFO: 2022-02-16 20:07:52,004]   LabelSmoothing Loss = 1.954047679901123\n",
      "[INFO: 2022-02-16 20:08:01,622] Iteration 20120 (DataTime/BatchTime: 0.0025/0.482) losses = 1.9532, lr = [3.115512134984275e-05, 0.00031155121349842746]\n",
      "[INFO: 2022-02-16 20:08:01,622]   LabelSmoothing Loss = 1.2120521068572998\n",
      "[INFO: 2022-02-16 20:08:11,338] Iteration 20140 (DataTime/BatchTime: 0.00214/0.486) losses = 2.314, lr = [3.1139649768539126e-05, 0.0003113964976853912]\n",
      "[INFO: 2022-02-16 20:08:11,339]   LabelSmoothing Loss = 1.4782249927520752\n",
      "[INFO: 2022-02-16 20:08:20,854] Iteration 20160 (DataTime/BatchTime: 0.00218/0.476) losses = 2.1032, lr = [3.11242012138509e-05, 0.000311242012138509]\n",
      "[INFO: 2022-02-16 20:08:20,854]   LabelSmoothing Loss = 1.9401464462280273\n",
      "[INFO: 2022-02-16 20:08:30,352] Iteration 20180 (DataTime/BatchTime: 0.0021/0.475) losses = 2.0952, lr = [3.110877562871654e-05, 0.00031108775628716536]\n",
      "[INFO: 2022-02-16 20:08:30,352]   LabelSmoothing Loss = 1.795963168144226\n",
      "[INFO: 2022-02-16 20:08:39,916] Iteration 20200 (DataTime/BatchTime: 0.00224/0.478) losses = 2.0996, lr = [3.1093372956272245e-05, 0.0003109337295627224]\n",
      "[INFO: 2022-02-16 20:08:39,916]   LabelSmoothing Loss = 2.5518643856048584\n",
      "[INFO: 2022-02-16 20:08:49,496] Iteration 20220 (DataTime/BatchTime: 0.00129/0.479) losses = 1.9679, lr = [3.107799313985112e-05, 0.0003107799313985112]\n",
      "[INFO: 2022-02-16 20:08:49,496]   LabelSmoothing Loss = 2.670346736907959\n",
      "[INFO: 2022-02-16 20:08:59,008] Iteration 20240 (DataTime/BatchTime: 0.00242/0.476) losses = 2.2462, lr = [3.106263612298228e-05, 0.0003106263612298228]\n",
      "[INFO: 2022-02-16 20:08:59,008]   LabelSmoothing Loss = 2.154674530029297\n",
      "[INFO: 2022-02-16 20:09:08,495] Iteration 20260 (DataTime/BatchTime: 0.0022/0.474) losses = 2.2253, lr = [3.104730184938999e-05, 0.00031047301849389985]\n",
      "[INFO: 2022-02-16 20:09:08,495]   LabelSmoothing Loss = 1.6154571771621704\n",
      "[INFO: 2022-02-16 20:09:18,115] Iteration 20280 (DataTime/BatchTime: 0.0014/0.481) losses = 2.0765, lr = [3.1031990262992756e-05, 0.00031031990262992754]\n",
      "[INFO: 2022-02-16 20:09:18,115]   LabelSmoothing Loss = 2.089109420776367\n",
      "[INFO: 2022-02-16 20:09:27,662] Iteration 20300 (DataTime/BatchTime: 0.00374/0.477) losses = 2.2163, lr = [3.101670130790254e-05, 0.0003101670130790254]\n",
      "[INFO: 2022-02-16 20:09:27,662]   LabelSmoothing Loss = 2.227962017059326\n",
      "[INFO: 2022-02-16 20:09:37,244] Iteration 20320 (DataTime/BatchTime: 0.00126/0.479) losses = 2.1965, lr = [3.100143492842384e-05, 0.00031001434928423836]\n",
      "[INFO: 2022-02-16 20:09:37,244]   LabelSmoothing Loss = 1.9387627840042114\n",
      "[INFO: 2022-02-16 20:09:46,732] Iteration 20340 (DataTime/BatchTime: 0.00219/0.474) losses = 2.1132, lr = [3.0986191069052843e-05, 0.0003098619106905284]\n",
      "[INFO: 2022-02-16 20:09:46,732]   LabelSmoothing Loss = 1.7460551261901855\n",
      "[INFO: 2022-02-16 20:09:56,336] Iteration 20360 (DataTime/BatchTime: 0.0029/0.48) losses = 2.3197, lr = [3.0970969674476616e-05, 0.00030970969674476613]\n",
      "[INFO: 2022-02-16 20:09:56,336]   LabelSmoothing Loss = 1.2545793056488037\n",
      "[INFO: 2022-02-16 20:10:05,943] Iteration 20380 (DataTime/BatchTime: 0.00129/0.48) losses = 2.0716, lr = [3.095577068957224e-05, 0.0003095577068957223]\n",
      "[INFO: 2022-02-16 20:10:05,943]   LabelSmoothing Loss = 3.403299570083618\n",
      "[INFO: 2022-02-16 20:10:15,667] Iteration 20400 (DataTime/BatchTime: 0.00138/0.486) losses = 2.1714, lr = [3.094059405940595e-05, 0.0003094059405940594]\n",
      "[INFO: 2022-02-16 20:10:15,667]   LabelSmoothing Loss = 2.6110994815826416\n",
      "[INFO: 2022-02-16 20:10:25,169] Iteration 20420 (DataTime/BatchTime: 0.00133/0.475) losses = 1.8966, lr = [3.0925439729232335e-05, 0.0003092543972923233]\n",
      "[INFO: 2022-02-16 20:10:25,169]   LabelSmoothing Loss = 2.1653244495391846\n",
      "[INFO: 2022-02-16 20:10:34,721] Iteration 20440 (DataTime/BatchTime: 0.00328/0.478) losses = 2.2082, lr = [3.0910307644493506e-05, 0.000309103076444935]\n",
      "[INFO: 2022-02-16 20:10:34,721]   LabelSmoothing Loss = 2.917741298675537\n",
      "[INFO: 2022-02-16 20:10:44,464] Iteration 20460 (DataTime/BatchTime: 0.00142/0.486) losses = 1.9866, lr = [3.089519775081824e-05, 0.0003089519775081823]\n",
      "[INFO: 2022-02-16 20:10:44,464]   LabelSmoothing Loss = 2.384150981903076\n",
      "[INFO: 2022-02-16 20:10:54,082] Iteration 20480 (DataTime/BatchTime: 0.00476/0.482) losses = 2.15, lr = [3.08801099940212e-05, 0.0003088010999402119]\n",
      "[INFO: 2022-02-16 20:10:54,082]   LabelSmoothing Loss = 1.4439677000045776\n",
      "[INFO: 2022-02-16 20:11:03,685] Iteration 20500 (DataTime/BatchTime: 0.00126/0.48) losses = 2.1687, lr = [3.0865044320102076e-05, 0.00030865044320102075]\n",
      "[INFO: 2022-02-16 20:11:03,685]   LabelSmoothing Loss = 0.5117899179458618\n",
      "[INFO: 2022-02-16 20:11:13,179] Iteration 20520 (DataTime/BatchTime: 0.00117/0.475) losses = 2.1264, lr = [3.085000067524483e-05, 0.0003085000067524483]\n",
      "[INFO: 2022-02-16 20:11:13,179]   LabelSmoothing Loss = 1.7273544073104858\n",
      "[INFO: 2022-02-16 20:11:22,681] Iteration 20540 (DataTime/BatchTime: 0.00215/0.475) losses = 2.0922, lr = [3.083497900581682e-05, 0.00030834979005816816]\n",
      "[INFO: 2022-02-16 20:11:22,681]   LabelSmoothing Loss = 1.9707117080688477\n",
      "[INFO: 2022-02-16 20:11:32,225] Iteration 20560 (DataTime/BatchTime: 0.00217/0.477) losses = 2.0111, lr = [3.0819979258368057e-05, 0.00030819979258368054]\n",
      "[INFO: 2022-02-16 20:11:32,225]   LabelSmoothing Loss = 0.9803858995437622\n",
      "[INFO: 2022-02-16 20:11:41,785] Iteration 20580 (DataTime/BatchTime: 0.00121/0.478) losses = 2.2683, lr = [3.0805001379630365e-05, 0.0003080500137963036]\n",
      "[INFO: 2022-02-16 20:11:41,785]   LabelSmoothing Loss = 1.6684985160827637\n",
      "[INFO: 2022-02-16 20:11:51,287] Iteration 20600 (DataTime/BatchTime: 0.0012/0.475) losses = 1.9709, lr = [3.0790045316516613e-05, 0.0003079004531651661]\n",
      "[INFO: 2022-02-16 20:11:51,287]   LabelSmoothing Loss = 2.1540982723236084\n",
      "[INFO: 2022-02-16 20:12:00,877] Iteration 20620 (DataTime/BatchTime: 0.00128/0.479) losses = 2.0661, lr = [3.077511101611991e-05, 0.00030775111016119905]\n",
      "[INFO: 2022-02-16 20:12:00,877]   LabelSmoothing Loss = 2.7612390518188477\n",
      "[INFO: 2022-02-16 20:12:10,433] Iteration 20640 (DataTime/BatchTime: 0.00247/0.478) losses = 2.0165, lr = [3.0760198425712835e-05, 0.0003076019842571283]\n",
      "[INFO: 2022-02-16 20:12:10,433]   LabelSmoothing Loss = 1.8997318744659424\n",
      "[INFO: 2022-02-16 20:12:19,983] Iteration 20660 (DataTime/BatchTime: 0.00129/0.477) losses = 2.2576, lr = [3.0745307492746615e-05, 0.0003074530749274661]\n",
      "[INFO: 2022-02-16 20:12:19,983]   LabelSmoothing Loss = 2.2088940143585205\n",
      "[INFO: 2022-02-16 20:12:29,517] Iteration 20680 (DataTime/BatchTime: 0.00213/0.477) losses = 2.1787, lr = [3.073043816485041e-05, 0.00030730438164850403]\n",
      "[INFO: 2022-02-16 20:12:29,517]   LabelSmoothing Loss = 2.142704963684082\n",
      "[INFO: 2022-02-16 20:12:39,083] Iteration 20700 (DataTime/BatchTime: 0.00131/0.478) losses = 2.2242, lr = [3.0715590389830475e-05, 0.0003071559038983047]\n",
      "[INFO: 2022-02-16 20:12:39,083]   LabelSmoothing Loss = 2.038034677505493\n",
      "[INFO: 2022-02-16 20:12:48,564] Iteration 20720 (DataTime/BatchTime: 0.00131/0.474) losses = 2.1837, lr = [3.070076411566944e-05, 0.0003070076411566944]\n",
      "[INFO: 2022-02-16 20:12:48,564]   LabelSmoothing Loss = 1.4809718132019043\n",
      "[INFO: 2022-02-16 20:12:58,069] Iteration 20740 (DataTime/BatchTime: 0.00218/0.475) losses = 2.2264, lr = [3.068595929052553e-05, 0.00030685959290525526]\n",
      "[INFO: 2022-02-16 20:12:58,069]   LabelSmoothing Loss = 2.071788787841797\n",
      "[INFO: 2022-02-16 20:13:07,684] Iteration 20760 (DataTime/BatchTime: 0.0013/0.481) losses = 2.1908, lr = [3.067117586273178e-05, 0.0003067117586273178]\n",
      "[INFO: 2022-02-16 20:13:07,684]   LabelSmoothing Loss = 2.6473050117492676\n",
      "[INFO: 2022-02-16 20:13:17,241] Iteration 20780 (DataTime/BatchTime: 0.00129/0.478) losses = 2.1734, lr = [3.0656413780795305e-05, 0.00030656413780795304]\n",
      "[INFO: 2022-02-16 20:13:17,242]   LabelSmoothing Loss = 2.283177614212036\n",
      "[INFO: 2022-02-16 20:13:26,914] Iteration 20800 (DataTime/BatchTime: 0.00216/0.484) losses = 2.0932, lr = [3.064167299339654e-05, 0.0003064167299339654]\n",
      "[INFO: 2022-02-16 20:13:26,914]   LabelSmoothing Loss = 2.7642621994018555\n",
      "[INFO: 2022-02-16 20:13:36,511] Iteration 20820 (DataTime/BatchTime: 0.00231/0.48) losses = 2.3262, lr = [3.062695344938849e-05, 0.0003062695344938849]\n",
      "[INFO: 2022-02-16 20:13:36,512]   LabelSmoothing Loss = 1.9433962106704712\n",
      "[INFO: 2022-02-16 20:13:46,087] Iteration 20840 (DataTime/BatchTime: 0.00294/0.478) losses = 2.026, lr = [3.061225509779599e-05, 0.00030612255097795985]\n",
      "[INFO: 2022-02-16 20:13:46,088]   LabelSmoothing Loss = 1.6897259950637817\n",
      "[INFO: 2022-02-16 20:13:55,737] Iteration 20860 (DataTime/BatchTime: 0.0059/0.484) losses = 2.0891, lr = [3.059757788781494e-05, 0.0003059757788781493]\n",
      "[INFO: 2022-02-16 20:13:55,737]   LabelSmoothing Loss = 2.7664706707000732\n",
      "[INFO: 2022-02-16 20:14:05,329] Iteration 20880 (DataTime/BatchTime: 0.00151/0.48) losses = 1.9732, lr = [3.058292176881159e-05, 0.0003058292176881158]\n",
      "[INFO: 2022-02-16 20:14:05,329]   LabelSmoothing Loss = 2.6532464027404785\n",
      "[INFO: 2022-02-16 20:14:14,866] Iteration 20900 (DataTime/BatchTime: 0.00219/0.477) losses = 2.0509, lr = [3.056828669032181e-05, 0.00030568286690321804]\n",
      "[INFO: 2022-02-16 20:14:14,867]   LabelSmoothing Loss = 2.6780753135681152\n",
      "[INFO: 2022-02-16 20:14:24,421] Iteration 20920 (DataTime/BatchTime: 0.00333/0.478) losses = 2.2296, lr = [3.0553672602050347e-05, 0.00030553672602050345]\n",
      "[INFO: 2022-02-16 20:14:24,421]   LabelSmoothing Loss = 1.8408522605895996\n",
      "[INFO: 2022-02-16 20:14:33,925] Iteration 20940 (DataTime/BatchTime: 0.00119/0.475) losses = 2.033, lr = [3.0539079453870106e-05, 0.00030539079453870106]\n",
      "[INFO: 2022-02-16 20:14:33,926]   LabelSmoothing Loss = 1.5442132949829102\n",
      "[INFO: 2022-02-16 20:14:43,634] Iteration 20960 (DataTime/BatchTime: 0.00136/0.485) losses = 2.0799, lr = [3.0524507195821415e-05, 0.0003052450719582141]\n",
      "[INFO: 2022-02-16 20:14:43,634]   LabelSmoothing Loss = 1.9390816688537598\n",
      "[INFO: 2022-02-16 20:14:53,200] Iteration 20980 (DataTime/BatchTime: 0.00312/0.478) losses = 1.9305, lr = [3.050995577811133e-05, 0.00030509955778111326]\n",
      "[INFO: 2022-02-16 20:14:53,200]   LabelSmoothing Loss = 2.8875536918640137\n",
      "[INFO: 2022-02-16 20:15:02,868] Iteration 21000 (DataTime/BatchTime: 0.00214/0.483) losses = 2.344, lr = [3.0495425151112898e-05, 0.00030495425151112895]\n",
      "[INFO: 2022-02-16 20:15:02,868]   LabelSmoothing Loss = 3.016592264175415\n",
      "[INFO: 2022-02-16 20:18:37,405] ######## Epoch (VAL)22 ########\n",
      "[INFO: 2022-02-16 20:18:37,405] {'Bleu_1': 0.36413081520983426, 'Bleu_2': 0.22705175291569565, 'Bleu_3': 0.15423528320281296, 'Bleu_4': 0.10895524271364006, 'METEOR': 0.18533213840955112, 'ROUGE_L': 0.32415187723537187, 'CIDEr': 0.3738893510492875}\n",
      "[INFO: 2022-02-16 20:22:11,680] ######## Epoch (TEST)22 ########\n",
      "[INFO: 2022-02-16 20:22:11,681] {'Bleu_1': 0.3351549471607736, 'Bleu_2': 0.1972837748302385, 'Bleu_3': 0.1269553453512406, 'Bleu_4': 0.08442866682235847, 'METEOR': 0.17028630657343577, 'ROUGE_L': 0.3002532284123427, 'CIDEr': 0.2692300797413971}\n",
      "[INFO: 2022-02-16 20:22:18,088] Iteration 21020 (DataTime/BatchTime: 0.109/0.582) losses = 1.972, lr = [3.048091526536446e-05, 0.00030480915265364457]\n",
      "[INFO: 2022-02-16 20:22:18,089]   LabelSmoothing Loss = 1.8370729684829712\n",
      "[INFO: 2022-02-16 20:22:27,505] Iteration 21040 (DataTime/BatchTime: 0.00212/0.471) losses = 2.0585, lr = [3.046642607156894e-05, 0.00030466426071568934]\n",
      "[INFO: 2022-02-16 20:22:27,505]   LabelSmoothing Loss = 2.759108543395996\n",
      "[INFO: 2022-02-16 20:22:37,027] Iteration 21060 (DataTime/BatchTime: 0.00132/0.476) losses = 1.9247, lr = [3.045195752059313e-05, 0.00030451957520593123]\n",
      "[INFO: 2022-02-16 20:22:37,027]   LabelSmoothing Loss = 0.44710320234298706\n",
      "[INFO: 2022-02-16 20:22:46,544] Iteration 21080 (DataTime/BatchTime: 0.00316/0.476) losses = 1.9575, lr = [3.0437509563467014e-05, 0.0003043750956346701]\n",
      "[INFO: 2022-02-16 20:22:46,544]   LabelSmoothing Loss = 1.3781466484069824\n",
      "[INFO: 2022-02-16 20:22:56,174] Iteration 21100 (DataTime/BatchTime: 0.00134/0.481) losses = 2.0543, lr = [3.0423082151383057e-05, 0.00030423082151383055]\n",
      "[INFO: 2022-02-16 20:22:56,174]   LabelSmoothing Loss = 0.9873930811882019\n",
      "[INFO: 2022-02-16 20:23:05,704] Iteration 21120 (DataTime/BatchTime: 0.00222/0.476) losses = 2.1304, lr = [3.040867523569551e-05, 0.00030408675235695507]\n",
      "[INFO: 2022-02-16 20:23:05,704]   LabelSmoothing Loss = 2.3732073307037354\n",
      "[INFO: 2022-02-16 20:23:15,306] Iteration 21140 (DataTime/BatchTime: 0.00136/0.48) losses = 2.1019, lr = [3.0394288767919726e-05, 0.0003039428876791972]\n",
      "[INFO: 2022-02-16 20:23:15,306]   LabelSmoothing Loss = 1.5039212703704834\n",
      "[INFO: 2022-02-16 20:23:24,777] Iteration 21160 (DataTime/BatchTime: 0.00129/0.474) losses = 1.896, lr = [3.037992269973148e-05, 0.00030379922699731477]\n",
      "[INFO: 2022-02-16 20:23:24,778]   LabelSmoothing Loss = 2.586214542388916\n",
      "[INFO: 2022-02-16 20:23:34,278] Iteration 21180 (DataTime/BatchTime: 0.00214/0.475) losses = 2.0776, lr = [3.036557698296627e-05, 0.00030365576982966264]\n",
      "[INFO: 2022-02-16 20:23:34,278]   LabelSmoothing Loss = 1.3472524881362915\n",
      "[INFO: 2022-02-16 20:23:43,795] Iteration 21200 (DataTime/BatchTime: 0.00128/0.476) losses = 2.0269, lr = [3.0351251569618664e-05, 0.00030351251569618663]\n",
      "[INFO: 2022-02-16 20:23:43,795]   LabelSmoothing Loss = 1.5673493146896362\n",
      "[INFO: 2022-02-16 20:23:53,327] Iteration 21220 (DataTime/BatchTime: 0.00128/0.477) losses = 2.0345, lr = [3.0336946411841602e-05, 0.00030336946411841596]\n",
      "[INFO: 2022-02-16 20:23:53,327]   LabelSmoothing Loss = 1.9030101299285889\n",
      "[INFO: 2022-02-16 20:24:02,857] Iteration 21240 (DataTime/BatchTime: 0.00217/0.477) losses = 2.1081, lr = [3.0322661461945735e-05, 0.0003032266146194573]\n",
      "[INFO: 2022-02-16 20:24:02,857]   LabelSmoothing Loss = 1.7441860437393188\n",
      "[INFO: 2022-02-16 20:24:12,391] Iteration 21260 (DataTime/BatchTime: 0.00129/0.477) losses = 1.9884, lr = [3.0308396672398764e-05, 0.0003030839667239876]\n",
      "[INFO: 2022-02-16 20:24:12,392]   LabelSmoothing Loss = 1.3591136932373047\n",
      "[INFO: 2022-02-16 20:24:21,943] Iteration 21280 (DataTime/BatchTime: 0.00131/0.478) losses = 2.1834, lr = [3.029415199582476e-05, 0.00030294151995824756]\n",
      "[INFO: 2022-02-16 20:24:21,943]   LabelSmoothing Loss = 2.5168232917785645\n",
      "[INFO: 2022-02-16 20:24:31,456] Iteration 21300 (DataTime/BatchTime: 0.00128/0.476) losses = 2.1244, lr = [3.0279927385003514e-05, 0.00030279927385003507]\n",
      "[INFO: 2022-02-16 20:24:31,456]   LabelSmoothing Loss = 3.1198322772979736\n",
      "[INFO: 2022-02-16 20:24:41,066] Iteration 21320 (DataTime/BatchTime: 0.00137/0.481) losses = 2.1985, lr = [3.0265722792869877e-05, 0.0003026572279286987]\n",
      "[INFO: 2022-02-16 20:24:41,066]   LabelSmoothing Loss = 1.7110521793365479\n",
      "[INFO: 2022-02-16 20:24:50,564] Iteration 21340 (DataTime/BatchTime: 0.00128/0.475) losses = 2.0451, lr = [3.025153817251311e-05, 0.0003025153817251311]\n",
      "[INFO: 2022-02-16 20:24:50,564]   LabelSmoothing Loss = 2.6542775630950928\n",
      "[INFO: 2022-02-16 20:25:00,070] Iteration 21360 (DataTime/BatchTime: 0.00129/0.475) losses = 2.2735, lr = [3.0237373477176223e-05, 0.0003023737347717622]\n",
      "[INFO: 2022-02-16 20:25:00,070]   LabelSmoothing Loss = 0.8602527379989624\n",
      "[INFO: 2022-02-16 20:25:09,641] Iteration 21380 (DataTime/BatchTime: 0.00128/0.479) losses = 2.2224, lr = [3.022322866025534e-05, 0.00030223228660255337]\n",
      "[INFO: 2022-02-16 20:25:09,641]   LabelSmoothing Loss = 0.9853208661079407\n",
      "[INFO: 2022-02-16 20:25:19,323] Iteration 21400 (DataTime/BatchTime: 0.00134/0.484) losses = 2.0285, lr = [3.0209103675299043e-05, 0.0003020910367529904]\n",
      "[INFO: 2022-02-16 20:25:19,323]   LabelSmoothing Loss = 3.384734869003296\n",
      "[INFO: 2022-02-16 20:25:28,796] Iteration 21420 (DataTime/BatchTime: 0.00129/0.474) losses = 2.1749, lr = [3.019499847600774e-05, 0.0003019499847600774]\n",
      "[INFO: 2022-02-16 20:25:28,796]   LabelSmoothing Loss = 1.8724465370178223\n",
      "[INFO: 2022-02-16 20:25:38,300] Iteration 21440 (DataTime/BatchTime: 0.00128/0.475) losses = 2.1875, lr = [3.0180913016233034e-05, 0.0003018091301623303]\n",
      "[INFO: 2022-02-16 20:25:38,300]   LabelSmoothing Loss = 2.8060598373413086\n",
      "[INFO: 2022-02-16 20:25:47,759] Iteration 21460 (DataTime/BatchTime: 0.00126/0.473) losses = 1.998, lr = [3.0166847249977057e-05, 0.00030166847249977054]\n",
      "[INFO: 2022-02-16 20:25:47,759]   LabelSmoothing Loss = 2.621629238128662\n",
      "[INFO: 2022-02-16 20:25:57,275] Iteration 21480 (DataTime/BatchTime: 0.00128/0.476) losses = 2.1428, lr = [3.0152801131391883e-05, 0.0003015280113139188]\n",
      "[INFO: 2022-02-16 20:25:57,275]   LabelSmoothing Loss = 2.523010015487671\n",
      "[INFO: 2022-02-16 20:26:06,793] Iteration 21500 (DataTime/BatchTime: 0.00127/0.476) losses = 2.0786, lr = [3.0138774614778874e-05, 0.0003013877461477887]\n",
      "[INFO: 2022-02-16 20:26:06,793]   LabelSmoothing Loss = 1.8818724155426025\n",
      "[INFO: 2022-02-16 20:26:16,379] Iteration 21520 (DataTime/BatchTime: 0.00135/0.479) losses = 2.0574, lr = [3.0124767654588054e-05, 0.0003012476765458805]\n",
      "[INFO: 2022-02-16 20:26:16,379]   LabelSmoothing Loss = 1.862113356590271\n",
      "[INFO: 2022-02-16 20:26:26,001] Iteration 21540 (DataTime/BatchTime: 0.00128/0.481) losses = 1.9302, lr = [3.01107802054175e-05, 0.000301107802054175]\n",
      "[INFO: 2022-02-16 20:26:26,002]   LabelSmoothing Loss = 1.7170796394348145\n",
      "[INFO: 2022-02-16 20:26:35,617] Iteration 21560 (DataTime/BatchTime: 0.0013/0.481) losses = 2.1082, lr = [3.009681222201272e-05, 0.0003009681222201272]\n",
      "[INFO: 2022-02-16 20:26:35,617]   LabelSmoothing Loss = 2.584620714187622\n",
      "[INFO: 2022-02-16 20:26:45,134] Iteration 21580 (DataTime/BatchTime: 0.00127/0.476) losses = 2.0935, lr = [3.0082863659266036e-05, 0.0003008286365926603]\n",
      "[INFO: 2022-02-16 20:26:45,134]   LabelSmoothing Loss = 1.7705868482589722\n",
      "[INFO: 2022-02-16 20:26:54,832] Iteration 21600 (DataTime/BatchTime: 0.00304/0.485) losses = 2.1816, lr = [3.0068934472215965e-05, 0.0003006893447221596]\n",
      "[INFO: 2022-02-16 20:26:54,832]   LabelSmoothing Loss = 2.7352914810180664\n",
      "[INFO: 2022-02-16 20:27:04,364] Iteration 21620 (DataTime/BatchTime: 0.00127/0.477) losses = 2.1936, lr = [3.0055024616046624e-05, 0.0003005502461604662]\n",
      "[INFO: 2022-02-16 20:27:04,364]   LabelSmoothing Loss = 1.4959702491760254\n",
      "[INFO: 2022-02-16 20:27:13,924] Iteration 21640 (DataTime/BatchTime: 0.00128/0.478) losses = 2.0637, lr = [3.0041134046087126e-05, 0.00030041134046087124]\n",
      "[INFO: 2022-02-16 20:27:13,924]   LabelSmoothing Loss = 2.513779640197754\n",
      "[INFO: 2022-02-16 20:27:23,512] Iteration 21660 (DataTime/BatchTime: 0.00206/0.479) losses = 2.171, lr = [3.0027262717810952e-05, 0.0003002726271781095]\n",
      "[INFO: 2022-02-16 20:27:23,512]   LabelSmoothing Loss = 2.5425901412963867\n",
      "[INFO: 2022-02-16 20:27:33,109] Iteration 21680 (DataTime/BatchTime: 0.0013/0.48) losses = 1.9586, lr = [3.001341058683538e-05, 0.00030013410586835377]\n",
      "[INFO: 2022-02-16 20:27:33,109]   LabelSmoothing Loss = 1.9220280647277832\n",
      "[INFO: 2022-02-16 20:27:42,652] Iteration 21700 (DataTime/BatchTime: 0.00208/0.477) losses = 2.0837, lr = [2.9999577608920883e-05, 0.0002999957760892088]\n",
      "[INFO: 2022-02-16 20:27:42,652]   LabelSmoothing Loss = 2.8313815593719482\n",
      "[INFO: 2022-02-16 20:27:52,217] Iteration 21720 (DataTime/BatchTime: 0.00129/0.478) losses = 2.1298, lr = [2.998576373997052e-05, 0.00029985763739970517]\n",
      "[INFO: 2022-02-16 20:27:52,217]   LabelSmoothing Loss = 2.8124475479125977\n",
      "[INFO: 2022-02-16 20:28:01,881] Iteration 21740 (DataTime/BatchTime: 0.00277/0.483) losses = 2.2859, lr = [2.9971968936029367e-05, 0.0002997196893602936]\n",
      "[INFO: 2022-02-16 20:28:01,882]   LabelSmoothing Loss = 2.642268180847168\n",
      "[INFO: 2022-02-16 20:28:11,400] Iteration 21760 (DataTime/BatchTime: 0.00217/0.476) losses = 2.0637, lr = [2.99581931532839e-05, 0.000299581931532839]\n",
      "[INFO: 2022-02-16 20:28:11,401]   LabelSmoothing Loss = 1.8333320617675781\n",
      "[INFO: 2022-02-16 20:28:20,952] Iteration 21780 (DataTime/BatchTime: 0.00129/0.478) losses = 2.2382, lr = [2.994443634806145e-05, 0.0002994443634806145]\n",
      "[INFO: 2022-02-16 20:28:20,952]   LabelSmoothing Loss = 1.0450737476348877\n",
      "[INFO: 2022-02-16 20:28:30,636] Iteration 21800 (DataTime/BatchTime: 0.00136/0.484) losses = 2.154, lr = [2.993069847682959e-05, 0.0002993069847682959]\n",
      "[INFO: 2022-02-16 20:28:30,636]   LabelSmoothing Loss = 2.4769511222839355\n",
      "[INFO: 2022-02-16 20:28:40,147] Iteration 21820 (DataTime/BatchTime: 0.00125/0.476) losses = 2.1251, lr = [2.9916979496195574e-05, 0.0002991697949619557]\n",
      "[INFO: 2022-02-16 20:28:40,148]   LabelSmoothing Loss = 2.1108129024505615\n",
      "[INFO: 2022-02-16 20:28:49,807] Iteration 21840 (DataTime/BatchTime: 0.0013/0.483) losses = 2.1148, lr = [2.9903279362905738e-05, 0.00029903279362905735]\n",
      "[INFO: 2022-02-16 20:28:49,807]   LabelSmoothing Loss = 1.669371485710144\n",
      "[INFO: 2022-02-16 20:28:59,396] Iteration 21860 (DataTime/BatchTime: 0.00134/0.479) losses = 2.1495, lr = [2.9889598033844964e-05, 0.0002988959803384496]\n",
      "[INFO: 2022-02-16 20:28:59,396]   LabelSmoothing Loss = 1.9240992069244385\n",
      "[INFO: 2022-02-16 20:29:08,972] Iteration 21880 (DataTime/BatchTime: 0.00209/0.479) losses = 1.9154, lr = [2.987593546603608e-05, 0.00029875935466036076]\n",
      "[INFO: 2022-02-16 20:29:08,972]   LabelSmoothing Loss = 1.3402429819107056\n",
      "[INFO: 2022-02-16 20:29:18,669] Iteration 21900 (DataTime/BatchTime: 0.00226/0.485) losses = 2.0446, lr = [2.9862291616639304e-05, 0.00029862291616639304]\n",
      "[INFO: 2022-02-16 20:29:18,669]   LabelSmoothing Loss = 2.322222948074341\n",
      "[INFO: 2022-02-16 20:29:28,286] Iteration 21920 (DataTime/BatchTime: 0.00127/0.481) losses = 2.2315, lr = [2.9848666442951676e-05, 0.0002984866644295167]\n",
      "[INFO: 2022-02-16 20:29:28,286]   LabelSmoothing Loss = 3.3170228004455566\n",
      "[INFO: 2022-02-16 20:29:37,933] Iteration 21940 (DataTime/BatchTime: 0.00141/0.482) losses = 2.1626, lr = [2.9835059902406506e-05, 0.000298350599024065]\n",
      "[INFO: 2022-02-16 20:29:37,933]   LabelSmoothing Loss = 1.4073598384857178\n",
      "[INFO: 2022-02-16 20:29:47,426] Iteration 21960 (DataTime/BatchTime: 0.00125/0.475) losses = 2.143, lr = [2.9821471952572798e-05, 0.00029821471952572794]\n",
      "[INFO: 2022-02-16 20:29:47,426]   LabelSmoothing Loss = 1.2637109756469727\n",
      "[INFO: 2022-02-16 20:33:26,082] ######## Epoch (VAL)23 ########\n",
      "[INFO: 2022-02-16 20:33:26,082] {'Bleu_1': 0.3401055748733046, 'Bleu_2': 0.209522544926381, 'Bleu_3': 0.14005669511715846, 'Bleu_4': 0.1006127690633987, 'METEOR': 0.1818398392132281, 'ROUGE_L': 0.2979636405423304, 'CIDEr': 0.29832837366774667}\n",
      "[INFO: 2022-02-16 20:37:08,567] ######## Epoch (TEST)23 ########\n",
      "[INFO: 2022-02-16 20:37:08,567] {'Bleu_1': 0.3180054821422586, 'Bleu_2': 0.18571284982428493, 'Bleu_3': 0.11905885368596168, 'Bleu_4': 0.08012151140981293, 'METEOR': 0.17208351285861337, 'ROUGE_L': 0.2862316930044561, 'CIDEr': 0.25154321199615803}\n",
      "[INFO: 2022-02-16 20:37:17,363] Iteration 21980 (DataTime/BatchTime: 0.0669/0.55) losses = 1.9439, lr = [2.980790255115472e-05, 0.00029807902551154717]\n",
      "[INFO: 2022-02-16 20:37:17,363]   LabelSmoothing Loss = 1.3136603832244873\n",
      "[INFO: 2022-02-16 20:37:26,880] Iteration 22000 (DataTime/BatchTime: 0.00326/0.476) losses = 1.9932, lr = [2.9794351655991022e-05, 0.0002979435165599102]\n",
      "[INFO: 2022-02-16 20:37:26,880]   LabelSmoothing Loss = 2.1558010578155518\n",
      "[INFO: 2022-02-16 20:37:36,288] Iteration 22020 (DataTime/BatchTime: 0.002/0.47) losses = 1.9317, lr = [2.9780819225054502e-05, 0.00029780819225054496]\n",
      "[INFO: 2022-02-16 20:37:36,289]   LabelSmoothing Loss = 1.9240245819091797\n",
      "[INFO: 2022-02-16 20:37:45,985] Iteration 22040 (DataTime/BatchTime: 0.00356/0.485) losses = 2.1647, lr = [2.976730521645147e-05, 0.00029767305216451466]\n",
      "[INFO: 2022-02-16 20:37:45,985]   LabelSmoothing Loss = 3.297482490539551\n",
      "[INFO: 2022-02-16 20:37:55,409] Iteration 22060 (DataTime/BatchTime: 0.00323/0.47) losses = 1.8561, lr = [2.9753809588421172e-05, 0.00029753809588421167]\n",
      "[INFO: 2022-02-16 20:37:55,409]   LabelSmoothing Loss = 1.4034149646759033\n",
      "[INFO: 2022-02-16 20:38:05,051] Iteration 22080 (DataTime/BatchTime: 0.0028/0.483) losses = 1.9634, lr = [2.9740332299335272e-05, 0.00029740332299335267]\n",
      "[INFO: 2022-02-16 20:38:05,051]   LabelSmoothing Loss = 2.475491523742676\n",
      "[INFO: 2022-02-16 20:38:14,575] Iteration 22100 (DataTime/BatchTime: 0.00206/0.476) losses = 2.0035, lr = [2.9726873307697316e-05, 0.0002972687330769731]\n",
      "[INFO: 2022-02-16 20:38:14,575]   LabelSmoothing Loss = 0.5762923359870911\n",
      "[INFO: 2022-02-16 20:38:24,118] Iteration 22120 (DataTime/BatchTime: 0.00113/0.477) losses = 1.9887, lr = [2.971343257214217e-05, 0.00029713432572142163]\n",
      "[INFO: 2022-02-16 20:38:24,118]   LabelSmoothing Loss = 2.38421368598938\n",
      "[INFO: 2022-02-16 20:38:33,589] Iteration 22140 (DataTime/BatchTime: 0.00119/0.474) losses = 1.9813, lr = [2.9700010051435507e-05, 0.00029700010051435504]\n",
      "[INFO: 2022-02-16 20:38:33,590]   LabelSmoothing Loss = 1.5457398891448975\n",
      "[INFO: 2022-02-16 20:38:43,238] Iteration 22160 (DataTime/BatchTime: 0.00205/0.482) losses = 2.196, lr = [2.9686605704473282e-05, 0.0002968660570447328]\n",
      "[INFO: 2022-02-16 20:38:43,238]   LabelSmoothing Loss = 3.0388686656951904\n",
      "[INFO: 2022-02-16 20:38:52,757] Iteration 22180 (DataTime/BatchTime: 0.00212/0.476) losses = 1.915, lr = [2.9673219490281174e-05, 0.00029673219490281174]\n",
      "[INFO: 2022-02-16 20:38:52,758]   LabelSmoothing Loss = 1.469702959060669\n",
      "[INFO: 2022-02-16 20:39:02,360] Iteration 22200 (DataTime/BatchTime: 0.00291/0.48) losses = 2.0148, lr = [2.965985136801409e-05, 0.00029659851368014087]\n",
      "[INFO: 2022-02-16 20:39:02,360]   LabelSmoothing Loss = 1.839780330657959\n",
      "[INFO: 2022-02-16 20:39:11,944] Iteration 22220 (DataTime/BatchTime: 0.00117/0.479) losses = 2.1133, lr = [2.9646501296955627e-05, 0.00029646501296955624]\n",
      "[INFO: 2022-02-16 20:39:11,944]   LabelSmoothing Loss = 2.621636390686035\n",
      "[INFO: 2022-02-16 20:39:21,491] Iteration 22240 (DataTime/BatchTime: 0.00181/0.477) losses = 2.1609, lr = [2.963316923651755e-05, 0.0002963316923651755]\n",
      "[INFO: 2022-02-16 20:39:21,491]   LabelSmoothing Loss = 2.2325401306152344\n",
      "[INFO: 2022-02-16 20:39:30,957] Iteration 22260 (DataTime/BatchTime: 0.00108/0.473) losses = 1.8136, lr = [2.961985514623928e-05, 0.0002961985514623928]\n",
      "[INFO: 2022-02-16 20:39:30,958]   LabelSmoothing Loss = 1.4083330631256104\n",
      "[INFO: 2022-02-16 20:39:40,484] Iteration 22280 (DataTime/BatchTime: 0.000964/0.476) losses = 2.3362, lr = [2.9606558985787377e-05, 0.00029606558985787373]\n",
      "[INFO: 2022-02-16 20:39:40,484]   LabelSmoothing Loss = 3.0214321613311768\n",
      "[INFO: 2022-02-16 20:39:49,995] Iteration 22300 (DataTime/BatchTime: 0.00116/0.476) losses = 2.2624, lr = [2.959328071495501e-05, 0.00029593280714955005]\n",
      "[INFO: 2022-02-16 20:39:49,995]   LabelSmoothing Loss = 1.5044246912002563\n",
      "[INFO: 2022-02-16 20:39:59,648] Iteration 22320 (DataTime/BatchTime: 0.00225/0.483) losses = 2.1655, lr = [2.958002029366149e-05, 0.00029580020293661487]\n",
      "[INFO: 2022-02-16 20:39:59,648]   LabelSmoothing Loss = 2.4147908687591553\n",
      "[INFO: 2022-02-16 20:40:09,217] Iteration 22340 (DataTime/BatchTime: 0.00131/0.478) losses = 2.2169, lr = [2.956677768195171e-05, 0.0002956677768195171]\n",
      "[INFO: 2022-02-16 20:40:09,217]   LabelSmoothing Loss = 1.602426290512085\n",
      "[INFO: 2022-02-16 20:40:18,738] Iteration 22360 (DataTime/BatchTime: 0.00109/0.476) losses = 2.3842, lr = [2.9553552839995675e-05, 0.00029553552839995675]\n",
      "[INFO: 2022-02-16 20:40:18,739]   LabelSmoothing Loss = 1.4192270040512085\n",
      "[INFO: 2022-02-16 20:40:28,221] Iteration 22380 (DataTime/BatchTime: 0.00116/0.474) losses = 1.9134, lr = [2.9540345728087982e-05, 0.0002954034572808798]\n",
      "[INFO: 2022-02-16 20:40:28,221]   LabelSmoothing Loss = 1.9200085401535034\n",
      "[INFO: 2022-02-16 20:40:37,957] Iteration 22400 (DataTime/BatchTime: 0.00317/0.487) losses = 2.2949, lr = [2.9527156306647323e-05, 0.00029527156306647317]\n",
      "[INFO: 2022-02-16 20:40:37,958]   LabelSmoothing Loss = 1.8470227718353271\n",
      "[INFO: 2022-02-16 20:40:47,532] Iteration 22420 (DataTime/BatchTime: 0.00116/0.479) losses = 2.1436, lr = [2.9513984536215988e-05, 0.0002951398453621598]\n",
      "[INFO: 2022-02-16 20:40:47,533]   LabelSmoothing Loss = 2.3134310245513916\n",
      "[INFO: 2022-02-16 20:40:57,065] Iteration 22440 (DataTime/BatchTime: 0.00118/0.477) losses = 2.1606, lr = [2.950083037745937e-05, 0.0002950083037745937]\n",
      "[INFO: 2022-02-16 20:40:57,065]   LabelSmoothing Loss = 2.786858081817627\n",
      "[INFO: 2022-02-16 20:41:06,685] Iteration 22460 (DataTime/BatchTime: 0.0021/0.481) losses = 2.2382, lr = [2.9487693791165473e-05, 0.0002948769379116547]\n",
      "[INFO: 2022-02-16 20:41:06,685]   LabelSmoothing Loss = 2.1703882217407227\n",
      "[INFO: 2022-02-16 20:41:16,183] Iteration 22480 (DataTime/BatchTime: 0.00113/0.475) losses = 2.0177, lr = [2.9474574738244423e-05, 0.0002947457473824442]\n",
      "[INFO: 2022-02-16 20:41:16,200]   LabelSmoothing Loss = 0.7739832997322083\n",
      "[INFO: 2022-02-16 20:41:25,733] Iteration 22500 (DataTime/BatchTime: 0.00208/0.478) losses = 2.1448, lr = [2.9461473179727955e-05, 0.0002946147317972795]\n",
      "[INFO: 2022-02-16 20:41:25,733]   LabelSmoothing Loss = 3.0961596965789795\n",
      "[INFO: 2022-02-16 20:41:35,228] Iteration 22520 (DataTime/BatchTime: 0.00119/0.474) losses = 1.6401, lr = [2.9448389076768972e-05, 0.0002944838907676897]\n",
      "[INFO: 2022-02-16 20:41:35,229]   LabelSmoothing Loss = 1.4511386156082153\n",
      "[INFO: 2022-02-16 20:41:44,659] Iteration 22540 (DataTime/BatchTime: 0.0026/0.473) losses = 2.2396, lr = [2.943532239064102e-05, 0.0002943532239064102]\n",
      "[INFO: 2022-02-16 20:41:44,659]   LabelSmoothing Loss = 1.9207181930541992\n",
      "[INFO: 2022-02-16 20:41:54,104] Iteration 22560 (DataTime/BatchTime: 0.0018/0.472) losses = 1.9349, lr = [2.9422273082737833e-05, 0.0002942227308273783]\n",
      "[INFO: 2022-02-16 20:41:54,104]   LabelSmoothing Loss = 2.0467748641967773\n",
      "[INFO: 2022-02-16 20:42:03,564] Iteration 22580 (DataTime/BatchTime: 0.00238/0.473) losses = 2.0213, lr = [2.940924111457284e-05, 0.00029409241114572833]\n",
      "[INFO: 2022-02-16 20:42:03,564]   LabelSmoothing Loss = 2.723841428756714\n",
      "[INFO: 2022-02-16 20:42:12,968] Iteration 22600 (DataTime/BatchTime: 0.00101/0.47) losses = 1.8456, lr = [2.939622644777868e-05, 0.0002939622644777868]\n",
      "[INFO: 2022-02-16 20:42:12,968]   LabelSmoothing Loss = 1.359397292137146\n",
      "[INFO: 2022-02-16 20:42:22,504] Iteration 22620 (DataTime/BatchTime: 0.00279/0.477) losses = 1.9717, lr = [2.938322904410676e-05, 0.0002938322904410676]\n",
      "[INFO: 2022-02-16 20:42:22,505]   LabelSmoothing Loss = 2.459230661392212\n",
      "[INFO: 2022-02-16 20:42:32,112] Iteration 22640 (DataTime/BatchTime: 0.00337/0.48) losses = 2.0738, lr = [2.937024886542675e-05, 0.00029370248865426746]\n",
      "[INFO: 2022-02-16 20:42:32,112]   LabelSmoothing Loss = 1.5917415618896484\n",
      "[INFO: 2022-02-16 20:42:41,666] Iteration 22660 (DataTime/BatchTime: 0.00326/0.478) losses = 2.1289, lr = [2.935728587372613e-05, 0.0002935728587372613]\n",
      "[INFO: 2022-02-16 20:42:41,667]   LabelSmoothing Loss = 1.4089635610580444\n",
      "[INFO: 2022-02-16 20:42:51,260] Iteration 22680 (DataTime/BatchTime: 0.00354/0.48) losses = 2.0868, lr = [2.9344340031109717e-05, 0.00029344340031109715]\n",
      "[INFO: 2022-02-16 20:42:51,260]   LabelSmoothing Loss = 2.866659641265869\n",
      "[INFO: 2022-02-16 20:43:00,981] Iteration 22700 (DataTime/BatchTime: 0.00263/0.486) losses = 2.1918, lr = [2.93314112997992e-05, 0.00029331411299799196]\n",
      "[INFO: 2022-02-16 20:43:00,981]   LabelSmoothing Loss = 3.253343343734741\n",
      "[INFO: 2022-02-16 20:43:10,610] Iteration 22720 (DataTime/BatchTime: 0.00246/0.481) losses = 2.0678, lr = [2.9318499642132677e-05, 0.00029318499642132673]\n",
      "[INFO: 2022-02-16 20:43:10,610]   LabelSmoothing Loss = 2.695054054260254\n",
      "[INFO: 2022-02-16 20:43:20,139] Iteration 22740 (DataTime/BatchTime: 0.00321/0.476) losses = 2.073, lr = [2.93056050205642e-05, 0.000293056050205642]\n",
      "[INFO: 2022-02-16 20:43:20,140]   LabelSmoothing Loss = 2.5530879497528076\n",
      "[INFO: 2022-02-16 20:43:29,716] Iteration 22760 (DataTime/BatchTime: 0.00319/0.479) losses = 2.1059, lr = [2.929272739766331e-05, 0.00029292727397663306]\n",
      "[INFO: 2022-02-16 20:43:29,716]   LabelSmoothing Loss = 2.5466458797454834\n",
      "[INFO: 2022-02-16 20:43:39,329] Iteration 22780 (DataTime/BatchTime: 0.00233/0.481) losses = 1.9239, lr = [2.927986673611457e-05, 0.00029279866736114566]\n",
      "[INFO: 2022-02-16 20:43:39,330]   LabelSmoothing Loss = 2.1304399967193604\n",
      "[INFO: 2022-02-16 20:43:48,829] Iteration 22800 (DataTime/BatchTime: 0.00435/0.475) losses = 2.0447, lr = [2.9267022998717144e-05, 0.0002926702299871714]\n",
      "[INFO: 2022-02-16 20:43:48,829]   LabelSmoothing Loss = 3.1438610553741455\n",
      "[INFO: 2022-02-16 20:43:58,403] Iteration 22820 (DataTime/BatchTime: 0.00149/0.479) losses = 2.1435, lr = [2.925419614838431e-05, 0.00029254196148384307]\n",
      "[INFO: 2022-02-16 20:43:58,403]   LabelSmoothing Loss = 1.1210997104644775\n",
      "[INFO: 2022-02-16 20:44:07,941] Iteration 22840 (DataTime/BatchTime: 0.00151/0.477) losses = 1.9351, lr = [2.9241386148143023e-05, 0.0002924138614814302]\n",
      "[INFO: 2022-02-16 20:44:07,941]   LabelSmoothing Loss = 2.1228294372558594\n",
      "[INFO: 2022-02-16 20:44:17,542] Iteration 22860 (DataTime/BatchTime: 0.0024/0.48) losses = 2.179, lr = [2.922859296113348e-05, 0.0002922859296113348]\n",
      "[INFO: 2022-02-16 20:44:17,542]   LabelSmoothing Loss = 1.8053975105285645\n",
      "[INFO: 2022-02-16 20:44:27,133] Iteration 22880 (DataTime/BatchTime: 0.00149/0.48) losses = 2.0732, lr = [2.9215816550608654e-05, 0.0002921581655060865]\n",
      "[INFO: 2022-02-16 20:44:27,133]   LabelSmoothing Loss = 1.6518912315368652\n",
      "[INFO: 2022-02-16 20:44:36,886] Iteration 22900 (DataTime/BatchTime: 0.00238/0.488) losses = 2.2366, lr = [2.9203056879933863e-05, 0.0002920305687993386]\n",
      "[INFO: 2022-02-16 20:44:36,886]   LabelSmoothing Loss = 1.2465914487838745\n",
      "[INFO: 2022-02-16 20:48:24,633] ######## Epoch (VAL)24 ########\n",
      "[INFO: 2022-02-16 20:48:24,634] {'Bleu_1': 0.35033160371241284, 'Bleu_2': 0.2211508141344426, 'Bleu_3': 0.15123130819443323, 'Bleu_4': 0.11029790478343925, 'METEOR': 0.18591084754851242, 'ROUGE_L': 0.3040473551896012, 'CIDEr': 0.38541683344351396}\n",
      "[INFO: 2022-02-16 20:52:04,887] ######## Epoch (TEST)24 ########\n",
      "[INFO: 2022-02-16 20:52:04,887] {'Bleu_1': 0.3117647094933931, 'Bleu_2': 0.18152898839770548, 'Bleu_3': 0.11442855830043065, 'Bleu_4': 0.07568299621488735, 'METEOR': 0.172142951210309, 'ROUGE_L': 0.28299511292368396, 'CIDEr': 0.24957202783366525}\n",
      "[INFO: 2022-02-16 20:52:06,484] Iteration 22920 (DataTime/BatchTime: 1.01/1.6) losses = 3.0935, lr = [2.919031391258632e-05, 0.00029190313912586316]\n",
      "[INFO: 2022-02-16 20:52:06,484]   LabelSmoothing Loss = 3.093493700027466\n",
      "[INFO: 2022-02-16 20:52:16,133] Iteration 22940 (DataTime/BatchTime: 0.00149/0.482) losses = 2.2757, lr = [2.9177587612154713e-05, 0.0002917758761215471]\n",
      "[INFO: 2022-02-16 20:52:16,134]   LabelSmoothing Loss = 2.813922643661499\n",
      "[INFO: 2022-02-16 20:52:25,738] Iteration 22960 (DataTime/BatchTime: 0.00237/0.48) losses = 2.0409, lr = [2.916487794233874e-05, 0.00029164877942338736]\n",
      "[INFO: 2022-02-16 20:52:25,738]   LabelSmoothing Loss = 2.2247910499572754\n",
      "[INFO: 2022-02-16 20:52:35,299] Iteration 22980 (DataTime/BatchTime: 0.00138/0.478) losses = 1.9779, lr = [2.9152184866948696e-05, 0.00029152184866948694]\n",
      "[INFO: 2022-02-16 20:52:35,299]   LabelSmoothing Loss = 1.0687696933746338\n",
      "[INFO: 2022-02-16 20:52:44,899] Iteration 23000 (DataTime/BatchTime: 0.00152/0.48) losses = 2.0882, lr = [2.9139508349905034e-05, 0.0002913950834990503]\n",
      "[INFO: 2022-02-16 20:52:44,899]   LabelSmoothing Loss = 2.5780439376831055\n",
      "[INFO: 2022-02-16 20:52:54,413] Iteration 23020 (DataTime/BatchTime: 0.00215/0.476) losses = 2.0374, lr = [2.912684835523793e-05, 0.00029126848355237925]\n",
      "[INFO: 2022-02-16 20:52:54,413]   LabelSmoothing Loss = 1.6665489673614502\n",
      "[INFO: 2022-02-16 20:53:03,992] Iteration 23040 (DataTime/BatchTime: 0.00134/0.479) losses = 2.0959, lr = [2.911420484708686e-05, 0.0002911420484708686]\n",
      "[INFO: 2022-02-16 20:53:03,992]   LabelSmoothing Loss = 2.138343334197998\n",
      "[INFO: 2022-02-16 20:53:13,570] Iteration 23060 (DataTime/BatchTime: 0.0022/0.479) losses = 1.9233, lr = [2.9101577789700167e-05, 0.00029101577789700163]\n",
      "[INFO: 2022-02-16 20:53:13,571]   LabelSmoothing Loss = 1.8201974630355835\n",
      "[INFO: 2022-02-16 20:53:23,084] Iteration 23080 (DataTime/BatchTime: 0.00134/0.476) losses = 1.7213, lr = [2.9088967147434645e-05, 0.0002908896714743464]\n",
      "[INFO: 2022-02-16 20:53:23,084]   LabelSmoothing Loss = 1.0945160388946533\n",
      "[INFO: 2022-02-16 20:53:32,696] Iteration 23100 (DataTime/BatchTime: 0.00131/0.481) losses = 1.9221, lr = [2.907637288475511e-05, 0.0002907637288475511]\n",
      "[INFO: 2022-02-16 20:53:32,696]   LabelSmoothing Loss = 1.96234130859375\n",
      "[INFO: 2022-02-16 20:53:42,247] Iteration 23120 (DataTime/BatchTime: 0.00155/0.478) losses = 1.9032, lr = [2.906379496623398e-05, 0.00029063794966233976]\n",
      "[INFO: 2022-02-16 20:53:42,247]   LabelSmoothing Loss = 1.2726675271987915\n",
      "[INFO: 2022-02-16 20:53:51,729] Iteration 23140 (DataTime/BatchTime: 0.00135/0.474) losses = 2.1972, lr = [2.905123335655086e-05, 0.0002905123335655086]\n",
      "[INFO: 2022-02-16 20:53:51,729]   LabelSmoothing Loss = 2.1693782806396484\n",
      "[INFO: 2022-02-16 20:54:01,311] Iteration 23160 (DataTime/BatchTime: 0.00232/0.479) losses = 1.9457, lr = [2.903868802049212e-05, 0.00029038688020492116]\n",
      "[INFO: 2022-02-16 20:54:01,311]   LabelSmoothing Loss = 1.9817742109298706\n",
      "[INFO: 2022-02-16 20:54:10,921] Iteration 23180 (DataTime/BatchTime: 0.00245/0.481) losses = 2.2151, lr = [2.902615892295049e-05, 0.00029026158922950486]\n",
      "[INFO: 2022-02-16 20:54:10,921]   LabelSmoothing Loss = 2.321812629699707\n",
      "[INFO: 2022-02-16 20:54:20,724] Iteration 23200 (DataTime/BatchTime: 0.00148/0.49) losses = 1.7336, lr = [2.9013646028924625e-05, 0.0002901364602892462]\n",
      "[INFO: 2022-02-16 20:54:20,724]   LabelSmoothing Loss = 2.3877034187316895\n",
      "[INFO: 2022-02-16 20:54:30,385] Iteration 23220 (DataTime/BatchTime: 0.00238/0.483) losses = 1.9961, lr = [2.9001149303518736e-05, 0.0002900114930351873]\n",
      "[INFO: 2022-02-16 20:54:30,386]   LabelSmoothing Loss = 2.0603420734405518\n",
      "[INFO: 2022-02-16 20:54:40,041] Iteration 23240 (DataTime/BatchTime: 0.00327/0.483) losses = 2.0612, lr = [2.898866871194213e-05, 0.00028988668711942125]\n",
      "[INFO: 2022-02-16 20:54:40,041]   LabelSmoothing Loss = 2.818223476409912\n",
      "[INFO: 2022-02-16 20:54:49,596] Iteration 23260 (DataTime/BatchTime: 0.00142/0.478) losses = 1.9487, lr = [2.8976204219508842e-05, 0.0002897620421950884]\n",
      "[INFO: 2022-02-16 20:54:49,596]   LabelSmoothing Loss = 2.6505329608917236\n",
      "[INFO: 2022-02-16 20:54:59,177] Iteration 23280 (DataTime/BatchTime: 0.00142/0.478) losses = 2.1592, lr = [2.896375579163722e-05, 0.00028963755791637215]\n",
      "[INFO: 2022-02-16 20:54:59,177]   LabelSmoothing Loss = 3.2703089714050293\n",
      "[INFO: 2022-02-16 20:55:08,761] Iteration 23300 (DataTime/BatchTime: 0.00317/0.479) losses = 2.0095, lr = [2.8951323393849502e-05, 0.00028951323393849496]\n",
      "[INFO: 2022-02-16 20:55:08,761]   LabelSmoothing Loss = 2.3444294929504395\n",
      "[INFO: 2022-02-16 20:55:18,426] Iteration 23320 (DataTime/BatchTime: 0.00234/0.484) losses = 1.9174, lr = [2.8938906991771445e-05, 0.00028938906991771444]\n",
      "[INFO: 2022-02-16 20:55:18,426]   LabelSmoothing Loss = 2.5728061199188232\n",
      "[INFO: 2022-02-16 20:55:27,960] Iteration 23340 (DataTime/BatchTime: 0.00342/0.477) losses = 2.0804, lr = [2.892650655113192e-05, 0.00028926506551131916]\n",
      "[INFO: 2022-02-16 20:55:27,960]   LabelSmoothing Loss = 2.857184648513794\n",
      "[INFO: 2022-02-16 20:55:37,614] Iteration 23360 (DataTime/BatchTime: 0.00353/0.483) losses = 2.0857, lr = [2.891412203776249e-05, 0.00028914122037762487]\n",
      "[INFO: 2022-02-16 20:55:37,614]   LabelSmoothing Loss = 2.290585517883301\n",
      "[INFO: 2022-02-16 20:55:47,226] Iteration 23380 (DataTime/BatchTime: 0.00233/0.481) losses = 2.0093, lr = [2.8901753417597034e-05, 0.0002890175341759703]\n",
      "[INFO: 2022-02-16 20:55:47,226]   LabelSmoothing Loss = 1.5057452917099\n",
      "[INFO: 2022-02-16 20:55:56,833] Iteration 23400 (DataTime/BatchTime: 0.00231/0.48) losses = 1.9829, lr = [2.8889400656671364e-05, 0.0002888940065667136]\n",
      "[INFO: 2022-02-16 20:55:56,834]   LabelSmoothing Loss = 2.5632309913635254\n",
      "[INFO: 2022-02-16 20:56:06,471] Iteration 23420 (DataTime/BatchTime: 0.00146/0.482) losses = 1.9574, lr = [2.8877063721122815e-05, 0.0002887706372112281]\n",
      "[INFO: 2022-02-16 20:56:06,472]   LabelSmoothing Loss = 3.5329174995422363\n",
      "[INFO: 2022-02-16 20:56:15,998] Iteration 23440 (DataTime/BatchTime: 0.00169/0.476) losses = 2.0137, lr = [2.886474257718985e-05, 0.0002886474257718985]\n",
      "[INFO: 2022-02-16 20:56:15,999]   LabelSmoothing Loss = 1.9025708436965942\n",
      "[INFO: 2022-02-16 20:56:25,652] Iteration 23460 (DataTime/BatchTime: 0.00148/0.483) losses = 1.9514, lr = [2.88524371912117e-05, 0.00028852437191211695]\n",
      "[INFO: 2022-02-16 20:56:25,652]   LabelSmoothing Loss = 1.6293905973434448\n",
      "[INFO: 2022-02-16 20:56:35,144] Iteration 23480 (DataTime/BatchTime: 0.00227/0.475) losses = 2.0474, lr = [2.8840147529627944e-05, 0.0002884014752962794]\n",
      "[INFO: 2022-02-16 20:56:35,144]   LabelSmoothing Loss = 0.7491958737373352\n",
      "[INFO: 2022-02-16 20:56:44,784] Iteration 23500 (DataTime/BatchTime: 0.00327/0.482) losses = 2.0618, lr = [2.8827873558978152e-05, 0.0002882787355897815]\n",
      "[INFO: 2022-02-16 20:56:44,784]   LabelSmoothing Loss = 2.2994587421417236\n",
      "[INFO: 2022-02-16 20:56:54,395] Iteration 23520 (DataTime/BatchTime: 0.00143/0.481) losses = 2.0667, lr = [2.8815615245901488e-05, 0.00028815615245901484]\n",
      "[INFO: 2022-02-16 20:56:54,395]   LabelSmoothing Loss = 2.1707515716552734\n",
      "[INFO: 2022-02-16 20:57:04,146] Iteration 23540 (DataTime/BatchTime: 0.00143/0.488) losses = 2.0947, lr = [2.880337255713633e-05, 0.0002880337255713633]\n",
      "[INFO: 2022-02-16 20:57:04,146]   LabelSmoothing Loss = 3.1392769813537598\n",
      "[INFO: 2022-02-16 20:57:13,886] Iteration 23560 (DataTime/BatchTime: 0.00243/0.487) losses = 2.3015, lr = [2.8791145459519903e-05, 0.000287911454595199]\n",
      "[INFO: 2022-02-16 20:57:13,886]   LabelSmoothing Loss = 2.0447351932525635\n",
      "[INFO: 2022-02-16 20:57:23,502] Iteration 23580 (DataTime/BatchTime: 0.00142/0.481) losses = 1.883, lr = [2.877893391998788e-05, 0.0002877893391998788]\n",
      "[INFO: 2022-02-16 20:57:23,502]   LabelSmoothing Loss = 1.7178510427474976\n",
      "[INFO: 2022-02-16 20:57:33,154] Iteration 23600 (DataTime/BatchTime: 0.00325/0.483) losses = 2.2875, lr = [2.8766737905574028e-05, 0.0002876673790557402]\n",
      "[INFO: 2022-02-16 20:57:33,154]   LabelSmoothing Loss = 2.4206197261810303\n",
      "[INFO: 2022-02-16 20:57:42,825] Iteration 23620 (DataTime/BatchTime: 0.00232/0.484) losses = 2.3686, lr = [2.875455738340981e-05, 0.000287545573834098]\n",
      "[INFO: 2022-02-16 20:57:42,826]   LabelSmoothing Loss = 2.126584768295288\n",
      "[INFO: 2022-02-16 20:57:52,557] Iteration 23640 (DataTime/BatchTime: 0.00161/0.487) losses = 2.0543, lr = [2.8742392320724048e-05, 0.00028742392320724045]\n",
      "[INFO: 2022-02-16 20:57:52,557]   LabelSmoothing Loss = 1.7630407810211182\n",
      "[INFO: 2022-02-16 20:58:02,180] Iteration 23660 (DataTime/BatchTime: 0.00147/0.481) losses = 2.0103, lr = [2.873024268484252e-05, 0.00028730242684842517]\n",
      "[INFO: 2022-02-16 20:58:02,180]   LabelSmoothing Loss = 1.7806382179260254\n",
      "[INFO: 2022-02-16 20:58:11,769] Iteration 23680 (DataTime/BatchTime: 0.00224/0.479) losses = 1.9916, lr = [2.8718108443187605e-05, 0.000287181084431876]\n",
      "[INFO: 2022-02-16 20:58:11,770]   LabelSmoothing Loss = 2.0586965084075928\n",
      "[INFO: 2022-02-16 20:58:21,385] Iteration 23700 (DataTime/BatchTime: 0.00328/0.482) losses = 2.1401, lr = [2.870598956327792e-05, 0.00028705989563277914]\n",
      "[INFO: 2022-02-16 20:58:21,385]   LabelSmoothing Loss = 2.1902191638946533\n",
      "[INFO: 2022-02-16 20:58:30,999] Iteration 23720 (DataTime/BatchTime: 0.00235/0.481) losses = 2.114, lr = [2.8693886012727942e-05, 0.0002869388601272794]\n",
      "[INFO: 2022-02-16 20:58:31,000]   LabelSmoothing Loss = 3.1737961769104004\n",
      "[INFO: 2022-02-16 20:58:40,548] Iteration 23740 (DataTime/BatchTime: 0.00234/0.477) losses = 1.9349, lr = [2.8681797759247664e-05, 0.0002868179775924766]\n",
      "[INFO: 2022-02-16 20:58:40,548]   LabelSmoothing Loss = 2.2477023601531982\n",
      "[INFO: 2022-02-16 20:58:50,244] Iteration 23760 (DataTime/BatchTime: 0.00313/0.485) losses = 2.2099, lr = [2.8669724770642207e-05, 0.00028669724770642203]\n",
      "[INFO: 2022-02-16 20:58:50,244]   LabelSmoothing Loss = 2.305683135986328\n",
      "[INFO: 2022-02-16 20:58:59,842] Iteration 23780 (DataTime/BatchTime: 0.00229/0.48) losses = 2.1312, lr = [2.8657667014811487e-05, 0.0002865766701481148]\n",
      "[INFO: 2022-02-16 20:58:59,842]   LabelSmoothing Loss = 1.4713430404663086\n",
      "[INFO: 2022-02-16 20:59:09,465] Iteration 23800 (DataTime/BatchTime: 0.00141/0.481) losses = 2.103, lr = [2.8645624459749837e-05, 0.0002864562445974983]\n",
      "[INFO: 2022-02-16 20:59:09,465]   LabelSmoothing Loss = 1.692806363105774\n",
      "[INFO: 2022-02-16 20:59:19,104] Iteration 23820 (DataTime/BatchTime: 0.00164/0.482) losses = 2.232, lr = [2.8633597073545657e-05, 0.0002863359707354565]\n",
      "[INFO: 2022-02-16 20:59:19,104]   LabelSmoothing Loss = 1.3023298978805542\n",
      "[INFO: 2022-02-16 20:59:28,652] Iteration 23840 (DataTime/BatchTime: 0.00233/0.477) losses = 1.9559, lr = [2.862158482438106e-05, 0.00028621584824381057]\n",
      "[INFO: 2022-02-16 20:59:28,652]   LabelSmoothing Loss = 2.2820000648498535\n",
      "[INFO: 2022-02-16 20:59:38,263] Iteration 23860 (DataTime/BatchTime: 0.00232/0.481) losses = 2.1149, lr = [2.8609587680531524e-05, 0.0002860958768053152]\n",
      "[INFO: 2022-02-16 20:59:38,263]   LabelSmoothing Loss = 2.763465404510498\n",
      "[INFO: 2022-02-16 21:03:18,328] ######## Epoch (VAL)25 ########\n",
      "[INFO: 2022-02-16 21:03:18,329] {'Bleu_1': 0.36459180742815317, 'Bleu_2': 0.2229760945710489, 'Bleu_3': 0.14969494461642244, 'Bleu_4': 0.10734426052881416, 'METEOR': 0.18543573829932075, 'ROUGE_L': 0.30529182228012874, 'CIDEr': 0.40753154250622464}\n",
      "[INFO: 2022-02-16 21:06:56,251] ######## Epoch (TEST)25 ########\n",
      "[INFO: 2022-02-16 21:06:56,252] {'Bleu_1': 0.35323959681344147, 'Bleu_2': 0.20640012309189404, 'Bleu_3': 0.13227625641435797, 'Bleu_4': 0.08969833265356564, 'METEOR': 0.17634089962973606, 'ROUGE_L': 0.2900089989457082, 'CIDEr': 0.29189062559616863}\n",
      "[INFO: 2022-02-16 21:07:00,238] Iteration 23880 (DataTime/BatchTime: 0.161/0.664) losses = 2.352, lr = [2.8597605610365524e-05, 0.0002859760561036552]\n",
      "[INFO: 2022-02-16 21:07:00,238]   LabelSmoothing Loss = 3.1725423336029053\n",
      "[INFO: 2022-02-16 21:07:09,733] Iteration 23900 (DataTime/BatchTime: 0.00118/0.475) losses = 2.0244, lr = [2.8585638582344198e-05, 0.00028585638582344196]\n",
      "[INFO: 2022-02-16 21:07:09,733]   LabelSmoothing Loss = 1.8110636472702026\n",
      "[INFO: 2022-02-16 21:07:19,238] Iteration 23920 (DataTime/BatchTime: 0.00118/0.475) losses = 2.0518, lr = [2.8573686565020987e-05, 0.0002857368656502098]\n",
      "[INFO: 2022-02-16 21:07:19,238]   LabelSmoothing Loss = 2.736851453781128\n",
      "[INFO: 2022-02-16 21:07:28,656] Iteration 23940 (DataTime/BatchTime: 0.00202/0.471) losses = 1.734, lr = [2.8561749527041293e-05, 0.0002856174952704129]\n",
      "[INFO: 2022-02-16 21:07:28,657]   LabelSmoothing Loss = 1.3877202272415161\n",
      "[INFO: 2022-02-16 21:07:38,246] Iteration 23960 (DataTime/BatchTime: 0.00238/0.479) losses = 2.1324, lr = [2.8549827437142133e-05, 0.00028549827437142133]\n",
      "[INFO: 2022-02-16 21:07:38,246]   LabelSmoothing Loss = 2.1090126037597656\n",
      "[INFO: 2022-02-16 21:07:47,788] Iteration 23980 (DataTime/BatchTime: 0.00205/0.477) losses = 1.9406, lr = [2.85379202641518e-05, 0.000285379202641518]\n",
      "[INFO: 2022-02-16 21:07:47,788]   LabelSmoothing Loss = 2.5016164779663086\n",
      "[INFO: 2022-02-16 21:07:57,293] Iteration 24000 (DataTime/BatchTime: 0.00198/0.475) losses = 2.1039, lr = [2.852602797698951e-05, 0.0002852602797698951]\n",
      "[INFO: 2022-02-16 21:07:57,293]   LabelSmoothing Loss = 2.505072832107544\n",
      "[INFO: 2022-02-16 21:08:06,753] Iteration 24020 (DataTime/BatchTime: 0.00117/0.473) losses = 1.9485, lr = [2.851415054466507e-05, 0.00028514150544665067]\n",
      "[INFO: 2022-02-16 21:08:06,753]   LabelSmoothing Loss = 1.7431572675704956\n",
      "[INFO: 2022-02-16 21:08:16,190] Iteration 24040 (DataTime/BatchTime: 0.00109/0.472) losses = 2.1238, lr = [2.850228793627854e-05, 0.00028502287936278534]\n",
      "[INFO: 2022-02-16 21:08:16,190]   LabelSmoothing Loss = 1.7306419610977173\n",
      "[INFO: 2022-02-16 21:08:25,714] Iteration 24060 (DataTime/BatchTime: 0.00108/0.476) losses = 2.1629, lr = [2.849044012101988e-05, 0.00028490440121019874]\n",
      "[INFO: 2022-02-16 21:08:25,714]   LabelSmoothing Loss = 3.2410075664520264\n",
      "[INFO: 2022-02-16 21:08:35,203] Iteration 24080 (DataTime/BatchTime: 0.00208/0.474) losses = 2.0048, lr = [2.8478607068168637e-05, 0.00028478607068168634]\n",
      "[INFO: 2022-02-16 21:08:35,204]   LabelSmoothing Loss = 2.649616241455078\n",
      "[INFO: 2022-02-16 21:08:44,691] Iteration 24100 (DataTime/BatchTime: 0.00124/0.474) losses = 2.0354, lr = [2.846678874709359e-05, 0.0002846678874709359]\n",
      "[INFO: 2022-02-16 21:08:44,691]   LabelSmoothing Loss = 2.33296537399292\n",
      "[INFO: 2022-02-16 21:08:54,311] Iteration 24120 (DataTime/BatchTime: 0.0021/0.481) losses = 2.0197, lr = [2.8454985127252426e-05, 0.00028454985127252425]\n",
      "[INFO: 2022-02-16 21:08:54,311]   LabelSmoothing Loss = 2.1815619468688965\n",
      "[INFO: 2022-02-16 21:09:03,809] Iteration 24140 (DataTime/BatchTime: 0.00137/0.475) losses = 1.9537, lr = [2.844319617819142e-05, 0.0002844319617819142]\n",
      "[INFO: 2022-02-16 21:09:03,809]   LabelSmoothing Loss = 2.007411479949951\n",
      "[INFO: 2022-02-16 21:09:13,277] Iteration 24160 (DataTime/BatchTime: 0.00323/0.473) losses = 1.8159, lr = [2.843142186954508e-05, 0.0002843142186954508]\n",
      "[INFO: 2022-02-16 21:09:13,277]   LabelSmoothing Loss = 1.151626706123352\n",
      "[INFO: 2022-02-16 21:09:22,762] Iteration 24180 (DataTime/BatchTime: 0.00115/0.474) losses = 2.0446, lr = [2.8419662171035838e-05, 0.00028419662171035834]\n",
      "[INFO: 2022-02-16 21:09:22,762]   LabelSmoothing Loss = 2.715514659881592\n",
      "[INFO: 2022-02-16 21:09:32,305] Iteration 24200 (DataTime/BatchTime: 0.00116/0.477) losses = 1.9258, lr = [2.840791705247371e-05, 0.0002840791705247371]\n",
      "[INFO: 2022-02-16 21:09:32,305]   LabelSmoothing Loss = 1.7611643075942993\n",
      "[INFO: 2022-02-16 21:09:41,829] Iteration 24220 (DataTime/BatchTime: 0.00202/0.476) losses = 2.1802, lr = [2.8396186483755992e-05, 0.00028396186483755986]\n",
      "[INFO: 2022-02-16 21:09:41,829]   LabelSmoothing Loss = 1.1450042724609375\n",
      "[INFO: 2022-02-16 21:09:51,296] Iteration 24240 (DataTime/BatchTime: 0.00207/0.473) losses = 2.0468, lr = [2.8384470434866895e-05, 0.0002838447043486689]\n",
      "[INFO: 2022-02-16 21:09:51,296]   LabelSmoothing Loss = 1.568895697593689\n",
      "[INFO: 2022-02-16 21:10:00,837] Iteration 24260 (DataTime/BatchTime: 0.00121/0.477) losses = 2.0847, lr = [2.8372768875877278e-05, 0.0002837276887587728]\n",
      "[INFO: 2022-02-16 21:10:00,837]   LabelSmoothing Loss = 1.2145750522613525\n",
      "[INFO: 2022-02-16 21:10:10,336] Iteration 24280 (DataTime/BatchTime: 0.00193/0.475) losses = 1.8379, lr = [2.836108177694428e-05, 0.00028361081776944277]\n",
      "[INFO: 2022-02-16 21:10:10,337]   LabelSmoothing Loss = 1.0643291473388672\n",
      "[INFO: 2022-02-16 21:10:19,870] Iteration 24300 (DataTime/BatchTime: 0.00231/0.477) losses = 1.946, lr = [2.834940910831102e-05, 0.00028349409108311015]\n",
      "[INFO: 2022-02-16 21:10:19,870]   LabelSmoothing Loss = 2.4214744567871094\n",
      "[INFO: 2022-02-16 21:10:29,321] Iteration 24320 (DataTime/BatchTime: 0.00201/0.473) losses = 2.0668, lr = [2.8337750840306277e-05, 0.0002833775084030628]\n",
      "[INFO: 2022-02-16 21:10:29,321]   LabelSmoothing Loss = 2.4951770305633545\n",
      "[INFO: 2022-02-16 21:10:38,847] Iteration 24340 (DataTime/BatchTime: 0.00192/0.476) losses = 2.1028, lr = [2.832610694334418e-05, 0.0002832610694334418]\n",
      "[INFO: 2022-02-16 21:10:38,847]   LabelSmoothing Loss = 2.2472269535064697\n",
      "[INFO: 2022-02-16 21:10:48,372] Iteration 24360 (DataTime/BatchTime: 0.00317/0.476) losses = 1.8199, lr = [2.8314477387923873e-05, 0.0002831447738792387]\n",
      "[INFO: 2022-02-16 21:10:48,373]   LabelSmoothing Loss = 1.8231250047683716\n",
      "[INFO: 2022-02-16 21:10:57,945] Iteration 24380 (DataTime/BatchTime: 0.00121/0.479) losses = 2.1357, lr = [2.8302862144629218e-05, 0.00028302862144629216]\n",
      "[INFO: 2022-02-16 21:10:57,946]   LabelSmoothing Loss = 1.740856409072876\n",
      "[INFO: 2022-02-16 21:11:07,490] Iteration 24400 (DataTime/BatchTime: 0.00115/0.477) losses = 1.9108, lr = [2.8291261184128484e-05, 0.0002829126118412848]\n",
      "[INFO: 2022-02-16 21:11:07,490]   LabelSmoothing Loss = 2.675049066543579\n",
      "[INFO: 2022-02-16 21:11:17,055] Iteration 24420 (DataTime/BatchTime: 0.00243/0.478) losses = 1.9903, lr = [2.827967447717402e-05, 0.0002827967447717402]\n",
      "[INFO: 2022-02-16 21:11:17,056]   LabelSmoothing Loss = 1.7464746236801147\n",
      "[INFO: 2022-02-16 21:11:26,560] Iteration 24440 (DataTime/BatchTime: 0.00289/0.475) losses = 2.0145, lr = [2.8268101994601968e-05, 0.0002826810199460196]\n",
      "[INFO: 2022-02-16 21:11:26,561]   LabelSmoothing Loss = 2.927544355392456\n",
      "[INFO: 2022-02-16 21:11:36,150] Iteration 24460 (DataTime/BatchTime: 0.00203/0.479) losses = 2.0818, lr = [2.825654370733193e-05, 0.00028256543707331924]\n",
      "[INFO: 2022-02-16 21:11:36,150]   LabelSmoothing Loss = 2.769777774810791\n",
      "[INFO: 2022-02-16 21:11:45,760] Iteration 24480 (DataTime/BatchTime: 0.00217/0.48) losses = 1.995, lr = [2.8244999586366678e-05, 0.00028244999586366675]\n",
      "[INFO: 2022-02-16 21:11:45,760]   LabelSmoothing Loss = 2.7756855487823486\n",
      "[INFO: 2022-02-16 21:11:55,277] Iteration 24500 (DataTime/BatchTime: 0.00139/0.476) losses = 1.8945, lr = [2.823346960279184e-05, 0.0002823346960279184]\n",
      "[INFO: 2022-02-16 21:11:55,277]   LabelSmoothing Loss = 1.8145148754119873\n",
      "[INFO: 2022-02-16 21:12:04,798] Iteration 24520 (DataTime/BatchTime: 0.00116/0.475) losses = 2.0949, lr = [2.8221953727775604e-05, 0.000282219537277756]\n",
      "[INFO: 2022-02-16 21:12:04,798]   LabelSmoothing Loss = 2.5755269527435303\n",
      "[INFO: 2022-02-16 21:12:14,516] Iteration 24540 (DataTime/BatchTime: 0.0021/0.487) losses = 2.2738, lr = [2.8210451932568407e-05, 0.00028210451932568405]\n",
      "[INFO: 2022-02-16 21:12:14,516]   LabelSmoothing Loss = 2.2285780906677246\n",
      "[INFO: 2022-02-16 21:12:24,099] Iteration 24560 (DataTime/BatchTime: 0.00118/0.479) losses = 1.8087, lr = [2.819896418850264e-05, 0.0002819896418850264]\n",
      "[INFO: 2022-02-16 21:12:24,099]   LabelSmoothing Loss = 1.3966768980026245\n",
      "[INFO: 2022-02-16 21:12:33,662] Iteration 24580 (DataTime/BatchTime: 0.00232/0.478) losses = 1.9328, lr = [2.818749046699234e-05, 0.0002818749046699234]\n",
      "[INFO: 2022-02-16 21:12:33,662]   LabelSmoothing Loss = 1.2681227922439575\n",
      "[INFO: 2022-02-16 21:12:43,291] Iteration 24600 (DataTime/BatchTime: 0.00117/0.481) losses = 2.2248, lr = [2.8176030739532904e-05, 0.000281760307395329]\n",
      "[INFO: 2022-02-16 21:12:43,291]   LabelSmoothing Loss = 1.6046555042266846\n",
      "[INFO: 2022-02-16 21:12:52,957] Iteration 24620 (DataTime/BatchTime: 0.00126/0.483) losses = 1.8967, lr = [2.8164584977700774e-05, 0.00028164584977700773]\n",
      "[INFO: 2022-02-16 21:12:52,957]   LabelSmoothing Loss = 1.1476162672042847\n",
      "[INFO: 2022-02-16 21:13:02,508] Iteration 24640 (DataTime/BatchTime: 0.0012/0.478) losses = 2.1288, lr = [2.8153153153153157e-05, 0.00028153153153153153]\n",
      "[INFO: 2022-02-16 21:13:02,508]   LabelSmoothing Loss = 1.47160804271698\n",
      "[INFO: 2022-02-16 21:13:12,048] Iteration 24660 (DataTime/BatchTime: 0.00113/0.477) losses = 2.0063, lr = [2.8141735237627722e-05, 0.0002814173523762772]\n",
      "[INFO: 2022-02-16 21:13:12,049]   LabelSmoothing Loss = 1.207634449005127\n",
      "[INFO: 2022-02-16 21:13:21,624] Iteration 24680 (DataTime/BatchTime: 0.00195/0.479) losses = 2.1774, lr = [2.8130331202942313e-05, 0.0002813033120294231]\n",
      "[INFO: 2022-02-16 21:13:21,624]   LabelSmoothing Loss = 2.230848789215088\n",
      "[INFO: 2022-02-16 21:13:31,156] Iteration 24700 (DataTime/BatchTime: 0.00287/0.477) losses = 1.9196, lr = [2.811894102099464e-05, 0.00028118941020994635]\n",
      "[INFO: 2022-02-16 21:13:31,157]   LabelSmoothing Loss = 1.8201205730438232\n",
      "[INFO: 2022-02-16 21:13:40,707] Iteration 24720 (DataTime/BatchTime: 0.00142/0.478) losses = 2.1173, lr = [2.8107564663762007e-05, 0.00028107564663762007]\n",
      "[INFO: 2022-02-16 21:13:40,707]   LabelSmoothing Loss = 2.4141623973846436\n",
      "[INFO: 2022-02-16 21:13:50,272] Iteration 24740 (DataTime/BatchTime: 0.00215/0.478) losses = 1.9169, lr = [2.809620210330103e-05, 0.00028096202103301024]\n",
      "[INFO: 2022-02-16 21:13:50,273]   LabelSmoothing Loss = 2.3844408988952637\n",
      "[INFO: 2022-02-16 21:13:59,870] Iteration 24760 (DataTime/BatchTime: 0.00226/0.48) losses = 2.2408, lr = [2.8084853311747306e-05, 0.000280848533117473]\n",
      "[INFO: 2022-02-16 21:13:59,870]   LabelSmoothing Loss = 1.4463849067687988\n",
      "[INFO: 2022-02-16 21:14:09,459] Iteration 24780 (DataTime/BatchTime: 0.00121/0.479) losses = 2.194, lr = [2.8073518261315177e-05, 0.0002807351826131517]\n",
      "[INFO: 2022-02-16 21:14:09,459]   LabelSmoothing Loss = 1.6294212341308594\n",
      "[INFO: 2022-02-16 21:14:19,014] Iteration 24800 (DataTime/BatchTime: 0.00109/0.478) losses = 2.1279, lr = [2.8062196924297412e-05, 0.00028062196924297407]\n",
      "[INFO: 2022-02-16 21:14:19,014]   LabelSmoothing Loss = 1.2652779817581177\n",
      "[INFO: 2022-02-16 21:14:28,525] Iteration 24820 (DataTime/BatchTime: 0.00109/0.476) losses = 2.1168, lr = [2.805088927306494e-05, 0.00028050889273064934]\n",
      "[INFO: 2022-02-16 21:14:28,526]   LabelSmoothing Loss = 2.8435122966766357\n",
      "[INFO: 2022-02-16 21:18:03,804] ######## Epoch (VAL)26 ########\n",
      "[INFO: 2022-02-16 21:18:03,804] {'Bleu_1': 0.34761341563315423, 'Bleu_2': 0.21205167468935543, 'Bleu_3': 0.1398128538256833, 'Bleu_4': 0.09741425328613136, 'METEOR': 0.18040631077702277, 'ROUGE_L': 0.28685409720965094, 'CIDEr': 0.29986238679651583}\n",
      "[INFO: 2022-02-16 21:21:40,319] ######## Epoch (TEST)26 ########\n",
      "[INFO: 2022-02-16 21:21:40,320] {'Bleu_1': 0.3390584521367953, 'Bleu_2': 0.20275781537393966, 'Bleu_3': 0.13194101074087608, 'Bleu_4': 0.09074735329086343, 'METEOR': 0.1764594505271811, 'ROUGE_L': 0.28194397666230014, 'CIDEr': 0.3126499186478492}\n",
      "[INFO: 2022-02-16 21:21:46,730] Iteration 24840 (DataTime/BatchTime: 0.105/0.583) losses = 2.1097, lr = [2.8039595280066546e-05, 0.0002803959528006654]\n",
      "[INFO: 2022-02-16 21:21:46,730]   LabelSmoothing Loss = 3.131525754928589\n",
      "[INFO: 2022-02-16 21:21:56,124] Iteration 24860 (DataTime/BatchTime: 0.00125/0.47) losses = 1.8606, lr = [2.8028314917828617e-05, 0.00028028314917828614]\n",
      "[INFO: 2022-02-16 21:21:56,124]   LabelSmoothing Loss = 1.7239067554473877\n",
      "[INFO: 2022-02-16 21:22:05,703] Iteration 24880 (DataTime/BatchTime: 0.00123/0.479) losses = 1.9442, lr = [2.8017048158954837e-05, 0.00028017048158954835]\n",
      "[INFO: 2022-02-16 21:22:05,703]   LabelSmoothing Loss = 2.766005277633667\n",
      "[INFO: 2022-02-16 21:22:15,174] Iteration 24900 (DataTime/BatchTime: 0.00297/0.474) losses = 1.9106, lr = [2.800579497612592e-05, 0.0002800579497612592]\n",
      "[INFO: 2022-02-16 21:22:15,174]   LabelSmoothing Loss = 1.8503667116165161\n",
      "[INFO: 2022-02-16 21:22:24,716] Iteration 24920 (DataTime/BatchTime: 0.00123/0.477) losses = 2.1895, lr = [2.799455534209933e-05, 0.00027994555342099325]\n",
      "[INFO: 2022-02-16 21:22:24,716]   LabelSmoothing Loss = 4.023796081542969\n",
      "[INFO: 2022-02-16 21:22:34,264] Iteration 24940 (DataTime/BatchTime: 0.00355/0.477) losses = 1.8061, lr = [2.7983329229708996e-05, 0.0002798332922970899]\n",
      "[INFO: 2022-02-16 21:22:34,264]   LabelSmoothing Loss = 2.701742172241211\n",
      "[INFO: 2022-02-16 21:22:43,748] Iteration 24960 (DataTime/BatchTime: 0.00126/0.474) losses = 2.1815, lr = [2.7972116611865054e-05, 0.0002797211661186505]\n",
      "[INFO: 2022-02-16 21:22:43,748]   LabelSmoothing Loss = 2.0579962730407715\n",
      "[INFO: 2022-02-16 21:22:53,407] Iteration 24980 (DataTime/BatchTime: 0.00203/0.483) losses = 2.0596, lr = [2.796091746155355e-05, 0.00027960917461553546]\n",
      "[INFO: 2022-02-16 21:22:53,407]   LabelSmoothing Loss = 1.2363944053649902\n",
      "[INFO: 2022-02-16 21:23:02,988] Iteration 25000 (DataTime/BatchTime: 0.00214/0.479) losses = 1.9278, lr = [2.7949731751836194e-05, 0.00027949731751836194]\n",
      "[INFO: 2022-02-16 21:23:02,988]   LabelSmoothing Loss = 2.936858892440796\n",
      "[INFO: 2022-02-16 21:23:12,524] Iteration 25020 (DataTime/BatchTime: 0.00402/0.477) losses = 1.9102, lr = [2.7938559455850054e-05, 0.00027938559455850046]\n",
      "[INFO: 2022-02-16 21:23:12,524]   LabelSmoothing Loss = 1.8236615657806396\n",
      "[INFO: 2022-02-16 21:23:22,173] Iteration 25040 (DataTime/BatchTime: 0.00132/0.482) losses = 2.1157, lr = [2.792740054680731e-05, 0.0002792740054680731]\n",
      "[INFO: 2022-02-16 21:23:22,173]   LabelSmoothing Loss = 2.2393624782562256\n",
      "[INFO: 2022-02-16 21:23:31,875] Iteration 25060 (DataTime/BatchTime: 0.00141/0.485) losses = 1.9904, lr = [2.791625499799498e-05, 0.0002791625499799498]\n",
      "[INFO: 2022-02-16 21:23:31,875]   LabelSmoothing Loss = 1.6820645332336426\n",
      "[INFO: 2022-02-16 21:23:41,390] Iteration 25080 (DataTime/BatchTime: 0.00215/0.476) losses = 2.0474, lr = [2.7905122782774655e-05, 0.0002790512278277465]\n",
      "[INFO: 2022-02-16 21:23:41,390]   LabelSmoothing Loss = 2.450773000717163\n",
      "[INFO: 2022-02-16 21:23:50,946] Iteration 25100 (DataTime/BatchTime: 0.00121/0.478) losses = 2.1432, lr = [2.7894003874582205e-05, 0.000278940038745822]\n",
      "[INFO: 2022-02-16 21:23:50,947]   LabelSmoothing Loss = 3.438441753387451\n",
      "[INFO: 2022-02-16 21:24:00,436] Iteration 25120 (DataTime/BatchTime: 0.00122/0.475) losses = 2.0443, lr = [2.788289824692755e-05, 0.0002788289824692755]\n",
      "[INFO: 2022-02-16 21:24:00,437]   LabelSmoothing Loss = 2.1398744583129883\n",
      "[INFO: 2022-02-16 21:24:10,027] Iteration 25140 (DataTime/BatchTime: 0.0013/0.48) losses = 1.7992, lr = [2.7871805873394378e-05, 0.0002787180587339437]\n",
      "[INFO: 2022-02-16 21:24:10,028]   LabelSmoothing Loss = 1.1301757097244263\n",
      "[INFO: 2022-02-16 21:24:19,602] Iteration 25160 (DataTime/BatchTime: 0.00217/0.479) losses = 2.1185, lr = [2.786072672763987e-05, 0.00027860726727639866]\n",
      "[INFO: 2022-02-16 21:24:19,602]   LabelSmoothing Loss = 2.3513994216918945\n",
      "[INFO: 2022-02-16 21:24:29,244] Iteration 25180 (DataTime/BatchTime: 0.00221/0.482) losses = 1.9867, lr = [2.7849660783394457e-05, 0.00027849660783394457]\n",
      "[INFO: 2022-02-16 21:24:29,244]   LabelSmoothing Loss = 1.4351950883865356\n",
      "[INFO: 2022-02-16 21:24:38,866] Iteration 25200 (DataTime/BatchTime: 0.00123/0.481) losses = 2.0007, lr = [2.783860801446155e-05, 0.0002783860801446155]\n",
      "[INFO: 2022-02-16 21:24:38,866]   LabelSmoothing Loss = 2.610280990600586\n",
      "[INFO: 2022-02-16 21:24:48,447] Iteration 25220 (DataTime/BatchTime: 0.00122/0.479) losses = 2.1515, lr = [2.7827568394717276e-05, 0.00027827568394717274]\n",
      "[INFO: 2022-02-16 21:24:48,448]   LabelSmoothing Loss = 1.9248336553573608\n",
      "[INFO: 2022-02-16 21:24:58,010] Iteration 25240 (DataTime/BatchTime: 0.00259/0.478) losses = 1.9432, lr = [2.781654189811022e-05, 0.0002781654189811022]\n",
      "[INFO: 2022-02-16 21:24:58,011]   LabelSmoothing Loss = 2.19130277633667\n",
      "[INFO: 2022-02-16 21:25:07,623] Iteration 25260 (DataTime/BatchTime: 0.00221/0.481) losses = 1.9079, lr = [2.780552849866117e-05, 0.0002780552849866117]\n",
      "[INFO: 2022-02-16 21:25:07,623]   LabelSmoothing Loss = 2.447856903076172\n",
      "[INFO: 2022-02-16 21:25:17,354] Iteration 25280 (DataTime/BatchTime: 0.0028/0.487) losses = 2.1646, lr = [2.7794528170462866e-05, 0.00027794528170462863]\n",
      "[INFO: 2022-02-16 21:25:17,354]   LabelSmoothing Loss = 1.5445523262023926\n",
      "[INFO: 2022-02-16 21:25:27,002] Iteration 25300 (DataTime/BatchTime: 0.00121/0.482) losses = 2.1317, lr = [2.7783540887679726e-05, 0.00027783540887679726]\n",
      "[INFO: 2022-02-16 21:25:27,002]   LabelSmoothing Loss = 1.5718718767166138\n",
      "[INFO: 2022-02-16 21:25:36,586] Iteration 25320 (DataTime/BatchTime: 0.00205/0.479) losses = 1.9703, lr = [2.777256662454761e-05, 0.0002777256662454761]\n",
      "[INFO: 2022-02-16 21:25:36,586]   LabelSmoothing Loss = 1.287113070487976\n",
      "[INFO: 2022-02-16 21:25:46,221] Iteration 25340 (DataTime/BatchTime: 0.00126/0.482) losses = 1.9772, lr = [2.7761605355373556e-05, 0.0002776160535537355]\n",
      "[INFO: 2022-02-16 21:25:46,222]   LabelSmoothing Loss = 2.746046543121338\n",
      "[INFO: 2022-02-16 21:25:55,777] Iteration 25360 (DataTime/BatchTime: 0.00214/0.478) losses = 1.9465, lr = [2.7750657054535523e-05, 0.00027750657054535516]\n",
      "[INFO: 2022-02-16 21:25:55,777]   LabelSmoothing Loss = 1.6067901849746704\n",
      "[INFO: 2022-02-16 21:26:05,438] Iteration 25380 (DataTime/BatchTime: 0.00118/0.483) losses = 2.1604, lr = [2.773972169648215e-05, 0.00027739721696482146]\n",
      "[INFO: 2022-02-16 21:26:05,438]   LabelSmoothing Loss = 1.8078607320785522\n",
      "[INFO: 2022-02-16 21:26:14,962] Iteration 25400 (DataTime/BatchTime: 0.00123/0.476) losses = 2.0333, lr = [2.7728799255732506e-05, 0.00027728799255732504]\n",
      "[INFO: 2022-02-16 21:26:14,962]   LabelSmoothing Loss = 2.3422164916992188\n",
      "[INFO: 2022-02-16 21:26:24,698] Iteration 25420 (DataTime/BatchTime: 0.00138/0.487) losses = 2.0368, lr = [2.771788970687584e-05, 0.00027717889706875836]\n",
      "[INFO: 2022-02-16 21:26:24,699]   LabelSmoothing Loss = 2.967957019805908\n",
      "[INFO: 2022-02-16 21:26:34,309] Iteration 25440 (DataTime/BatchTime: 0.00121/0.48) losses = 1.9706, lr = [2.7706993024571306e-05, 0.00027706993024571305]\n",
      "[INFO: 2022-02-16 21:26:34,309]   LabelSmoothing Loss = 1.495243787765503\n",
      "[INFO: 2022-02-16 21:26:43,905] Iteration 25460 (DataTime/BatchTime: 0.00206/0.48) losses = 2.2017, lr = [2.7696109183547766e-05, 0.00027696109183547764]\n",
      "[INFO: 2022-02-16 21:26:43,905]   LabelSmoothing Loss = 1.4956133365631104\n",
      "[INFO: 2022-02-16 21:26:53,497] Iteration 25480 (DataTime/BatchTime: 0.002/0.48) losses = 2.1137, lr = [2.76852381586035e-05, 0.00027685238158603497]\n",
      "[INFO: 2022-02-16 21:26:53,497]   LabelSmoothing Loss = 2.4720733165740967\n",
      "[INFO: 2022-02-16 21:27:03,166] Iteration 25500 (DataTime/BatchTime: 0.0032/0.483) losses = 2.2993, lr = [2.7674379924605983e-05, 0.0002767437992460598]\n",
      "[INFO: 2022-02-16 21:27:03,166]   LabelSmoothing Loss = 2.056079864501953\n",
      "[INFO: 2022-02-16 21:27:12,827] Iteration 25520 (DataTime/BatchTime: 0.00124/0.482) losses = 1.8302, lr = [2.7663534456491632e-05, 0.00027663534456491627]\n",
      "[INFO: 2022-02-16 21:27:12,827]   LabelSmoothing Loss = 1.0304256677627563\n",
      "[INFO: 2022-02-16 21:27:22,357] Iteration 25540 (DataTime/BatchTime: 0.00213/0.477) losses = 1.8269, lr = [2.7652701729265572e-05, 0.0002765270172926557]\n",
      "[INFO: 2022-02-16 21:27:22,357]   LabelSmoothing Loss = 1.6268386840820312\n",
      "[INFO: 2022-02-16 21:27:31,968] Iteration 25560 (DataTime/BatchTime: 0.00124/0.48) losses = 1.9926, lr = [2.764188171800138e-05, 0.00027641881718001377]\n",
      "[INFO: 2022-02-16 21:27:31,968]   LabelSmoothing Loss = 1.8555543422698975\n",
      "[INFO: 2022-02-16 21:27:41,579] Iteration 25580 (DataTime/BatchTime: 0.00219/0.481) losses = 2.0638, lr = [2.763107439784086e-05, 0.0002763107439784086]\n",
      "[INFO: 2022-02-16 21:27:41,580]   LabelSmoothing Loss = 2.6573591232299805\n",
      "[INFO: 2022-02-16 21:27:51,238] Iteration 25600 (DataTime/BatchTime: 0.00199/0.483) losses = 2.0429, lr = [2.7620279743993798e-05, 0.00027620279743993794]\n",
      "[INFO: 2022-02-16 21:27:51,238]   LabelSmoothing Loss = 1.6915030479431152\n",
      "[INFO: 2022-02-16 21:28:00,726] Iteration 25620 (DataTime/BatchTime: 0.00112/0.474) losses = 1.9315, lr = [2.76094977317377e-05, 0.000276094977317377]\n",
      "[INFO: 2022-02-16 21:28:00,727]   LabelSmoothing Loss = 1.8989537954330444\n",
      "[INFO: 2022-02-16 21:28:10,317] Iteration 25640 (DataTime/BatchTime: 0.00109/0.48) losses = 2.0228, lr = [2.7598728336417608e-05, 0.00027598728336417604]\n",
      "[INFO: 2022-02-16 21:28:10,318]   LabelSmoothing Loss = 1.003092885017395\n",
      "[INFO: 2022-02-16 21:28:19,849] Iteration 25660 (DataTime/BatchTime: 0.00197/0.477) losses = 1.8564, lr = [2.7587971533445807e-05, 0.00027587971533445804]\n",
      "[INFO: 2022-02-16 21:28:19,850]   LabelSmoothing Loss = 1.1257438659667969\n",
      "[INFO: 2022-02-16 21:28:29,399] Iteration 25680 (DataTime/BatchTime: 0.0024/0.477) losses = 1.7842, lr = [2.757722729830161e-05, 0.0002757722729830161]\n",
      "[INFO: 2022-02-16 21:28:29,399]   LabelSmoothing Loss = 2.731767177581787\n",
      "[INFO: 2022-02-16 21:28:39,028] Iteration 25700 (DataTime/BatchTime: 0.00133/0.481) losses = 2.1124, lr = [2.756649560653115e-05, 0.00027566495606531146]\n",
      "[INFO: 2022-02-16 21:28:39,028]   LabelSmoothing Loss = 1.9888848066329956\n",
      "[INFO: 2022-02-16 21:28:48,658] Iteration 25720 (DataTime/BatchTime: 0.00225/0.482) losses = 1.9798, lr = [2.755577643374709e-05, 0.00027555776433747087]\n",
      "[INFO: 2022-02-16 21:28:48,659]   LabelSmoothing Loss = 2.3945181369781494\n",
      "[INFO: 2022-02-16 21:28:58,599] Iteration 25740 (DataTime/BatchTime: 0.00462/0.497) losses = 1.807, lr = [2.7545069755628443e-05, 0.0002754506975562844]\n",
      "[INFO: 2022-02-16 21:28:58,599]   LabelSmoothing Loss = 1.1613062620162964\n",
      "[INFO: 2022-02-16 21:29:08,204] Iteration 25760 (DataTime/BatchTime: 0.00136/0.48) losses = 1.9718, lr = [2.7534375547920318e-05, 0.0002753437554792031]\n",
      "[INFO: 2022-02-16 21:29:08,204]   LabelSmoothing Loss = 2.463685989379883\n",
      "[INFO: 2022-02-16 21:29:17,706] Iteration 25780 (DataTime/BatchTime: 0.00246/0.475) losses = 2.1458, lr = [2.7523693786433682e-05, 0.0002752369378643368]\n",
      "[INFO: 2022-02-16 21:29:17,706]   LabelSmoothing Loss = 2.255722761154175\n",
      "[INFO: 2022-02-16 21:32:52,574] ######## Epoch (VAL)27 ########\n",
      "[INFO: 2022-02-16 21:32:52,575] {'Bleu_1': 0.3634075335316537, 'Bleu_2': 0.22537566294133507, 'Bleu_3': 0.15211282542839344, 'Bleu_4': 0.10917496707059075, 'METEOR': 0.18763312215844566, 'ROUGE_L': 0.29987578399349474, 'CIDEr': 0.3700995765491178}\n",
      "[INFO: 2022-02-16 21:36:31,114] ######## Epoch (TEST)27 ########\n",
      "[INFO: 2022-02-16 21:36:31,115] {'Bleu_1': 0.34213022995507836, 'Bleu_2': 0.20410773840092072, 'Bleu_3': 0.13287192051480884, 'Bleu_4': 0.0915365032576931, 'METEOR': 0.178108692155097, 'ROUGE_L': 0.28701306667285814, 'CIDEr': 0.31904411213502265}\n",
      "[INFO: 2022-02-16 21:36:39,931] Iteration 25800 (DataTime/BatchTime: 0.0714/0.551) losses = 1.932, lr = [2.7513024447045143e-05, 0.00027513024447045143]\n",
      "[INFO: 2022-02-16 21:36:39,931]   LabelSmoothing Loss = 1.6209218502044678\n",
      "[INFO: 2022-02-16 21:36:49,522] Iteration 25820 (DataTime/BatchTime: 0.00255/0.48) losses = 2.1406, lr = [2.7502367505696727e-05, 0.00027502367505696725]\n",
      "[INFO: 2022-02-16 21:36:49,522]   LabelSmoothing Loss = 2.376985549926758\n",
      "[INFO: 2022-02-16 21:36:59,109] Iteration 25840 (DataTime/BatchTime: 0.00132/0.479) losses = 2.0626, lr = [2.7491722938395618e-05, 0.0002749172293839562]\n",
      "[INFO: 2022-02-16 21:36:59,109]   LabelSmoothing Loss = 2.140784740447998\n",
      "[INFO: 2022-02-16 21:37:08,654] Iteration 25860 (DataTime/BatchTime: 0.00212/0.477) losses = 1.8062, lr = [2.7481090721213975e-05, 0.00027481090721213973]\n",
      "[INFO: 2022-02-16 21:37:08,654]   LabelSmoothing Loss = 1.9773098230361938\n",
      "[INFO: 2022-02-16 21:37:18,209] Iteration 25880 (DataTime/BatchTime: 0.00215/0.478) losses = 2.0203, lr = [2.7470470830288673e-05, 0.0002747047083028867]\n",
      "[INFO: 2022-02-16 21:37:18,209]   LabelSmoothing Loss = 2.4800119400024414\n",
      "[INFO: 2022-02-16 21:37:27,735] Iteration 25900 (DataTime/BatchTime: 0.00288/0.476) losses = 2.0531, lr = [2.7459863241821086e-05, 0.0002745986324182108]\n",
      "[INFO: 2022-02-16 21:37:27,735]   LabelSmoothing Loss = 2.2980339527130127\n",
      "[INFO: 2022-02-16 21:37:37,291] Iteration 25920 (DataTime/BatchTime: 0.00129/0.478) losses = 1.9421, lr = [2.744926793207688e-05, 0.0002744926793207688]\n",
      "[INFO: 2022-02-16 21:37:37,291]   LabelSmoothing Loss = 2.393446922302246\n",
      "[INFO: 2022-02-16 21:37:46,878] Iteration 25940 (DataTime/BatchTime: 0.00217/0.479) losses = 1.8155, lr = [2.7438684877385765e-05, 0.0002743868487738576]\n",
      "[INFO: 2022-02-16 21:37:46,878]   LabelSmoothing Loss = 1.0045753717422485\n",
      "[INFO: 2022-02-16 21:37:56,512] Iteration 25960 (DataTime/BatchTime: 0.00238/0.482) losses = 2.0433, lr = [2.7428114054141286e-05, 0.00027428114054141284]\n",
      "[INFO: 2022-02-16 21:37:56,512]   LabelSmoothing Loss = 2.465606927871704\n",
      "[INFO: 2022-02-16 21:38:06,088] Iteration 25980 (DataTime/BatchTime: 0.00219/0.479) losses = 1.9962, lr = [2.7417555438800607e-05, 0.000274175554388006]\n",
      "[INFO: 2022-02-16 21:38:06,088]   LabelSmoothing Loss = 0.8500475287437439\n",
      "[INFO: 2022-02-16 21:38:15,662] Iteration 26000 (DataTime/BatchTime: 0.0013/0.479) losses = 2.1142, lr = [2.7407009007884272e-05, 0.0002740700900788427]\n",
      "[INFO: 2022-02-16 21:38:15,662]   LabelSmoothing Loss = 1.6431297063827515\n",
      "[INFO: 2022-02-16 21:38:25,324] Iteration 26020 (DataTime/BatchTime: 0.0021/0.483) losses = 2.112, lr = [2.739647473797601e-05, 0.00027396474737976004]\n",
      "[INFO: 2022-02-16 21:38:25,324]   LabelSmoothing Loss = 1.5545555353164673\n",
      "[INFO: 2022-02-16 21:38:35,005] Iteration 26040 (DataTime/BatchTime: 0.00138/0.484) losses = 2.1259, lr = [2.7385952605722494e-05, 0.0002738595260572249]\n",
      "[INFO: 2022-02-16 21:38:35,005]   LabelSmoothing Loss = 0.7605682611465454\n",
      "[INFO: 2022-02-16 21:38:44,679] Iteration 26060 (DataTime/BatchTime: 0.00142/0.484) losses = 1.8949, lr = [2.737544258783314e-05, 0.0002737544258783314]\n",
      "[INFO: 2022-02-16 21:38:44,679]   LabelSmoothing Loss = 1.3927488327026367\n",
      "[INFO: 2022-02-16 21:38:54,230] Iteration 26080 (DataTime/BatchTime: 0.0031/0.478) losses = 1.9957, lr = [2.736494466107989e-05, 0.00027364944661079885]\n",
      "[INFO: 2022-02-16 21:38:54,230]   LabelSmoothing Loss = 1.570984959602356\n",
      "[INFO: 2022-02-16 21:39:03,778] Iteration 26100 (DataTime/BatchTime: 0.00242/0.477) losses = 1.8662, lr = [2.7354458802296972e-05, 0.0002735445880229697]\n",
      "[INFO: 2022-02-16 21:39:03,778]   LabelSmoothing Loss = 1.4890286922454834\n",
      "[INFO: 2022-02-16 21:39:13,407] Iteration 26120 (DataTime/BatchTime: 0.0021/0.481) losses = 1.6999, lr = [2.7343984988380717e-05, 0.00027343984988380715]\n",
      "[INFO: 2022-02-16 21:39:13,407]   LabelSmoothing Loss = 1.5385340452194214\n",
      "[INFO: 2022-02-16 21:39:22,999] Iteration 26140 (DataTime/BatchTime: 0.00169/0.48) losses = 1.9172, lr = [2.733352319628934e-05, 0.0002733352319628934]\n",
      "[INFO: 2022-02-16 21:39:22,999]   LabelSmoothing Loss = 2.2683908939361572\n",
      "[INFO: 2022-02-16 21:39:32,611] Iteration 26160 (DataTime/BatchTime: 0.00196/0.481) losses = 1.865, lr = [2.7323073403042697e-05, 0.00027323073403042695]\n",
      "[INFO: 2022-02-16 21:39:32,612]   LabelSmoothing Loss = 1.2705827951431274\n",
      "[INFO: 2022-02-16 21:39:42,148] Iteration 26180 (DataTime/BatchTime: 0.00201/0.477) losses = 1.8253, lr = [2.7312635585722117e-05, 0.00027312635585722113]\n",
      "[INFO: 2022-02-16 21:39:42,148]   LabelSmoothing Loss = 0.957869827747345\n",
      "[INFO: 2022-02-16 21:39:51,765] Iteration 26200 (DataTime/BatchTime: 0.00124/0.481) losses = 2.0942, lr = [2.7302209721470158e-05, 0.00027302209721470156]\n",
      "[INFO: 2022-02-16 21:39:51,766]   LabelSmoothing Loss = 3.1033730506896973\n",
      "[INFO: 2022-02-16 21:40:01,338] Iteration 26220 (DataTime/BatchTime: 0.00132/0.479) losses = 2.0704, lr = [2.729179578749041e-05, 0.00027291795787490403]\n",
      "[INFO: 2022-02-16 21:40:01,338]   LabelSmoothing Loss = 1.9560338258743286\n",
      "[INFO: 2022-02-16 21:40:10,854] Iteration 26240 (DataTime/BatchTime: 0.00227/0.476) losses = 1.8308, lr = [2.7281393761047275e-05, 0.0002728139376104727]\n",
      "[INFO: 2022-02-16 21:40:10,854]   LabelSmoothing Loss = 1.8425788879394531\n",
      "[INFO: 2022-02-16 21:40:20,358] Iteration 26260 (DataTime/BatchTime: 0.00129/0.475) losses = 1.852, lr = [2.727100361946579e-05, 0.0002727100361946579]\n",
      "[INFO: 2022-02-16 21:40:20,358]   LabelSmoothing Loss = 1.8669945001602173\n",
      "[INFO: 2022-02-16 21:40:29,881] Iteration 26280 (DataTime/BatchTime: 0.00131/0.476) losses = 1.9078, lr = [2.7260625340131375e-05, 0.0002726062534013137]\n",
      "[INFO: 2022-02-16 21:40:29,881]   LabelSmoothing Loss = 1.429186463356018\n",
      "[INFO: 2022-02-16 21:40:39,436] Iteration 26300 (DataTime/BatchTime: 0.00128/0.478) losses = 2.1029, lr = [2.7250258900489655e-05, 0.0002725025890048965]\n",
      "[INFO: 2022-02-16 21:40:39,437]   LabelSmoothing Loss = 1.227739930152893\n",
      "[INFO: 2022-02-16 21:40:48,957] Iteration 26320 (DataTime/BatchTime: 0.00126/0.476) losses = 2.0384, lr = [2.7239904278046243e-05, 0.00027239904278046243]\n",
      "[INFO: 2022-02-16 21:40:48,957]   LabelSmoothing Loss = 1.8195545673370361\n",
      "[INFO: 2022-02-16 21:40:58,472] Iteration 26340 (DataTime/BatchTime: 0.00128/0.476) losses = 1.9706, lr = [2.7229561450366548e-05, 0.0002722956145036655]\n",
      "[INFO: 2022-02-16 21:40:58,472]   LabelSmoothing Loss = 1.7382242679595947\n",
      "[INFO: 2022-02-16 21:41:08,056] Iteration 26360 (DataTime/BatchTime: 0.00127/0.479) losses = 2.0505, lr = [2.7219230395075557e-05, 0.00027219230395075555]\n",
      "[INFO: 2022-02-16 21:41:08,056]   LabelSmoothing Loss = 2.9325640201568604\n",
      "[INFO: 2022-02-16 21:41:17,532] Iteration 26380 (DataTime/BatchTime: 0.00126/0.474) losses = 1.8662, lr = [2.7208911089857632e-05, 0.0002720891108985763]\n",
      "[INFO: 2022-02-16 21:41:17,532]   LabelSmoothing Loss = 2.306894540786743\n",
      "[INFO: 2022-02-16 21:41:27,005] Iteration 26400 (DataTime/BatchTime: 0.00127/0.474) losses = 1.8587, lr = [2.719860351245632e-05, 0.0002719860351245632]\n",
      "[INFO: 2022-02-16 21:41:27,005]   LabelSmoothing Loss = 2.022008180618286\n",
      "[INFO: 2022-02-16 21:41:36,543] Iteration 26420 (DataTime/BatchTime: 0.00129/0.477) losses = 1.9699, lr = [2.718830764067413e-05, 0.0002718830764067413]\n",
      "[INFO: 2022-02-16 21:41:36,543]   LabelSmoothing Loss = 2.1991825103759766\n",
      "[INFO: 2022-02-16 21:41:46,057] Iteration 26440 (DataTime/BatchTime: 0.00127/0.476) losses = 1.8616, lr = [2.7178023452372365e-05, 0.00027178023452372363]\n",
      "[INFO: 2022-02-16 21:41:46,057]   LabelSmoothing Loss = 2.91025710105896\n",
      "[INFO: 2022-02-16 21:41:55,627] Iteration 26460 (DataTime/BatchTime: 0.00126/0.479) losses = 2.1972, lr = [2.7167750925470893e-05, 0.0002716775092547089]\n",
      "[INFO: 2022-02-16 21:41:55,628]   LabelSmoothing Loss = 1.8206651210784912\n",
      "[INFO: 2022-02-16 21:42:05,164] Iteration 26480 (DataTime/BatchTime: 0.00128/0.477) losses = 1.8349, lr = [2.7157490037947945e-05, 0.00027157490037947943]\n",
      "[INFO: 2022-02-16 21:42:05,165]   LabelSmoothing Loss = 1.8739240169525146\n",
      "[INFO: 2022-02-16 21:42:14,750] Iteration 26500 (DataTime/BatchTime: 0.00128/0.479) losses = 1.9284, lr = [2.714724076783995e-05, 0.0002714724076783995]\n",
      "[INFO: 2022-02-16 21:42:14,751]   LabelSmoothing Loss = 0.8729718327522278\n",
      "[INFO: 2022-02-16 21:42:24,322] Iteration 26520 (DataTime/BatchTime: 0.00128/0.479) losses = 2.0066, lr = [2.713700309324131e-05, 0.00027137003093241304]\n",
      "[INFO: 2022-02-16 21:42:24,323]   LabelSmoothing Loss = 1.9770629405975342\n",
      "[INFO: 2022-02-16 21:42:33,936] Iteration 26540 (DataTime/BatchTime: 0.0013/0.481) losses = 2.2148, lr = [2.71267769923042e-05, 0.000271267769923042]\n",
      "[INFO: 2022-02-16 21:42:33,936]   LabelSmoothing Loss = 1.7882307767868042\n",
      "[INFO: 2022-02-16 21:42:43,503] Iteration 26560 (DataTime/BatchTime: 0.00212/0.478) losses = 2.1715, lr = [2.7116562443238396e-05, 0.0002711656244323839]\n",
      "[INFO: 2022-02-16 21:42:43,503]   LabelSmoothing Loss = 2.1028010845184326\n",
      "[INFO: 2022-02-16 21:42:53,037] Iteration 26580 (DataTime/BatchTime: 0.0013/0.477) losses = 2.0674, lr = [2.710635942431106e-05, 0.0002710635942431106]\n",
      "[INFO: 2022-02-16 21:42:53,037]   LabelSmoothing Loss = 2.3847155570983887\n",
      "[INFO: 2022-02-16 21:43:02,558] Iteration 26600 (DataTime/BatchTime: 0.00129/0.476) losses = 2.1001, lr = [2.7096167913846553e-05, 0.0002709616791384655]\n",
      "[INFO: 2022-02-16 21:43:02,558]   LabelSmoothing Loss = 1.8598787784576416\n",
      "[INFO: 2022-02-16 21:43:12,214] Iteration 26620 (DataTime/BatchTime: 0.00128/0.483) losses = 2.1844, lr = [2.708598789022624e-05, 0.00027085987890226236]\n",
      "[INFO: 2022-02-16 21:43:12,214]   LabelSmoothing Loss = 2.2885801792144775\n",
      "[INFO: 2022-02-16 21:43:21,723] Iteration 26640 (DataTime/BatchTime: 0.00208/0.475) losses = 1.9992, lr = [2.7075819331888303e-05, 0.000270758193318883]\n",
      "[INFO: 2022-02-16 21:43:21,723]   LabelSmoothing Loss = 1.1677052974700928\n",
      "[INFO: 2022-02-16 21:43:31,219] Iteration 26660 (DataTime/BatchTime: 0.00127/0.475) losses = 2.0517, lr = [2.7065662217327533e-05, 0.0002706566221732753]\n",
      "[INFO: 2022-02-16 21:43:31,219]   LabelSmoothing Loss = 1.5617369413375854\n",
      "[INFO: 2022-02-16 21:43:40,763] Iteration 26680 (DataTime/BatchTime: 0.00128/0.477) losses = 2.0336, lr = [2.7055516525095164e-05, 0.0002705551652509516]\n",
      "[INFO: 2022-02-16 21:43:40,764]   LabelSmoothing Loss = 1.6565262079238892\n",
      "[INFO: 2022-02-16 21:43:50,234] Iteration 26700 (DataTime/BatchTime: 0.00127/0.474) losses = 1.8526, lr = [2.704538223379866e-05, 0.00027045382233798653]\n",
      "[INFO: 2022-02-16 21:43:50,234]   LabelSmoothing Loss = 2.594991445541382\n",
      "[INFO: 2022-02-16 21:43:59,921] Iteration 26720 (DataTime/BatchTime: 0.00127/0.484) losses = 2.1735, lr = [2.703525932210153e-05, 0.0002703525932210153]\n",
      "[INFO: 2022-02-16 21:43:59,921]   LabelSmoothing Loss = 1.7224035263061523\n",
      "[INFO: 2022-02-16 21:47:38,058] ######## Epoch (VAL)28 ########\n",
      "[INFO: 2022-02-16 21:47:38,059] {'Bleu_1': 0.3224672078423686, 'Bleu_2': 0.1984292773855937, 'Bleu_3': 0.131232265164419, 'Bleu_4': 0.09171324259556049, 'METEOR': 0.17274085903661368, 'ROUGE_L': 0.30080229058702185, 'CIDEr': 0.4058176518864926}\n",
      "[INFO: 2022-02-16 21:51:15,805] ######## Epoch (TEST)28 ########\n",
      "[INFO: 2022-02-16 21:51:15,806] {'Bleu_1': 0.28585093353599206, 'Bleu_2': 0.16483115671303772, 'Bleu_3': 0.1048374001104095, 'Bleu_4': 0.07041419980998552, 'METEOR': 0.16071448011499082, 'ROUGE_L': 0.27571361896403995, 'CIDEr': 0.24378575678020267}\n",
      "[INFO: 2022-02-16 21:51:17,284] Iteration 26740 (DataTime/BatchTime: 0.908/1.48) losses = 1.3211, lr = [2.7025147768723164e-05, 0.0002702514776872316]\n",
      "[INFO: 2022-02-16 21:51:17,284]   LabelSmoothing Loss = 1.321079969406128\n",
      "[INFO: 2022-02-16 21:51:26,843] Iteration 26760 (DataTime/BatchTime: 0.00201/0.478) losses = 2.1224, lr = [2.70150475524386e-05, 0.00027015047552438596]\n",
      "[INFO: 2022-02-16 21:51:26,843]   LabelSmoothing Loss = 2.6414616107940674\n",
      "[INFO: 2022-02-16 21:51:36,323] Iteration 26780 (DataTime/BatchTime: 0.00128/0.474) losses = 2.0921, lr = [2.700495865207839e-05, 0.00027004958652078383]\n",
      "[INFO: 2022-02-16 21:51:36,323]   LabelSmoothing Loss = 2.3518760204315186\n",
      "[INFO: 2022-02-16 21:51:45,856] Iteration 26800 (DataTime/BatchTime: 0.00251/0.477) losses = 1.9987, lr = [2.699488104652835e-05, 0.0002699488104652835]\n",
      "[INFO: 2022-02-16 21:51:45,857]   LabelSmoothing Loss = 2.164245367050171\n",
      "[INFO: 2022-02-16 21:51:55,473] Iteration 26820 (DataTime/BatchTime: 0.00135/0.481) losses = 1.9332, lr = [2.6984814714729438e-05, 0.00026984814714729434]\n",
      "[INFO: 2022-02-16 21:51:55,474]   LabelSmoothing Loss = 1.6797008514404297\n",
      "[INFO: 2022-02-16 21:52:05,028] Iteration 26840 (DataTime/BatchTime: 0.00131/0.478) losses = 2.1329, lr = [2.6974759635677538e-05, 0.00026974759635677535]\n",
      "[INFO: 2022-02-16 21:52:05,028]   LabelSmoothing Loss = 2.228153944015503\n",
      "[INFO: 2022-02-16 21:52:14,545] Iteration 26860 (DataTime/BatchTime: 0.00132/0.476) losses = 1.9391, lr = [2.6964715788423272e-05, 0.0002696471578842327]\n",
      "[INFO: 2022-02-16 21:52:14,546]   LabelSmoothing Loss = 1.8627573251724243\n",
      "[INFO: 2022-02-16 21:52:24,161] Iteration 26880 (DataTime/BatchTime: 0.00296/0.481) losses = 1.9579, lr = [2.6954683152071818e-05, 0.0002695468315207182]\n",
      "[INFO: 2022-02-16 21:52:24,161]   LabelSmoothing Loss = 1.6635288000106812\n",
      "[INFO: 2022-02-16 21:52:33,720] Iteration 26900 (DataTime/BatchTime: 0.00133/0.478) losses = 2.0464, lr = [2.6944661705782752e-05, 0.0002694466170578275]\n",
      "[INFO: 2022-02-16 21:52:33,720]   LabelSmoothing Loss = 2.3550117015838623\n",
      "[INFO: 2022-02-16 21:52:43,233] Iteration 26920 (DataTime/BatchTime: 0.00129/0.476) losses = 1.7629, lr = [2.6934651428769827e-05, 0.00026934651428769826]\n",
      "[INFO: 2022-02-16 21:52:43,233]   LabelSmoothing Loss = 2.3783657550811768\n",
      "[INFO: 2022-02-16 21:52:52,777] Iteration 26940 (DataTime/BatchTime: 0.0013/0.477) losses = 1.9727, lr = [2.6924652300300822e-05, 0.0002692465230030082]\n",
      "[INFO: 2022-02-16 21:52:52,777]   LabelSmoothing Loss = 1.543312668800354\n",
      "[INFO: 2022-02-16 21:53:02,288] Iteration 26960 (DataTime/BatchTime: 0.00214/0.476) losses = 1.7455, lr = [2.691466429969736e-05, 0.00026914664299697354]\n",
      "[INFO: 2022-02-16 21:53:02,289]   LabelSmoothing Loss = 1.2939680814743042\n",
      "[INFO: 2022-02-16 21:53:11,830] Iteration 26980 (DataTime/BatchTime: 0.00216/0.477) losses = 2.0222, lr = [2.69046874063347e-05, 0.000269046874063347]\n",
      "[INFO: 2022-02-16 21:53:11,830]   LabelSmoothing Loss = 1.71929931640625\n",
      "[INFO: 2022-02-16 21:53:21,389] Iteration 27000 (DataTime/BatchTime: 0.00128/0.478) losses = 2.2685, lr = [2.68947215996416e-05, 0.0002689472159964159]\n",
      "[INFO: 2022-02-16 21:53:21,389]   LabelSmoothing Loss = 1.5349451303482056\n",
      "[INFO: 2022-02-16 21:53:30,899] Iteration 27020 (DataTime/BatchTime: 0.0013/0.475) losses = 1.761, lr = [2.68847668591001e-05, 0.000268847668591001]\n",
      "[INFO: 2022-02-16 21:53:30,899]   LabelSmoothing Loss = 1.0293182134628296\n",
      "[INFO: 2022-02-16 21:53:40,372] Iteration 27040 (DataTime/BatchTime: 0.00127/0.474) losses = 1.7665, lr = [2.6874823164245372e-05, 0.0002687482316424537]\n",
      "[INFO: 2022-02-16 21:53:40,372]   LabelSmoothing Loss = 1.2640255689620972\n",
      "[INFO: 2022-02-16 21:53:49,926] Iteration 27060 (DataTime/BatchTime: 0.00129/0.478) losses = 1.9992, lr = [2.6864890494665534e-05, 0.0002686489049466553]\n",
      "[INFO: 2022-02-16 21:53:49,926]   LabelSmoothing Loss = 2.765807867050171\n",
      "[INFO: 2022-02-16 21:53:59,423] Iteration 27080 (DataTime/BatchTime: 0.00132/0.475) losses = 1.9911, lr = [2.6854968830001465e-05, 0.0002685496883000146]\n",
      "[INFO: 2022-02-16 21:53:59,423]   LabelSmoothing Loss = 2.254258394241333\n",
      "[INFO: 2022-02-16 21:54:09,006] Iteration 27100 (DataTime/BatchTime: 0.00131/0.479) losses = 2.1782, lr = [2.6845058149946648e-05, 0.00026845058149946646]\n",
      "[INFO: 2022-02-16 21:54:09,006]   LabelSmoothing Loss = 2.722452402114868\n",
      "[INFO: 2022-02-16 21:54:18,553] Iteration 27120 (DataTime/BatchTime: 0.0022/0.477) losses = 1.8467, lr = [2.6835158434246977e-05, 0.0002683515843424697]\n",
      "[INFO: 2022-02-16 21:54:18,553]   LabelSmoothing Loss = 2.7477593421936035\n",
      "[INFO: 2022-02-16 21:54:28,196] Iteration 27140 (DataTime/BatchTime: 0.00216/0.482) losses = 1.8324, lr = [2.6825269662700594e-05, 0.0002682526966270059]\n",
      "[INFO: 2022-02-16 21:54:28,197]   LabelSmoothing Loss = 1.451719045639038\n",
      "[INFO: 2022-02-16 21:54:37,694] Iteration 27160 (DataTime/BatchTime: 0.00126/0.475) losses = 2.063, lr = [2.681539181515771e-05, 0.0002681539181515771]\n",
      "[INFO: 2022-02-16 21:54:37,695]   LabelSmoothing Loss = 1.4011108875274658\n",
      "[INFO: 2022-02-16 21:54:47,347] Iteration 27180 (DataTime/BatchTime: 0.00134/0.483) losses = 1.9926, lr = [2.6805524871520455e-05, 0.0002680552487152045]\n",
      "[INFO: 2022-02-16 21:54:47,347]   LabelSmoothing Loss = 1.9858207702636719\n",
      "[INFO: 2022-02-16 21:54:56,901] Iteration 27200 (DataTime/BatchTime: 0.00129/0.478) losses = 1.8466, lr = [2.679566881174266e-05, 0.00026795668811742656]\n",
      "[INFO: 2022-02-16 21:54:56,902]   LabelSmoothing Loss = 1.3002516031265259\n",
      "[INFO: 2022-02-16 21:55:06,424] Iteration 27220 (DataTime/BatchTime: 0.0013/0.476) losses = 1.8795, lr = [2.6785823615829724e-05, 0.00026785823615829723]\n",
      "[INFO: 2022-02-16 21:55:06,425]   LabelSmoothing Loss = 2.3308582305908203\n",
      "[INFO: 2022-02-16 21:55:15,929] Iteration 27240 (DataTime/BatchTime: 0.00133/0.475) losses = 1.992, lr = [2.6775989263838436e-05, 0.00026775989263838433]\n",
      "[INFO: 2022-02-16 21:55:15,930]   LabelSmoothing Loss = 1.8641360998153687\n",
      "[INFO: 2022-02-16 21:55:25,460] Iteration 27260 (DataTime/BatchTime: 0.00129/0.477) losses = 1.9985, lr = [2.676616573587681e-05, 0.00026766165735876804]\n",
      "[INFO: 2022-02-16 21:55:25,460]   LabelSmoothing Loss = 1.420773983001709\n",
      "[INFO: 2022-02-16 21:55:34,986] Iteration 27280 (DataTime/BatchTime: 0.00298/0.476) losses = 1.8783, lr = [2.675635301210389e-05, 0.0002675635301210388]\n",
      "[INFO: 2022-02-16 21:55:34,987]   LabelSmoothing Loss = 1.5973776578903198\n",
      "[INFO: 2022-02-16 21:55:44,547] Iteration 27300 (DataTime/BatchTime: 0.00135/0.478) losses = 1.8359, lr = [2.6746551072729605e-05, 0.000267465510727296]\n",
      "[INFO: 2022-02-16 21:55:44,547]   LabelSmoothing Loss = 0.6871915459632874\n",
      "[INFO: 2022-02-16 21:55:54,060] Iteration 27320 (DataTime/BatchTime: 0.00212/0.476) losses = 2.1419, lr = [2.6736759898014606e-05, 0.00026736759898014604]\n",
      "[INFO: 2022-02-16 21:55:54,060]   LabelSmoothing Loss = 1.9921663999557495\n",
      "[INFO: 2022-02-16 21:56:03,620] Iteration 27340 (DataTime/BatchTime: 0.00136/0.478) losses = 1.869, lr = [2.6726979468270082e-05, 0.00026726979468270077]\n",
      "[INFO: 2022-02-16 21:56:03,620]   LabelSmoothing Loss = 1.585776448249817\n",
      "[INFO: 2022-02-16 21:56:13,118] Iteration 27360 (DataTime/BatchTime: 0.00131/0.475) losses = 1.9164, lr = [2.6717209763857595e-05, 0.0002671720976385759]\n",
      "[INFO: 2022-02-16 21:56:13,118]   LabelSmoothing Loss = 1.6466619968414307\n",
      "[INFO: 2022-02-16 21:56:22,798] Iteration 27380 (DataTime/BatchTime: 0.00148/0.484) losses = 1.929, lr = [2.670745076518894e-05, 0.00026707450765188934]\n",
      "[INFO: 2022-02-16 21:56:22,798]   LabelSmoothing Loss = 1.9416712522506714\n",
      "[INFO: 2022-02-16 21:56:32,294] Iteration 27400 (DataTime/BatchTime: 0.0013/0.475) losses = 1.7959, lr = [2.6697702452725933e-05, 0.0002669770245272593]\n",
      "[INFO: 2022-02-16 21:56:32,294]   LabelSmoothing Loss = 2.080651044845581\n",
      "[INFO: 2022-02-16 21:56:41,883] Iteration 27420 (DataTime/BatchTime: 0.00135/0.479) losses = 1.9122, lr = [2.6687964806980297e-05, 0.00026687964806980293]\n",
      "[INFO: 2022-02-16 21:56:41,883]   LabelSmoothing Loss = 1.5341033935546875\n",
      "[INFO: 2022-02-16 21:56:51,348] Iteration 27440 (DataTime/BatchTime: 0.0013/0.473) losses = 1.9999, lr = [2.6678237808513466e-05, 0.0002667823780851346]\n",
      "[INFO: 2022-02-16 21:56:51,349]   LabelSmoothing Loss = 2.164752960205078\n",
      "[INFO: 2022-02-16 21:57:00,924] Iteration 27460 (DataTime/BatchTime: 0.0013/0.479) losses = 2.111, lr = [2.666852143793643e-05, 0.00026668521437936426]\n",
      "[INFO: 2022-02-16 21:57:00,924]   LabelSmoothing Loss = 3.280909776687622\n",
      "[INFO: 2022-02-16 21:57:10,491] Iteration 27480 (DataTime/BatchTime: 0.0013/0.478) losses = 2.2368, lr = [2.665881567590958e-05, 0.0002665881567590958]\n",
      "[INFO: 2022-02-16 21:57:10,491]   LabelSmoothing Loss = 1.9198317527770996\n",
      "[INFO: 2022-02-16 21:57:20,068] Iteration 27500 (DataTime/BatchTime: 0.0013/0.479) losses = 1.7428, lr = [2.6649120503142534e-05, 0.0002664912050314253]\n",
      "[INFO: 2022-02-16 21:57:20,068]   LabelSmoothing Loss = 1.7813506126403809\n",
      "[INFO: 2022-02-16 21:57:29,589] Iteration 27520 (DataTime/BatchTime: 0.00124/0.476) losses = 1.7136, lr = [2.663943590039399e-05, 0.00026639435900393984]\n",
      "[INFO: 2022-02-16 21:57:29,589]   LabelSmoothing Loss = 1.3622316122055054\n",
      "[INFO: 2022-02-16 21:57:39,196] Iteration 27540 (DataTime/BatchTime: 0.00122/0.48) losses = 1.9363, lr = [2.6629761848471545e-05, 0.00026629761848471546]\n",
      "[INFO: 2022-02-16 21:57:39,196]   LabelSmoothing Loss = 1.7119601964950562\n",
      "[INFO: 2022-02-16 21:57:48,735] Iteration 27560 (DataTime/BatchTime: 0.00209/0.477) losses = 1.9709, lr = [2.6620098328231563e-05, 0.0002662009832823156]\n",
      "[INFO: 2022-02-16 21:57:48,735]   LabelSmoothing Loss = 1.8741613626480103\n",
      "[INFO: 2022-02-16 21:57:58,376] Iteration 27580 (DataTime/BatchTime: 0.00128/0.482) losses = 2.1386, lr = [2.6610445320578994e-05, 0.0002661044532057899]\n",
      "[INFO: 2022-02-16 21:57:58,376]   LabelSmoothing Loss = 2.509753704071045\n",
      "[INFO: 2022-02-16 21:58:07,948] Iteration 27600 (DataTime/BatchTime: 0.00133/0.479) losses = 1.9107, lr = [2.6600802806467228e-05, 0.00026600802806467225]\n",
      "[INFO: 2022-02-16 21:58:07,949]   LabelSmoothing Loss = 1.4399443864822388\n",
      "[INFO: 2022-02-16 21:58:17,642] Iteration 27620 (DataTime/BatchTime: 0.00146/0.485) losses = 1.9335, lr = [2.659117076689792e-05, 0.00026591170766897916]\n",
      "[INFO: 2022-02-16 21:58:17,642]   LabelSmoothing Loss = 1.6689900159835815\n",
      "[INFO: 2022-02-16 21:58:27,193] Iteration 27640 (DataTime/BatchTime: 0.00133/0.478) losses = 2.0919, lr = [2.6581549182920855e-05, 0.0002658154918292085]\n",
      "[INFO: 2022-02-16 21:58:27,193]   LabelSmoothing Loss = 2.509878396987915\n",
      "[INFO: 2022-02-16 21:58:36,885] Iteration 27660 (DataTime/BatchTime: 0.00134/0.485) losses = 2.1877, lr = [2.6571938035633784e-05, 0.0002657193803563378]\n",
      "[INFO: 2022-02-16 21:58:36,885]   LabelSmoothing Loss = 1.3151508569717407\n",
      "[INFO: 2022-02-16 21:58:46,490] Iteration 27680 (DataTime/BatchTime: 0.00128/0.48) losses = 2.1119, lr = [2.656233730618225e-05, 0.00026562337306182247]\n",
      "[INFO: 2022-02-16 21:58:46,490]   LabelSmoothing Loss = 1.9659979343414307\n",
      "[INFO: 2022-02-16 22:02:25,917] ######## Epoch (VAL)29 ########\n",
      "[INFO: 2022-02-16 22:02:25,917] {'Bleu_1': 0.32071762396732567, 'Bleu_2': 0.18800481440220693, 'Bleu_3': 0.117728802148925, 'Bleu_4': 0.07612144667980997, 'METEOR': 0.170170454096901, 'ROUGE_L': 0.27919539068255755, 'CIDEr': 0.259418538449254}\n",
      "[INFO: 2022-02-16 22:06:02,101] ######## Epoch (TEST)29 ########\n",
      "[INFO: 2022-02-16 22:06:02,102] {'Bleu_1': 0.3197883960644868, 'Bleu_2': 0.1920305159760713, 'Bleu_3': 0.12749016895807927, 'Bleu_4': 0.0902073656257901, 'METEOR': 0.16887514442549234, 'ROUGE_L': 0.2919532441609997, 'CIDEr': 0.34602951738951904}\n",
      "[INFO: 2022-02-16 22:06:06,156] Iteration 27700 (DataTime/BatchTime: 0.189/0.676) losses = 2.1036, lr = [2.6552746975759468e-05, 0.00026552746975759463]\n",
      "[INFO: 2022-02-16 22:06:06,156]   LabelSmoothing Loss = 1.9873062372207642\n",
      "[INFO: 2022-02-16 22:06:15,687] Iteration 27720 (DataTime/BatchTime: 0.00221/0.477) losses = 2.046, lr = [2.6543167025606135e-05, 0.0002654316702560613]\n",
      "[INFO: 2022-02-16 22:06:15,687]   LabelSmoothing Loss = 1.8880935907363892\n",
      "[INFO: 2022-02-16 22:06:25,192] Iteration 27740 (DataTime/BatchTime: 0.00221/0.475) losses = 1.9273, lr = [2.653359743701029e-05, 0.00026533597437010284]\n",
      "[INFO: 2022-02-16 22:06:25,193]   LabelSmoothing Loss = 2.2456510066986084\n",
      "[INFO: 2022-02-16 22:06:34,745] Iteration 27760 (DataTime/BatchTime: 0.00227/0.478) losses = 1.9647, lr = [2.652403819130717e-05, 0.00026524038191307167]\n",
      "[INFO: 2022-02-16 22:06:34,745]   LabelSmoothing Loss = 2.088599920272827\n",
      "[INFO: 2022-02-16 22:06:44,334] Iteration 27780 (DataTime/BatchTime: 0.00135/0.479) losses = 1.9888, lr = [2.651448926987905e-05, 0.00026514489269879047]\n",
      "[INFO: 2022-02-16 22:06:44,335]   LabelSmoothing Loss = 2.7308316230773926\n",
      "[INFO: 2022-02-16 22:06:53,924] Iteration 27800 (DataTime/BatchTime: 0.0013/0.479) losses = 2.1005, lr = [2.6504950654155083e-05, 0.0002650495065415508]\n",
      "[INFO: 2022-02-16 22:06:53,924]   LabelSmoothing Loss = 2.950941324234009\n",
      "[INFO: 2022-02-16 22:07:03,496] Iteration 27820 (DataTime/BatchTime: 0.00131/0.479) losses = 1.9119, lr = [2.649542232561115e-05, 0.0002649542232561115]\n",
      "[INFO: 2022-02-16 22:07:03,496]   LabelSmoothing Loss = 2.3504061698913574\n",
      "[INFO: 2022-02-16 22:07:13,145] Iteration 27840 (DataTime/BatchTime: 0.0022/0.482) losses = 2.1406, lr = [2.6485904265769734e-05, 0.0002648590426576973]\n",
      "[INFO: 2022-02-16 22:07:13,145]   LabelSmoothing Loss = 2.0946404933929443\n",
      "[INFO: 2022-02-16 22:07:22,721] Iteration 27860 (DataTime/BatchTime: 0.00141/0.479) losses = 1.9184, lr = [2.6476396456199716e-05, 0.0002647639645619971]\n",
      "[INFO: 2022-02-16 22:07:22,721]   LabelSmoothing Loss = 2.58131742477417\n",
      "[INFO: 2022-02-16 22:07:32,330] Iteration 27880 (DataTime/BatchTime: 0.00312/0.48) losses = 1.9687, lr = [2.6466898878516288e-05, 0.0002646689887851628]\n",
      "[INFO: 2022-02-16 22:07:32,331]   LabelSmoothing Loss = 1.4548968076705933\n",
      "[INFO: 2022-02-16 22:07:41,887] Iteration 27900 (DataTime/BatchTime: 0.00141/0.478) losses = 1.7499, lr = [2.645741151438076e-05, 0.0002645741151438076]\n",
      "[INFO: 2022-02-16 22:07:41,888]   LabelSmoothing Loss = 0.895460307598114\n",
      "[INFO: 2022-02-16 22:07:51,459] Iteration 27920 (DataTime/BatchTime: 0.00303/0.479) losses = 2.1984, lr = [2.6447934345500427e-05, 0.0002644793434550042]\n",
      "[INFO: 2022-02-16 22:07:51,459]   LabelSmoothing Loss = 3.1326048374176025\n",
      "[INFO: 2022-02-16 22:08:01,017] Iteration 27940 (DataTime/BatchTime: 0.00227/0.478) losses = 1.729, lr = [2.643846735362842e-05, 0.0002643846735362842]\n",
      "[INFO: 2022-02-16 22:08:01,017]   LabelSmoothing Loss = 1.0953868627548218\n",
      "[INFO: 2022-02-16 22:08:10,668] Iteration 27960 (DataTime/BatchTime: 0.0022/0.483) losses = 1.7218, lr = [2.6429010520563557e-05, 0.0002642901052056355]\n",
      "[INFO: 2022-02-16 22:08:10,668]   LabelSmoothing Loss = 1.1751494407653809\n",
      "[INFO: 2022-02-16 22:08:20,270] Iteration 27980 (DataTime/BatchTime: 0.00413/0.48) losses = 1.9803, lr = [2.6419563828150197e-05, 0.0002641956382815019]\n",
      "[INFO: 2022-02-16 22:08:20,270]   LabelSmoothing Loss = 2.024606466293335\n",
      "[INFO: 2022-02-16 22:08:29,985] Iteration 28000 (DataTime/BatchTime: 0.0023/0.486) losses = 1.9385, lr = [2.6410127258278086e-05, 0.0002641012725827808]\n",
      "[INFO: 2022-02-16 22:08:29,985]   LabelSmoothing Loss = 1.8092821836471558\n",
      "[INFO: 2022-02-16 22:08:39,619] Iteration 28020 (DataTime/BatchTime: 0.00139/0.482) losses = 2.0279, lr = [2.6400700792882232e-05, 0.0002640070079288223]\n",
      "[INFO: 2022-02-16 22:08:39,619]   LabelSmoothing Loss = 1.7322227954864502\n",
      "[INFO: 2022-02-16 22:08:49,150] Iteration 28040 (DataTime/BatchTime: 0.00219/0.477) losses = 2.0377, lr = [2.6391284413942733e-05, 0.0002639128441394273]\n",
      "[INFO: 2022-02-16 22:08:49,150]   LabelSmoothing Loss = 2.3410143852233887\n",
      "[INFO: 2022-02-16 22:08:58,717] Iteration 28060 (DataTime/BatchTime: 0.0014/0.478) losses = 1.8886, lr = [2.6381878103484657e-05, 0.0002638187810348465]\n",
      "[INFO: 2022-02-16 22:08:58,717]   LabelSmoothing Loss = 3.084557056427002\n",
      "[INFO: 2022-02-16 22:09:08,259] Iteration 28080 (DataTime/BatchTime: 0.00131/0.477) losses = 1.9871, lr = [2.637248184357787e-05, 0.0002637248184357787]\n",
      "[INFO: 2022-02-16 22:09:08,259]   LabelSmoothing Loss = 2.799955129623413\n",
      "[INFO: 2022-02-16 22:09:17,850] Iteration 28100 (DataTime/BatchTime: 0.00136/0.48) losses = 1.9821, lr = [2.6363095616336922e-05, 0.0002636309561633692]\n",
      "[INFO: 2022-02-16 22:09:17,850]   LabelSmoothing Loss = 2.307464599609375\n",
      "[INFO: 2022-02-16 22:09:27,422] Iteration 28120 (DataTime/BatchTime: 0.00211/0.479) losses = 2.0609, lr = [2.6353719403920885e-05, 0.0002635371940392088]\n",
      "[INFO: 2022-02-16 22:09:27,422]   LabelSmoothing Loss = 2.8407373428344727\n",
      "[INFO: 2022-02-16 22:09:36,952] Iteration 28140 (DataTime/BatchTime: 0.00127/0.476) losses = 1.9423, lr = [2.6344353188533223e-05, 0.0002634435318853322]\n",
      "[INFO: 2022-02-16 22:09:36,952]   LabelSmoothing Loss = 2.4053492546081543\n",
      "[INFO: 2022-02-16 22:09:46,482] Iteration 28160 (DataTime/BatchTime: 0.00132/0.477) losses = 1.9357, lr = [2.6334996952421634e-05, 0.0002633499695242163]\n",
      "[INFO: 2022-02-16 22:09:46,482]   LabelSmoothing Loss = 1.477817177772522\n",
      "[INFO: 2022-02-16 22:09:55,964] Iteration 28180 (DataTime/BatchTime: 0.00209/0.474) losses = 2.0469, lr = [2.6325650677877924e-05, 0.0002632565067787792]\n",
      "[INFO: 2022-02-16 22:09:55,964]   LabelSmoothing Loss = 2.9441089630126953\n",
      "[INFO: 2022-02-16 22:10:05,456] Iteration 28200 (DataTime/BatchTime: 0.00129/0.475) losses = 1.8083, lr = [2.6316314347237856e-05, 0.0002631631434723785]\n",
      "[INFO: 2022-02-16 22:10:05,456]   LabelSmoothing Loss = 1.5396238565444946\n",
      "[INFO: 2022-02-16 22:10:15,126] Iteration 28220 (DataTime/BatchTime: 0.00236/0.483) losses = 2.109, lr = [2.6306987942881015e-05, 0.0002630698794288101]\n",
      "[INFO: 2022-02-16 22:10:15,127]   LabelSmoothing Loss = 1.0869654417037964\n",
      "[INFO: 2022-02-16 22:10:24,756] Iteration 28240 (DataTime/BatchTime: 0.00208/0.482) losses = 1.8519, lr = [2.629767144723067e-05, 0.0002629767144723067]\n",
      "[INFO: 2022-02-16 22:10:24,757]   LabelSmoothing Loss = 2.1894097328186035\n",
      "[INFO: 2022-02-16 22:10:34,488] Iteration 28260 (DataTime/BatchTime: 0.00394/0.487) losses = 1.8138, lr = [2.6288364842753634e-05, 0.0002628836484275363]\n",
      "[INFO: 2022-02-16 22:10:34,488]   LabelSmoothing Loss = 0.832040011882782\n",
      "[INFO: 2022-02-16 22:10:44,188] Iteration 28280 (DataTime/BatchTime: 0.00129/0.485) losses = 2.1619, lr = [2.6279068111960117e-05, 0.00026279068111960115]\n",
      "[INFO: 2022-02-16 22:10:44,188]   LabelSmoothing Loss = 2.67472505569458\n",
      "[INFO: 2022-02-16 22:10:53,791] Iteration 28300 (DataTime/BatchTime: 0.0013/0.48) losses = 2.0053, lr = [2.6269781237403594e-05, 0.00026269781237403593]\n",
      "[INFO: 2022-02-16 22:10:53,791]   LabelSmoothing Loss = 2.4860122203826904\n",
      "[INFO: 2022-02-16 22:11:03,421] Iteration 28320 (DataTime/BatchTime: 0.0013/0.481) losses = 1.8702, lr = [2.626050420168068e-05, 0.00026260504201680677]\n",
      "[INFO: 2022-02-16 22:11:03,421]   LabelSmoothing Loss = 1.1319493055343628\n",
      "[INFO: 2022-02-16 22:11:13,027] Iteration 28340 (DataTime/BatchTime: 0.00214/0.48) losses = 2.0611, lr = [2.6251236987430964e-05, 0.00026251236987430963]\n",
      "[INFO: 2022-02-16 22:11:13,027]   LabelSmoothing Loss = 2.4029691219329834\n",
      "[INFO: 2022-02-16 22:11:22,579] Iteration 28360 (DataTime/BatchTime: 0.00128/0.478) losses = 1.8567, lr = [2.62419795773369e-05, 0.000262419795773369]\n",
      "[INFO: 2022-02-16 22:11:22,579]   LabelSmoothing Loss = 1.4804624319076538\n",
      "[INFO: 2022-02-16 22:11:32,141] Iteration 28380 (DataTime/BatchTime: 0.0013/0.478) losses = 1.904, lr = [2.623273195412367e-05, 0.0002623273195412367]\n",
      "[INFO: 2022-02-16 22:11:32,141]   LabelSmoothing Loss = 1.5128381252288818\n",
      "[INFO: 2022-02-16 22:11:41,725] Iteration 28400 (DataTime/BatchTime: 0.00128/0.479) losses = 1.9989, lr = [2.6223494100559017e-05, 0.00026223494100559015]\n",
      "[INFO: 2022-02-16 22:11:41,725]   LabelSmoothing Loss = 2.0591518878936768\n",
      "[INFO: 2022-02-16 22:11:51,328] Iteration 28420 (DataTime/BatchTime: 0.00206/0.48) losses = 1.9485, lr = [2.621426599945315e-05, 0.00026214265999453145]\n",
      "[INFO: 2022-02-16 22:11:51,328]   LabelSmoothing Loss = 1.7788333892822266\n",
      "[INFO: 2022-02-16 22:12:00,888] Iteration 28440 (DataTime/BatchTime: 0.00127/0.478) losses = 2.0603, lr = [2.6205047633658578e-05, 0.00026205047633658574]\n",
      "[INFO: 2022-02-16 22:12:00,888]   LabelSmoothing Loss = 3.188605546951294\n",
      "[INFO: 2022-02-16 22:12:10,422] Iteration 28460 (DataTime/BatchTime: 0.00128/0.477) losses = 1.9893, lr = [2.619583898607001e-05, 0.00026195838986070005]\n",
      "[INFO: 2022-02-16 22:12:10,422]   LabelSmoothing Loss = 0.8832128643989563\n",
      "[INFO: 2022-02-16 22:12:19,941] Iteration 28480 (DataTime/BatchTime: 0.00129/0.476) losses = 1.7719, lr = [2.6186640039624178e-05, 0.00026186640039624175]\n",
      "[INFO: 2022-02-16 22:12:19,941]   LabelSmoothing Loss = 2.0936203002929688\n",
      "[INFO: 2022-02-16 22:12:29,622] Iteration 28500 (DataTime/BatchTime: 0.00377/0.484) losses = 2.0999, lr = [2.6177450777299748e-05, 0.00026177450777299747]\n",
      "[INFO: 2022-02-16 22:12:29,623]   LabelSmoothing Loss = 2.6467554569244385\n",
      "[INFO: 2022-02-16 22:12:39,196] Iteration 28520 (DataTime/BatchTime: 0.00133/0.479) losses = 1.9685, lr = [2.616827118211716e-05, 0.00026168271182117157]\n",
      "[INFO: 2022-02-16 22:12:39,196]   LabelSmoothing Loss = 2.2429893016815186\n",
      "[INFO: 2022-02-16 22:12:48,837] Iteration 28540 (DataTime/BatchTime: 0.0013/0.482) losses = 1.8678, lr = [2.6159101237138506e-05, 0.00026159101237138504]\n",
      "[INFO: 2022-02-16 22:12:48,837]   LabelSmoothing Loss = 1.7703896760940552\n",
      "[INFO: 2022-02-16 22:12:58,439] Iteration 28560 (DataTime/BatchTime: 0.0013/0.48) losses = 1.9909, lr = [2.6149940925467386e-05, 0.0002614994092546738]\n",
      "[INFO: 2022-02-16 22:12:58,439]   LabelSmoothing Loss = 1.6940325498580933\n",
      "[INFO: 2022-02-16 22:13:07,971] Iteration 28580 (DataTime/BatchTime: 0.0013/0.477) losses = 1.7747, lr = [2.6140790230248805e-05, 0.000261407902302488]\n",
      "[INFO: 2022-02-16 22:13:07,971]   LabelSmoothing Loss = 1.590181589126587\n",
      "[INFO: 2022-02-16 22:13:17,568] Iteration 28600 (DataTime/BatchTime: 0.00173/0.48) losses = 1.8399, lr = [2.613164913466902e-05, 0.00026131649134669016]\n",
      "[INFO: 2022-02-16 22:13:17,568]   LabelSmoothing Loss = 1.912979006767273\n",
      "[INFO: 2022-02-16 22:13:27,133] Iteration 28620 (DataTime/BatchTime: 0.00274/0.478) losses = 1.8731, lr = [2.6122517621955405e-05, 0.000261225176219554]\n",
      "[INFO: 2022-02-16 22:13:27,133]   LabelSmoothing Loss = 2.3480384349823\n",
      "[INFO: 2022-02-16 22:13:36,662] Iteration 28640 (DataTime/BatchTime: 0.00304/0.476) losses = 1.9525, lr = [2.611339567537635e-05, 0.0002611339567537635]\n",
      "[INFO: 2022-02-16 22:13:36,663]   LabelSmoothing Loss = 1.9763342142105103\n",
      "[INFO: 2022-02-16 22:17:13,255] ######## Epoch (VAL)30 ########\n",
      "[INFO: 2022-02-16 22:17:13,256] {'Bleu_1': 0.3371015034058704, 'Bleu_2': 0.2099240436643337, 'Bleu_3': 0.14099975070769757, 'Bleu_4': 0.09969289518528984, 'METEOR': 0.1795907395162519, 'ROUGE_L': 0.2979496035087552, 'CIDEr': 0.36591019475268366}\n",
      "[INFO: 2022-02-16 22:20:51,595] ######## Epoch (TEST)30 ########\n",
      "[INFO: 2022-02-16 22:20:51,596] {'Bleu_1': 0.31145884223253917, 'Bleu_2': 0.18289035829474146, 'Bleu_3': 0.1186147858861324, 'Bleu_4': 0.08109739809928158, 'METEOR': 0.16653825306175973, 'ROUGE_L': 0.2823665748918977, 'CIDEr': 0.30292310656558924}\n",
      "[INFO: 2022-02-16 22:20:57,944] Iteration 28660 (DataTime/BatchTime: 0.0912/0.577) losses = 1.6645, lr = [2.6104283278241104e-05, 0.000261042832782411]\n",
      "[INFO: 2022-02-16 22:20:57,944]   LabelSmoothing Loss = 1.893751621246338\n",
      "[INFO: 2022-02-16 22:21:07,426] Iteration 28680 (DataTime/BatchTime: 0.00391/0.474) losses = 1.9792, lr = [2.6095180413899667e-05, 0.00026095180413899664]\n",
      "[INFO: 2022-02-16 22:21:07,426]   LabelSmoothing Loss = 1.9972119331359863\n",
      "[INFO: 2022-02-16 22:21:16,859] Iteration 28700 (DataTime/BatchTime: 0.00125/0.472) losses = 2.021, lr = [2.608608706574264e-05, 0.0002608608706574264]\n",
      "[INFO: 2022-02-16 22:21:16,860]   LabelSmoothing Loss = 1.8208467960357666\n",
      "[INFO: 2022-02-16 22:21:26,334] Iteration 28720 (DataTime/BatchTime: 0.0012/0.474) losses = 2.0501, lr = [2.6077003217201114e-05, 0.0002607700321720111]\n",
      "[INFO: 2022-02-16 22:21:26,334]   LabelSmoothing Loss = 2.4345757961273193\n",
      "[INFO: 2022-02-16 22:21:35,879] Iteration 28740 (DataTime/BatchTime: 0.00192/0.477) losses = 2.1753, lr = [2.606792885174656e-05, 0.00026067928851746555]\n",
      "[INFO: 2022-02-16 22:21:35,879]   LabelSmoothing Loss = 2.6052451133728027\n",
      "[INFO: 2022-02-16 22:21:45,511] Iteration 28760 (DataTime/BatchTime: 0.00413/0.482) losses = 1.885, lr = [2.6058863952890643e-05, 0.0002605886395289064]\n",
      "[INFO: 2022-02-16 22:21:45,511]   LabelSmoothing Loss = 1.1056187152862549\n",
      "[INFO: 2022-02-16 22:21:55,091] Iteration 28780 (DataTime/BatchTime: 0.00112/0.479) losses = 2.1105, lr = [2.6049808504185182e-05, 0.0002604980850418518]\n",
      "[INFO: 2022-02-16 22:21:55,091]   LabelSmoothing Loss = 2.299999475479126\n",
      "[INFO: 2022-02-16 22:22:04,579] Iteration 28800 (DataTime/BatchTime: 0.00119/0.474) losses = 1.8982, lr = [2.6040762489221937e-05, 0.00026040762489221934]\n",
      "[INFO: 2022-02-16 22:22:04,579]   LabelSmoothing Loss = 1.3488426208496094\n",
      "[INFO: 2022-02-16 22:22:14,116] Iteration 28820 (DataTime/BatchTime: 0.00293/0.477) losses = 1.8751, lr = [2.6031725891632554e-05, 0.0002603172589163255]\n",
      "[INFO: 2022-02-16 22:22:14,116]   LabelSmoothing Loss = 1.9262675046920776\n",
      "[INFO: 2022-02-16 22:22:23,683] Iteration 28840 (DataTime/BatchTime: 0.00279/0.478) losses = 1.6913, lr = [2.60226986950884e-05, 0.000260226986950884]\n",
      "[INFO: 2022-02-16 22:22:23,684]   LabelSmoothing Loss = 2.5365426540374756\n",
      "[INFO: 2022-02-16 22:22:33,288] Iteration 28860 (DataTime/BatchTime: 0.00119/0.48) losses = 1.7714, lr = [2.6013680883300455e-05, 0.00026013680883300454]\n",
      "[INFO: 2022-02-16 22:22:33,289]   LabelSmoothing Loss = 1.2577475309371948\n",
      "[INFO: 2022-02-16 22:22:42,912] Iteration 28880 (DataTime/BatchTime: 0.00116/0.481) losses = 2.2228, lr = [2.6004672440019185e-05, 0.0002600467244001918]\n",
      "[INFO: 2022-02-16 22:22:42,912]   LabelSmoothing Loss = 2.380732774734497\n",
      "[INFO: 2022-02-16 22:22:52,559] Iteration 28900 (DataTime/BatchTime: 0.00113/0.482) losses = 2.0286, lr = [2.599567334903441e-05, 0.0002599567334903441]\n",
      "[INFO: 2022-02-16 22:22:52,559]   LabelSmoothing Loss = 1.8887197971343994\n",
      "[INFO: 2022-02-16 22:23:02,360] Iteration 28920 (DataTime/BatchTime: 0.00268/0.49) losses = 1.8157, lr = [2.59866835941752e-05, 0.000259866835941752]\n",
      "[INFO: 2022-02-16 22:23:02,360]   LabelSmoothing Loss = 2.164121627807617\n",
      "[INFO: 2022-02-16 22:23:11,840] Iteration 28940 (DataTime/BatchTime: 0.000996/0.474) losses = 1.7701, lr = [2.5977703159309742e-05, 0.0002597770315930974]\n",
      "[INFO: 2022-02-16 22:23:11,840]   LabelSmoothing Loss = 1.4454336166381836\n",
      "[INFO: 2022-02-16 22:23:21,422] Iteration 28960 (DataTime/BatchTime: 0.00284/0.479) losses = 1.7875, lr = [2.5968732028345224e-05, 0.0002596873202834522]\n",
      "[INFO: 2022-02-16 22:23:21,422]   LabelSmoothing Loss = 0.995864748954773\n",
      "[INFO: 2022-02-16 22:23:31,044] Iteration 28980 (DataTime/BatchTime: 0.0026/0.481) losses = 1.8128, lr = [2.5959770185227694e-05, 0.0002595977018522769]\n",
      "[INFO: 2022-02-16 22:23:31,044]   LabelSmoothing Loss = 1.3045741319656372\n",
      "[INFO: 2022-02-16 22:23:40,576] Iteration 29000 (DataTime/BatchTime: 0.00107/0.477) losses = 1.95, lr = [2.595081761394197e-05, 0.00025950817613941966]\n",
      "[INFO: 2022-02-16 22:23:40,577]   LabelSmoothing Loss = 1.3007482290267944\n",
      "[INFO: 2022-02-16 22:23:50,049] Iteration 29020 (DataTime/BatchTime: 0.00304/0.474) losses = 1.9097, lr = [2.59418742985115e-05, 0.000259418742985115]\n",
      "[INFO: 2022-02-16 22:23:50,049]   LabelSmoothing Loss = 1.5511080026626587\n",
      "[INFO: 2022-02-16 22:23:59,683] Iteration 29040 (DataTime/BatchTime: 0.00133/0.482) losses = 1.932, lr = [2.5932940222998242e-05, 0.0002593294022299824]\n",
      "[INFO: 2022-02-16 22:23:59,684]   LabelSmoothing Loss = 1.5284150838851929\n",
      "[INFO: 2022-02-16 22:24:09,383] Iteration 29060 (DataTime/BatchTime: 0.00248/0.485) losses = 1.8391, lr = [2.592401537150256e-05, 0.00025924015371502556]\n",
      "[INFO: 2022-02-16 22:24:09,384]   LabelSmoothing Loss = 2.8456335067749023\n",
      "[INFO: 2022-02-16 22:24:18,997] Iteration 29080 (DataTime/BatchTime: 0.00229/0.481) losses = 2.0825, lr = [2.5915099728163087e-05, 0.00025915099728163085]\n",
      "[INFO: 2022-02-16 22:24:18,998]   LabelSmoothing Loss = 2.566363573074341\n",
      "[INFO: 2022-02-16 22:24:28,606] Iteration 29100 (DataTime/BatchTime: 0.00206/0.48) losses = 1.8846, lr = [2.5906193277156614e-05, 0.0002590619327715661]\n",
      "[INFO: 2022-02-16 22:24:28,607]   LabelSmoothing Loss = 2.7607736587524414\n",
      "[INFO: 2022-02-16 22:24:38,337] Iteration 29120 (DataTime/BatchTime: 0.00129/0.487) losses = 1.9908, lr = [2.5897296002697975e-05, 0.00025897296002697973]\n",
      "[INFO: 2022-02-16 22:24:38,337]   LabelSmoothing Loss = 2.7415637969970703\n",
      "[INFO: 2022-02-16 22:24:47,968] Iteration 29140 (DataTime/BatchTime: 0.0019/0.482) losses = 2.0754, lr = [2.5888407889039934e-05, 0.0002588840788903993]\n",
      "[INFO: 2022-02-16 22:24:47,968]   LabelSmoothing Loss = 1.7082343101501465\n",
      "[INFO: 2022-02-16 22:24:57,522] Iteration 29160 (DataTime/BatchTime: 0.0039/0.478) losses = 1.8809, lr = [2.5879528920473047e-05, 0.0002587952892047304]\n",
      "[INFO: 2022-02-16 22:24:57,522]   LabelSmoothing Loss = 1.9898247718811035\n",
      "[INFO: 2022-02-16 22:25:07,002] Iteration 29180 (DataTime/BatchTime: 0.00318/0.474) losses = 1.7952, lr = [2.5870659081325565e-05, 0.0002587065908132556]\n",
      "[INFO: 2022-02-16 22:25:07,002]   LabelSmoothing Loss = 0.9290682077407837\n",
      "[INFO: 2022-02-16 22:25:16,629] Iteration 29200 (DataTime/BatchTime: 0.00223/0.481) losses = 1.8713, lr = [2.5861798355963314e-05, 0.0002586179835596331]\n",
      "[INFO: 2022-02-16 22:25:16,629]   LabelSmoothing Loss = 2.4769649505615234\n",
      "[INFO: 2022-02-16 22:25:26,150] Iteration 29220 (DataTime/BatchTime: 0.00111/0.476) losses = 1.8188, lr = [2.585294672878958e-05, 0.0002585294672878958]\n",
      "[INFO: 2022-02-16 22:25:26,150]   LabelSmoothing Loss = 2.0182766914367676\n",
      "[INFO: 2022-02-16 22:25:35,729] Iteration 29240 (DataTime/BatchTime: 0.000989/0.479) losses = 1.9496, lr = [2.5844104184244987e-05, 0.00025844104184244985]\n",
      "[INFO: 2022-02-16 22:25:35,730]   LabelSmoothing Loss = 2.2947700023651123\n",
      "[INFO: 2022-02-16 22:25:45,329] Iteration 29260 (DataTime/BatchTime: 0.00195/0.48) losses = 1.8843, lr = [2.5835270706807386e-05, 0.00025835270706807385]\n",
      "[INFO: 2022-02-16 22:25:45,329]   LabelSmoothing Loss = 2.8901052474975586\n",
      "[INFO: 2022-02-16 22:25:54,914] Iteration 29280 (DataTime/BatchTime: 0.00185/0.479) losses = 2.0502, lr = [2.582644628099174e-05, 0.00025826446280991736]\n",
      "[INFO: 2022-02-16 22:25:54,915]   LabelSmoothing Loss = 1.2101542949676514\n",
      "[INFO: 2022-02-16 22:26:04,461] Iteration 29300 (DataTime/BatchTime: 0.00226/0.477) losses = 1.8622, lr = [2.5817630891350016e-05, 0.00025817630891350013]\n",
      "[INFO: 2022-02-16 22:26:04,461]   LabelSmoothing Loss = 1.1826725006103516\n",
      "[INFO: 2022-02-16 22:26:14,055] Iteration 29320 (DataTime/BatchTime: 0.00209/0.48) losses = 1.9208, lr = [2.580882452247106e-05, 0.00025808824522471056]\n",
      "[INFO: 2022-02-16 22:26:14,055]   LabelSmoothing Loss = 1.8199572563171387\n",
      "[INFO: 2022-02-16 22:26:23,586] Iteration 29340 (DataTime/BatchTime: 0.00214/0.477) losses = 2.015, lr = [2.580002715898049e-05, 0.0002580002715898049]\n",
      "[INFO: 2022-02-16 22:26:23,586]   LabelSmoothing Loss = 2.345127582550049\n",
      "[INFO: 2022-02-16 22:26:33,212] Iteration 29360 (DataTime/BatchTime: 0.00121/0.481) losses = 1.9118, lr = [2.579123878554059e-05, 0.0002579123878554059]\n",
      "[INFO: 2022-02-16 22:26:33,212]   LabelSmoothing Loss = 1.9757599830627441\n",
      "[INFO: 2022-02-16 22:26:42,733] Iteration 29380 (DataTime/BatchTime: 0.00116/0.476) losses = 2.0426, lr = [2.5782459386850186e-05, 0.0002578245938685018]\n",
      "[INFO: 2022-02-16 22:26:42,733]   LabelSmoothing Loss = 2.3969759941101074\n",
      "[INFO: 2022-02-16 22:26:52,386] Iteration 29400 (DataTime/BatchTime: 0.00123/0.483) losses = 1.9418, lr = [2.5773688947644538e-05, 0.00025773688947644535]\n",
      "[INFO: 2022-02-16 22:26:52,386]   LabelSmoothing Loss = 1.4976357221603394\n",
      "[INFO: 2022-02-16 22:27:01,948] Iteration 29420 (DataTime/BatchTime: 0.00202/0.477) losses = 2.1042, lr = [2.5764927452695236e-05, 0.0002576492745269523]\n",
      "[INFO: 2022-02-16 22:27:01,949]   LabelSmoothing Loss = 1.903816819190979\n",
      "[INFO: 2022-02-16 22:27:11,564] Iteration 29440 (DataTime/BatchTime: 0.00292/0.482) losses = 1.9054, lr = [2.5756174886810077e-05, 0.00025756174886810073]\n",
      "[INFO: 2022-02-16 22:27:11,564]   LabelSmoothing Loss = 0.9226893186569214\n",
      "[INFO: 2022-02-16 22:27:21,047] Iteration 29460 (DataTime/BatchTime: 0.00311/0.474) losses = 1.8072, lr = [2.574743123483295e-05, 0.0002574743123483295]\n",
      "[INFO: 2022-02-16 22:27:21,047]   LabelSmoothing Loss = 1.3561886548995972\n",
      "[INFO: 2022-02-16 22:27:30,571] Iteration 29480 (DataTime/BatchTime: 0.00337/0.476) losses = 1.9384, lr = [2.5738696481643765e-05, 0.00025738696481643765]\n",
      "[INFO: 2022-02-16 22:27:30,571]   LabelSmoothing Loss = 2.5948069095611572\n",
      "[INFO: 2022-02-16 22:27:40,239] Iteration 29500 (DataTime/BatchTime: 0.00133/0.483) losses = 1.8789, lr = [2.5729970612158284e-05, 0.0002572997061215828]\n",
      "[INFO: 2022-02-16 22:27:40,240]   LabelSmoothing Loss = 2.2864434719085693\n",
      "[INFO: 2022-02-16 22:27:49,806] Iteration 29520 (DataTime/BatchTime: 0.00199/0.478) losses = 1.8817, lr = [2.5721253611328054e-05, 0.0002572125361132805]\n",
      "[INFO: 2022-02-16 22:27:49,806]   LabelSmoothing Loss = 2.5376012325286865\n",
      "[INFO: 2022-02-16 22:27:59,341] Iteration 29540 (DataTime/BatchTime: 0.00227/0.477) losses = 1.8757, lr = [2.5712545464140287e-05, 0.00025712545464140284]\n",
      "[INFO: 2022-02-16 22:27:59,342]   LabelSmoothing Loss = 1.7682101726531982\n",
      "[INFO: 2022-02-16 22:28:08,963] Iteration 29560 (DataTime/BatchTime: 0.00226/0.481) losses = 2.3907, lr = [2.5703846155617745e-05, 0.0002570384615561774]\n",
      "[INFO: 2022-02-16 22:28:08,963]   LabelSmoothing Loss = 1.979585886001587\n",
      "[INFO: 2022-02-16 22:28:18,508] Iteration 29580 (DataTime/BatchTime: 0.00113/0.477) losses = 2.0812, lr = [2.5695155670818643e-05, 0.00025695155670818644]\n",
      "[INFO: 2022-02-16 22:28:18,508]   LabelSmoothing Loss = 1.0144870281219482\n",
      "[INFO: 2022-02-16 22:28:27,970] Iteration 29600 (DataTime/BatchTime: 0.00315/0.473) losses = 1.881, lr = [2.568647399483653e-05, 0.00025686473994836526]\n",
      "[INFO: 2022-02-16 22:28:27,970]   LabelSmoothing Loss = 1.4724262952804565\n",
      "[INFO: 2022-02-16 22:31:58,887] ######## Epoch (VAL)31 ########\n",
      "[INFO: 2022-02-16 22:31:58,887] {'Bleu_1': 0.35147212471516753, 'Bleu_2': 0.21667634150452936, 'Bleu_3': 0.14499175459610394, 'Bleu_4': 0.10366444834451652, 'METEOR': 0.1861330596866481, 'ROUGE_L': 0.2945335341052424, 'CIDEr': 0.34061654725952056}\n",
      "[INFO: 2022-02-16 22:35:36,034] ######## Epoch (TEST)31 ########\n",
      "[INFO: 2022-02-16 22:35:36,034] {'Bleu_1': 0.3368317028264611, 'Bleu_2': 0.19971396293611973, 'Bleu_3': 0.12972886476560852, 'Bleu_4': 0.08953675897969833, 'METEOR': 0.17534064640612887, 'ROUGE_L': 0.2873052113425134, 'CIDEr': 0.3004206708867578}\n",
      "[INFO: 2022-02-16 22:35:44,850] Iteration 29620 (DataTime/BatchTime: 0.0681/0.551) losses = 1.8852, lr = [2.5677801112800183e-05, 0.00025677801112800177]\n",
      "[INFO: 2022-02-16 22:35:44,851]   LabelSmoothing Loss = 1.7209045886993408\n",
      "[INFO: 2022-02-16 22:35:54,436] Iteration 29640 (DataTime/BatchTime: 0.00221/0.479) losses = 1.9531, lr = [2.5669137009873513e-05, 0.0002566913700987351]\n",
      "[INFO: 2022-02-16 22:35:54,437]   LabelSmoothing Loss = 2.544292688369751\n",
      "[INFO: 2022-02-16 22:36:04,018] Iteration 29660 (DataTime/BatchTime: 0.00219/0.479) losses = 1.9619, lr = [2.566048167125544e-05, 0.00025660481671255437]\n",
      "[INFO: 2022-02-16 22:36:04,019]   LabelSmoothing Loss = 1.8378069400787354\n",
      "[INFO: 2022-02-16 22:36:13,643] Iteration 29680 (DataTime/BatchTime: 0.00333/0.481) losses = 1.8566, lr = [2.56518350821798e-05, 0.000256518350821798]\n",
      "[INFO: 2022-02-16 22:36:13,643]   LabelSmoothing Loss = 2.0048880577087402\n",
      "[INFO: 2022-02-16 22:36:23,367] Iteration 29700 (DataTime/BatchTime: 0.00134/0.486) losses = 1.9978, lr = [2.5643197227915242e-05, 0.00025643197227915237]\n",
      "[INFO: 2022-02-16 22:36:23,368]   LabelSmoothing Loss = 1.6246730089187622\n",
      "[INFO: 2022-02-16 22:36:33,046] Iteration 29720 (DataTime/BatchTime: 0.00136/0.484) losses = 1.97, lr = [2.5634568093765096e-05, 0.00025634568093765094]\n",
      "[INFO: 2022-02-16 22:36:33,046]   LabelSmoothing Loss = 2.6777119636535645\n",
      "[INFO: 2022-02-16 22:36:42,687] Iteration 29740 (DataTime/BatchTime: 0.00134/0.482) losses = 1.8337, lr = [2.562594766506731e-05, 0.0002562594766506731]\n",
      "[INFO: 2022-02-16 22:36:42,687]   LabelSmoothing Loss = 1.7682468891143799\n",
      "[INFO: 2022-02-16 22:36:52,338] Iteration 29760 (DataTime/BatchTime: 0.00134/0.483) losses = 1.868, lr = [2.5617335927194308e-05, 0.00025617335927194304]\n",
      "[INFO: 2022-02-16 22:36:52,338]   LabelSmoothing Loss = 2.4702887535095215\n",
      "[INFO: 2022-02-16 22:37:01,945] Iteration 29780 (DataTime/BatchTime: 0.00214/0.48) losses = 1.9457, lr = [2.5608732865552904e-05, 0.000256087328655529]\n",
      "[INFO: 2022-02-16 22:37:01,945]   LabelSmoothing Loss = 1.126924753189087\n",
      "[INFO: 2022-02-16 22:37:11,493] Iteration 29800 (DataTime/BatchTime: 0.00126/0.477) losses = 1.9031, lr = [2.5600138465584195e-05, 0.00025600138465584196]\n",
      "[INFO: 2022-02-16 22:37:11,493]   LabelSmoothing Loss = 2.6936557292938232\n",
      "[INFO: 2022-02-16 22:37:21,124] Iteration 29820 (DataTime/BatchTime: 0.00129/0.482) losses = 1.8233, lr = [2.5591552712763466e-05, 0.0002559155271276346]\n",
      "[INFO: 2022-02-16 22:37:21,124]   LabelSmoothing Loss = 1.6199164390563965\n",
      "[INFO: 2022-02-16 22:37:30,776] Iteration 29840 (DataTime/BatchTime: 0.00294/0.483) losses = 1.9564, lr = [2.5582975592600063e-05, 0.0002558297559260006]\n",
      "[INFO: 2022-02-16 22:37:30,776]   LabelSmoothing Loss = 1.317205548286438\n",
      "[INFO: 2022-02-16 22:37:40,293] Iteration 29860 (DataTime/BatchTime: 0.00129/0.476) losses = 1.8301, lr = [2.5574407090637312e-05, 0.0002557440709063731]\n",
      "[INFO: 2022-02-16 22:37:40,293]   LabelSmoothing Loss = 1.4811562299728394\n",
      "[INFO: 2022-02-16 22:37:49,990] Iteration 29880 (DataTime/BatchTime: 0.0024/0.485) losses = 2.0796, lr = [2.5565847192452415e-05, 0.0002556584719245241]\n",
      "[INFO: 2022-02-16 22:37:49,991]   LabelSmoothing Loss = 2.139427661895752\n",
      "[INFO: 2022-02-16 22:37:59,649] Iteration 29900 (DataTime/BatchTime: 0.00252/0.483) losses = 1.6981, lr = [2.5557295883656338e-05, 0.00025557295883656334]\n",
      "[INFO: 2022-02-16 22:37:59,649]   LabelSmoothing Loss = 1.683821439743042\n",
      "[INFO: 2022-02-16 22:38:09,319] Iteration 29920 (DataTime/BatchTime: 0.00145/0.483) losses = 1.7977, lr = [2.554875314989371e-05, 0.0002554875314989371]\n",
      "[INFO: 2022-02-16 22:38:09,319]   LabelSmoothing Loss = 1.6553077697753906\n",
      "[INFO: 2022-02-16 22:38:18,990] Iteration 29940 (DataTime/BatchTime: 0.00144/0.484) losses = 2.0387, lr = [2.5540218976842738e-05, 0.0002554021897684274]\n",
      "[INFO: 2022-02-16 22:38:18,990]   LabelSmoothing Loss = 1.841692566871643\n",
      "[INFO: 2022-02-16 22:38:28,729] Iteration 29960 (DataTime/BatchTime: 0.00237/0.487) losses = 2.1344, lr = [2.5531693350215092e-05, 0.00025531693350215086]\n",
      "[INFO: 2022-02-16 22:38:28,729]   LabelSmoothing Loss = 2.204080820083618\n",
      "[INFO: 2022-02-16 22:38:38,462] Iteration 29980 (DataTime/BatchTime: 0.00146/0.487) losses = 1.9169, lr = [2.5523176255755795e-05, 0.0002552317625575579]\n",
      "[INFO: 2022-02-16 22:38:38,462]   LabelSmoothing Loss = 2.1876940727233887\n",
      "[INFO: 2022-02-16 22:38:48,298] Iteration 30000 (DataTime/BatchTime: 0.00252/0.492) losses = 1.8574, lr = [2.5514667679243145e-05, 0.00025514667679243144]\n",
      "[INFO: 2022-02-16 22:38:48,298]   LabelSmoothing Loss = 1.0484057664871216\n",
      "[INFO: 2022-02-16 22:38:57,908] Iteration 30020 (DataTime/BatchTime: 0.00234/0.481) losses = 1.9165, lr = [2.5506167606488607e-05, 0.00025506167606488604]\n",
      "[INFO: 2022-02-16 22:38:57,908]   LabelSmoothing Loss = 1.6076029539108276\n",
      "[INFO: 2022-02-16 22:39:07,505] Iteration 30040 (DataTime/BatchTime: 0.00141/0.48) losses = 1.9433, lr = [2.5497676023336706e-05, 0.000254976760233367]\n",
      "[INFO: 2022-02-16 22:39:07,505]   LabelSmoothing Loss = 1.7061591148376465\n",
      "[INFO: 2022-02-16 22:39:17,192] Iteration 30060 (DataTime/BatchTime: 0.00314/0.484) losses = 1.849, lr = [2.5489192915664935e-05, 0.00025489192915664934]\n",
      "[INFO: 2022-02-16 22:39:17,192]   LabelSmoothing Loss = 1.4952293634414673\n",
      "[INFO: 2022-02-16 22:39:26,847] Iteration 30080 (DataTime/BatchTime: 0.00143/0.483) losses = 1.9335, lr = [2.548071826938366e-05, 0.0002548071826938366]\n",
      "[INFO: 2022-02-16 22:39:26,848]   LabelSmoothing Loss = 1.5157239437103271\n",
      "[INFO: 2022-02-16 22:39:36,446] Iteration 30100 (DataTime/BatchTime: 0.00417/0.48) losses = 2.0587, lr = [2.5472252070436006e-05, 0.00025472252070436003]\n",
      "[INFO: 2022-02-16 22:39:36,446]   LabelSmoothing Loss = 1.1303503513336182\n",
      "[INFO: 2022-02-16 22:39:46,079] Iteration 30120 (DataTime/BatchTime: 0.00139/0.482) losses = 1.7811, lr = [2.5463794304797788e-05, 0.00025463794304797787]\n",
      "[INFO: 2022-02-16 22:39:46,079]   LabelSmoothing Loss = 2.290512800216675\n",
      "[INFO: 2022-02-16 22:39:55,684] Iteration 30140 (DataTime/BatchTime: 0.00142/0.48) losses = 2.0793, lr = [2.5455344958477374e-05, 0.00025455344958477373]\n",
      "[INFO: 2022-02-16 22:39:55,684]   LabelSmoothing Loss = 1.0981894731521606\n",
      "[INFO: 2022-02-16 22:40:05,444] Iteration 30160 (DataTime/BatchTime: 0.00226/0.488) losses = 1.9105, lr = [2.5446904017515624e-05, 0.00025446904017515623]\n",
      "[INFO: 2022-02-16 22:40:05,444]   LabelSmoothing Loss = 2.1790261268615723\n",
      "[INFO: 2022-02-16 22:40:15,107] Iteration 30180 (DataTime/BatchTime: 0.00312/0.483) losses = 1.9432, lr = [2.543847146798578e-05, 0.0002543847146798578]\n",
      "[INFO: 2022-02-16 22:40:15,108]   LabelSmoothing Loss = 1.248254418373108\n",
      "[INFO: 2022-02-16 22:40:24,767] Iteration 30200 (DataTime/BatchTime: 0.00328/0.483) losses = 1.7069, lr = [2.5430047295993353e-05, 0.0002543004729599335]\n",
      "[INFO: 2022-02-16 22:40:24,767]   LabelSmoothing Loss = 1.7958682775497437\n",
      "[INFO: 2022-02-16 22:40:34,482] Iteration 30220 (DataTime/BatchTime: 0.0015/0.486) losses = 2.0415, lr = [2.542163148767605e-05, 0.0002542163148767605]\n",
      "[INFO: 2022-02-16 22:40:34,482]   LabelSmoothing Loss = 2.092710018157959\n",
      "[INFO: 2022-02-16 22:40:44,192] Iteration 30240 (DataTime/BatchTime: 0.00149/0.485) losses = 1.9389, lr = [2.5413224029203675e-05, 0.0002541322402920367]\n",
      "[INFO: 2022-02-16 22:40:44,192]   LabelSmoothing Loss = 1.9270042181015015\n",
      "[INFO: 2022-02-16 22:40:53,840] Iteration 30260 (DataTime/BatchTime: 0.00326/0.482) losses = 1.7259, lr = [2.5404824906778023e-05, 0.0002540482490677802]\n",
      "[INFO: 2022-02-16 22:40:53,840]   LabelSmoothing Loss = 1.7412844896316528\n",
      "[INFO: 2022-02-16 22:41:03,421] Iteration 30280 (DataTime/BatchTime: 0.00446/0.479) losses = 1.8533, lr = [2.5396434106632787e-05, 0.0002539643410663278]\n",
      "[INFO: 2022-02-16 22:41:03,422]   LabelSmoothing Loss = 1.1798192262649536\n",
      "[INFO: 2022-02-16 22:41:13,125] Iteration 30300 (DataTime/BatchTime: 0.00169/0.485) losses = 1.828, lr = [2.538805161503347e-05, 0.00025388051615033466]\n",
      "[INFO: 2022-02-16 22:41:13,125]   LabelSmoothing Loss = 2.8991246223449707\n",
      "[INFO: 2022-02-16 22:41:22,813] Iteration 30320 (DataTime/BatchTime: 0.00157/0.484) losses = 1.8144, lr = [2.5379677418277294e-05, 0.00025379677418277294]\n",
      "[INFO: 2022-02-16 22:41:22,813]   LabelSmoothing Loss = 1.7328037023544312\n",
      "[INFO: 2022-02-16 22:41:32,451] Iteration 30340 (DataTime/BatchTime: 0.00141/0.482) losses = 1.9434, lr = [2.5371311502693087e-05, 0.0002537131150269308]\n",
      "[INFO: 2022-02-16 22:41:32,451]   LabelSmoothing Loss = 1.3637195825576782\n",
      "[INFO: 2022-02-16 22:41:42,064] Iteration 30360 (DataTime/BatchTime: 0.00151/0.481) losses = 2.021, lr = [2.536295385464121e-05, 0.00025362953854641206]\n",
      "[INFO: 2022-02-16 22:41:42,064]   LabelSmoothing Loss = 1.3985106945037842\n",
      "[INFO: 2022-02-16 22:41:51,668] Iteration 30380 (DataTime/BatchTime: 0.00142/0.48) losses = 1.9613, lr = [2.535460446051345e-05, 0.0002535460446051345]\n",
      "[INFO: 2022-02-16 22:41:51,668]   LabelSmoothing Loss = 2.4080498218536377\n",
      "[INFO: 2022-02-16 22:42:01,419] Iteration 30400 (DataTime/BatchTime: 0.00145/0.488) losses = 2.0519, lr = [2.5346263306732928e-05, 0.0002534626330673293]\n",
      "[INFO: 2022-02-16 22:42:01,420]   LabelSmoothing Loss = 2.488752841949463\n",
      "[INFO: 2022-02-16 22:42:11,163] Iteration 30420 (DataTime/BatchTime: 0.00155/0.487) losses = 1.8323, lr = [2.5337930379754024e-05, 0.0002533793037975402]\n",
      "[INFO: 2022-02-16 22:42:11,163]   LabelSmoothing Loss = 1.3136221170425415\n",
      "[INFO: 2022-02-16 22:42:20,906] Iteration 30440 (DataTime/BatchTime: 0.00257/0.487) losses = 2.0182, lr = [2.5329605666062257e-05, 0.00025329605666062256]\n",
      "[INFO: 2022-02-16 22:42:20,906]   LabelSmoothing Loss = 2.699820041656494\n",
      "[INFO: 2022-02-16 22:42:30,514] Iteration 30460 (DataTime/BatchTime: 0.00233/0.48) losses = 1.9929, lr = [2.5321289152174213e-05, 0.0002532128915217421]\n",
      "[INFO: 2022-02-16 22:42:30,514]   LabelSmoothing Loss = 1.989396333694458\n",
      "[INFO: 2022-02-16 22:42:40,043] Iteration 30480 (DataTime/BatchTime: 0.00312/0.476) losses = 1.7627, lr = [2.5312980824637445e-05, 0.0002531298082463744]\n",
      "[INFO: 2022-02-16 22:42:40,043]   LabelSmoothing Loss = 2.2709155082702637\n",
      "[INFO: 2022-02-16 22:42:49,756] Iteration 30500 (DataTime/BatchTime: 0.00231/0.486) losses = 1.8721, lr = [2.5304680670030384e-05, 0.0002530468067003038]\n",
      "[INFO: 2022-02-16 22:42:49,756]   LabelSmoothing Loss = 2.3192708492279053\n",
      "[INFO: 2022-02-16 22:42:59,447] Iteration 30520 (DataTime/BatchTime: 0.0017/0.485) losses = 2.0961, lr = [2.5296388674962247e-05, 0.00025296388674962244]\n",
      "[INFO: 2022-02-16 22:42:59,448]   LabelSmoothing Loss = 2.5982823371887207\n",
      "[INFO: 2022-02-16 22:43:09,037] Iteration 30540 (DataTime/BatchTime: 0.00139/0.479) losses = 1.8688, lr = [2.5288104826072948e-05, 0.00025288104826072944]\n",
      "[INFO: 2022-02-16 22:43:09,037]   LabelSmoothing Loss = 1.768336534500122\n",
      "[INFO: 2022-02-16 22:46:50,345] ######## Epoch (VAL)32 ########\n",
      "[INFO: 2022-02-16 22:46:50,345] {'Bleu_1': 0.3603521138745733, 'Bleu_2': 0.22029250548636725, 'Bleu_3': 0.14712427715759957, 'Bleu_4': 0.10362755373312989, 'METEOR': 0.18447386992759363, 'ROUGE_L': 0.3033673529737577, 'CIDEr': 0.3321593691251627}\n",
      "[INFO: 2022-02-16 22:50:29,178] ######## Epoch (TEST)32 ########\n",
      "[INFO: 2022-02-16 22:50:29,178] {'Bleu_1': 0.3511328343575936, 'Bleu_2': 0.21085050551901213, 'Bleu_3': 0.13883854323210815, 'Bleu_4': 0.09628043636295074, 'METEOR': 0.1777352506279958, 'ROUGE_L': 0.298149429779643, 'CIDEr': 0.3199604514987689}\n",
      "[INFO: 2022-02-16 22:50:30,706] Iteration 30560 (DataTime/BatchTime: 0.918/1.53) losses = 2.1414, lr = [2.5279829110033e-05, 0.00025279829110032997]\n",
      "[INFO: 2022-02-16 22:50:30,707]   LabelSmoothing Loss = 2.141404628753662\n",
      "[INFO: 2022-02-16 22:50:40,167] Iteration 30580 (DataTime/BatchTime: 0.00225/0.473) losses = 1.8208, lr = [2.5271561513543445e-05, 0.00025271561513543443]\n",
      "[INFO: 2022-02-16 22:50:40,167]   LabelSmoothing Loss = 1.9063547849655151\n",
      "[INFO: 2022-02-16 22:50:49,665] Iteration 30600 (DataTime/BatchTime: 0.00127/0.475) losses = 1.8718, lr = [2.5263302023335742e-05, 0.0002526330202333574]\n",
      "[INFO: 2022-02-16 22:50:49,665]   LabelSmoothing Loss = 0.651170015335083\n",
      "[INFO: 2022-02-16 22:50:59,267] Iteration 30620 (DataTime/BatchTime: 0.00222/0.48) losses = 1.8094, lr = [2.525505062617168e-05, 0.0002525505062617168]\n",
      "[INFO: 2022-02-16 22:50:59,267]   LabelSmoothing Loss = 1.5854328870773315\n",
      "[INFO: 2022-02-16 22:51:09,016] Iteration 30640 (DataTime/BatchTime: 0.00222/0.487) losses = 1.7599, lr = [2.524680730884331e-05, 0.00025246807308843303]\n",
      "[INFO: 2022-02-16 22:51:09,016]   LabelSmoothing Loss = 2.210223436355591\n",
      "[INFO: 2022-02-16 22:51:18,565] Iteration 30660 (DataTime/BatchTime: 0.00216/0.477) losses = 1.9552, lr = [2.523857205817282e-05, 0.0002523857205817282]\n",
      "[INFO: 2022-02-16 22:51:18,565]   LabelSmoothing Loss = 1.9777065515518188\n",
      "[INFO: 2022-02-16 22:51:28,204] Iteration 30680 (DataTime/BatchTime: 0.00138/0.482) losses = 1.77, lr = [2.5230344861012486e-05, 0.0002523034486101248]\n",
      "[INFO: 2022-02-16 22:51:28,204]   LabelSmoothing Loss = 1.6046351194381714\n",
      "[INFO: 2022-02-16 22:51:37,875] Iteration 30700 (DataTime/BatchTime: 0.00137/0.484) losses = 2.295, lr = [2.522212570424456e-05, 0.0002522212570424456]\n",
      "[INFO: 2022-02-16 22:51:37,875]   LabelSmoothing Loss = 2.617957353591919\n",
      "[INFO: 2022-02-16 22:51:47,453] Iteration 30720 (DataTime/BatchTime: 0.00313/0.479) losses = 1.7512, lr = [2.521391457478119e-05, 0.00025213914574781184]\n",
      "[INFO: 2022-02-16 22:51:47,454]   LabelSmoothing Loss = 2.2776620388031006\n",
      "[INFO: 2022-02-16 22:51:57,042] Iteration 30740 (DataTime/BatchTime: 0.00138/0.479) losses = 1.963, lr = [2.520571145956432e-05, 0.00025205711459564317]\n",
      "[INFO: 2022-02-16 22:51:57,042]   LabelSmoothing Loss = 2.0127899646759033\n",
      "[INFO: 2022-02-16 22:52:06,653] Iteration 30760 (DataTime/BatchTime: 0.00222/0.481) losses = 1.8702, lr = [2.519751634556562e-05, 0.00025197516345565617]\n",
      "[INFO: 2022-02-16 22:52:06,654]   LabelSmoothing Loss = 1.8539447784423828\n",
      "[INFO: 2022-02-16 22:52:16,228] Iteration 30780 (DataTime/BatchTime: 0.0014/0.479) losses = 1.8054, lr = [2.51893292197864e-05, 0.000251893292197864]\n",
      "[INFO: 2022-02-16 22:52:16,229]   LabelSmoothing Loss = 2.0288853645324707\n",
      "[INFO: 2022-02-16 22:52:25,807] Iteration 30800 (DataTime/BatchTime: 0.00137/0.479) losses = 2.0071, lr = [2.5181150069257502e-05, 0.00025181150069257497]\n",
      "[INFO: 2022-02-16 22:52:25,807]   LabelSmoothing Loss = 1.8938508033752441\n",
      "[INFO: 2022-02-16 22:52:35,278] Iteration 30820 (DataTime/BatchTime: 0.00219/0.474) losses = 1.6898, lr = [2.5172978881039234e-05, 0.0002517297888103923]\n",
      "[INFO: 2022-02-16 22:52:35,278]   LabelSmoothing Loss = 2.513556480407715\n",
      "[INFO: 2022-02-16 22:52:44,954] Iteration 30840 (DataTime/BatchTime: 0.00305/0.484) losses = 2.0346, lr = [2.516481564222127e-05, 0.0002516481564222127]\n",
      "[INFO: 2022-02-16 22:52:44,954]   LabelSmoothing Loss = 2.018453598022461\n",
      "[INFO: 2022-02-16 22:52:54,468] Iteration 30860 (DataTime/BatchTime: 0.00136/0.476) losses = 1.8812, lr = [2.5156660339922582e-05, 0.00025156660339922576]\n",
      "[INFO: 2022-02-16 22:52:54,468]   LabelSmoothing Loss = 1.765854001045227\n",
      "[INFO: 2022-02-16 22:53:04,192] Iteration 30880 (DataTime/BatchTime: 0.00144/0.486) losses = 2.0432, lr = [2.5148512961291337e-05, 0.00025148512961291336]\n",
      "[INFO: 2022-02-16 22:53:04,192]   LabelSmoothing Loss = 1.5378872156143188\n",
      "[INFO: 2022-02-16 22:53:13,863] Iteration 30900 (DataTime/BatchTime: 0.00311/0.484) losses = 1.9871, lr = [2.514037349350482e-05, 0.0002514037349350482]\n",
      "[INFO: 2022-02-16 22:53:13,863]   LabelSmoothing Loss = 2.7072157859802246\n",
      "[INFO: 2022-02-16 22:53:23,446] Iteration 30920 (DataTime/BatchTime: 0.00391/0.479) losses = 1.7986, lr = [2.5132241923769354e-05, 0.0002513224192376935]\n",
      "[INFO: 2022-02-16 22:53:23,446]   LabelSmoothing Loss = 1.4953129291534424\n",
      "[INFO: 2022-02-16 22:53:32,956] Iteration 30940 (DataTime/BatchTime: 0.00217/0.476) losses = 1.838, lr = [2.51241182393202e-05, 0.00025124118239320197]\n",
      "[INFO: 2022-02-16 22:53:32,956]   LabelSmoothing Loss = 2.044233560562134\n",
      "[INFO: 2022-02-16 22:53:42,563] Iteration 30960 (DataTime/BatchTime: 0.00225/0.48) losses = 1.8854, lr = [2.511600242742149e-05, 0.00025116002427421485]\n",
      "[INFO: 2022-02-16 22:53:42,563]   LabelSmoothing Loss = 2.2242701053619385\n",
      "[INFO: 2022-02-16 22:53:52,133] Iteration 30980 (DataTime/BatchTime: 0.00136/0.478) losses = 1.5797, lr = [2.5107894475366133e-05, 0.0002510789447536613]\n",
      "[INFO: 2022-02-16 22:53:52,133]   LabelSmoothing Loss = 1.4401968717575073\n",
      "[INFO: 2022-02-16 22:54:01,849] Iteration 31000 (DataTime/BatchTime: 0.00343/0.486) losses = 1.9657, lr = [2.5099794370475735e-05, 0.00025099794370475733]\n",
      "[INFO: 2022-02-16 22:54:01,849]   LabelSmoothing Loss = 1.977169394493103\n",
      "[INFO: 2022-02-16 22:54:11,519] Iteration 31020 (DataTime/BatchTime: 0.00228/0.484) losses = 1.9471, lr = [2.5091702100100512e-05, 0.0002509170210010051]\n",
      "[INFO: 2022-02-16 22:54:11,519]   LabelSmoothing Loss = 1.9755316972732544\n",
      "[INFO: 2022-02-16 22:54:21,150] Iteration 31040 (DataTime/BatchTime: 0.00326/0.482) losses = 1.9639, lr = [2.5083617651619215e-05, 0.0002508361765161921]\n",
      "[INFO: 2022-02-16 22:54:21,150]   LabelSmoothing Loss = 1.9854488372802734\n",
      "[INFO: 2022-02-16 22:54:30,752] Iteration 31060 (DataTime/BatchTime: 0.00332/0.48) losses = 1.9971, lr = [2.507554101243904e-05, 0.00025075541012439036]\n",
      "[INFO: 2022-02-16 22:54:30,752]   LabelSmoothing Loss = 2.1994364261627197\n",
      "[INFO: 2022-02-16 22:54:40,439] Iteration 31080 (DataTime/BatchTime: 0.0015/0.484) losses = 1.9335, lr = [2.506747216999555e-05, 0.00025067472169995543]\n",
      "[INFO: 2022-02-16 22:54:40,439]   LabelSmoothing Loss = 1.9492998123168945\n",
      "[INFO: 2022-02-16 22:54:50,025] Iteration 31100 (DataTime/BatchTime: 0.0023/0.479) losses = 2.0037, lr = [2.505941111175258e-05, 0.0002505941111175258]\n",
      "[INFO: 2022-02-16 22:54:50,025]   LabelSmoothing Loss = 1.6658446788787842\n",
      "[INFO: 2022-02-16 22:54:59,566] Iteration 31120 (DataTime/BatchTime: 0.00153/0.477) losses = 1.7396, lr = [2.5051357825202182e-05, 0.0002505135782520218]\n",
      "[INFO: 2022-02-16 22:54:59,566]   LabelSmoothing Loss = 1.670259952545166\n",
      "[INFO: 2022-02-16 22:55:09,164] Iteration 31140 (DataTime/BatchTime: 0.00138/0.48) losses = 2.1575, lr = [2.5043312297864517e-05, 0.00025043312297864516]\n",
      "[INFO: 2022-02-16 22:55:09,164]   LabelSmoothing Loss = 2.1894543170928955\n",
      "[INFO: 2022-02-16 22:55:18,795] Iteration 31160 (DataTime/BatchTime: 0.00218/0.482) losses = 2.0545, lr = [2.503527451728779e-05, 0.0002503527451728779]\n",
      "[INFO: 2022-02-16 22:55:18,795]   LabelSmoothing Loss = 1.4848217964172363\n",
      "[INFO: 2022-02-16 22:55:28,367] Iteration 31180 (DataTime/BatchTime: 0.00136/0.479) losses = 1.7938, lr = [2.502724447104816e-05, 0.00025027244471048155]\n",
      "[INFO: 2022-02-16 22:55:28,367]   LabelSmoothing Loss = 2.316659927368164\n",
      "[INFO: 2022-02-16 22:55:37,974] Iteration 31200 (DataTime/BatchTime: 0.00145/0.48) losses = 1.9357, lr = [2.5019222146749657e-05, 0.00025019222146749657]\n",
      "[INFO: 2022-02-16 22:55:37,974]   LabelSmoothing Loss = 1.711652398109436\n",
      "[INFO: 2022-02-16 22:55:47,556] Iteration 31220 (DataTime/BatchTime: 0.00231/0.479) losses = 1.9584, lr = [2.5011207532024126e-05, 0.00025011207532024123]\n",
      "[INFO: 2022-02-16 22:55:47,556]   LabelSmoothing Loss = 3.2896487712860107\n",
      "[INFO: 2022-02-16 22:55:57,138] Iteration 31240 (DataTime/BatchTime: 0.00129/0.479) losses = 2.0347, lr = [2.5003200614531105e-05, 0.000250032006145311]\n",
      "[INFO: 2022-02-16 22:55:57,139]   LabelSmoothing Loss = 1.9093971252441406\n",
      "[INFO: 2022-02-16 22:56:06,765] Iteration 31260 (DataTime/BatchTime: 0.00231/0.481) losses = 1.6311, lr = [2.4995201381957785e-05, 0.0002499520138195778]\n",
      "[INFO: 2022-02-16 22:56:06,765]   LabelSmoothing Loss = 0.8020809888839722\n",
      "[INFO: 2022-02-16 22:56:16,455] Iteration 31280 (DataTime/BatchTime: 0.00256/0.485) losses = 2.0249, lr = [2.4987209822018904e-05, 0.00024987209822018903]\n",
      "[INFO: 2022-02-16 22:56:16,456]   LabelSmoothing Loss = 0.9464088082313538\n",
      "[INFO: 2022-02-16 22:56:25,959] Iteration 31300 (DataTime/BatchTime: 0.0013/0.475) losses = 1.7281, lr = [2.497922592245669e-05, 0.00024979225922456687]\n",
      "[INFO: 2022-02-16 22:56:25,960]   LabelSmoothing Loss = 2.412257671356201\n",
      "[INFO: 2022-02-16 22:56:35,567] Iteration 31320 (DataTime/BatchTime: 0.0013/0.48) losses = 1.9634, lr = [2.497124967104075e-05, 0.0002497124967104075]\n",
      "[INFO: 2022-02-16 22:56:35,567]   LabelSmoothing Loss = 1.9401776790618896\n",
      "[INFO: 2022-02-16 22:56:45,169] Iteration 31340 (DataTime/BatchTime: 0.00196/0.48) losses = 1.8628, lr = [2.4963281055568028e-05, 0.00024963281055568026]\n",
      "[INFO: 2022-02-16 22:56:45,170]   LabelSmoothing Loss = 1.2840088605880737\n",
      "[INFO: 2022-02-16 22:56:54,798] Iteration 31360 (DataTime/BatchTime: 0.00127/0.481) losses = 2.0991, lr = [2.495532006386271e-05, 0.00024955320063862704]\n",
      "[INFO: 2022-02-16 22:56:54,798]   LabelSmoothing Loss = 2.2667853832244873\n",
      "[INFO: 2022-02-16 22:57:04,392] Iteration 31380 (DataTime/BatchTime: 0.00215/0.48) losses = 1.8713, lr = [2.494736668377613e-05, 0.0002494736668377613]\n",
      "[INFO: 2022-02-16 22:57:04,392]   LabelSmoothing Loss = 2.1784486770629883\n",
      "[INFO: 2022-02-16 22:57:13,946] Iteration 31400 (DataTime/BatchTime: 0.00131/0.478) losses = 1.7513, lr = [2.493942090318672e-05, 0.0002493942090318672]\n",
      "[INFO: 2022-02-16 22:57:13,946]   LabelSmoothing Loss = 1.0842746496200562\n",
      "[INFO: 2022-02-16 22:57:23,619] Iteration 31420 (DataTime/BatchTime: 0.0021/0.484) losses = 2.0209, lr = [2.4931482709999924e-05, 0.0002493148270999992]\n",
      "[INFO: 2022-02-16 22:57:23,619]   LabelSmoothing Loss = 2.652066707611084\n",
      "[INFO: 2022-02-16 22:57:33,190] Iteration 31440 (DataTime/BatchTime: 0.00128/0.479) losses = 1.787, lr = [2.4923552092148103e-05, 0.00024923552092148097]\n",
      "[INFO: 2022-02-16 22:57:33,191]   LabelSmoothing Loss = 2.419574737548828\n",
      "[INFO: 2022-02-16 22:57:42,741] Iteration 31460 (DataTime/BatchTime: 0.00126/0.478) losses = 1.7895, lr = [2.4915629037590474e-05, 0.00024915629037590474]\n",
      "[INFO: 2022-02-16 22:57:42,742]   LabelSmoothing Loss = 1.9151595830917358\n",
      "[INFO: 2022-02-16 22:57:52,285] Iteration 31480 (DataTime/BatchTime: 0.00188/0.477) losses = 1.779, lr = [2.4907713534313046e-05, 0.0002490771353431304]\n",
      "[INFO: 2022-02-16 22:57:52,285]   LabelSmoothing Loss = 2.542276620864868\n",
      "[INFO: 2022-02-16 22:58:01,933] Iteration 31500 (DataTime/BatchTime: 0.00128/0.482) losses = 2.0183, lr = [2.4899805570328512e-05, 0.0002489980557032851]\n",
      "[INFO: 2022-02-16 22:58:01,933]   LabelSmoothing Loss = 1.8400663137435913\n",
      "[INFO: 2022-02-16 23:01:41,655] ######## Epoch (VAL)33 ########\n",
      "[INFO: 2022-02-16 23:01:41,655] {'Bleu_1': 0.32407337905949274, 'Bleu_2': 0.19196299605686568, 'Bleu_3': 0.12173031605103878, 'Bleu_4': 0.08041140317604857, 'METEOR': 0.1702845919114169, 'ROUGE_L': 0.2876862565109423, 'CIDEr': 0.33616412716923766}\n",
      "[INFO: 2022-02-16 23:05:23,245] ######## Epoch (TEST)33 ########\n",
      "[INFO: 2022-02-16 23:05:23,245] {'Bleu_1': 0.29917338186352443, 'Bleu_2': 0.1676351759637163, 'Bleu_3': 0.10235385850668723, 'Bleu_4': 0.06507350417751276, 'METEOR': 0.15976680055497194, 'ROUGE_L': 0.2690807149391147, 'CIDEr': 0.24077417205127943}\n",
      "[INFO: 2022-02-16 23:05:27,304] Iteration 31520 (DataTime/BatchTime: 0.187/0.676) losses = 1.4829, lr = [2.4891905133676194e-05, 0.0002489190513367619]\n",
      "[INFO: 2022-02-16 23:05:27,304]   LabelSmoothing Loss = 0.6075530648231506\n",
      "[INFO: 2022-02-16 23:05:36,857] Iteration 31540 (DataTime/BatchTime: 0.00491/0.478) losses = 1.9642, lr = [2.4884012212421965e-05, 0.0002488401221242196]\n",
      "[INFO: 2022-02-16 23:05:36,857]   LabelSmoothing Loss = 1.0355052947998047\n",
      "[INFO: 2022-02-16 23:05:46,424] Iteration 31560 (DataTime/BatchTime: 0.00239/0.478) losses = 2.1431, lr = [2.4876126794658168e-05, 0.00024876126794658166]\n",
      "[INFO: 2022-02-16 23:05:46,424]   LabelSmoothing Loss = 1.1170746088027954\n",
      "[INFO: 2022-02-16 23:05:56,042] Iteration 31580 (DataTime/BatchTime: 0.00246/0.481) losses = 1.8691, lr = [2.486824886850354e-05, 0.0002486824886850354]\n",
      "[INFO: 2022-02-16 23:05:56,043]   LabelSmoothing Loss = 1.06175696849823\n",
      "[INFO: 2022-02-16 23:06:05,712] Iteration 31600 (DataTime/BatchTime: 0.00317/0.483) losses = 2.0234, lr = [2.4860378422103148e-05, 0.00024860378422103145]\n",
      "[INFO: 2022-02-16 23:06:05,712]   LabelSmoothing Loss = 2.1713788509368896\n",
      "[INFO: 2022-02-16 23:06:15,443] Iteration 31620 (DataTime/BatchTime: 0.0015/0.487) losses = 1.7414, lr = [2.4852515443628296e-05, 0.0002485251544362829]\n",
      "[INFO: 2022-02-16 23:06:15,443]   LabelSmoothing Loss = 1.858274221420288\n",
      "[INFO: 2022-02-16 23:06:25,019] Iteration 31640 (DataTime/BatchTime: 0.00317/0.479) losses = 1.7536, lr = [2.4844659921276467e-05, 0.0002484465992127646]\n",
      "[INFO: 2022-02-16 23:06:25,019]   LabelSmoothing Loss = 1.703575611114502\n",
      "[INFO: 2022-02-16 23:06:34,641] Iteration 31660 (DataTime/BatchTime: 0.00343/0.481) losses = 1.7467, lr = [2.483681184327124e-05, 0.00024836811843271237]\n",
      "[INFO: 2022-02-16 23:06:34,641]   LabelSmoothing Loss = 1.3801085948944092\n",
      "[INFO: 2022-02-16 23:06:44,293] Iteration 31680 (DataTime/BatchTime: 0.0015/0.483) losses = 2.0801, lr = [2.4828971197862217e-05, 0.0002482897119786221]\n",
      "[INFO: 2022-02-16 23:06:44,293]   LabelSmoothing Loss = 2.2526233196258545\n",
      "[INFO: 2022-02-16 23:06:53,920] Iteration 31700 (DataTime/BatchTime: 0.00428/0.481) losses = 1.7137, lr = [2.4821137973324946e-05, 0.00024821137973324943]\n",
      "[INFO: 2022-02-16 23:06:53,920]   LabelSmoothing Loss = 2.036508798599243\n",
      "[INFO: 2022-02-16 23:07:03,504] Iteration 31720 (DataTime/BatchTime: 0.00362/0.479) losses = 1.8169, lr = [2.481331215796086e-05, 0.00024813312157960857]\n",
      "[INFO: 2022-02-16 23:07:03,504]   LabelSmoothing Loss = 1.5056217908859253\n",
      "[INFO: 2022-02-16 23:07:13,257] Iteration 31740 (DataTime/BatchTime: 0.00362/0.488) losses = 1.91, lr = [2.4805493740097188e-05, 0.0002480549374009719]\n",
      "[INFO: 2022-02-16 23:07:13,257]   LabelSmoothing Loss = 2.1934688091278076\n",
      "[INFO: 2022-02-16 23:07:22,761] Iteration 31760 (DataTime/BatchTime: 0.00113/0.475) losses = 2.0206, lr = [2.479768270808689e-05, 0.0002479768270808689]\n",
      "[INFO: 2022-02-16 23:07:22,761]   LabelSmoothing Loss = 2.427396297454834\n",
      "[INFO: 2022-02-16 23:07:32,355] Iteration 31780 (DataTime/BatchTime: 0.00238/0.48) losses = 1.6568, lr = [2.4789879050308587e-05, 0.00024789879050308587]\n",
      "[INFO: 2022-02-16 23:07:32,355]   LabelSmoothing Loss = 0.4976238012313843\n",
      "[INFO: 2022-02-16 23:07:41,930] Iteration 31800 (DataTime/BatchTime: 0.0024/0.479) losses = 2.0585, lr = [2.4782082755166476e-05, 0.0002478208275516647]\n",
      "[INFO: 2022-02-16 23:07:41,930]   LabelSmoothing Loss = 2.5359365940093994\n",
      "[INFO: 2022-02-16 23:07:51,617] Iteration 31820 (DataTime/BatchTime: 0.00173/0.484) losses = 1.8204, lr = [2.4774293811090265e-05, 0.0002477429381109026]\n",
      "[INFO: 2022-02-16 23:07:51,618]   LabelSmoothing Loss = 2.636298656463623\n",
      "[INFO: 2022-02-16 23:08:01,252] Iteration 31840 (DataTime/BatchTime: 0.00214/0.482) losses = 1.8543, lr = [2.476651220653511e-05, 0.0002476651220653511]\n",
      "[INFO: 2022-02-16 23:08:01,252]   LabelSmoothing Loss = 0.8222445249557495\n",
      "[INFO: 2022-02-16 23:08:10,881] Iteration 31860 (DataTime/BatchTime: 0.00157/0.481) losses = 1.7655, lr = [2.4758737929981537e-05, 0.00024758737929981537]\n",
      "[INFO: 2022-02-16 23:08:10,881]   LabelSmoothing Loss = 2.699491024017334\n",
      "[INFO: 2022-02-16 23:08:20,558] Iteration 31880 (DataTime/BatchTime: 0.00309/0.484) losses = 1.9192, lr = [2.4750970969935356e-05, 0.0002475097096993535]\n",
      "[INFO: 2022-02-16 23:08:20,558]   LabelSmoothing Loss = 2.035228729248047\n",
      "[INFO: 2022-02-16 23:08:30,294] Iteration 31900 (DataTime/BatchTime: 0.00205/0.486) losses = 1.8904, lr = [2.474321131492761e-05, 0.0002474321131492761]\n",
      "[INFO: 2022-02-16 23:08:30,294]   LabelSmoothing Loss = 2.2633814811706543\n",
      "[INFO: 2022-02-16 23:08:39,973] Iteration 31920 (DataTime/BatchTime: 0.00229/0.485) losses = 1.8801, lr = [2.4735458953514488e-05, 0.00024735458953514485]\n",
      "[INFO: 2022-02-16 23:08:39,973]   LabelSmoothing Loss = 1.0065284967422485\n",
      "[INFO: 2022-02-16 23:08:49,572] Iteration 31940 (DataTime/BatchTime: 0.00272/0.48) losses = 1.8986, lr = [2.4727713874277277e-05, 0.00024727713874277276]\n",
      "[INFO: 2022-02-16 23:08:49,572]   LabelSmoothing Loss = 2.404547929763794\n",
      "[INFO: 2022-02-16 23:08:59,090] Iteration 31960 (DataTime/BatchTime: 0.00297/0.476) losses = 1.771, lr = [2.4719976065822258e-05, 0.00024719976065822253]\n",
      "[INFO: 2022-02-16 23:08:59,090]   LabelSmoothing Loss = 2.160907745361328\n",
      "[INFO: 2022-02-16 23:09:08,614] Iteration 31980 (DataTime/BatchTime: 0.00188/0.476) losses = 1.9233, lr = [2.471224551678067e-05, 0.00024712245516780667]\n",
      "[INFO: 2022-02-16 23:09:08,614]   LabelSmoothing Loss = 1.7144474983215332\n",
      "[INFO: 2022-02-16 23:09:18,103] Iteration 32000 (DataTime/BatchTime: 0.00193/0.474) losses = 1.6865, lr = [2.4704522215808603e-05, 0.00024704522215808597]\n",
      "[INFO: 2022-02-16 23:09:18,103]   LabelSmoothing Loss = 1.464415192604065\n",
      "[INFO: 2022-02-16 23:09:27,575] Iteration 32020 (DataTime/BatchTime: 0.00107/0.473) losses = 1.929, lr = [2.4696806151586968e-05, 0.0002469680615158697]\n",
      "[INFO: 2022-02-16 23:09:27,576]   LabelSmoothing Loss = 2.822864532470703\n",
      "[INFO: 2022-02-16 23:09:37,043] Iteration 32040 (DataTime/BatchTime: 0.00188/0.474) losses = 1.9098, lr = [2.4689097312821406e-05, 0.000246890973128214]\n",
      "[INFO: 2022-02-16 23:09:37,043]   LabelSmoothing Loss = 1.5506411790847778\n",
      "[INFO: 2022-02-16 23:09:46,585] Iteration 32060 (DataTime/BatchTime: 0.00122/0.477) losses = 1.8865, lr = [2.4681395688242205e-05, 0.000246813956882422]\n",
      "[INFO: 2022-02-16 23:09:46,586]   LabelSmoothing Loss = 2.7846732139587402\n",
      "[INFO: 2022-02-16 23:09:56,078] Iteration 32080 (DataTime/BatchTime: 0.00208/0.475) losses = 1.774, lr = [2.467370126660427e-05, 0.00024673701266604266]\n",
      "[INFO: 2022-02-16 23:09:56,078]   LabelSmoothing Loss = 1.6721611022949219\n",
      "[INFO: 2022-02-16 23:10:05,606] Iteration 32100 (DataTime/BatchTime: 0.0012/0.476) losses = 1.8889, lr = [2.4666014036687e-05, 0.00024666014036687]\n",
      "[INFO: 2022-02-16 23:10:05,606]   LabelSmoothing Loss = 1.903733730316162\n",
      "[INFO: 2022-02-16 23:10:15,098] Iteration 32120 (DataTime/BatchTime: 0.00116/0.475) losses = 1.7811, lr = [2.4658333987294283e-05, 0.0002465833398729428]\n",
      "[INFO: 2022-02-16 23:10:15,098]   LabelSmoothing Loss = 1.7702996730804443\n",
      "[INFO: 2022-02-16 23:10:24,655] Iteration 32140 (DataTime/BatchTime: 0.00222/0.478) losses = 1.8071, lr = [2.465066110725437e-05, 0.00024650661107254365]\n",
      "[INFO: 2022-02-16 23:10:24,655]   LabelSmoothing Loss = 2.149928092956543\n",
      "[INFO: 2022-02-16 23:10:34,244] Iteration 32160 (DataTime/BatchTime: 0.00112/0.479) losses = 1.9756, lr = [2.4642995385419833e-05, 0.0002464299538541983]\n",
      "[INFO: 2022-02-16 23:10:34,244]   LabelSmoothing Loss = 2.3028407096862793\n",
      "[INFO: 2022-02-16 23:10:44,118] Iteration 32180 (DataTime/BatchTime: 0.00126/0.494) losses = 2.2123, lr = [2.463533681066751e-05, 0.0002463533681066751]\n",
      "[INFO: 2022-02-16 23:10:44,118]   LabelSmoothing Loss = 3.363968849182129\n",
      "[INFO: 2022-02-16 23:10:53,586] Iteration 32200 (DataTime/BatchTime: 0.00113/0.473) losses = 1.5555, lr = [2.462768537189841e-05, 0.0002462768537189841]\n",
      "[INFO: 2022-02-16 23:10:53,586]   LabelSmoothing Loss = 1.7264554500579834\n",
      "[INFO: 2022-02-16 23:11:03,227] Iteration 32220 (DataTime/BatchTime: 0.00216/0.482) losses = 1.8658, lr = [2.462004105803766e-05, 0.0002462004105803766]\n",
      "[INFO: 2022-02-16 23:11:03,227]   LabelSmoothing Loss = 3.3113348484039307\n",
      "[INFO: 2022-02-16 23:11:12,702] Iteration 32240 (DataTime/BatchTime: 0.00214/0.474) losses = 1.9208, lr = [2.4612403858034435e-05, 0.00024612403858034434]\n",
      "[INFO: 2022-02-16 23:11:12,703]   LabelSmoothing Loss = 2.2026240825653076\n",
      "[INFO: 2022-02-16 23:11:22,212] Iteration 32260 (DataTime/BatchTime: 0.00119/0.475) losses = 1.9168, lr = [2.460477376086189e-05, 0.0002460477376086189]\n",
      "[INFO: 2022-02-16 23:11:22,212]   LabelSmoothing Loss = 1.229234218597412\n",
      "[INFO: 2022-02-16 23:11:31,713] Iteration 32280 (DataTime/BatchTime: 0.00198/0.475) losses = 1.9811, lr = [2.4597150755517097e-05, 0.00024597150755517095]\n",
      "[INFO: 2022-02-16 23:11:31,714]   LabelSmoothing Loss = 2.846046209335327\n",
      "[INFO: 2022-02-16 23:11:41,281] Iteration 32300 (DataTime/BatchTime: 0.00105/0.478) losses = 2.2086, lr = [2.4589534831020974e-05, 0.0002458953483102097]\n",
      "[INFO: 2022-02-16 23:11:41,281]   LabelSmoothing Loss = 2.050690174102783\n",
      "[INFO: 2022-02-16 23:11:50,898] Iteration 32320 (DataTime/BatchTime: 0.00107/0.481) losses = 1.9365, lr = [2.4581925976418217e-05, 0.00024581925976418216]\n",
      "[INFO: 2022-02-16 23:11:50,898]   LabelSmoothing Loss = 1.1939951181411743\n",
      "[INFO: 2022-02-16 23:12:00,388] Iteration 32340 (DataTime/BatchTime: 0.00265/0.474) losses = 1.8753, lr = [2.4574324180777246e-05, 0.0002457432418077724]\n",
      "[INFO: 2022-02-16 23:12:00,388]   LabelSmoothing Loss = 2.562551736831665\n",
      "[INFO: 2022-02-16 23:12:09,901] Iteration 32360 (DataTime/BatchTime: 0.00126/0.476) losses = 1.9016, lr = [2.456672943319012e-05, 0.00024566729433190117]\n",
      "[INFO: 2022-02-16 23:12:09,901]   LabelSmoothing Loss = 1.5308666229248047\n",
      "[INFO: 2022-02-16 23:12:19,443] Iteration 32380 (DataTime/BatchTime: 0.00131/0.477) losses = 1.928, lr = [2.455914172277249e-05, 0.0002455914172277249]\n",
      "[INFO: 2022-02-16 23:12:19,443]   LabelSmoothing Loss = 2.4133412837982178\n",
      "[INFO: 2022-02-16 23:12:28,940] Iteration 32400 (DataTime/BatchTime: 0.00318/0.475) losses = 1.838, lr = [2.4551561038663517e-05, 0.00024551561038663514]\n",
      "[INFO: 2022-02-16 23:12:28,940]   LabelSmoothing Loss = 1.712790608406067\n",
      "[INFO: 2022-02-16 23:12:38,566] Iteration 32420 (DataTime/BatchTime: 0.00136/0.481) losses = 1.873, lr = [2.4543987370025813e-05, 0.0002454398737002581]\n",
      "[INFO: 2022-02-16 23:12:38,566]   LabelSmoothing Loss = 1.7100237607955933\n",
      "[INFO: 2022-02-16 23:12:48,109] Iteration 32440 (DataTime/BatchTime: 0.00215/0.477) losses = 1.9768, lr = [2.4536420706045393e-05, 0.0002453642070604539]\n",
      "[INFO: 2022-02-16 23:12:48,109]   LabelSmoothing Loss = 1.784704327583313\n",
      "[INFO: 2022-02-16 23:12:57,656] Iteration 32460 (DataTime/BatchTime: 0.0034/0.477) losses = 1.9619, lr = [2.4528861035931576e-05, 0.00024528861035931574]\n",
      "[INFO: 2022-02-16 23:12:57,657]   LabelSmoothing Loss = 1.970608115196228\n",
      "[INFO: 2022-02-16 23:16:35,479] ######## Epoch (VAL)34 ########\n",
      "[INFO: 2022-02-16 23:16:35,480] {'Bleu_1': 0.3533046658931689, 'Bleu_2': 0.21614410494666006, 'Bleu_3': 0.14257177896937917, 'Bleu_4': 0.09953245215051396, 'METEOR': 0.1812740487030281, 'ROUGE_L': 0.2954585861673202, 'CIDEr': 0.313575026138529}\n",
      "[INFO: 2022-02-16 23:20:15,205] ######## Epoch (TEST)34 ########\n",
      "[INFO: 2022-02-16 23:20:15,206] {'Bleu_1': 0.3429567166446224, 'Bleu_2': 0.20412367395584977, 'Bleu_3': 0.1326137365611655, 'Bleu_4': 0.091402864624463, 'METEOR': 0.17519177570946867, 'ROUGE_L': 0.2911019572337083, 'CIDEr': 0.3005798090851597}\n",
      "[INFO: 2022-02-16 23:20:21,743] Iteration 32480 (DataTime/BatchTime: 0.0997/0.594) losses = 1.9777, lr = [2.4521308348916944e-05, 0.0002452130834891694]\n",
      "[INFO: 2022-02-16 23:20:21,743]   LabelSmoothing Loss = 1.7726185321807861\n",
      "[INFO: 2022-02-16 23:20:31,290] Iteration 32500 (DataTime/BatchTime: 0.0023/0.477) losses = 1.7909, lr = [2.4513762634257283e-05, 0.0002451376263425728]\n",
      "[INFO: 2022-02-16 23:20:31,290]   LabelSmoothing Loss = 2.07902455329895\n",
      "[INFO: 2022-02-16 23:20:40,845] Iteration 32520 (DataTime/BatchTime: 0.002/0.478) losses = 1.9936, lr = [2.45062238812315e-05, 0.00024506223881231497]\n",
      "[INFO: 2022-02-16 23:20:40,846]   LabelSmoothing Loss = 1.3034825325012207\n",
      "[INFO: 2022-02-16 23:20:50,496] Iteration 32540 (DataTime/BatchTime: 0.00186/0.483) losses = 1.7032, lr = [2.449869207914156e-05, 0.00024498692079141554]\n",
      "[INFO: 2022-02-16 23:20:50,496]   LabelSmoothing Loss = 1.7516404390335083\n",
      "[INFO: 2022-02-16 23:21:00,047] Iteration 32560 (DataTime/BatchTime: 0.00112/0.478) losses = 1.882, lr = [2.4491167217312445e-05, 0.00024491167217312445]\n",
      "[INFO: 2022-02-16 23:21:00,047]   LabelSmoothing Loss = 1.4980350732803345\n",
      "[INFO: 2022-02-16 23:21:09,580] Iteration 32580 (DataTime/BatchTime: 0.00113/0.477) losses = 1.6537, lr = [2.448364928509206e-05, 0.00024483649285092057]\n",
      "[INFO: 2022-02-16 23:21:09,580]   LabelSmoothing Loss = 1.6558321714401245\n",
      "[INFO: 2022-02-16 23:21:19,159] Iteration 32600 (DataTime/BatchTime: 0.00129/0.479) losses = 1.8923, lr = [2.4476138271851204e-05, 0.000244761382718512]\n",
      "[INFO: 2022-02-16 23:21:19,159]   LabelSmoothing Loss = 1.4759076833724976\n",
      "[INFO: 2022-02-16 23:21:28,817] Iteration 32620 (DataTime/BatchTime: 0.00217/0.483) losses = 1.8057, lr = [2.4468634166983463e-05, 0.0002446863416698346]\n",
      "[INFO: 2022-02-16 23:21:28,817]   LabelSmoothing Loss = 1.8787857294082642\n",
      "[INFO: 2022-02-16 23:21:38,422] Iteration 32640 (DataTime/BatchTime: 0.00118/0.48) losses = 2.0436, lr = [2.446113695990519e-05, 0.0002446113695990519]\n",
      "[INFO: 2022-02-16 23:21:38,422]   LabelSmoothing Loss = 1.3620402812957764\n",
      "[INFO: 2022-02-16 23:21:48,018] Iteration 32660 (DataTime/BatchTime: 0.00121/0.48) losses = 1.9324, lr = [2.4453646640055417e-05, 0.00024453646640055414]\n",
      "[INFO: 2022-02-16 23:21:48,018]   LabelSmoothing Loss = 1.7239580154418945\n",
      "[INFO: 2022-02-16 23:21:57,636] Iteration 32680 (DataTime/BatchTime: 0.00369/0.481) losses = 1.9224, lr = [2.4446163196895802e-05, 0.000244461631968958]\n",
      "[INFO: 2022-02-16 23:21:57,636]   LabelSmoothing Loss = 2.505420684814453\n",
      "[INFO: 2022-02-16 23:22:07,297] Iteration 32700 (DataTime/BatchTime: 0.00202/0.483) losses = 1.95, lr = [2.443868661991056e-05, 0.0002443868661991056]\n",
      "[INFO: 2022-02-16 23:22:07,297]   LabelSmoothing Loss = 2.0337347984313965\n",
      "[INFO: 2022-02-16 23:22:16,905] Iteration 32720 (DataTime/BatchTime: 0.00203/0.48) losses = 1.8617, lr = [2.4431216898606416e-05, 0.00024431216898606413]\n",
      "[INFO: 2022-02-16 23:22:16,905]   LabelSmoothing Loss = 2.5304057598114014\n",
      "[INFO: 2022-02-16 23:22:26,540] Iteration 32740 (DataTime/BatchTime: 0.0012/0.482) losses = 1.7683, lr = [2.4423754022512512e-05, 0.0002442375402251251]\n",
      "[INFO: 2022-02-16 23:22:26,540]   LabelSmoothing Loss = 1.9611908197402954\n",
      "[INFO: 2022-02-16 23:22:36,109] Iteration 32760 (DataTime/BatchTime: 0.00122/0.478) losses = 1.8298, lr = [2.4416297981180388e-05, 0.0002441629798118038]\n",
      "[INFO: 2022-02-16 23:22:36,109]   LabelSmoothing Loss = 1.6733875274658203\n",
      "[INFO: 2022-02-16 23:22:45,683] Iteration 32780 (DataTime/BatchTime: 0.00298/0.479) losses = 1.9521, lr = [2.4408848764183886e-05, 0.00024408848764183883]\n",
      "[INFO: 2022-02-16 23:22:45,683]   LabelSmoothing Loss = 2.4561994075775146\n",
      "[INFO: 2022-02-16 23:22:55,251] Iteration 32800 (DataTime/BatchTime: 0.00123/0.478) losses = 1.8719, lr = [2.44014063611191e-05, 0.00024401406361119097]\n",
      "[INFO: 2022-02-16 23:22:55,251]   LabelSmoothing Loss = 1.3803138732910156\n",
      "[INFO: 2022-02-16 23:23:04,861] Iteration 32820 (DataTime/BatchTime: 0.0012/0.48) losses = 1.9076, lr = [2.439397076160432e-05, 0.00024393970761604316]\n",
      "[INFO: 2022-02-16 23:23:04,861]   LabelSmoothing Loss = 2.0249781608581543\n",
      "[INFO: 2022-02-16 23:23:14,532] Iteration 32840 (DataTime/BatchTime: 0.00148/0.484) losses = 1.8237, lr = [2.438654195527997e-05, 0.00024386541955279966]\n",
      "[INFO: 2022-02-16 23:23:14,532]   LabelSmoothing Loss = 1.567394733428955\n",
      "[INFO: 2022-02-16 23:23:24,068] Iteration 32860 (DataTime/BatchTime: 0.00123/0.477) losses = 1.6519, lr = [2.4379119931808535e-05, 0.00024379119931808532]\n",
      "[INFO: 2022-02-16 23:23:24,068]   LabelSmoothing Loss = 1.9898995161056519\n",
      "[INFO: 2022-02-16 23:23:33,669] Iteration 32880 (DataTime/BatchTime: 0.00127/0.48) losses = 1.6986, lr = [2.4371704680874523e-05, 0.0002437170468087452]\n",
      "[INFO: 2022-02-16 23:23:33,669]   LabelSmoothing Loss = 1.9324039220809937\n",
      "[INFO: 2022-02-16 23:23:43,298] Iteration 32900 (DataTime/BatchTime: 0.00223/0.481) losses = 2.0156, lr = [2.4364296192184378e-05, 0.00024364296192184374]\n",
      "[INFO: 2022-02-16 23:23:43,299]   LabelSmoothing Loss = 2.368905782699585\n",
      "[INFO: 2022-02-16 23:23:52,902] Iteration 32920 (DataTime/BatchTime: 0.00128/0.48) losses = 2.0547, lr = [2.4356894455466445e-05, 0.0002435689445546644]\n",
      "[INFO: 2022-02-16 23:23:52,902]   LabelSmoothing Loss = 2.444009780883789\n",
      "[INFO: 2022-02-16 23:24:02,466] Iteration 32940 (DataTime/BatchTime: 0.00329/0.478) losses = 1.9027, lr = [2.4349499460470893e-05, 0.00024349499460470892]\n",
      "[INFO: 2022-02-16 23:24:02,466]   LabelSmoothing Loss = 2.077899217605591\n",
      "[INFO: 2022-02-16 23:24:12,017] Iteration 32960 (DataTime/BatchTime: 0.00314/0.478) losses = 1.813, lr = [2.4342111196969664e-05, 0.0002434211119696966]\n",
      "[INFO: 2022-02-16 23:24:12,017]   LabelSmoothing Loss = 1.1177483797073364\n",
      "[INFO: 2022-02-16 23:24:21,714] Iteration 32980 (DataTime/BatchTime: 0.00144/0.485) losses = 1.765, lr = [2.4334729654756406e-05, 0.00024334729654756402]\n",
      "[INFO: 2022-02-16 23:24:21,714]   LabelSmoothing Loss = 1.2620010375976562\n",
      "[INFO: 2022-02-16 23:24:31,305] Iteration 33000 (DataTime/BatchTime: 0.00136/0.48) losses = 2.0755, lr = [2.432735482364643e-05, 0.00024327354823646427]\n",
      "[INFO: 2022-02-16 23:24:31,305]   LabelSmoothing Loss = 1.488228678703308\n",
      "[INFO: 2022-02-16 23:24:40,968] Iteration 33020 (DataTime/BatchTime: 0.00141/0.483) losses = 2.0385, lr = [2.4319986693476627e-05, 0.00024319986693476626]\n",
      "[INFO: 2022-02-16 23:24:40,968]   LabelSmoothing Loss = 1.24431312084198\n",
      "[INFO: 2022-02-16 23:24:50,615] Iteration 33040 (DataTime/BatchTime: 0.00151/0.482) losses = 1.847, lr = [2.4312625254105432e-05, 0.0002431262525410543]\n",
      "[INFO: 2022-02-16 23:24:50,615]   LabelSmoothing Loss = 2.395508289337158\n",
      "[INFO: 2022-02-16 23:25:00,188] Iteration 33060 (DataTime/BatchTime: 0.00221/0.479) losses = 1.8731, lr = [2.4305270495412746e-05, 0.0002430527049541274]\n",
      "[INFO: 2022-02-16 23:25:00,188]   LabelSmoothing Loss = 2.252962350845337\n",
      "[INFO: 2022-02-16 23:25:09,849] Iteration 33080 (DataTime/BatchTime: 0.00352/0.483) losses = 1.8631, lr = [2.4297922407299896e-05, 0.00024297922407299892]\n",
      "[INFO: 2022-02-16 23:25:09,849]   LabelSmoothing Loss = 1.8687268495559692\n",
      "[INFO: 2022-02-16 23:25:19,446] Iteration 33100 (DataTime/BatchTime: 0.0014/0.48) losses = 1.9689, lr = [2.429058097968956e-05, 0.0002429058097968956]\n",
      "[INFO: 2022-02-16 23:25:19,446]   LabelSmoothing Loss = 2.0604560375213623\n",
      "[INFO: 2022-02-16 23:25:29,092] Iteration 33120 (DataTime/BatchTime: 0.0022/0.482) losses = 1.9747, lr = [2.4283246202525727e-05, 0.00024283246202525723]\n",
      "[INFO: 2022-02-16 23:25:29,092]   LabelSmoothing Loss = 1.308323860168457\n",
      "[INFO: 2022-02-16 23:25:38,693] Iteration 33140 (DataTime/BatchTime: 0.00427/0.48) losses = 1.562, lr = [2.4275918065773614e-05, 0.00024275918065773614]\n",
      "[INFO: 2022-02-16 23:25:38,693]   LabelSmoothing Loss = 2.0434963703155518\n",
      "[INFO: 2022-02-16 23:25:48,292] Iteration 33160 (DataTime/BatchTime: 0.00129/0.48) losses = 1.8044, lr = [2.4268596559419636e-05, 0.00024268596559419631]\n",
      "[INFO: 2022-02-16 23:25:48,292]   LabelSmoothing Loss = 2.670532703399658\n",
      "[INFO: 2022-02-16 23:25:57,876] Iteration 33180 (DataTime/BatchTime: 0.00223/0.479) losses = 1.9532, lr = [2.4261281673471325e-05, 0.0002426128167347132]\n",
      "[INFO: 2022-02-16 23:25:57,876]   LabelSmoothing Loss = 1.5409899950027466\n",
      "[INFO: 2022-02-16 23:26:07,532] Iteration 33200 (DataTime/BatchTime: 0.00136/0.483) losses = 1.8224, lr = [2.4253973397957293e-05, 0.0002425397339795729]\n",
      "[INFO: 2022-02-16 23:26:07,532]   LabelSmoothing Loss = 1.5965228080749512\n",
      "[INFO: 2022-02-16 23:26:17,119] Iteration 33220 (DataTime/BatchTime: 0.0013/0.479) losses = 1.6854, lr = [2.4246671722927164e-05, 0.0002424667172292716]\n",
      "[INFO: 2022-02-16 23:26:17,119]   LabelSmoothing Loss = 2.5365078449249268\n",
      "[INFO: 2022-02-16 23:26:26,661] Iteration 33240 (DataTime/BatchTime: 0.00126/0.477) losses = 1.8522, lr = [2.4239376638451512e-05, 0.0002423937663845151]\n",
      "[INFO: 2022-02-16 23:26:26,661]   LabelSmoothing Loss = 1.9555363655090332\n",
      "[INFO: 2022-02-16 23:26:36,263] Iteration 33260 (DataTime/BatchTime: 0.00129/0.48) losses = 1.7541, lr = [2.4232088134621818e-05, 0.00024232088134621814]\n",
      "[INFO: 2022-02-16 23:26:36,263]   LabelSmoothing Loss = 2.0931742191314697\n",
      "[INFO: 2022-02-16 23:26:45,822] Iteration 33280 (DataTime/BatchTime: 0.00217/0.478) losses = 1.7696, lr = [2.422480620155039e-05, 0.00024224806201550387]\n",
      "[INFO: 2022-02-16 23:26:45,822]   LabelSmoothing Loss = 1.5031341314315796\n",
      "[INFO: 2022-02-16 23:26:55,445] Iteration 33300 (DataTime/BatchTime: 0.00124/0.48) losses = 2.0096, lr = [2.4217530829370354e-05, 0.0002421753082937035]\n",
      "[INFO: 2022-02-16 23:26:55,445]   LabelSmoothing Loss = 2.2160160541534424\n",
      "[INFO: 2022-02-16 23:27:05,075] Iteration 33320 (DataTime/BatchTime: 0.00213/0.482) losses = 1.9052, lr = [2.4210262008235532e-05, 0.0002421026200823553]\n",
      "[INFO: 2022-02-16 23:27:05,075]   LabelSmoothing Loss = 2.969810962677002\n",
      "[INFO: 2022-02-16 23:27:14,603] Iteration 33340 (DataTime/BatchTime: 0.0012/0.476) losses = 1.8371, lr = [2.4202999728320445e-05, 0.00024202999728320442]\n",
      "[INFO: 2022-02-16 23:27:14,603]   LabelSmoothing Loss = 1.3253973722457886\n",
      "[INFO: 2022-02-16 23:27:24,179] Iteration 33360 (DataTime/BatchTime: 0.00221/0.479) losses = 1.8446, lr = [2.419574397982022e-05, 0.00024195743979820214]\n",
      "[INFO: 2022-02-16 23:27:24,179]   LabelSmoothing Loss = 0.90403813123703\n",
      "[INFO: 2022-02-16 23:27:33,797] Iteration 33380 (DataTime/BatchTime: 0.00128/0.481) losses = 2.0029, lr = [2.4188494752950552e-05, 0.0002418849475295055]\n",
      "[INFO: 2022-02-16 23:27:33,797]   LabelSmoothing Loss = 1.6087779998779297\n",
      "[INFO: 2022-02-16 23:27:43,387] Iteration 33400 (DataTime/BatchTime: 0.00128/0.48) losses = 1.7971, lr = [2.418125203794765e-05, 0.00024181252037947646]\n",
      "[INFO: 2022-02-16 23:27:43,387]   LabelSmoothing Loss = 1.0575156211853027\n",
      "[INFO: 2022-02-16 23:27:52,888] Iteration 33420 (DataTime/BatchTime: 0.00124/0.475) losses = 1.8343, lr = [2.4174015825068164e-05, 0.0002417401582506816]\n",
      "[INFO: 2022-02-16 23:27:52,888]   LabelSmoothing Loss = 1.7223213911056519\n",
      "[INFO: 2022-02-16 23:31:26,176] ######## Epoch (VAL)35 ########\n",
      "[INFO: 2022-02-16 23:31:26,176] {'Bleu_1': 0.31938686984366316, 'Bleu_2': 0.19528782207109743, 'Bleu_3': 0.1287357312412064, 'Bleu_4': 0.08901848217567561, 'METEOR': 0.17679593816225234, 'ROUGE_L': 0.28271784770630404, 'CIDEr': 0.2884026184762444}\n",
      "[INFO: 2022-02-16 23:35:06,530] ######## Epoch (TEST)35 ########\n",
      "[INFO: 2022-02-16 23:35:06,530] {'Bleu_1': 0.3017298637805405, 'Bleu_2': 0.17785704586762122, 'Bleu_3': 0.11389846672824769, 'Bleu_4': 0.07707503155492933, 'METEOR': 0.16984957555924143, 'ROUGE_L': 0.27531394007039095, 'CIDEr': 0.264443690971005}\n",
      "[INFO: 2022-02-16 23:35:15,397] Iteration 33440 (DataTime/BatchTime: 0.0669/0.554) losses = 2.0692, lr = [2.4166786104589144e-05, 0.0002416678610458914]\n",
      "[INFO: 2022-02-16 23:35:15,398]   LabelSmoothing Loss = 2.343231439590454\n",
      "[INFO: 2022-02-16 23:35:24,988] Iteration 33460 (DataTime/BatchTime: 0.00217/0.48) losses = 1.8631, lr = [2.415956286680799e-05, 0.00024159562866807985]\n",
      "[INFO: 2022-02-16 23:35:24,988]   LabelSmoothing Loss = 2.105790138244629\n",
      "[INFO: 2022-02-16 23:35:34,513] Iteration 33480 (DataTime/BatchTime: 0.00138/0.476) losses = 1.7575, lr = [2.4152346102042383e-05, 0.0002415234610204238]\n",
      "[INFO: 2022-02-16 23:35:34,513]   LabelSmoothing Loss = 1.2310229539871216\n",
      "[INFO: 2022-02-16 23:35:43,960] Iteration 33500 (DataTime/BatchTime: 0.00132/0.472) losses = 1.6526, lr = [2.414513580063024e-05, 0.00024145135800630234]\n",
      "[INFO: 2022-02-16 23:35:43,961]   LabelSmoothing Loss = 1.2629040479660034\n",
      "[INFO: 2022-02-16 23:35:53,617] Iteration 33520 (DataTime/BatchTime: 0.00301/0.483) losses = 1.9013, lr = [2.4137931952929656e-05, 0.00024137931952929656]\n",
      "[INFO: 2022-02-16 23:35:53,618]   LabelSmoothing Loss = 2.713961124420166\n",
      "[INFO: 2022-02-16 23:36:03,144] Iteration 33540 (DataTime/BatchTime: 0.00128/0.476) losses = 1.9089, lr = [2.4130734549318856e-05, 0.00024130734549318851]\n",
      "[INFO: 2022-02-16 23:36:03,144]   LabelSmoothing Loss = 2.248094081878662\n",
      "[INFO: 2022-02-16 23:36:12,774] Iteration 33560 (DataTime/BatchTime: 0.00215/0.481) losses = 1.8549, lr = [2.4123543580196133e-05, 0.0002412354358019613]\n",
      "[INFO: 2022-02-16 23:36:12,774]   LabelSmoothing Loss = 1.402959942817688\n",
      "[INFO: 2022-02-16 23:36:22,399] Iteration 33580 (DataTime/BatchTime: 0.00127/0.481) losses = 1.9796, lr = [2.411635903597979e-05, 0.00024116359035979788]\n",
      "[INFO: 2022-02-16 23:36:22,399]   LabelSmoothing Loss = 1.6641604900360107\n",
      "[INFO: 2022-02-16 23:36:31,967] Iteration 33600 (DataTime/BatchTime: 0.00132/0.478) losses = 1.8658, lr = [2.4109180907108107e-05, 0.00024109180907108105]\n",
      "[INFO: 2022-02-16 23:36:31,967]   LabelSmoothing Loss = 1.67117178440094\n",
      "[INFO: 2022-02-16 23:36:41,507] Iteration 33620 (DataTime/BatchTime: 0.00445/0.477) losses = 1.9551, lr = [2.4102009184039265e-05, 0.00024102009184039262]\n",
      "[INFO: 2022-02-16 23:36:41,507]   LabelSmoothing Loss = 1.2890628576278687\n",
      "[INFO: 2022-02-16 23:36:51,035] Iteration 33640 (DataTime/BatchTime: 0.00127/0.476) losses = 1.9787, lr = [2.4094843857251305e-05, 0.00024094843857251302]\n",
      "[INFO: 2022-02-16 23:36:51,035]   LabelSmoothing Loss = 2.570856809616089\n",
      "[INFO: 2022-02-16 23:37:00,625] Iteration 33660 (DataTime/BatchTime: 0.00259/0.48) losses = 1.7177, lr = [2.408768491724207e-05, 0.00024087684917242067]\n",
      "[INFO: 2022-02-16 23:37:00,625]   LabelSmoothing Loss = 2.583648681640625\n",
      "[INFO: 2022-02-16 23:37:10,239] Iteration 33680 (DataTime/BatchTime: 0.00132/0.481) losses = 1.9059, lr = [2.4080532354529152e-05, 0.0002408053235452915]\n",
      "[INFO: 2022-02-16 23:37:10,239]   LabelSmoothing Loss = 1.8628454208374023\n",
      "[INFO: 2022-02-16 23:37:19,882] Iteration 33700 (DataTime/BatchTime: 0.00296/0.482) losses = 1.9908, lr = [2.407338615964985e-05, 0.00024073386159649847]\n",
      "[INFO: 2022-02-16 23:37:19,882]   LabelSmoothing Loss = 1.5426592826843262\n",
      "[INFO: 2022-02-16 23:37:29,517] Iteration 33720 (DataTime/BatchTime: 0.00239/0.481) losses = 1.9152, lr = [2.4066246323161097e-05, 0.00024066246323161094]\n",
      "[INFO: 2022-02-16 23:37:29,518]   LabelSmoothing Loss = 1.1999059915542603\n",
      "[INFO: 2022-02-16 23:37:39,044] Iteration 33740 (DataTime/BatchTime: 0.00303/0.477) losses = 1.8939, lr = [2.405911283563943e-05, 0.0002405911283563943]\n",
      "[INFO: 2022-02-16 23:37:39,044]   LabelSmoothing Loss = 1.9998100996017456\n",
      "[INFO: 2022-02-16 23:37:48,698] Iteration 33760 (DataTime/BatchTime: 0.00141/0.483) losses = 1.9084, lr = [2.405198568768092e-05, 0.00024051985687680914]\n",
      "[INFO: 2022-02-16 23:37:48,698]   LabelSmoothing Loss = 2.1923797130584717\n",
      "[INFO: 2022-02-16 23:37:58,224] Iteration 33780 (DataTime/BatchTime: 0.00123/0.476) losses = 1.9089, lr = [2.4044864869901125e-05, 0.00024044864869901121]\n",
      "[INFO: 2022-02-16 23:37:58,225]   LabelSmoothing Loss = 0.9849950671195984\n",
      "[INFO: 2022-02-16 23:38:07,815] Iteration 33800 (DataTime/BatchTime: 0.00254/0.48) losses = 1.6702, lr = [2.4037750372935053e-05, 0.00024037750372935047]\n",
      "[INFO: 2022-02-16 23:38:07,815]   LabelSmoothing Loss = 1.6489331722259521\n",
      "[INFO: 2022-02-16 23:38:17,342] Iteration 33820 (DataTime/BatchTime: 0.00303/0.476) losses = 1.8384, lr = [2.4030642187437076e-05, 0.00024030642187437075]\n",
      "[INFO: 2022-02-16 23:38:17,342]   LabelSmoothing Loss = 1.1757943630218506\n",
      "[INFO: 2022-02-16 23:38:26,887] Iteration 33840 (DataTime/BatchTime: 0.00218/0.477) losses = 1.9947, lr = [2.402354030408092e-05, 0.00024023540304080916]\n",
      "[INFO: 2022-02-16 23:38:26,887]   LabelSmoothing Loss = 2.483135223388672\n",
      "[INFO: 2022-02-16 23:38:36,454] Iteration 33860 (DataTime/BatchTime: 0.00211/0.478) losses = 1.8267, lr = [2.401644471355958e-05, 0.00024016444713559576]\n",
      "[INFO: 2022-02-16 23:38:36,454]   LabelSmoothing Loss = 2.2214884757995605\n",
      "[INFO: 2022-02-16 23:38:46,015] Iteration 33880 (DataTime/BatchTime: 0.00211/0.477) losses = 1.8015, lr = [2.400935540658529e-05, 0.00024009355406585286]\n",
      "[INFO: 2022-02-16 23:38:46,015]   LabelSmoothing Loss = 1.8718762397766113\n",
      "[INFO: 2022-02-16 23:38:55,581] Iteration 33900 (DataTime/BatchTime: 0.00387/0.479) losses = 1.7022, lr = [2.4002272373889463e-05, 0.00024002272373889458]\n",
      "[INFO: 2022-02-16 23:38:55,581]   LabelSmoothing Loss = 1.1194478273391724\n",
      "[INFO: 2022-02-16 23:39:05,119] Iteration 33920 (DataTime/BatchTime: 0.0024/0.477) losses = 1.8709, lr = [2.3995195606222632e-05, 0.0002399519560622263]\n",
      "[INFO: 2022-02-16 23:39:05,119]   LabelSmoothing Loss = 2.1182494163513184\n",
      "[INFO: 2022-02-16 23:39:14,638] Iteration 33940 (DataTime/BatchTime: 0.00124/0.476) losses = 1.8448, lr = [2.3988125094354415e-05, 0.00023988125094354413]\n",
      "[INFO: 2022-02-16 23:39:14,638]   LabelSmoothing Loss = 1.9067825078964233\n",
      "[INFO: 2022-02-16 23:39:24,233] Iteration 33960 (DataTime/BatchTime: 0.00297/0.48) losses = 1.8875, lr = [2.3981060829073467e-05, 0.00023981060829073465]\n",
      "[INFO: 2022-02-16 23:39:24,233]   LabelSmoothing Loss = 1.770979881286621\n",
      "[INFO: 2022-02-16 23:39:33,773] Iteration 33980 (DataTime/BatchTime: 0.00408/0.477) losses = 1.8792, lr = [2.3974002801187404e-05, 0.00023974002801187402]\n",
      "[INFO: 2022-02-16 23:39:33,773]   LabelSmoothing Loss = 2.1362600326538086\n",
      "[INFO: 2022-02-16 23:39:43,334] Iteration 34000 (DataTime/BatchTime: 0.00125/0.478) losses = 1.856, lr = [2.396695100152278e-05, 0.00023966951001522778]\n",
      "[INFO: 2022-02-16 23:39:43,334]   LabelSmoothing Loss = 3.0469093322753906\n",
      "[INFO: 2022-02-16 23:39:52,891] Iteration 34020 (DataTime/BatchTime: 0.00214/0.478) losses = 1.7795, lr = [2.395990542092502e-05, 0.0002395990542092502]\n",
      "[INFO: 2022-02-16 23:39:52,892]   LabelSmoothing Loss = 2.771554946899414\n",
      "[INFO: 2022-02-16 23:40:02,421] Iteration 34040 (DataTime/BatchTime: 0.00213/0.476) losses = 1.9866, lr = [2.395286605025838e-05, 0.00023952866050258378]\n",
      "[INFO: 2022-02-16 23:40:02,422]   LabelSmoothing Loss = 2.108039140701294\n",
      "[INFO: 2022-02-16 23:40:11,963] Iteration 34060 (DataTime/BatchTime: 0.00243/0.477) losses = 1.7303, lr = [2.3945832880405894e-05, 0.00023945832880405891]\n",
      "[INFO: 2022-02-16 23:40:11,963]   LabelSmoothing Loss = 1.5070981979370117\n",
      "[INFO: 2022-02-16 23:40:21,502] Iteration 34080 (DataTime/BatchTime: 0.00129/0.477) losses = 1.7668, lr = [2.3938805902269323e-05, 0.0002393880590226932]\n",
      "[INFO: 2022-02-16 23:40:21,502]   LabelSmoothing Loss = 2.5137085914611816\n",
      "[INFO: 2022-02-16 23:40:31,021] Iteration 34100 (DataTime/BatchTime: 0.00126/0.476) losses = 1.7557, lr = [2.39317851067691e-05, 0.00023931785106769094]\n",
      "[INFO: 2022-02-16 23:40:31,021]   LabelSmoothing Loss = 2.2242817878723145\n",
      "[INFO: 2022-02-16 23:40:40,656] Iteration 34120 (DataTime/BatchTime: 0.00137/0.482) losses = 1.7636, lr = [2.392477048484429e-05, 0.0002392477048484429]\n",
      "[INFO: 2022-02-16 23:40:40,656]   LabelSmoothing Loss = 2.310762405395508\n",
      "[INFO: 2022-02-16 23:40:50,192] Iteration 34140 (DataTime/BatchTime: 0.00311/0.477) losses = 1.855, lr = [2.3917762027452554e-05, 0.0002391776202745255]\n",
      "[INFO: 2022-02-16 23:40:50,193]   LabelSmoothing Loss = 1.2573893070220947\n",
      "[INFO: 2022-02-16 23:40:59,756] Iteration 34160 (DataTime/BatchTime: 0.00242/0.478) losses = 1.8746, lr = [2.391075972557006e-05, 0.00023910759725570056]\n",
      "[INFO: 2022-02-16 23:40:59,756]   LabelSmoothing Loss = 2.3098976612091064\n",
      "[INFO: 2022-02-16 23:41:09,368] Iteration 34180 (DataTime/BatchTime: 0.00137/0.481) losses = 1.9064, lr = [2.3903763570191472e-05, 0.0002390376357019147]\n",
      "[INFO: 2022-02-16 23:41:09,369]   LabelSmoothing Loss = 1.5305179357528687\n",
      "[INFO: 2022-02-16 23:41:18,907] Iteration 34200 (DataTime/BatchTime: 0.00307/0.477) losses = 1.7515, lr = [2.389677355232988e-05, 0.0002389677355232988]\n",
      "[INFO: 2022-02-16 23:41:18,907]   LabelSmoothing Loss = 2.2547593116760254\n",
      "[INFO: 2022-02-16 23:41:28,545] Iteration 34220 (DataTime/BatchTime: 0.0021/0.482) losses = 1.7996, lr = [2.388978966301677e-05, 0.0002388978966301677]\n",
      "[INFO: 2022-02-16 23:41:28,545]   LabelSmoothing Loss = 2.265894651412964\n",
      "[INFO: 2022-02-16 23:41:38,107] Iteration 34240 (DataTime/BatchTime: 0.00227/0.478) losses = 1.8155, lr = [2.3882811893301954e-05, 0.0002388281189330195]\n",
      "[INFO: 2022-02-16 23:41:38,107]   LabelSmoothing Loss = 1.2216414213180542\n",
      "[INFO: 2022-02-16 23:41:47,687] Iteration 34260 (DataTime/BatchTime: 0.0021/0.479) losses = 1.7829, lr = [2.387584023425354e-05, 0.00023875840234253537]\n",
      "[INFO: 2022-02-16 23:41:47,687]   LabelSmoothing Loss = 1.742732286453247\n",
      "[INFO: 2022-02-16 23:41:57,208] Iteration 34280 (DataTime/BatchTime: 0.0038/0.476) losses = 1.629, lr = [2.3868874676957873e-05, 0.0002386887467695787]\n",
      "[INFO: 2022-02-16 23:41:57,208]   LabelSmoothing Loss = 1.9283229112625122\n",
      "[INFO: 2022-02-16 23:42:06,819] Iteration 34300 (DataTime/BatchTime: 0.00127/0.481) losses = 1.9798, lr = [2.386191521251949e-05, 0.00023861915212519487]\n",
      "[INFO: 2022-02-16 23:42:06,820]   LabelSmoothing Loss = 1.0724067687988281\n",
      "[INFO: 2022-02-16 23:42:16,445] Iteration 34320 (DataTime/BatchTime: 0.00221/0.481) losses = 1.8668, lr = [2.3854961832061075e-05, 0.0002385496183206107]\n",
      "[INFO: 2022-02-16 23:42:16,445]   LabelSmoothing Loss = 1.8164024353027344\n",
      "[INFO: 2022-02-16 23:42:26,091] Iteration 34340 (DataTime/BatchTime: 0.00124/0.482) losses = 2.1019, lr = [2.3848014526723404e-05, 0.000238480145267234]\n",
      "[INFO: 2022-02-16 23:42:26,091]   LabelSmoothing Loss = 1.7258429527282715\n",
      "[INFO: 2022-02-16 23:42:35,722] Iteration 34360 (DataTime/BatchTime: 0.00122/0.482) losses = 1.8399, lr = [2.3841073287665315e-05, 0.0002384107328766531]\n",
      "[INFO: 2022-02-16 23:42:35,723]   LabelSmoothing Loss = 1.3897497653961182\n",
      "[INFO: 2022-02-16 23:46:17,392] ######## Epoch (VAL)36 ########\n",
      "[INFO: 2022-02-16 23:46:17,392] {'Bleu_1': 0.2947909009047015, 'Bleu_2': 0.17417593050554997, 'Bleu_3': 0.1120140271588627, 'Bleu_4': 0.07627098846608318, 'METEOR': 0.16404224871958006, 'ROUGE_L': 0.2923432069738031, 'CIDEr': 0.3508837225081082}\n",
      "[INFO: 2022-02-16 23:49:59,075] ######## Epoch (TEST)36 ########\n",
      "[INFO: 2022-02-16 23:49:59,075] {'Bleu_1': 0.27748677316224873, 'Bleu_2': 0.1525153403091945, 'Bleu_3': 0.0899136440159304, 'Bleu_4': 0.05415668011975442, 'METEOR': 0.15787469609922003, 'ROUGE_L': 0.2703359951760686, 'CIDEr': 0.15691455587953704}\n",
      "[INFO: 2022-02-16 23:50:00,673] Iteration 34380 (DataTime/BatchTime: 0.981/1.6) losses = 1.4986, lr = [2.383413810606364e-05, 0.00023834138106063635]\n",
      "[INFO: 2022-02-16 23:50:00,673]   LabelSmoothing Loss = 1.4986498355865479\n",
      "[INFO: 2022-02-16 23:50:10,183] Iteration 34400 (DataTime/BatchTime: 0.00257/0.475) losses = 1.7748, lr = [2.382720897311316e-05, 0.00023827208973113158]\n",
      "[INFO: 2022-02-16 23:50:10,183]   LabelSmoothing Loss = 2.5100739002227783\n",
      "[INFO: 2022-02-16 23:50:19,634] Iteration 34420 (DataTime/BatchTime: 0.00321/0.473) losses = 1.7803, lr = [2.3820285880026587e-05, 0.00023820285880026584]\n",
      "[INFO: 2022-02-16 23:50:19,634]   LabelSmoothing Loss = 1.1135777235031128\n",
      "[INFO: 2022-02-16 23:50:29,272] Iteration 34440 (DataTime/BatchTime: 0.00234/0.482) losses = 1.8069, lr = [2.381336881803447e-05, 0.00023813368818034465]\n",
      "[INFO: 2022-02-16 23:50:29,273]   LabelSmoothing Loss = 2.8205134868621826\n",
      "[INFO: 2022-02-16 23:50:38,874] Iteration 34460 (DataTime/BatchTime: 0.00142/0.48) losses = 1.8291, lr = [2.3806457778385185e-05, 0.00023806457778385184]\n",
      "[INFO: 2022-02-16 23:50:38,874]   LabelSmoothing Loss = 0.9689555764198303\n",
      "[INFO: 2022-02-16 23:50:48,426] Iteration 34480 (DataTime/BatchTime: 0.0027/0.478) losses = 1.5973, lr = [2.3799552752344883e-05, 0.0002379955275234488]\n",
      "[INFO: 2022-02-16 23:50:48,426]   LabelSmoothing Loss = 1.3704050779342651\n",
      "[INFO: 2022-02-16 23:50:58,033] Iteration 34500 (DataTime/BatchTime: 0.0024/0.48) losses = 1.8429, lr = [2.3792653731197422e-05, 0.0002379265373119742]\n",
      "[INFO: 2022-02-16 23:50:58,034]   LabelSmoothing Loss = 1.24577796459198\n",
      "[INFO: 2022-02-16 23:51:07,631] Iteration 34520 (DataTime/BatchTime: 0.00156/0.48) losses = 1.6099, lr = [2.3785760706244354e-05, 0.0002378576070624435]\n",
      "[INFO: 2022-02-16 23:51:07,632]   LabelSmoothing Loss = 1.245131015777588\n",
      "[INFO: 2022-02-16 23:51:17,380] Iteration 34540 (DataTime/BatchTime: 0.0015/0.487) losses = 1.9882, lr = [2.377887366880484e-05, 0.00023778873668804838]\n",
      "[INFO: 2022-02-16 23:51:17,380]   LabelSmoothing Loss = 1.8980189561843872\n",
      "[INFO: 2022-02-16 23:51:26,933] Iteration 34560 (DataTime/BatchTime: 0.00148/0.478) losses = 1.9471, lr = [2.3771992610215644e-05, 0.00023771992610215642]\n",
      "[INFO: 2022-02-16 23:51:26,934]   LabelSmoothing Loss = 2.177140951156616\n",
      "[INFO: 2022-02-16 23:51:36,453] Iteration 34580 (DataTime/BatchTime: 0.00145/0.476) losses = 1.7458, lr = [2.376511752183106e-05, 0.00023765117521831056]\n",
      "[INFO: 2022-02-16 23:51:36,454]   LabelSmoothing Loss = 1.5197367668151855\n",
      "[INFO: 2022-02-16 23:51:46,000] Iteration 34600 (DataTime/BatchTime: 0.00151/0.477) losses = 1.7809, lr = [2.375824839502288e-05, 0.00023758248395022878]\n",
      "[INFO: 2022-02-16 23:51:46,000]   LabelSmoothing Loss = 1.424566626548767\n",
      "[INFO: 2022-02-16 23:51:55,616] Iteration 34620 (DataTime/BatchTime: 0.00158/0.481) losses = 1.694, lr = [2.375138522118033e-05, 0.00023751385221180328]\n",
      "[INFO: 2022-02-16 23:51:55,616]   LabelSmoothing Loss = 1.6419153213500977\n",
      "[INFO: 2022-02-16 23:52:05,256] Iteration 34640 (DataTime/BatchTime: 0.00146/0.482) losses = 1.8713, lr = [2.3744527991710057e-05, 0.00023744527991710054]\n",
      "[INFO: 2022-02-16 23:52:05,256]   LabelSmoothing Loss = 1.7051830291748047\n",
      "[INFO: 2022-02-16 23:52:14,904] Iteration 34660 (DataTime/BatchTime: 0.00163/0.482) losses = 1.8121, lr = [2.373767669803605e-05, 0.0002373767669803605]\n",
      "[INFO: 2022-02-16 23:52:14,904]   LabelSmoothing Loss = 2.1409850120544434\n",
      "[INFO: 2022-02-16 23:52:24,705] Iteration 34680 (DataTime/BatchTime: 0.00167/0.49) losses = 1.812, lr = [2.373083133159962e-05, 0.00023730831331599618]\n",
      "[INFO: 2022-02-16 23:52:24,706]   LabelSmoothing Loss = 3.0191469192504883\n",
      "[INFO: 2022-02-16 23:52:34,387] Iteration 34700 (DataTime/BatchTime: 0.0015/0.484) losses = 1.9597, lr = [2.372399188385933e-05, 0.0002372399188385933]\n",
      "[INFO: 2022-02-16 23:52:34,387]   LabelSmoothing Loss = 2.77174711227417\n",
      "[INFO: 2022-02-16 23:52:43,964] Iteration 34720 (DataTime/BatchTime: 0.00145/0.479) losses = 1.8598, lr = [2.371715834629099e-05, 0.0002371715834629099]\n",
      "[INFO: 2022-02-16 23:52:43,964]   LabelSmoothing Loss = 1.4035567045211792\n",
      "[INFO: 2022-02-16 23:52:53,570] Iteration 34740 (DataTime/BatchTime: 0.00229/0.48) losses = 1.8522, lr = [2.371033071038756e-05, 0.00023710330710387557]\n",
      "[INFO: 2022-02-16 23:52:53,570]   LabelSmoothing Loss = 2.4203226566314697\n",
      "[INFO: 2022-02-16 23:53:03,234] Iteration 34760 (DataTime/BatchTime: 0.00156/0.483) losses = 2.0353, lr = [2.3703508967659153e-05, 0.0002370350896765915]\n",
      "[INFO: 2022-02-16 23:53:03,234]   LabelSmoothing Loss = 2.3102784156799316\n",
      "[INFO: 2022-02-16 23:53:12,894] Iteration 34780 (DataTime/BatchTime: 0.00148/0.483) losses = 1.7909, lr = [2.3696693109632955e-05, 0.00023696693109632953]\n",
      "[INFO: 2022-02-16 23:53:12,894]   LabelSmoothing Loss = 2.874476432800293\n",
      "[INFO: 2022-02-16 23:53:22,555] Iteration 34800 (DataTime/BatchTime: 0.0025/0.483) losses = 1.812, lr = [2.368988312785321e-05, 0.0002368988312785321]\n",
      "[INFO: 2022-02-16 23:53:22,555]   LabelSmoothing Loss = 2.5747523307800293\n",
      "[INFO: 2022-02-16 23:53:32,050] Iteration 34820 (DataTime/BatchTime: 0.0022/0.475) losses = 1.797, lr = [2.3683079013881165e-05, 0.0002368307901388116]\n",
      "[INFO: 2022-02-16 23:53:32,050]   LabelSmoothing Loss = 1.2442243099212646\n",
      "[INFO: 2022-02-16 23:53:41,606] Iteration 34840 (DataTime/BatchTime: 0.00139/0.478) losses = 1.8774, lr = [2.3676280759295002e-05, 0.00023676280759295]\n",
      "[INFO: 2022-02-16 23:53:41,607]   LabelSmoothing Loss = 1.6719714403152466\n",
      "[INFO: 2022-02-16 23:53:51,219] Iteration 34860 (DataTime/BatchTime: 0.00122/0.481) losses = 1.6171, lr = [2.3669488355689838e-05, 0.00023669488355689832]\n",
      "[INFO: 2022-02-16 23:53:51,219]   LabelSmoothing Loss = 1.386197805404663\n",
      "[INFO: 2022-02-16 23:54:00,857] Iteration 34880 (DataTime/BatchTime: 0.00119/0.482) losses = 1.9374, lr = [2.3662701794677643e-05, 0.0002366270179467764]\n",
      "[INFO: 2022-02-16 23:54:00,857]   LabelSmoothing Loss = 1.4521995782852173\n",
      "[INFO: 2022-02-16 23:54:10,367] Iteration 34900 (DataTime/BatchTime: 0.00215/0.475) losses = 1.9672, lr = [2.3655921067887227e-05, 0.00023655921067887223]\n",
      "[INFO: 2022-02-16 23:54:10,367]   LabelSmoothing Loss = 1.9574462175369263\n",
      "[INFO: 2022-02-16 23:54:19,809] Iteration 34920 (DataTime/BatchTime: 0.00122/0.472) losses = 1.751, lr = [2.3649146166964173e-05, 0.0002364914616696417]\n",
      "[INFO: 2022-02-16 23:54:19,809]   LabelSmoothing Loss = 1.383858323097229\n",
      "[INFO: 2022-02-16 23:54:29,375] Iteration 34940 (DataTime/BatchTime: 0.00209/0.478) losses = 1.964, lr = [2.3642377083570804e-05, 0.00023642377083570804]\n",
      "[INFO: 2022-02-16 23:54:29,375]   LabelSmoothing Loss = 1.5606818199157715\n",
      "[INFO: 2022-02-16 23:54:38,953] Iteration 34960 (DataTime/BatchTime: 0.00189/0.479) losses = 1.6544, lr = [2.363561380938614e-05, 0.0002363561380938614]\n",
      "[INFO: 2022-02-16 23:54:38,953]   LabelSmoothing Loss = 2.365144968032837\n",
      "[INFO: 2022-02-16 23:54:48,574] Iteration 34980 (DataTime/BatchTime: 0.00193/0.481) losses = 1.9604, lr = [2.3628856336105858e-05, 0.00023628856336105857]\n",
      "[INFO: 2022-02-16 23:54:48,574]   LabelSmoothing Loss = 2.397773504257202\n",
      "[INFO: 2022-02-16 23:54:58,222] Iteration 35000 (DataTime/BatchTime: 0.00213/0.482) losses = 2.0177, lr = [2.3622104655442236e-05, 0.00023622104655442235]\n",
      "[INFO: 2022-02-16 23:54:58,222]   LabelSmoothing Loss = 2.4119625091552734\n",
      "[INFO: 2022-02-16 23:55:07,779] Iteration 35020 (DataTime/BatchTime: 0.0012/0.478) losses = 1.658, lr = [2.3615358759124123e-05, 0.00023615358759124122]\n",
      "[INFO: 2022-02-16 23:55:07,779]   LabelSmoothing Loss = 2.027242422103882\n",
      "[INFO: 2022-02-16 23:55:17,339] Iteration 35040 (DataTime/BatchTime: 0.00201/0.478) losses = 1.9308, lr = [2.3608618638896903e-05, 0.00023608618638896903]\n",
      "[INFO: 2022-02-16 23:55:17,339]   LabelSmoothing Loss = 2.32930064201355\n",
      "[INFO: 2022-02-16 23:55:26,891] Iteration 35060 (DataTime/BatchTime: 0.00226/0.478) losses = 1.8728, lr = [2.3601884286522425e-05, 0.00023601884286522423]\n",
      "[INFO: 2022-02-16 23:55:26,891]   LabelSmoothing Loss = 2.247551202774048\n",
      "[INFO: 2022-02-16 23:55:36,505] Iteration 35080 (DataTime/BatchTime: 0.00118/0.481) losses = 2.0893, lr = [2.359515569377899e-05, 0.00023595155693778986]\n",
      "[INFO: 2022-02-16 23:55:36,505]   LabelSmoothing Loss = 2.0158820152282715\n",
      "[INFO: 2022-02-16 23:55:46,078] Iteration 35100 (DataTime/BatchTime: 0.00116/0.479) losses = 1.743, lr = [2.3588432852461294e-05, 0.0002358843285246129]\n",
      "[INFO: 2022-02-16 23:55:46,078]   LabelSmoothing Loss = 2.9995930194854736\n",
      "[INFO: 2022-02-16 23:55:55,542] Iteration 35120 (DataTime/BatchTime: 0.00122/0.473) losses = 1.6916, lr = [2.3581715754380383e-05, 0.00023581715754380383]\n",
      "[INFO: 2022-02-16 23:55:55,542]   LabelSmoothing Loss = 0.6610167622566223\n",
      "[INFO: 2022-02-16 23:56:05,085] Iteration 35140 (DataTime/BatchTime: 0.00266/0.477) losses = 1.8162, lr = [2.3575004391363633e-05, 0.0002357500439136363]\n",
      "[INFO: 2022-02-16 23:56:05,085]   LabelSmoothing Loss = 2.33217191696167\n",
      "[INFO: 2022-02-16 23:56:14,674] Iteration 35160 (DataTime/BatchTime: 0.00122/0.479) losses = 1.8632, lr = [2.356829875525467e-05, 0.00023568298755254668]\n",
      "[INFO: 2022-02-16 23:56:14,674]   LabelSmoothing Loss = 1.9873802661895752\n",
      "[INFO: 2022-02-16 23:56:24,132] Iteration 35180 (DataTime/BatchTime: 0.0021/0.473) losses = 1.6289, lr = [2.3561598837913377e-05, 0.00023561598837913372]\n",
      "[INFO: 2022-02-16 23:56:24,132]   LabelSmoothing Loss = 1.3637751340866089\n",
      "[INFO: 2022-02-16 23:56:33,812] Iteration 35200 (DataTime/BatchTime: 0.00209/0.484) losses = 1.8714, lr = [2.35549046312158e-05, 0.00023554904631215798]\n",
      "[INFO: 2022-02-16 23:56:33,812]   LabelSmoothing Loss = 2.5839579105377197\n",
      "[INFO: 2022-02-16 23:56:43,333] Iteration 35220 (DataTime/BatchTime: 0.00133/0.476) losses = 1.7311, lr = [2.3548216127054146e-05, 0.00023548216127054143]\n",
      "[INFO: 2022-02-16 23:56:43,333]   LabelSmoothing Loss = 1.229830265045166\n",
      "[INFO: 2022-02-16 23:56:52,803] Iteration 35240 (DataTime/BatchTime: 0.003/0.473) losses = 1.9481, lr = [2.354153331733673e-05, 0.0002354153331733673]\n",
      "[INFO: 2022-02-16 23:56:52,803]   LabelSmoothing Loss = 2.8388571739196777\n",
      "[INFO: 2022-02-16 23:57:02,297] Iteration 35260 (DataTime/BatchTime: 0.00122/0.475) losses = 1.8866, lr = [2.353485619398793e-05, 0.00023534856193987928]\n",
      "[INFO: 2022-02-16 23:57:02,298]   LabelSmoothing Loss = 1.4797645807266235\n",
      "[INFO: 2022-02-16 23:57:11,811] Iteration 35280 (DataTime/BatchTime: 0.00128/0.476) losses = 2.0939, lr = [2.3528184748948147e-05, 0.00023528184748948145]\n",
      "[INFO: 2022-02-16 23:57:11,811]   LabelSmoothing Loss = 2.2104721069335938\n",
      "[INFO: 2022-02-16 23:57:21,320] Iteration 35300 (DataTime/BatchTime: 0.00311/0.475) losses = 1.5392, lr = [2.3521518974173766e-05, 0.0002352151897417376]\n",
      "[INFO: 2022-02-16 23:57:21,320]   LabelSmoothing Loss = 1.8399542570114136\n",
      "[INFO: 2022-02-16 23:57:30,876] Iteration 35320 (DataTime/BatchTime: 0.00213/0.478) losses = 1.8623, lr = [2.3514858861637112e-05, 0.0002351485886163711]\n",
      "[INFO: 2022-02-16 23:57:30,876]   LabelSmoothing Loss = 2.5213990211486816\n",
      "[INFO: 2022-02-17 00:01:09,344] ######## Epoch (VAL)37 ########\n",
      "[INFO: 2022-02-17 00:01:09,345] {'Bleu_1': 0.33234700088833063, 'Bleu_2': 0.20050399166163896, 'Bleu_3': 0.13056102194873825, 'Bleu_4': 0.08855181767439972, 'METEOR': 0.17387331242595475, 'ROUGE_L': 0.28917680304073534, 'CIDEr': 0.33044460699050304}\n",
      "[INFO: 2022-02-17 00:04:46,043] ######## Epoch (TEST)37 ########\n",
      "[INFO: 2022-02-17 00:04:46,043] {'Bleu_1': 0.3198710665385794, 'Bleu_2': 0.18782759060805213, 'Bleu_3': 0.12004264740773063, 'Bleu_4': 0.08117515410934592, 'METEOR': 0.17049475295858824, 'ROUGE_L': 0.28162886296108364, 'CIDEr': 0.3250754196710809}\n",
      "[INFO: 2022-02-17 00:04:50,142] Iteration 35340 (DataTime/BatchTime: 0.196/0.683) losses = 1.8013, lr = [2.3508204403326424e-05, 0.00023508204403326421]\n",
      "[INFO: 2022-02-17 00:04:50,142]   LabelSmoothing Loss = 0.9893248677253723\n",
      "[INFO: 2022-02-17 00:04:59,602] Iteration 35360 (DataTime/BatchTime: 0.00137/0.473) losses = 1.6558, lr = [2.3501555591245788e-05, 0.00023501555591245784]\n",
      "[INFO: 2022-02-17 00:04:59,602]   LabelSmoothing Loss = 1.1579437255859375\n",
      "[INFO: 2022-02-17 00:05:09,138] Iteration 35380 (DataTime/BatchTime: 0.00132/0.477) losses = 2.0239, lr = [2.3494912417415116e-05, 0.00023494912417415113]\n",
      "[INFO: 2022-02-17 00:05:09,138]   LabelSmoothing Loss = 1.6940391063690186\n",
      "[INFO: 2022-02-17 00:05:18,816] Iteration 35400 (DataTime/BatchTime: 0.00136/0.484) losses = 1.9633, lr = [2.3488274873870104e-05, 0.000234882748738701]\n",
      "[INFO: 2022-02-17 00:05:18,816]   LabelSmoothing Loss = 1.5081920623779297\n",
      "[INFO: 2022-02-17 00:05:28,389] Iteration 35420 (DataTime/BatchTime: 0.00413/0.479) losses = 1.8503, lr = [2.3481642952662188e-05, 0.00023481642952662187]\n",
      "[INFO: 2022-02-17 00:05:28,389]   LabelSmoothing Loss = 1.874208927154541\n",
      "[INFO: 2022-02-17 00:05:38,124] Iteration 35440 (DataTime/BatchTime: 0.00238/0.487) losses = 1.9027, lr = [2.347501664585851e-05, 0.00023475016645858508]\n",
      "[INFO: 2022-02-17 00:05:38,124]   LabelSmoothing Loss = 1.2526302337646484\n",
      "[INFO: 2022-02-17 00:05:47,731] Iteration 35460 (DataTime/BatchTime: 0.0014/0.48) losses = 1.8964, lr = [2.3468395945541863e-05, 0.00023468395945541861]\n",
      "[INFO: 2022-02-17 00:05:47,731]   LabelSmoothing Loss = 0.7808152437210083\n",
      "[INFO: 2022-02-17 00:05:57,199] Iteration 35480 (DataTime/BatchTime: 0.00128/0.473) losses = 1.6797, lr = [2.3461780843810666e-05, 0.0002346178084381066]\n",
      "[INFO: 2022-02-17 00:05:57,200]   LabelSmoothing Loss = 1.9495084285736084\n",
      "[INFO: 2022-02-17 00:06:06,814] Iteration 35500 (DataTime/BatchTime: 0.00242/0.481) losses = 1.757, lr = [2.3455171332778926e-05, 0.00023455171332778922]\n",
      "[INFO: 2022-02-17 00:06:06,814]   LabelSmoothing Loss = 0.9053530693054199\n",
      "[INFO: 2022-02-17 00:06:16,345] Iteration 35520 (DataTime/BatchTime: 0.0012/0.477) losses = 1.6653, lr = [2.344856740457618e-05, 0.0002344856740457618]\n",
      "[INFO: 2022-02-17 00:06:16,345]   LabelSmoothing Loss = 1.8636329174041748\n",
      "[INFO: 2022-02-17 00:06:26,000] Iteration 35540 (DataTime/BatchTime: 0.00261/0.483) losses = 1.7914, lr = [2.3441969051347478e-05, 0.00023441969051347477]\n",
      "[INFO: 2022-02-17 00:06:26,001]   LabelSmoothing Loss = 1.7880892753601074\n",
      "[INFO: 2022-02-17 00:06:35,527] Iteration 35560 (DataTime/BatchTime: 0.00224/0.476) losses = 1.5095, lr = [2.3435376265253335e-05, 0.00023435376265253333]\n",
      "[INFO: 2022-02-17 00:06:35,528]   LabelSmoothing Loss = 1.7488791942596436\n",
      "[INFO: 2022-02-17 00:06:45,104] Iteration 35580 (DataTime/BatchTime: 0.00132/0.479) losses = 1.8371, lr = [2.3428789038469683e-05, 0.00023428789038469681]\n",
      "[INFO: 2022-02-17 00:06:45,104]   LabelSmoothing Loss = 1.728820562362671\n",
      "[INFO: 2022-02-17 00:06:54,711] Iteration 35600 (DataTime/BatchTime: 0.00226/0.48) losses = 1.7228, lr = [2.3422207363187843e-05, 0.0002342220736318784]\n",
      "[INFO: 2022-02-17 00:06:54,711]   LabelSmoothing Loss = 1.1026164293289185\n",
      "[INFO: 2022-02-17 00:07:04,210] Iteration 35620 (DataTime/BatchTime: 0.00115/0.475) losses = 1.652, lr = [2.341563123161448e-05, 0.00023415631231614477]\n",
      "[INFO: 2022-02-17 00:07:04,210]   LabelSmoothing Loss = 1.9289003610610962\n",
      "[INFO: 2022-02-17 00:07:13,744] Iteration 35640 (DataTime/BatchTime: 0.00125/0.476) losses = 1.7249, lr = [2.3409060635971578e-05, 0.00023409060635971575]\n",
      "[INFO: 2022-02-17 00:07:13,744]   LabelSmoothing Loss = 1.795066475868225\n",
      "[INFO: 2022-02-17 00:07:23,233] Iteration 35660 (DataTime/BatchTime: 0.00196/0.475) losses = 1.6957, lr = [2.3402495568496376e-05, 0.00023402495568496372]\n",
      "[INFO: 2022-02-17 00:07:23,233]   LabelSmoothing Loss = 2.133728265762329\n",
      "[INFO: 2022-02-17 00:07:32,745] Iteration 35680 (DataTime/BatchTime: 0.00131/0.476) losses = 1.7392, lr = [2.339593602144135e-05, 0.00023395936021441347]\n",
      "[INFO: 2022-02-17 00:07:32,745]   LabelSmoothing Loss = 1.8569475412368774\n",
      "[INFO: 2022-02-17 00:07:42,301] Iteration 35700 (DataTime/BatchTime: 0.00242/0.478) losses = 1.9135, lr = [2.3389381987074173e-05, 0.0002338938198707417]\n",
      "[INFO: 2022-02-17 00:07:42,301]   LabelSmoothing Loss = 2.2345170974731445\n",
      "[INFO: 2022-02-17 00:07:51,967] Iteration 35720 (DataTime/BatchTime: 0.0012/0.483) losses = 1.8897, lr = [2.338283345767767e-05, 0.00023382833457677666]\n",
      "[INFO: 2022-02-17 00:07:51,967]   LabelSmoothing Loss = 1.2778387069702148\n",
      "[INFO: 2022-02-17 00:08:01,510] Iteration 35740 (DataTime/BatchTime: 0.00196/0.477) losses = 1.8324, lr = [2.337629042554977e-05, 0.0002337629042554977]\n",
      "[INFO: 2022-02-17 00:08:01,511]   LabelSmoothing Loss = 2.540395736694336\n",
      "[INFO: 2022-02-17 00:08:11,043] Iteration 35760 (DataTime/BatchTime: 0.00257/0.477) losses = 1.6878, lr = [2.3369752883003502e-05, 0.000233697528830035]\n",
      "[INFO: 2022-02-17 00:08:11,043]   LabelSmoothing Loss = 1.2772936820983887\n",
      "[INFO: 2022-02-17 00:08:20,532] Iteration 35780 (DataTime/BatchTime: 0.00116/0.474) losses = 1.8936, lr = [2.3363220822366916e-05, 0.00023363220822366913]\n",
      "[INFO: 2022-02-17 00:08:20,532]   LabelSmoothing Loss = 2.020575761795044\n",
      "[INFO: 2022-02-17 00:08:29,949] Iteration 35800 (DataTime/BatchTime: 0.00318/0.471) losses = 1.6335, lr = [2.3356694235983077e-05, 0.00023356694235983073]\n",
      "[INFO: 2022-02-17 00:08:29,949]   LabelSmoothing Loss = 1.7707133293151855\n",
      "[INFO: 2022-02-17 00:08:39,519] Iteration 35820 (DataTime/BatchTime: 0.00185/0.478) losses = 1.8545, lr = [2.335017311621e-05, 0.0002335017311621]\n",
      "[INFO: 2022-02-17 00:08:39,519]   LabelSmoothing Loss = 1.6858936548233032\n",
      "[INFO: 2022-02-17 00:08:48,933] Iteration 35840 (DataTime/BatchTime: 0.00114/0.471) losses = 1.7428, lr = [2.3343657455420648e-05, 0.00023343657455420646]\n",
      "[INFO: 2022-02-17 00:08:48,934]   LabelSmoothing Loss = 0.8662815690040588\n",
      "[INFO: 2022-02-17 00:08:58,427] Iteration 35860 (DataTime/BatchTime: 0.00226/0.475) losses = 1.9889, lr = [2.3337147246002856e-05, 0.00023337147246002855]\n",
      "[INFO: 2022-02-17 00:08:58,427]   LabelSmoothing Loss = 2.491672992706299\n",
      "[INFO: 2022-02-17 00:09:07,880] Iteration 35880 (DataTime/BatchTime: 0.00116/0.473) losses = 1.9784, lr = [2.3330642480359315e-05, 0.00023330642480359312]\n",
      "[INFO: 2022-02-17 00:09:07,880]   LabelSmoothing Loss = 2.6782326698303223\n",
      "[INFO: 2022-02-17 00:09:17,398] Iteration 35900 (DataTime/BatchTime: 0.00209/0.476) losses = 1.8922, lr = [2.3324143150907532e-05, 0.0002332414315090753]\n",
      "[INFO: 2022-02-17 00:09:17,398]   LabelSmoothing Loss = 2.322716474533081\n",
      "[INFO: 2022-02-17 00:09:26,886] Iteration 35920 (DataTime/BatchTime: 0.00111/0.474) losses = 1.9625, lr = [2.3317649250079795e-05, 0.0002331764925007979]\n",
      "[INFO: 2022-02-17 00:09:26,886]   LabelSmoothing Loss = 1.9830621480941772\n",
      "[INFO: 2022-02-17 00:09:36,449] Iteration 35940 (DataTime/BatchTime: 0.00114/0.478) losses = 1.962, lr = [2.3311160770323135e-05, 0.0002331116077032313]\n",
      "[INFO: 2022-02-17 00:09:36,449]   LabelSmoothing Loss = 1.7991642951965332\n",
      "[INFO: 2022-02-17 00:09:45,895] Iteration 35960 (DataTime/BatchTime: 0.00123/0.472) losses = 1.8359, lr = [2.3304677704099273e-05, 0.0002330467770409927]\n",
      "[INFO: 2022-02-17 00:09:45,895]   LabelSmoothing Loss = 1.3250441551208496\n",
      "[INFO: 2022-02-17 00:09:55,485] Iteration 35980 (DataTime/BatchTime: 0.00259/0.479) losses = 1.769, lr = [2.329820004388461e-05, 0.0002329820004388461]\n",
      "[INFO: 2022-02-17 00:09:55,485]   LabelSmoothing Loss = 1.9702327251434326\n",
      "[INFO: 2022-02-17 00:10:05,089] Iteration 36000 (DataTime/BatchTime: 0.00242/0.48) losses = 2.0272, lr = [2.329172778217018e-05, 0.00023291727782170175]\n",
      "[INFO: 2022-02-17 00:10:05,090]   LabelSmoothing Loss = 1.659756064414978\n",
      "[INFO: 2022-02-17 00:10:14,675] Iteration 36020 (DataTime/BatchTime: 0.00133/0.479) losses = 1.7887, lr = [2.3285260911461593e-05, 0.00023285260911461592]\n",
      "[INFO: 2022-02-17 00:10:14,675]   LabelSmoothing Loss = 1.715306043624878\n",
      "[INFO: 2022-02-17 00:10:24,123] Iteration 36040 (DataTime/BatchTime: 0.0038/0.472) losses = 1.7785, lr = [2.3278799424279036e-05, 0.00023278799424279034]\n",
      "[INFO: 2022-02-17 00:10:24,123]   LabelSmoothing Loss = 1.1882457733154297\n",
      "[INFO: 2022-02-17 00:10:33,573] Iteration 36060 (DataTime/BatchTime: 0.00325/0.473) losses = 1.8772, lr = [2.3272343313157207e-05, 0.00023272343313157203]\n",
      "[INFO: 2022-02-17 00:10:33,573]   LabelSmoothing Loss = 1.834794521331787\n",
      "[INFO: 2022-02-17 00:10:43,144] Iteration 36080 (DataTime/BatchTime: 0.00215/0.479) losses = 1.8037, lr = [2.3265892570645295e-05, 0.00023265892570645293]\n",
      "[INFO: 2022-02-17 00:10:43,144]   LabelSmoothing Loss = 2.1591970920562744\n",
      "[INFO: 2022-02-17 00:10:52,606] Iteration 36100 (DataTime/BatchTime: 0.0022/0.473) losses = 1.8769, lr = [2.325944718930693e-05, 0.00023259447189306927]\n",
      "[INFO: 2022-02-17 00:10:52,606]   LabelSmoothing Loss = 2.2373852729797363\n",
      "[INFO: 2022-02-17 00:11:02,123] Iteration 36120 (DataTime/BatchTime: 0.00316/0.476) losses = 1.8081, lr = [2.3253007161720157e-05, 0.00023253007161720153]\n",
      "[INFO: 2022-02-17 00:11:02,123]   LabelSmoothing Loss = 2.0169246196746826\n",
      "[INFO: 2022-02-17 00:11:11,806] Iteration 36140 (DataTime/BatchTime: 0.00333/0.484) losses = 1.9432, lr = [2.3246572480477402e-05, 0.000232465724804774]\n",
      "[INFO: 2022-02-17 00:11:11,807]   LabelSmoothing Loss = 2.2458488941192627\n",
      "[INFO: 2022-02-17 00:11:21,499] Iteration 36160 (DataTime/BatchTime: 0.00227/0.485) losses = 1.7012, lr = [2.324014313818543e-05, 0.00023240143138185428]\n",
      "[INFO: 2022-02-17 00:11:21,499]   LabelSmoothing Loss = 1.5065470933914185\n",
      "[INFO: 2022-02-17 00:11:31,135] Iteration 36180 (DataTime/BatchTime: 0.00137/0.482) losses = 1.9312, lr = [2.3233719127465312e-05, 0.0002323371912746531]\n",
      "[INFO: 2022-02-17 00:11:31,135]   LabelSmoothing Loss = 2.73616099357605\n",
      "[INFO: 2022-02-17 00:11:40,682] Iteration 36200 (DataTime/BatchTime: 0.00137/0.477) losses = 1.7451, lr = [2.3227300440952383e-05, 0.00023227300440952382]\n",
      "[INFO: 2022-02-17 00:11:40,683]   LabelSmoothing Loss = 1.2802915573120117\n",
      "[INFO: 2022-02-17 00:11:50,414] Iteration 36220 (DataTime/BatchTime: 0.00145/0.487) losses = 1.8656, lr = [2.322088707129622e-05, 0.0002322088707129622]\n",
      "[INFO: 2022-02-17 00:11:50,415]   LabelSmoothing Loss = 2.6723198890686035\n",
      "[INFO: 2022-02-17 00:12:00,065] Iteration 36240 (DataTime/BatchTime: 0.00141/0.483) losses = 1.7766, lr = [2.3214479011160603e-05, 0.000232144790111606]\n",
      "[INFO: 2022-02-17 00:12:00,066]   LabelSmoothing Loss = 1.9299534559249878\n",
      "[INFO: 2022-02-17 00:12:09,747] Iteration 36260 (DataTime/BatchTime: 0.00285/0.484) losses = 1.5277, lr = [2.3208076253223454e-05, 0.00023208076253223453]\n",
      "[INFO: 2022-02-17 00:12:09,747]   LabelSmoothing Loss = 1.305629014968872\n",
      "[INFO: 2022-02-17 00:12:19,322] Iteration 36280 (DataTime/BatchTime: 0.00249/0.479) losses = 1.9438, lr = [2.3201678790176855e-05, 0.00023201678790176852]\n",
      "[INFO: 2022-02-17 00:12:19,322]   LabelSmoothing Loss = 1.9712657928466797\n",
      "[INFO: 2022-02-17 00:15:55,430] ######## Epoch (VAL)38 ########\n",
      "[INFO: 2022-02-17 00:15:55,430] {'Bleu_1': 0.34833929424462423, 'Bleu_2': 0.2081978054680515, 'Bleu_3': 0.13190186037972854, 'Bleu_4': 0.08520990925684453, 'METEOR': 0.18034210037615142, 'ROUGE_L': 0.2885323913231158, 'CIDEr': 0.2422446241481393}\n",
      "[INFO: 2022-02-17 00:19:35,232] ######## Epoch (TEST)38 ########\n",
      "[INFO: 2022-02-17 00:19:35,233] {'Bleu_1': 0.3177531783392353, 'Bleu_2': 0.181212128443851, 'Bleu_3': 0.11171819547453447, 'Bleu_4': 0.07033121169596934, 'METEOR': 0.16787090650852413, 'ROUGE_L': 0.27469028748925584, 'CIDEr': 0.1739777392866414}\n",
      "[INFO: 2022-02-17 00:19:41,419] Iteration 36300 (DataTime/BatchTime: 0.0862/0.562) losses = 1.764, lr = [2.319528661472695e-05, 0.0002319528661472695]\n",
      "[INFO: 2022-02-17 00:19:41,420]   LabelSmoothing Loss = 1.9541680812835693\n",
      "[INFO: 2022-02-17 00:19:50,951] Iteration 36320 (DataTime/BatchTime: 0.00123/0.477) losses = 1.8834, lr = [2.3188899719593972e-05, 0.0002318889971959397]\n",
      "[INFO: 2022-02-17 00:19:50,952]   LabelSmoothing Loss = 1.8144875764846802\n",
      "[INFO: 2022-02-17 00:20:00,453] Iteration 36340 (DataTime/BatchTime: 0.00451/0.475) losses = 1.7197, lr = [2.318251809751215e-05, 0.00023182518097512148]\n",
      "[INFO: 2022-02-17 00:20:00,453]   LabelSmoothing Loss = 2.674509048461914\n",
      "[INFO: 2022-02-17 00:20:10,026] Iteration 36360 (DataTime/BatchTime: 0.00198/0.479) losses = 1.8761, lr = [2.3176141741229722e-05, 0.0002317614174122972]\n",
      "[INFO: 2022-02-17 00:20:10,026]   LabelSmoothing Loss = 2.35066294670105\n",
      "[INFO: 2022-02-17 00:20:19,614] Iteration 36380 (DataTime/BatchTime: 0.00125/0.479) losses = 1.8162, lr = [2.316977064350887e-05, 0.00023169770643508868]\n",
      "[INFO: 2022-02-17 00:20:19,615]   LabelSmoothing Loss = 1.8335561752319336\n",
      "[INFO: 2022-02-17 00:20:29,302] Iteration 36400 (DataTime/BatchTime: 0.00124/0.484) losses = 1.8879, lr = [2.3163404797125702e-05, 0.000231634047971257]\n",
      "[INFO: 2022-02-17 00:20:29,302]   LabelSmoothing Loss = 2.4368703365325928\n",
      "[INFO: 2022-02-17 00:20:38,813] Iteration 36420 (DataTime/BatchTime: 0.00122/0.476) losses = 1.6605, lr = [2.3157044194870205e-05, 0.00023157044194870203]\n",
      "[INFO: 2022-02-17 00:20:38,814]   LabelSmoothing Loss = 2.5794875621795654\n",
      "[INFO: 2022-02-17 00:20:48,359] Iteration 36440 (DataTime/BatchTime: 0.00216/0.477) losses = 1.7786, lr = [2.315068882954623e-05, 0.00023150688829546225]\n",
      "[INFO: 2022-02-17 00:20:48,359]   LabelSmoothing Loss = 2.2999300956726074\n",
      "[INFO: 2022-02-17 00:20:57,800] Iteration 36460 (DataTime/BatchTime: 0.00216/0.472) losses = 1.805, lr = [2.3144338693971426e-05, 0.00023144338693971422]\n",
      "[INFO: 2022-02-17 00:20:57,800]   LabelSmoothing Loss = 1.7434344291687012\n",
      "[INFO: 2022-02-17 00:21:07,345] Iteration 36480 (DataTime/BatchTime: 0.00216/0.477) losses = 2.0519, lr = [2.3137993780977237e-05, 0.00023137993780977237]\n",
      "[INFO: 2022-02-17 00:21:07,345]   LabelSmoothing Loss = 1.9950025081634521\n",
      "[INFO: 2022-02-17 00:21:16,908] Iteration 36500 (DataTime/BatchTime: 0.00121/0.478) losses = 1.6924, lr = [2.3131654083408867e-05, 0.00023131654083408863]\n",
      "[INFO: 2022-02-17 00:21:16,908]   LabelSmoothing Loss = 2.5588455200195312\n",
      "[INFO: 2022-02-17 00:21:26,671] Iteration 36520 (DataTime/BatchTime: 0.00148/0.488) losses = 1.9343, lr = [2.3125319594125205e-05, 0.00023125319594125202]\n",
      "[INFO: 2022-02-17 00:21:26,671]   LabelSmoothing Loss = 1.0908310413360596\n",
      "[INFO: 2022-02-17 00:21:36,280] Iteration 36540 (DataTime/BatchTime: 0.00447/0.48) losses = 1.829, lr = [2.311899030599885e-05, 0.0002311899030599885]\n",
      "[INFO: 2022-02-17 00:21:36,280]   LabelSmoothing Loss = 1.875543475151062\n",
      "[INFO: 2022-02-17 00:21:45,744] Iteration 36560 (DataTime/BatchTime: 0.00148/0.473) losses = 1.9026, lr = [2.311266621191604e-05, 0.00023112666211916037]\n",
      "[INFO: 2022-02-17 00:21:45,744]   LabelSmoothing Loss = 1.6863820552825928\n",
      "[INFO: 2022-02-17 00:21:55,269] Iteration 36580 (DataTime/BatchTime: 0.00334/0.476) losses = 1.6483, lr = [2.3106347304776615e-05, 0.00023106347304776613]\n",
      "[INFO: 2022-02-17 00:21:55,270]   LabelSmoothing Loss = 1.4831264019012451\n",
      "[INFO: 2022-02-17 00:22:04,824] Iteration 36600 (DataTime/BatchTime: 0.00147/0.478) losses = 1.9121, lr = [2.310003357749402e-05, 0.00023100033577494014]\n",
      "[INFO: 2022-02-17 00:22:04,824]   LabelSmoothing Loss = 1.805481195449829\n",
      "[INFO: 2022-02-17 00:22:14,507] Iteration 36620 (DataTime/BatchTime: 0.00154/0.484) losses = 1.9113, lr = [2.309372502299521e-05, 0.0002309372502299521]\n",
      "[INFO: 2022-02-17 00:22:14,507]   LabelSmoothing Loss = 1.5448685884475708\n",
      "[INFO: 2022-02-17 00:22:24,202] Iteration 36640 (DataTime/BatchTime: 0.0024/0.485) losses = 1.7266, lr = [2.3087421634220703e-05, 0.000230874216342207]\n",
      "[INFO: 2022-02-17 00:22:24,202]   LabelSmoothing Loss = 1.859306812286377\n",
      "[INFO: 2022-02-17 00:22:33,807] Iteration 36660 (DataTime/BatchTime: 0.0015/0.48) losses = 1.7065, lr = [2.3081123404124452e-05, 0.0002308112340412445]\n",
      "[INFO: 2022-02-17 00:22:33,807]   LabelSmoothing Loss = 1.4835350513458252\n",
      "[INFO: 2022-02-17 00:22:43,726] Iteration 36680 (DataTime/BatchTime: 0.00242/0.496) losses = 1.8899, lr = [2.307483032567389e-05, 0.00023074830325673886]\n",
      "[INFO: 2022-02-17 00:22:43,726]   LabelSmoothing Loss = 2.9783079624176025\n",
      "[INFO: 2022-02-17 00:22:53,483] Iteration 36700 (DataTime/BatchTime: 0.0024/0.488) losses = 1.7732, lr = [2.306854239184984e-05, 0.0002306854239184984]\n",
      "[INFO: 2022-02-17 00:22:53,483]   LabelSmoothing Loss = 1.2705999612808228\n",
      "[INFO: 2022-02-17 00:23:03,120] Iteration 36720 (DataTime/BatchTime: 0.00156/0.482) losses = 1.7716, lr = [2.3062259595646534e-05, 0.00023062259595646532]\n",
      "[INFO: 2022-02-17 00:23:03,120]   LabelSmoothing Loss = 1.3672019243240356\n",
      "[INFO: 2022-02-17 00:23:12,881] Iteration 36740 (DataTime/BatchTime: 0.00243/0.488) losses = 1.9429, lr = [2.3055981930071523e-05, 0.00023055981930071522]\n",
      "[INFO: 2022-02-17 00:23:12,881]   LabelSmoothing Loss = 1.6898224353790283\n",
      "[INFO: 2022-02-17 00:23:22,488] Iteration 36760 (DataTime/BatchTime: 0.00149/0.48) losses = 1.8414, lr = [2.30497093881457e-05, 0.00023049709388145697]\n",
      "[INFO: 2022-02-17 00:23:22,488]   LabelSmoothing Loss = 2.536930561065674\n",
      "[INFO: 2022-02-17 00:23:32,039] Iteration 36780 (DataTime/BatchTime: 0.00426/0.478) losses = 1.6165, lr = [2.304344196290323e-05, 0.00023043441962903224]\n",
      "[INFO: 2022-02-17 00:23:32,039]   LabelSmoothing Loss = 2.3551714420318604\n",
      "[INFO: 2022-02-17 00:23:41,677] Iteration 36800 (DataTime/BatchTime: 0.00155/0.482) losses = 1.9168, lr = [2.3037179647391523e-05, 0.0002303717964739152]\n",
      "[INFO: 2022-02-17 00:23:41,677]   LabelSmoothing Loss = 2.7808287143707275\n",
      "[INFO: 2022-02-17 00:23:51,207] Iteration 36820 (DataTime/BatchTime: 0.00152/0.477) losses = 1.9387, lr = [2.3030922434671217e-05, 0.00023030922434671215]\n",
      "[INFO: 2022-02-17 00:23:51,207]   LabelSmoothing Loss = 1.0853348970413208\n",
      "[INFO: 2022-02-17 00:24:00,852] Iteration 36840 (DataTime/BatchTime: 0.00151/0.482) losses = 1.7712, lr = [2.302467031781614e-05, 0.0002302467031781614]\n",
      "[INFO: 2022-02-17 00:24:00,852]   LabelSmoothing Loss = 2.0546486377716064\n",
      "[INFO: 2022-02-17 00:24:10,474] Iteration 36860 (DataTime/BatchTime: 0.00262/0.481) losses = 1.6556, lr = [2.301842328991327e-05, 0.0002301842328991327]\n",
      "[INFO: 2022-02-17 00:24:10,474]   LabelSmoothing Loss = 2.026962995529175\n",
      "[INFO: 2022-02-17 00:24:20,077] Iteration 36880 (DataTime/BatchTime: 0.0033/0.479) losses = 1.8436, lr = [2.3012181344062707e-05, 0.00023012181344062705]\n",
      "[INFO: 2022-02-17 00:24:20,077]   LabelSmoothing Loss = 1.938019871711731\n",
      "[INFO: 2022-02-17 00:24:29,800] Iteration 36900 (DataTime/BatchTime: 0.00328/0.487) losses = 1.8318, lr = [2.3005944473377634e-05, 0.00023005944473377632]\n",
      "[INFO: 2022-02-17 00:24:29,800]   LabelSmoothing Loss = 1.518867015838623\n",
      "[INFO: 2022-02-17 00:24:39,358] Iteration 36920 (DataTime/BatchTime: 0.0024/0.478) losses = 1.8213, lr = [2.299971267098431e-05, 0.00022999712670984307]\n",
      "[INFO: 2022-02-17 00:24:39,358]   LabelSmoothing Loss = 2.4030725955963135\n",
      "[INFO: 2022-02-17 00:24:49,115] Iteration 36940 (DataTime/BatchTime: 0.00258/0.488) losses = 1.8537, lr = [2.2993485930021998e-05, 0.00022993485930021995]\n",
      "[INFO: 2022-02-17 00:24:49,115]   LabelSmoothing Loss = 1.4087821245193481\n",
      "[INFO: 2022-02-17 00:24:58,763] Iteration 36960 (DataTime/BatchTime: 0.00265/0.482) losses = 1.9571, lr = [2.2987264243642977e-05, 0.00022987264243642974]\n",
      "[INFO: 2022-02-17 00:24:58,763]   LabelSmoothing Loss = 1.7385107278823853\n",
      "[INFO: 2022-02-17 00:25:08,330] Iteration 36980 (DataTime/BatchTime: 0.00325/0.478) losses = 1.7837, lr = [2.2981047605012474e-05, 0.00022981047605012472]\n",
      "[INFO: 2022-02-17 00:25:08,330]   LabelSmoothing Loss = 0.8271219730377197\n",
      "[INFO: 2022-02-17 00:25:17,917] Iteration 37000 (DataTime/BatchTime: 0.00236/0.479) losses = 1.847, lr = [2.2974836007308662e-05, 0.00022974836007308658]\n",
      "[INFO: 2022-02-17 00:25:17,917]   LabelSmoothing Loss = 2.0145606994628906\n",
      "[INFO: 2022-02-17 00:25:27,487] Iteration 37020 (DataTime/BatchTime: 0.00246/0.478) losses = 1.8151, lr = [2.2968629443722595e-05, 0.0002296862944372259]\n",
      "[INFO: 2022-02-17 00:25:27,487]   LabelSmoothing Loss = 2.200343370437622\n",
      "[INFO: 2022-02-17 00:25:37,120] Iteration 37040 (DataTime/BatchTime: 0.00251/0.482) losses = 1.7374, lr = [2.2962427907458214e-05, 0.00022962427907458212]\n",
      "[INFO: 2022-02-17 00:25:37,120]   LabelSmoothing Loss = 1.3474901914596558\n",
      "[INFO: 2022-02-17 00:25:46,797] Iteration 37060 (DataTime/BatchTime: 0.00171/0.484) losses = 1.9378, lr = [2.295623139173229e-05, 0.0002295623139173229]\n",
      "[INFO: 2022-02-17 00:25:46,797]   LabelSmoothing Loss = 3.038975715637207\n",
      "[INFO: 2022-02-17 00:25:56,528] Iteration 37080 (DataTime/BatchTime: 0.00157/0.487) losses = 1.8552, lr = [2.29500398897744e-05, 0.00022950039889774401]\n",
      "[INFO: 2022-02-17 00:25:56,528]   LabelSmoothing Loss = 1.9320998191833496\n",
      "[INFO: 2022-02-17 00:26:06,161] Iteration 37100 (DataTime/BatchTime: 0.0024/0.482) losses = 1.8827, lr = [2.2943853394826902e-05, 0.00022943853394826898]\n",
      "[INFO: 2022-02-17 00:26:06,161]   LabelSmoothing Loss = 2.274474620819092\n",
      "[INFO: 2022-02-17 00:26:15,686] Iteration 37120 (DataTime/BatchTime: 0.00144/0.476) losses = 1.5492, lr = [2.2937671900144887e-05, 0.00022937671900144884]\n",
      "[INFO: 2022-02-17 00:26:15,686]   LabelSmoothing Loss = 1.8872889280319214\n",
      "[INFO: 2022-02-17 00:26:25,275] Iteration 37140 (DataTime/BatchTime: 0.00239/0.479) losses = 1.6997, lr = [2.293149539899617e-05, 0.00022931495398996165]\n",
      "[INFO: 2022-02-17 00:26:25,275]   LabelSmoothing Loss = 2.040897846221924\n",
      "[INFO: 2022-02-17 00:26:34,798] Iteration 37160 (DataTime/BatchTime: 0.00243/0.476) losses = 1.6976, lr = [2.2925323884661243e-05, 0.0002292532388466124]\n",
      "[INFO: 2022-02-17 00:26:34,798]   LabelSmoothing Loss = 1.3211346864700317\n",
      "[INFO: 2022-02-17 00:26:44,354] Iteration 37180 (DataTime/BatchTime: 0.00236/0.478) losses = 1.659, lr = [2.2919157350433256e-05, 0.00022919157350433252]\n",
      "[INFO: 2022-02-17 00:26:44,354]   LabelSmoothing Loss = 0.802592933177948\n",
      "[INFO: 2022-02-17 00:26:53,981] Iteration 37200 (DataTime/BatchTime: 0.00145/0.481) losses = 1.7538, lr = [2.2912995789617973e-05, 0.0002291299578961797]\n",
      "[INFO: 2022-02-17 00:26:53,981]   LabelSmoothing Loss = 1.4910869598388672\n",
      "[INFO: 2022-02-17 00:27:03,565] Iteration 37220 (DataTime/BatchTime: 0.00515/0.479) losses = 1.6399, lr = [2.2906839195533757e-05, 0.00022906839195533754]\n",
      "[INFO: 2022-02-17 00:27:03,565]   LabelSmoothing Loss = 1.7226271629333496\n",
      "[INFO: 2022-02-17 00:27:13,123] Iteration 37240 (DataTime/BatchTime: 0.00152/0.478) losses = 1.8441, lr = [2.290068756151152e-05, 0.0002290068756151152]\n",
      "[INFO: 2022-02-17 00:27:13,123]   LabelSmoothing Loss = 2.2033262252807617\n",
      "[INFO: 2022-02-17 00:30:48,777] ######## Epoch (VAL)39 ########\n",
      "[INFO: 2022-02-17 00:30:48,777] {'Bleu_1': 0.3667351949485423, 'Bleu_2': 0.22276241598592275, 'Bleu_3': 0.14720273285556346, 'Bleu_4': 0.10195318577562709, 'METEOR': 0.18751899100812067, 'ROUGE_L': 0.2984068170395035, 'CIDEr': 0.30713537165097027}\n",
      "[INFO: 2022-02-17 00:34:25,851] ######## Epoch (TEST)39 ########\n",
      "[INFO: 2022-02-17 00:34:25,851] {'Bleu_1': 0.34582513644871393, 'Bleu_2': 0.2033898274098132, 'Bleu_3': 0.13144874554912603, 'Bleu_4': 0.0893891652400853, 'METEOR': 0.17815603709222674, 'ROUGE_L': 0.2860034497288279, 'CIDEr': 0.3036630862246032}\n",
      "[INFO: 2022-02-17 00:34:34,595] Iteration 37260 (DataTime/BatchTime: 0.0717/0.546) losses = 1.898, lr = [2.289454088089472e-05, 0.00022894540880894718]\n",
      "[INFO: 2022-02-17 00:34:34,595]   LabelSmoothing Loss = 1.3372610807418823\n",
      "[INFO: 2022-02-17 00:34:44,111] Iteration 37280 (DataTime/BatchTime: 0.00217/0.476) losses = 2.0187, lr = [2.28883991470393e-05, 0.00022888399147039297]\n",
      "[INFO: 2022-02-17 00:34:44,111]   LabelSmoothing Loss = 1.9565645456314087\n",
      "[INFO: 2022-02-17 00:34:53,654] Iteration 37300 (DataTime/BatchTime: 0.00125/0.477) losses = 1.7781, lr = [2.288226235331368e-05, 0.0002288226235331368]\n",
      "[INFO: 2022-02-17 00:34:53,654]   LabelSmoothing Loss = 1.8038915395736694\n",
      "[INFO: 2022-02-17 00:35:03,152] Iteration 37320 (DataTime/BatchTime: 0.00213/0.475) losses = 1.8631, lr = [2.287613049309872e-05, 0.00022876130493098719]\n",
      "[INFO: 2022-02-17 00:35:03,152]   LabelSmoothing Loss = 1.2224282026290894\n",
      "[INFO: 2022-02-17 00:35:12,685] Iteration 37340 (DataTime/BatchTime: 0.00134/0.477) losses = 1.8316, lr = [2.287000355978769e-05, 0.00022870003559787686]\n",
      "[INFO: 2022-02-17 00:35:12,685]   LabelSmoothing Loss = 2.290748357772827\n",
      "[INFO: 2022-02-17 00:35:22,271] Iteration 37360 (DataTime/BatchTime: 0.00133/0.479) losses = 1.8876, lr = [2.2863881546786233e-05, 0.00022863881546786232]\n",
      "[INFO: 2022-02-17 00:35:22,271]   LabelSmoothing Loss = 2.182393789291382\n",
      "[INFO: 2022-02-17 00:35:31,744] Iteration 37380 (DataTime/BatchTime: 0.00298/0.474) losses = 1.6958, lr = [2.2857764447512353e-05, 0.00022857764447512349]\n",
      "[INFO: 2022-02-17 00:35:31,744]   LabelSmoothing Loss = 1.6869746446609497\n",
      "[INFO: 2022-02-17 00:35:41,328] Iteration 37400 (DataTime/BatchTime: 0.00131/0.479) losses = 2.1084, lr = [2.2851652255396363e-05, 0.0002285165225539636]\n",
      "[INFO: 2022-02-17 00:35:41,329]   LabelSmoothing Loss = 1.9439464807510376\n",
      "[INFO: 2022-02-17 00:35:50,877] Iteration 37420 (DataTime/BatchTime: 0.00218/0.477) losses = 1.7452, lr = [2.2845544963880872e-05, 0.0002284554496388087]\n",
      "[INFO: 2022-02-17 00:35:50,878]   LabelSmoothing Loss = 1.4315825700759888\n",
      "[INFO: 2022-02-17 00:36:00,428] Iteration 37440 (DataTime/BatchTime: 0.00134/0.478) losses = 1.7317, lr = [2.2839442566420752e-05, 0.00022839442566420748]\n",
      "[INFO: 2022-02-17 00:36:00,428]   LabelSmoothing Loss = 1.6861813068389893\n",
      "[INFO: 2022-02-17 00:36:09,956] Iteration 37460 (DataTime/BatchTime: 0.00131/0.476) losses = 1.5861, lr = [2.2833345056483105e-05, 0.00022833345056483105]\n",
      "[INFO: 2022-02-17 00:36:09,956]   LabelSmoothing Loss = 1.6100414991378784\n",
      "[INFO: 2022-02-17 00:36:19,479] Iteration 37480 (DataTime/BatchTime: 0.00129/0.476) losses = 2.0343, lr = [2.2827252427547235e-05, 0.00022827252427547233]\n",
      "[INFO: 2022-02-17 00:36:19,480]   LabelSmoothing Loss = 1.9896762371063232\n",
      "[INFO: 2022-02-17 00:36:29,057] Iteration 37500 (DataTime/BatchTime: 0.00127/0.479) losses = 1.6871, lr = [2.282116467310462e-05, 0.00022821164673104616]\n",
      "[INFO: 2022-02-17 00:36:29,057]   LabelSmoothing Loss = 0.7287952303886414\n",
      "[INFO: 2022-02-17 00:36:38,538] Iteration 37520 (DataTime/BatchTime: 0.00233/0.474) losses = 1.5208, lr = [2.2815081786658874e-05, 0.0002281508178665887]\n",
      "[INFO: 2022-02-17 00:36:38,539]   LabelSmoothing Loss = 1.5888092517852783\n",
      "[INFO: 2022-02-17 00:36:48,093] Iteration 37540 (DataTime/BatchTime: 0.00128/0.478) losses = 1.8315, lr = [2.2809003761725738e-05, 0.00022809003761725734]\n",
      "[INFO: 2022-02-17 00:36:48,093]   LabelSmoothing Loss = 1.1739519834518433\n",
      "[INFO: 2022-02-17 00:36:57,569] Iteration 37560 (DataTime/BatchTime: 0.00131/0.474) losses = 1.7161, lr = [2.2802930591833027e-05, 0.00022802930591833025]\n",
      "[INFO: 2022-02-17 00:36:57,569]   LabelSmoothing Loss = 0.4813412129878998\n",
      "[INFO: 2022-02-17 00:37:07,128] Iteration 37580 (DataTime/BatchTime: 0.0013/0.478) losses = 1.8249, lr = [2.2796862270520627e-05, 0.00022796862270520624]\n",
      "[INFO: 2022-02-17 00:37:07,128]   LabelSmoothing Loss = 2.3037116527557373\n",
      "[INFO: 2022-02-17 00:37:16,677] Iteration 37600 (DataTime/BatchTime: 0.00212/0.477) losses = 1.8078, lr = [2.2790798791340436e-05, 0.00022790798791340433]\n",
      "[INFO: 2022-02-17 00:37:16,677]   LabelSmoothing Loss = 2.1774394512176514\n",
      "[INFO: 2022-02-17 00:37:26,186] Iteration 37620 (DataTime/BatchTime: 0.00129/0.475) losses = 1.7645, lr = [2.2784740147856362e-05, 0.0002278474014785636]\n",
      "[INFO: 2022-02-17 00:37:26,186]   LabelSmoothing Loss = 2.1590774059295654\n",
      "[INFO: 2022-02-17 00:37:35,657] Iteration 37640 (DataTime/BatchTime: 0.00127/0.474) losses = 1.8492, lr = [2.2778686333644273e-05, 0.0002277868633364427]\n",
      "[INFO: 2022-02-17 00:37:35,657]   LabelSmoothing Loss = 1.5887603759765625\n",
      "[INFO: 2022-02-17 00:37:45,144] Iteration 37660 (DataTime/BatchTime: 0.00127/0.474) losses = 1.6597, lr = [2.2772637342291995e-05, 0.0002277263734229199]\n",
      "[INFO: 2022-02-17 00:37:45,145]   LabelSmoothing Loss = 0.9881386160850525\n",
      "[INFO: 2022-02-17 00:37:54,660] Iteration 37680 (DataTime/BatchTime: 0.00128/0.476) losses = 1.6603, lr = [2.276659316739925e-05, 0.00022766593167399245]\n",
      "[INFO: 2022-02-17 00:37:54,660]   LabelSmoothing Loss = 2.3895726203918457\n",
      "[INFO: 2022-02-17 00:38:04,171] Iteration 37700 (DataTime/BatchTime: 0.00129/0.476) losses = 1.8232, lr = [2.276055380257765e-05, 0.0002276055380257765]\n",
      "[INFO: 2022-02-17 00:38:04,171]   LabelSmoothing Loss = 2.247525691986084\n",
      "[INFO: 2022-02-17 00:38:13,794] Iteration 37720 (DataTime/BatchTime: 0.00129/0.481) losses = 1.6093, lr = [2.2754519241450674e-05, 0.00022754519241450672]\n",
      "[INFO: 2022-02-17 00:38:13,794]   LabelSmoothing Loss = 1.655498743057251\n",
      "[INFO: 2022-02-17 00:38:23,335] Iteration 37740 (DataTime/BatchTime: 0.00129/0.477) losses = 1.8516, lr = [2.2748489477653616e-05, 0.00022748489477653611]\n",
      "[INFO: 2022-02-17 00:38:23,335]   LabelSmoothing Loss = 1.344045877456665\n",
      "[INFO: 2022-02-17 00:38:32,879] Iteration 37760 (DataTime/BatchTime: 0.00126/0.477) losses = 1.9396, lr = [2.2742464504833574e-05, 0.0002274246450483357]\n",
      "[INFO: 2022-02-17 00:38:32,879]   LabelSmoothing Loss = 3.219106435775757\n",
      "[INFO: 2022-02-17 00:38:42,468] Iteration 37780 (DataTime/BatchTime: 0.00132/0.479) losses = 1.9128, lr = [2.2736444316649415e-05, 0.00022736444316649412]\n",
      "[INFO: 2022-02-17 00:38:42,468]   LabelSmoothing Loss = 2.4058167934417725\n",
      "[INFO: 2022-02-17 00:38:51,928] Iteration 37800 (DataTime/BatchTime: 0.00126/0.473) losses = 1.6951, lr = [2.2730428906771757e-05, 0.00022730428906771755]\n",
      "[INFO: 2022-02-17 00:38:51,928]   LabelSmoothing Loss = 1.4187859296798706\n",
      "[INFO: 2022-02-17 00:39:01,432] Iteration 37820 (DataTime/BatchTime: 0.00126/0.475) losses = 1.7747, lr = [2.2724418268882933e-05, 0.0002272441826888293]\n",
      "[INFO: 2022-02-17 00:39:01,432]   LabelSmoothing Loss = 1.8254371881484985\n",
      "[INFO: 2022-02-17 00:39:10,912] Iteration 37840 (DataTime/BatchTime: 0.00128/0.474) losses = 1.6652, lr = [2.2718412396676953e-05, 0.0002271841239667695]\n",
      "[INFO: 2022-02-17 00:39:10,912]   LabelSmoothing Loss = 1.9277287721633911\n",
      "[INFO: 2022-02-17 00:39:20,426] Iteration 37860 (DataTime/BatchTime: 0.00128/0.476) losses = 1.7065, lr = [2.2712411283859504e-05, 0.000227124112838595]\n",
      "[INFO: 2022-02-17 00:39:20,426]   LabelSmoothing Loss = 2.9983060359954834\n",
      "[INFO: 2022-02-17 00:39:29,945] Iteration 37880 (DataTime/BatchTime: 0.00126/0.476) losses = 1.7908, lr = [2.2706414924147886e-05, 0.00022706414924147884]\n",
      "[INFO: 2022-02-17 00:39:29,945]   LabelSmoothing Loss = 1.3316837549209595\n",
      "[INFO: 2022-02-17 00:39:39,514] Iteration 37900 (DataTime/BatchTime: 0.00126/0.478) losses = 2.0805, lr = [2.270042331127102e-05, 0.00022700423311271018]\n",
      "[INFO: 2022-02-17 00:39:39,514]   LabelSmoothing Loss = 1.973511815071106\n",
      "[INFO: 2022-02-17 00:39:49,016] Iteration 37920 (DataTime/BatchTime: 0.00128/0.475) losses = 1.5902, lr = [2.2694436438969396e-05, 0.00022694436438969396]\n",
      "[INFO: 2022-02-17 00:39:49,017]   LabelSmoothing Loss = 1.2058581113815308\n",
      "[INFO: 2022-02-17 00:39:58,907] Iteration 37940 (DataTime/BatchTime: 0.0015/0.495) losses = 1.8456, lr = [2.268845430099506e-05, 0.0002268845430099506]\n",
      "[INFO: 2022-02-17 00:39:58,908]   LabelSmoothing Loss = 1.2592806816101074\n",
      "[INFO: 2022-02-17 00:40:08,612] Iteration 37960 (DataTime/BatchTime: 0.00228/0.485) losses = 1.8763, lr = [2.268247689111158e-05, 0.00022682476891111575]\n",
      "[INFO: 2022-02-17 00:40:08,612]   LabelSmoothing Loss = 2.560840368270874\n",
      "[INFO: 2022-02-17 00:40:18,216] Iteration 37980 (DataTime/BatchTime: 0.00216/0.48) losses = 1.7113, lr = [2.2676504203094e-05, 0.00022676504203094]\n",
      "[INFO: 2022-02-17 00:40:18,216]   LabelSmoothing Loss = 1.081732988357544\n",
      "[INFO: 2022-02-17 00:40:27,971] Iteration 38000 (DataTime/BatchTime: 0.00226/0.488) losses = 2.0248, lr = [2.2670536230728865e-05, 0.00022670536230728864]\n",
      "[INFO: 2022-02-17 00:40:27,971]   LabelSmoothing Loss = 2.5506505966186523\n",
      "[INFO: 2022-02-17 00:40:37,639] Iteration 38020 (DataTime/BatchTime: 0.00157/0.483) losses = 1.7965, lr = [2.266457296781414e-05, 0.00022664572967814138]\n",
      "[INFO: 2022-02-17 00:40:37,639]   LabelSmoothing Loss = 1.1378593444824219\n",
      "[INFO: 2022-02-17 00:40:47,242] Iteration 38040 (DataTime/BatchTime: 0.00424/0.48) losses = 1.5901, lr = [2.26586144081592e-05, 0.00022658614408159196]\n",
      "[INFO: 2022-02-17 00:40:47,242]   LabelSmoothing Loss = 1.6933250427246094\n",
      "[INFO: 2022-02-17 00:40:56,896] Iteration 38060 (DataTime/BatchTime: 0.00135/0.483) losses = 1.9143, lr = [2.2652660545584816e-05, 0.00022652660545584814]\n",
      "[INFO: 2022-02-17 00:40:56,896]   LabelSmoothing Loss = 1.1058357954025269\n",
      "[INFO: 2022-02-17 00:41:06,656] Iteration 38080 (DataTime/BatchTime: 0.00137/0.488) losses = 1.7035, lr = [2.264671137392312e-05, 0.00022646711373923117]\n",
      "[INFO: 2022-02-17 00:41:06,656]   LabelSmoothing Loss = 2.6090457439422607\n",
      "[INFO: 2022-02-17 00:41:16,236] Iteration 38100 (DataTime/BatchTime: 0.0023/0.479) losses = 1.7763, lr = [2.2640766887017577e-05, 0.00022640766887017572]\n",
      "[INFO: 2022-02-17 00:41:16,236]   LabelSmoothing Loss = 1.3420495986938477\n",
      "[INFO: 2022-02-17 00:41:25,813] Iteration 38120 (DataTime/BatchTime: 0.00234/0.479) losses = 1.8805, lr = [2.2634827078722943e-05, 0.00022634827078722939]\n",
      "[INFO: 2022-02-17 00:41:25,813]   LabelSmoothing Loss = 1.7845820188522339\n",
      "[INFO: 2022-02-17 00:41:35,349] Iteration 38140 (DataTime/BatchTime: 0.00127/0.477) losses = 1.7576, lr = [2.2628891942905274e-05, 0.00022628891942905272]\n",
      "[INFO: 2022-02-17 00:41:35,349]   LabelSmoothing Loss = 1.4782912731170654\n",
      "[INFO: 2022-02-17 00:41:44,864] Iteration 38160 (DataTime/BatchTime: 0.00375/0.476) losses = 1.7783, lr = [2.262296147344187e-05, 0.0002262296147344187]\n",
      "[INFO: 2022-02-17 00:41:44,864]   LabelSmoothing Loss = 1.9680324792861938\n",
      "[INFO: 2022-02-17 00:41:54,460] Iteration 38180 (DataTime/BatchTime: 0.00129/0.48) losses = 1.8784, lr = [2.2617035664221255e-05, 0.00022617035664221252]\n",
      "[INFO: 2022-02-17 00:41:54,460]   LabelSmoothing Loss = 1.4923330545425415\n",
      "[INFO: 2022-02-17 00:45:37,945] ######## Epoch (VAL)40 ########\n",
      "[INFO: 2022-02-17 00:45:37,945] {'Bleu_1': 0.3551910787257583, 'Bleu_2': 0.2152821221708602, 'Bleu_3': 0.14341616530544699, 'Bleu_4': 0.09913815396705616, 'METEOR': 0.18482659865184536, 'ROUGE_L': 0.30119122837272017, 'CIDEr': 0.30051564602711256}\n",
      "[INFO: 2022-02-17 00:49:19,595] ######## Epoch (TEST)40 ########\n",
      "[INFO: 2022-02-17 00:49:19,595] {'Bleu_1': 0.3421890576386531, 'Bleu_2': 0.200450653036498, 'Bleu_3': 0.12840894907697037, 'Bleu_4': 0.08470009406334543, 'METEOR': 0.17930862687417498, 'ROUGE_L': 0.28505061713725716, 'CIDEr': 0.1924346555276385}\n",
      "[INFO: 2022-02-17 00:49:21,212] Iteration 38200 (DataTime/BatchTime: 1.0/1.62) losses = 2.0784, lr = [2.2611114509143156e-05, 0.00022611114509143155]\n",
      "[INFO: 2022-02-17 00:49:21,212]   LabelSmoothing Loss = 2.078446626663208\n",
      "[INFO: 2022-02-17 00:49:30,829] Iteration 38220 (DataTime/BatchTime: 0.00239/0.481) losses = 1.739, lr = [2.2605198002118473e-05, 0.0002260519800211847]\n",
      "[INFO: 2022-02-17 00:49:30,830]   LabelSmoothing Loss = 1.6233736276626587\n",
      "[INFO: 2022-02-17 00:49:40,253] Iteration 38240 (DataTime/BatchTime: 0.00404/0.471) losses = 1.7287, lr = [2.2599286137069257e-05, 0.00022599286137069255]\n",
      "[INFO: 2022-02-17 00:49:40,253]   LabelSmoothing Loss = 0.8573557734489441\n",
      "[INFO: 2022-02-17 00:49:49,897] Iteration 38260 (DataTime/BatchTime: 0.0032/0.482) losses = 1.7241, lr = [2.259337890792867e-05, 0.0002259337890792867]\n",
      "[INFO: 2022-02-17 00:49:49,897]   LabelSmoothing Loss = 2.4671695232391357\n",
      "[INFO: 2022-02-17 00:49:59,666] Iteration 38280 (DataTime/BatchTime: 0.00168/0.488) losses = 1.7797, lr = [2.258747630864098e-05, 0.00022587476308640975]\n",
      "[INFO: 2022-02-17 00:49:59,667]   LabelSmoothing Loss = 2.1850578784942627\n",
      "[INFO: 2022-02-17 00:50:09,238] Iteration 38300 (DataTime/BatchTime: 0.00154/0.479) losses = 1.7756, lr = [2.2581578333161515e-05, 0.00022581578333161513]\n",
      "[INFO: 2022-02-17 00:50:09,239]   LabelSmoothing Loss = 1.9561232328414917\n",
      "[INFO: 2022-02-17 00:50:18,791] Iteration 38320 (DataTime/BatchTime: 0.00236/0.478) losses = 1.9757, lr = [2.2575684975456648e-05, 0.00022575684975456646]\n",
      "[INFO: 2022-02-17 00:50:18,791]   LabelSmoothing Loss = 2.120027780532837\n",
      "[INFO: 2022-02-17 00:50:28,454] Iteration 38340 (DataTime/BatchTime: 0.00162/0.482) losses = 1.8045, lr = [2.2569796229503778e-05, 0.00022569796229503775]\n",
      "[INFO: 2022-02-17 00:50:28,454]   LabelSmoothing Loss = 1.8615660667419434\n",
      "[INFO: 2022-02-17 00:50:38,258] Iteration 38360 (DataTime/BatchTime: 0.00281/0.491) losses = 1.6559, lr = [2.2563912089291285e-05, 0.0002256391208929128]\n",
      "[INFO: 2022-02-17 00:50:38,258]   LabelSmoothing Loss = 1.4839483499526978\n",
      "[INFO: 2022-02-17 00:50:48,231] Iteration 38380 (DataTime/BatchTime: 0.00195/0.499) losses = 1.9316, lr = [2.2558032548818512e-05, 0.0002255803254881851]\n",
      "[INFO: 2022-02-17 00:50:48,231]   LabelSmoothing Loss = 1.6584808826446533\n",
      "[INFO: 2022-02-17 00:50:58,224] Iteration 38400 (DataTime/BatchTime: 0.00285/0.5) losses = 1.7076, lr = [2.2552157602095752e-05, 0.0002255215760209575]\n",
      "[INFO: 2022-02-17 00:50:58,224]   LabelSmoothing Loss = 2.228160858154297\n",
      "[INFO: 2022-02-17 00:51:07,929] Iteration 38420 (DataTime/BatchTime: 0.0053/0.484) losses = 1.7598, lr = [2.2546287243144205e-05, 0.00022546287243144203]\n",
      "[INFO: 2022-02-17 00:51:07,930]   LabelSmoothing Loss = 2.9434611797332764\n",
      "[INFO: 2022-02-17 00:51:17,595] Iteration 38440 (DataTime/BatchTime: 0.00382/0.484) losses = 1.7259, lr = [2.254042146599596e-05, 0.00022540421465995958]\n",
      "[INFO: 2022-02-17 00:51:17,595]   LabelSmoothing Loss = 0.8094706535339355\n",
      "[INFO: 2022-02-17 00:51:27,300] Iteration 38460 (DataTime/BatchTime: 0.00333/0.485) losses = 1.7134, lr = [2.2534560264693967e-05, 0.00022534560264693965]\n",
      "[INFO: 2022-02-17 00:51:27,300]   LabelSmoothing Loss = 1.8703033924102783\n",
      "[INFO: 2022-02-17 00:51:36,985] Iteration 38480 (DataTime/BatchTime: 0.00141/0.484) losses = 1.8658, lr = [2.252870363329202e-05, 0.0002252870363329202]\n",
      "[INFO: 2022-02-17 00:51:36,985]   LabelSmoothing Loss = 2.3796169757843018\n",
      "[INFO: 2022-02-17 00:51:46,558] Iteration 38500 (DataTime/BatchTime: 0.00216/0.479) losses = 1.6839, lr = [2.2522851565854723e-05, 0.0002252285156585472]\n",
      "[INFO: 2022-02-17 00:51:46,558]   LabelSmoothing Loss = 1.680437684059143\n",
      "[INFO: 2022-02-17 00:51:56,177] Iteration 38520 (DataTime/BatchTime: 0.00141/0.481) losses = 1.6807, lr = [2.251700405645746e-05, 0.00022517004056457455]\n",
      "[INFO: 2022-02-17 00:51:56,177]   LabelSmoothing Loss = 1.2054842710494995\n",
      "[INFO: 2022-02-17 00:52:05,797] Iteration 38540 (DataTime/BatchTime: 0.00139/0.481) losses = 1.8553, lr = [2.2511161099186378e-05, 0.00022511161099186377]\n",
      "[INFO: 2022-02-17 00:52:05,797]   LabelSmoothing Loss = 2.207153081893921\n",
      "[INFO: 2022-02-17 00:52:15,414] Iteration 38560 (DataTime/BatchTime: 0.00218/0.481) losses = 1.8446, lr = [2.2505322688138375e-05, 0.0002250532268813837]\n",
      "[INFO: 2022-02-17 00:52:15,415]   LabelSmoothing Loss = 1.248388409614563\n",
      "[INFO: 2022-02-17 00:52:25,210] Iteration 38580 (DataTime/BatchTime: 0.00153/0.49) losses = 1.6563, lr = [2.249948881742104e-05, 0.00022499488817421037]\n",
      "[INFO: 2022-02-17 00:52:25,210]   LabelSmoothing Loss = 2.2211384773254395\n",
      "[INFO: 2022-02-17 00:52:34,698] Iteration 38600 (DataTime/BatchTime: 0.00238/0.474) losses = 1.6658, lr = [2.2493659481152667e-05, 0.00022493659481152666]\n",
      "[INFO: 2022-02-17 00:52:34,699]   LabelSmoothing Loss = 1.7298165559768677\n",
      "[INFO: 2022-02-17 00:52:44,465] Iteration 38620 (DataTime/BatchTime: 0.00383/0.488) losses = 1.9435, lr = [2.2487834673462196e-05, 0.00022487834673462194]\n",
      "[INFO: 2022-02-17 00:52:44,465]   LabelSmoothing Loss = 1.4848923683166504\n",
      "[INFO: 2022-02-17 00:52:53,926] Iteration 38640 (DataTime/BatchTime: 0.00199/0.473) losses = 1.5858, lr = [2.2482014388489216e-05, 0.00022482014388489213]\n",
      "[INFO: 2022-02-17 00:52:53,926]   LabelSmoothing Loss = 1.7039682865142822\n",
      "[INFO: 2022-02-17 00:53:03,429] Iteration 38660 (DataTime/BatchTime: 0.00119/0.475) losses = 1.6064, lr = [2.2476198620383917e-05, 0.00022476198620383913]\n",
      "[INFO: 2022-02-17 00:53:03,429]   LabelSmoothing Loss = 0.9599164724349976\n",
      "[INFO: 2022-02-17 00:53:12,940] Iteration 38680 (DataTime/BatchTime: 0.00204/0.476) losses = 1.7081, lr = [2.2470387363307087e-05, 0.0002247038736330708]\n",
      "[INFO: 2022-02-17 00:53:12,941]   LabelSmoothing Loss = 0.8169649839401245\n",
      "[INFO: 2022-02-17 00:53:22,453] Iteration 38700 (DataTime/BatchTime: 0.00126/0.476) losses = 1.6995, lr = [2.2464580611430066e-05, 0.00022464580611430062]\n",
      "[INFO: 2022-02-17 00:53:22,453]   LabelSmoothing Loss = 1.495301604270935\n",
      "[INFO: 2022-02-17 00:53:32,123] Iteration 38720 (DataTime/BatchTime: 0.00332/0.483) losses = 1.9411, lr = [2.2458778358934744e-05, 0.00022458778358934743]\n",
      "[INFO: 2022-02-17 00:53:32,123]   LabelSmoothing Loss = 1.5494366884231567\n",
      "[INFO: 2022-02-17 00:53:41,835] Iteration 38740 (DataTime/BatchTime: 0.00142/0.486) losses = 1.701, lr = [2.2452980600013517e-05, 0.00022452980600013513]\n",
      "[INFO: 2022-02-17 00:53:41,835]   LabelSmoothing Loss = 2.5660417079925537\n",
      "[INFO: 2022-02-17 00:53:51,695] Iteration 38760 (DataTime/BatchTime: 0.00401/0.493) losses = 1.7524, lr = [2.244718732886927e-05, 0.00022447187328869267]\n",
      "[INFO: 2022-02-17 00:53:51,695]   LabelSmoothing Loss = 2.5097594261169434\n",
      "[INFO: 2022-02-17 00:54:01,360] Iteration 38780 (DataTime/BatchTime: 0.00208/0.483) losses = 2.0381, lr = [2.2441398539715356e-05, 0.00022441398539715354]\n",
      "[INFO: 2022-02-17 00:54:01,360]   LabelSmoothing Loss = 2.7186949253082275\n",
      "[INFO: 2022-02-17 00:54:11,017] Iteration 38800 (DataTime/BatchTime: 0.00136/0.483) losses = 1.8424, lr = [2.243561422677557e-05, 0.00022435614226775567]\n",
      "[INFO: 2022-02-17 00:54:11,017]   LabelSmoothing Loss = 1.7084990739822388\n",
      "[INFO: 2022-02-17 00:54:20,602] Iteration 38820 (DataTime/BatchTime: 0.00214/0.479) losses = 1.5955, lr = [2.2429834384284116e-05, 0.00022429834384284113]\n",
      "[INFO: 2022-02-17 00:54:20,603]   LabelSmoothing Loss = 2.4651122093200684\n",
      "[INFO: 2022-02-17 00:54:30,335] Iteration 38840 (DataTime/BatchTime: 0.00136/0.487) losses = 1.8401, lr = [2.24240590064856e-05, 0.00022424059006485598]\n",
      "[INFO: 2022-02-17 00:54:30,335]   LabelSmoothing Loss = 1.8231922388076782\n",
      "[INFO: 2022-02-17 00:54:40,042] Iteration 38860 (DataTime/BatchTime: 0.00129/0.485) losses = 1.8476, lr = [2.2418288087634987e-05, 0.00022418288087634982]\n",
      "[INFO: 2022-02-17 00:54:40,042]   LabelSmoothing Loss = 1.1229294538497925\n",
      "[INFO: 2022-02-17 00:54:49,772] Iteration 38880 (DataTime/BatchTime: 0.00237/0.486) losses = 1.7239, lr = [2.2412521621997594e-05, 0.0002241252162199759]\n",
      "[INFO: 2022-02-17 00:54:49,772]   LabelSmoothing Loss = 2.395580530166626\n",
      "[INFO: 2022-02-17 00:54:59,441] Iteration 38900 (DataTime/BatchTime: 0.00225/0.483) losses = 1.8491, lr = [2.240675960384905e-05, 0.00022406759603849048]\n",
      "[INFO: 2022-02-17 00:54:59,441]   LabelSmoothing Loss = 1.9991341829299927\n",
      "[INFO: 2022-02-17 00:55:09,070] Iteration 38920 (DataTime/BatchTime: 0.00219/0.481) losses = 1.5727, lr = [2.2401002027475292e-05, 0.0002240100202747529]\n",
      "[INFO: 2022-02-17 00:55:09,070]   LabelSmoothing Loss = 1.2576186656951904\n",
      "[INFO: 2022-02-17 00:55:18,655] Iteration 38940 (DataTime/BatchTime: 0.00201/0.479) losses = 1.9492, lr = [2.2395248887172517e-05, 0.00022395248887172517]\n",
      "[INFO: 2022-02-17 00:55:18,656]   LabelSmoothing Loss = 2.345109701156616\n",
      "[INFO: 2022-02-17 00:55:28,251] Iteration 38960 (DataTime/BatchTime: 0.00227/0.48) losses = 1.7359, lr = [2.238950017724718e-05, 0.0002238950017724718]\n",
      "[INFO: 2022-02-17 00:55:28,251]   LabelSmoothing Loss = 1.4550389051437378\n",
      "[INFO: 2022-02-17 00:55:37,808] Iteration 38980 (DataTime/BatchTime: 0.00122/0.477) losses = 1.8659, lr = [2.2383755892015958e-05, 0.00022383755892015956]\n",
      "[INFO: 2022-02-17 00:55:37,808]   LabelSmoothing Loss = 2.171842575073242\n",
      "[INFO: 2022-02-17 00:55:47,411] Iteration 39000 (DataTime/BatchTime: 0.00305/0.481) losses = 1.8894, lr = [2.237801602580573e-05, 0.0002237801602580573]\n",
      "[INFO: 2022-02-17 00:55:47,411]   LabelSmoothing Loss = 1.6538481712341309\n",
      "[INFO: 2022-02-17 00:55:57,101] Iteration 39020 (DataTime/BatchTime: 0.00133/0.485) losses = 1.7811, lr = [2.2372280572953548e-05, 0.00022372280572953546]\n",
      "[INFO: 2022-02-17 00:55:57,101]   LabelSmoothing Loss = 1.994273066520691\n",
      "[INFO: 2022-02-17 00:56:06,604] Iteration 39040 (DataTime/BatchTime: 0.00299/0.475) losses = 1.7768, lr = [2.236654952780663e-05, 0.0002236654952780663]\n",
      "[INFO: 2022-02-17 00:56:06,604]   LabelSmoothing Loss = 2.124202251434326\n",
      "[INFO: 2022-02-17 00:56:16,200] Iteration 39060 (DataTime/BatchTime: 0.00293/0.48) losses = 1.8142, lr = [2.2360822884722317e-05, 0.00022360822884722313]\n",
      "[INFO: 2022-02-17 00:56:16,201]   LabelSmoothing Loss = 3.4807703495025635\n",
      "[INFO: 2022-02-17 00:56:25,844] Iteration 39080 (DataTime/BatchTime: 0.00308/0.482) losses = 1.7085, lr = [2.2355100638068054e-05, 0.00022355100638068052]\n",
      "[INFO: 2022-02-17 00:56:25,844]   LabelSmoothing Loss = 1.35165274143219\n",
      "[INFO: 2022-02-17 00:56:35,473] Iteration 39100 (DataTime/BatchTime: 0.00129/0.481) losses = 2.1746, lr = [2.2349382782221385e-05, 0.0002234938278222138]\n",
      "[INFO: 2022-02-17 00:56:35,474]   LabelSmoothing Loss = 1.9830856323242188\n",
      "[INFO: 2022-02-17 00:56:45,028] Iteration 39120 (DataTime/BatchTime: 0.00125/0.478) losses = 1.7011, lr = [2.2343669311569895e-05, 0.00022343669311569893]\n",
      "[INFO: 2022-02-17 00:56:45,028]   LabelSmoothing Loss = 1.4342777729034424\n",
      "[INFO: 2022-02-17 00:56:54,699] Iteration 39140 (DataTime/BatchTime: 0.00148/0.484) losses = 1.8791, lr = [2.2337960220511227e-05, 0.00022337960220511225]\n",
      "[INFO: 2022-02-17 00:56:54,699]   LabelSmoothing Loss = 2.0410094261169434\n",
      "[INFO: 2022-02-17 01:00:32,122] ######## Epoch (VAL)41 ########\n",
      "[INFO: 2022-02-17 01:00:32,123] {'Bleu_1': 0.3571672424559901, 'Bleu_2': 0.21250928829366517, 'Bleu_3': 0.13732762483198283, 'Bleu_4': 0.09198674898589602, 'METEOR': 0.18593226699457044, 'ROUGE_L': 0.29417555671534623, 'CIDEr': 0.2851290295396153}\n",
      "[INFO: 2022-02-17 01:04:09,468] ######## Epoch (TEST)41 ########\n",
      "[INFO: 2022-02-17 01:04:09,469] {'Bleu_1': 0.3293411451122174, 'Bleu_2': 0.18221896476900903, 'Bleu_3': 0.10694489514896992, 'Bleu_4': 0.06057979906500187, 'METEOR': 0.1724126400769239, 'ROUGE_L': 0.2724458981444916, 'CIDEr': 0.16304427916166703}\n",
      "[INFO: 2022-02-17 01:04:13,661] Iteration 39160 (DataTime/BatchTime: 0.208/0.698) losses = 1.4463, lr = [2.2332255503453033e-05, 0.0002233225550345303]\n",
      "[INFO: 2022-02-17 01:04:13,661]   LabelSmoothing Loss = 0.5034416913986206\n",
      "[INFO: 2022-02-17 01:04:23,359] Iteration 39180 (DataTime/BatchTime: 0.00321/0.485) losses = 2.0703, lr = [2.2326555154812948e-05, 0.00022326555154812946]\n",
      "[INFO: 2022-02-17 01:04:23,359]   LabelSmoothing Loss = 2.090850830078125\n",
      "[INFO: 2022-02-17 01:04:32,974] Iteration 39200 (DataTime/BatchTime: 0.00225/0.481) losses = 1.7879, lr = [2.232085916901859e-05, 0.00022320859169018588]\n",
      "[INFO: 2022-02-17 01:04:32,974]   LabelSmoothing Loss = 1.426085114479065\n",
      "[INFO: 2022-02-17 01:04:42,584] Iteration 39220 (DataTime/BatchTime: 0.00114/0.48) losses = 1.8123, lr = [2.2315167540507515e-05, 0.00022315167540507512]\n",
      "[INFO: 2022-02-17 01:04:42,584]   LabelSmoothing Loss = 1.5235506296157837\n",
      "[INFO: 2022-02-17 01:04:52,123] Iteration 39240 (DataTime/BatchTime: 0.00147/0.477) losses = 1.9336, lr = [2.2309480263727197e-05, 0.00022309480263727193]\n",
      "[INFO: 2022-02-17 01:04:52,123]   LabelSmoothing Loss = 1.3638399839401245\n",
      "[INFO: 2022-02-17 01:05:01,723] Iteration 39260 (DataTime/BatchTime: 0.00132/0.48) losses = 1.7858, lr = [2.230379733313503e-05, 0.00022303797333135026]\n",
      "[INFO: 2022-02-17 01:05:01,724]   LabelSmoothing Loss = 0.9700074195861816\n",
      "[INFO: 2022-02-17 01:05:11,315] Iteration 39280 (DataTime/BatchTime: 0.00115/0.48) losses = 1.7017, lr = [2.2298118743198267e-05, 0.00022298118743198264]\n",
      "[INFO: 2022-02-17 01:05:11,315]   LabelSmoothing Loss = 0.9502487778663635\n",
      "[INFO: 2022-02-17 01:05:20,813] Iteration 39300 (DataTime/BatchTime: 0.00218/0.475) losses = 1.7304, lr = [2.2292444488394024e-05, 0.0002229244448839402]\n",
      "[INFO: 2022-02-17 01:05:20,813]   LabelSmoothing Loss = 2.6291208267211914\n",
      "[INFO: 2022-02-17 01:05:30,375] Iteration 39320 (DataTime/BatchTime: 0.00291/0.478) losses = 1.721, lr = [2.228677456320925e-05, 0.0002228677456320925]\n",
      "[INFO: 2022-02-17 01:05:30,375]   LabelSmoothing Loss = 1.5035094022750854\n",
      "[INFO: 2022-02-17 01:05:39,904] Iteration 39340 (DataTime/BatchTime: 0.00227/0.476) losses = 1.6958, lr = [2.228110896214071e-05, 0.0002228110896214071]\n",
      "[INFO: 2022-02-17 01:05:39,904]   LabelSmoothing Loss = 1.1091612577438354\n",
      "[INFO: 2022-02-17 01:05:49,517] Iteration 39360 (DataTime/BatchTime: 0.00116/0.481) losses = 1.8451, lr = [2.2275447679694943e-05, 0.0002227544767969494]\n",
      "[INFO: 2022-02-17 01:05:49,517]   LabelSmoothing Loss = 2.545393705368042\n",
      "[INFO: 2022-02-17 01:05:59,070] Iteration 39380 (DataTime/BatchTime: 0.00184/0.478) losses = 1.6567, lr = [2.2269790710388268e-05, 0.00022269790710388268]\n",
      "[INFO: 2022-02-17 01:05:59,070]   LabelSmoothing Loss = 2.359858274459839\n",
      "[INFO: 2022-02-17 01:06:08,585] Iteration 39400 (DataTime/BatchTime: 0.00125/0.476) losses = 1.7446, lr = [2.226413804874674e-05, 0.00022264138048746736]\n",
      "[INFO: 2022-02-17 01:06:08,585]   LabelSmoothing Loss = 0.8288922309875488\n",
      "[INFO: 2022-02-17 01:06:18,275] Iteration 39420 (DataTime/BatchTime: 0.00124/0.485) losses = 1.6714, lr = [2.2258489689306136e-05, 0.00022258489689306132]\n",
      "[INFO: 2022-02-17 01:06:18,276]   LabelSmoothing Loss = 3.241300582885742\n",
      "[INFO: 2022-02-17 01:06:27,795] Iteration 39440 (DataTime/BatchTime: 0.00213/0.476) losses = 1.7762, lr = [2.2252845626611926e-05, 0.00022252845626611925]\n",
      "[INFO: 2022-02-17 01:06:27,795]   LabelSmoothing Loss = 2.067866325378418\n",
      "[INFO: 2022-02-17 01:06:37,335] Iteration 39460 (DataTime/BatchTime: 0.00118/0.477) losses = 1.7123, lr = [2.2247205855219273e-05, 0.0002224720585521927]\n",
      "[INFO: 2022-02-17 01:06:37,335]   LabelSmoothing Loss = 1.4983696937561035\n",
      "[INFO: 2022-02-17 01:06:46,916] Iteration 39480 (DataTime/BatchTime: 0.00121/0.479) losses = 1.6691, lr = [2.2241570369692983e-05, 0.00022241570369692978]\n",
      "[INFO: 2022-02-17 01:06:46,916]   LabelSmoothing Loss = 1.746889591217041\n",
      "[INFO: 2022-02-17 01:06:56,389] Iteration 39500 (DataTime/BatchTime: 0.00198/0.474) losses = 1.7425, lr = [2.223593916460749e-05, 0.00022235939164607485]\n",
      "[INFO: 2022-02-17 01:06:56,389]   LabelSmoothing Loss = 1.2132041454315186\n",
      "[INFO: 2022-02-17 01:07:05,906] Iteration 39520 (DataTime/BatchTime: 0.00119/0.476) losses = 1.7994, lr = [2.2230312234546848e-05, 0.00022230312234546845]\n",
      "[INFO: 2022-02-17 01:07:05,906]   LabelSmoothing Loss = 1.994490385055542\n",
      "[INFO: 2022-02-17 01:07:15,389] Iteration 39540 (DataTime/BatchTime: 0.00125/0.474) losses = 1.8071, lr = [2.22246895741047e-05, 0.00022224689574104695]\n",
      "[INFO: 2022-02-17 01:07:15,389]   LabelSmoothing Loss = 1.9903911352157593\n",
      "[INFO: 2022-02-17 01:07:24,894] Iteration 39560 (DataTime/BatchTime: 0.00131/0.475) losses = 1.7041, lr = [2.2219071177884247e-05, 0.00022219071177884245]\n",
      "[INFO: 2022-02-17 01:07:24,894]   LabelSmoothing Loss = 1.335105061531067\n",
      "[INFO: 2022-02-17 01:07:34,469] Iteration 39580 (DataTime/BatchTime: 0.0021/0.479) losses = 1.6082, lr = [2.221345704049825e-05, 0.00022213457040498247]\n",
      "[INFO: 2022-02-17 01:07:34,469]   LabelSmoothing Loss = 1.0112193822860718\n",
      "[INFO: 2022-02-17 01:07:44,000] Iteration 39600 (DataTime/BatchTime: 0.00127/0.477) losses = 1.8945, lr = [2.220784715656898e-05, 0.00022207847156568977]\n",
      "[INFO: 2022-02-17 01:07:44,000]   LabelSmoothing Loss = 1.7332733869552612\n",
      "[INFO: 2022-02-17 01:07:53,576] Iteration 39620 (DataTime/BatchTime: 0.00133/0.479) losses = 1.914, lr = [2.220224152072822e-05, 0.00022202241520728215]\n",
      "[INFO: 2022-02-17 01:07:53,576]   LabelSmoothing Loss = 2.464111804962158\n",
      "[INFO: 2022-02-17 01:08:03,157] Iteration 39640 (DataTime/BatchTime: 0.00252/0.479) losses = 1.517, lr = [2.219664012761722e-05, 0.00022196640127617216]\n",
      "[INFO: 2022-02-17 01:08:03,158]   LabelSmoothing Loss = 1.053694248199463\n",
      "[INFO: 2022-02-17 01:08:12,811] Iteration 39660 (DataTime/BatchTime: 0.00248/0.483) losses = 1.7625, lr = [2.21910429718867e-05, 0.00022191042971886698]\n",
      "[INFO: 2022-02-17 01:08:12,811]   LabelSmoothing Loss = 0.9664586782455444\n",
      "[INFO: 2022-02-17 01:08:22,366] Iteration 39680 (DataTime/BatchTime: 0.00127/0.478) losses = 1.7737, lr = [2.2185450048196825e-05, 0.0002218545004819682]\n",
      "[INFO: 2022-02-17 01:08:22,366]   LabelSmoothing Loss = 1.905835509300232\n",
      "[INFO: 2022-02-17 01:08:31,978] Iteration 39700 (DataTime/BatchTime: 0.00236/0.481) losses = 1.8316, lr = [2.2179861351217154e-05, 0.0002217986135121715]\n",
      "[INFO: 2022-02-17 01:08:31,978]   LabelSmoothing Loss = 1.2801387310028076\n",
      "[INFO: 2022-02-17 01:08:41,540] Iteration 39720 (DataTime/BatchTime: 0.00137/0.478) losses = 1.8771, lr = [2.2174276875626655e-05, 0.0002217427687562665]\n",
      "[INFO: 2022-02-17 01:08:41,540]   LabelSmoothing Loss = 2.0562098026275635\n",
      "[INFO: 2022-02-17 01:08:51,068] Iteration 39740 (DataTime/BatchTime: 0.00145/0.476) losses = 1.7266, lr = [2.216869661611367e-05, 0.00022168696616113666]\n",
      "[INFO: 2022-02-17 01:08:51,068]   LabelSmoothing Loss = 0.9759265780448914\n",
      "[INFO: 2022-02-17 01:09:00,574] Iteration 39760 (DataTime/BatchTime: 0.00129/0.475) losses = 1.6769, lr = [2.216312056737589e-05, 0.0002216312056737589]\n",
      "[INFO: 2022-02-17 01:09:00,574]   LabelSmoothing Loss = 1.0497580766677856\n",
      "[INFO: 2022-02-17 01:09:10,110] Iteration 39780 (DataTime/BatchTime: 0.00301/0.477) losses = 1.6288, lr = [2.215754872412034e-05, 0.00022157548724120334]\n",
      "[INFO: 2022-02-17 01:09:10,111]   LabelSmoothing Loss = 1.247546911239624\n",
      "[INFO: 2022-02-17 01:09:19,642] Iteration 39800 (DataTime/BatchTime: 0.00126/0.477) losses = 1.7575, lr = [2.2151981081063345e-05, 0.00022151981081063341]\n",
      "[INFO: 2022-02-17 01:09:19,642]   LabelSmoothing Loss = 1.138081431388855\n",
      "[INFO: 2022-02-17 01:09:29,210] Iteration 39820 (DataTime/BatchTime: 0.0014/0.478) losses = 1.7175, lr = [2.214641763293053e-05, 0.0002214641763293053]\n",
      "[INFO: 2022-02-17 01:09:29,210]   LabelSmoothing Loss = 1.399802803993225\n",
      "[INFO: 2022-02-17 01:09:38,778] Iteration 39840 (DataTime/BatchTime: 0.00138/0.478) losses = 1.603, lr = [2.2140858374456788e-05, 0.00022140858374456785]\n",
      "[INFO: 2022-02-17 01:09:38,778]   LabelSmoothing Loss = 1.6115187406539917\n",
      "[INFO: 2022-02-17 01:09:48,285] Iteration 39860 (DataTime/BatchTime: 0.00299/0.475) losses = 2.0381, lr = [2.213530330038625e-05, 0.00022135303300386248]\n",
      "[INFO: 2022-02-17 01:09:48,285]   LabelSmoothing Loss = 2.2078161239624023\n",
      "[INFO: 2022-02-17 01:09:57,811] Iteration 39880 (DataTime/BatchTime: 0.0038/0.476) losses = 1.7279, lr = [2.2129752405472285e-05, 0.0002212975240547228]\n",
      "[INFO: 2022-02-17 01:09:57,811]   LabelSmoothing Loss = 2.3188958168029785\n",
      "[INFO: 2022-02-17 01:10:07,345] Iteration 39900 (DataTime/BatchTime: 0.00306/0.477) losses = 1.6984, lr = [2.2124205684477453e-05, 0.0002212420568447745]\n",
      "[INFO: 2022-02-17 01:10:07,345]   LabelSmoothing Loss = 2.3869211673736572\n",
      "[INFO: 2022-02-17 01:10:16,757] Iteration 39920 (DataTime/BatchTime: 0.00213/0.471) losses = 1.4307, lr = [2.211866313217351e-05, 0.00022118663132173508]\n",
      "[INFO: 2022-02-17 01:10:16,757]   LabelSmoothing Loss = 1.2062140703201294\n",
      "[INFO: 2022-02-17 01:10:26,332] Iteration 39940 (DataTime/BatchTime: 0.00255/0.479) losses = 1.9561, lr = [2.211312474334137e-05, 0.00022113124743341366]\n",
      "[INFO: 2022-02-17 01:10:26,332]   LabelSmoothing Loss = 2.3134446144104004\n",
      "[INFO: 2022-02-17 01:10:35,898] Iteration 39960 (DataTime/BatchTime: 0.00246/0.478) losses = 1.7236, lr = [2.2107590512771094e-05, 0.00022107590512771092]\n",
      "[INFO: 2022-02-17 01:10:35,898]   LabelSmoothing Loss = 0.8467404842376709\n",
      "[INFO: 2022-02-17 01:10:45,388] Iteration 39980 (DataTime/BatchTime: 0.00208/0.475) losses = 2.0248, lr = [2.2102060435261866e-05, 0.00022102060435261862]\n",
      "[INFO: 2022-02-17 01:10:45,389]   LabelSmoothing Loss = 2.738018035888672\n",
      "[INFO: 2022-02-17 01:10:54,905] Iteration 40000 (DataTime/BatchTime: 0.00316/0.476) losses = 1.8573, lr = [2.2096534505621966e-05, 0.00022096534505621965]\n",
      "[INFO: 2022-02-17 01:10:54,905]   LabelSmoothing Loss = 1.256394624710083\n",
      "[INFO: 2022-02-17 01:11:04,398] Iteration 40020 (DataTime/BatchTime: 0.0013/0.475) losses = 1.6287, lr = [2.2091012718668765e-05, 0.00022091012718668764]\n",
      "[INFO: 2022-02-17 01:11:04,398]   LabelSmoothing Loss = 1.341081976890564\n",
      "[INFO: 2022-02-17 01:11:13,941] Iteration 40040 (DataTime/BatchTime: 0.00242/0.477) losses = 1.7944, lr = [2.2085495069228687e-05, 0.00022085495069228684]\n",
      "[INFO: 2022-02-17 01:11:13,941]   LabelSmoothing Loss = 1.9594279527664185\n",
      "[INFO: 2022-02-17 01:11:23,482] Iteration 40060 (DataTime/BatchTime: 0.00221/0.477) losses = 1.8449, lr = [2.2079981552137197e-05, 0.00022079981552137193]\n",
      "[INFO: 2022-02-17 01:11:23,482]   LabelSmoothing Loss = 1.5083122253417969\n",
      "[INFO: 2022-02-17 01:11:33,038] Iteration 40080 (DataTime/BatchTime: 0.00156/0.478) losses = 1.6626, lr = [2.207447216223879e-05, 0.00022074472162238786]\n",
      "[INFO: 2022-02-17 01:11:33,038]   LabelSmoothing Loss = 1.6609126329421997\n",
      "[INFO: 2022-02-17 01:11:42,605] Iteration 40100 (DataTime/BatchTime: 0.00138/0.478) losses = 1.6646, lr = [2.2068966894386946e-05, 0.00022068966894386944]\n",
      "[INFO: 2022-02-17 01:11:42,605]   LabelSmoothing Loss = 1.5861250162124634\n",
      "[INFO: 2022-02-17 01:15:18,429] ######## Epoch (VAL)42 ########\n",
      "[INFO: 2022-02-17 01:15:18,430] {'Bleu_1': 0.37124615748399487, 'Bleu_2': 0.23075545552003734, 'Bleu_3': 0.15590026582138464, 'Bleu_4': 0.11007130598709036, 'METEOR': 0.1835129658878216, 'ROUGE_L': 0.29784728783328046, 'CIDEr': 0.3484075118352242}\n",
      "[INFO: 2022-02-17 01:18:56,339] ######## Epoch (TEST)42 ########\n",
      "[INFO: 2022-02-17 01:18:56,339] {'Bleu_1': 0.3396123097141233, 'Bleu_2': 0.2014655601435779, 'Bleu_3': 0.12993261196052663, 'Bleu_4': 0.08736686154741449, 'METEOR': 0.1743624735102722, 'ROUGE_L': 0.2825591482146947, 'CIDEr': 0.2699024162621854}\n",
      "[INFO: 2022-02-17 01:19:02,937] Iteration 40120 (DataTime/BatchTime: 0.116/0.6) losses = 2.0624, lr = [2.2063465743444142e-05, 0.0002206346574344414]\n",
      "[INFO: 2022-02-17 01:19:02,937]   LabelSmoothing Loss = 2.052339792251587\n",
      "[INFO: 2022-02-17 01:19:12,483] Iteration 40140 (DataTime/BatchTime: 0.00308/0.477) losses = 1.5513, lr = [2.2057968704281804e-05, 0.00022057968704281803]\n",
      "[INFO: 2022-02-17 01:19:12,483]   LabelSmoothing Loss = 0.7967065572738647\n",
      "[INFO: 2022-02-17 01:19:22,023] Iteration 40160 (DataTime/BatchTime: 0.0012/0.477) losses = 1.641, lr = [2.2052475771780298e-05, 0.00022052475771780296]\n",
      "[INFO: 2022-02-17 01:19:22,023]   LabelSmoothing Loss = 1.7855983972549438\n",
      "[INFO: 2022-02-17 01:19:31,550] Iteration 40180 (DataTime/BatchTime: 0.00235/0.476) losses = 1.8413, lr = [2.2046986940828916e-05, 0.00022046986940828914]\n",
      "[INFO: 2022-02-17 01:19:31,550]   LabelSmoothing Loss = 1.8131284713745117\n",
      "[INFO: 2022-02-17 01:19:41,094] Iteration 40200 (DataTime/BatchTime: 0.00232/0.477) losses = 1.5393, lr = [2.204150220632585e-05, 0.00022041502206325846]\n",
      "[INFO: 2022-02-17 01:19:41,094]   LabelSmoothing Loss = 2.346238613128662\n",
      "[INFO: 2022-02-17 01:19:50,574] Iteration 40220 (DataTime/BatchTime: 0.00214/0.474) losses = 1.5789, lr = [2.203602156317816e-05, 0.0002203602156317816]\n",
      "[INFO: 2022-02-17 01:19:50,574]   LabelSmoothing Loss = 1.2700855731964111\n",
      "[INFO: 2022-02-17 01:20:00,048] Iteration 40240 (DataTime/BatchTime: 0.00494/0.474) losses = 1.7267, lr = [2.2030545006301778e-05, 0.00022030545006301776]\n",
      "[INFO: 2022-02-17 01:20:00,048]   LabelSmoothing Loss = 1.1316614151000977\n",
      "[INFO: 2022-02-17 01:20:09,649] Iteration 40260 (DataTime/BatchTime: 0.00204/0.48) losses = 1.9191, lr = [2.202507253062148e-05, 0.00022025072530621476]\n",
      "[INFO: 2022-02-17 01:20:09,649]   LabelSmoothing Loss = 1.0464036464691162\n",
      "[INFO: 2022-02-17 01:20:19,246] Iteration 40280 (DataTime/BatchTime: 0.00113/0.48) losses = 1.7823, lr = [2.2019604131070843e-05, 0.0002201960413107084]\n",
      "[INFO: 2022-02-17 01:20:19,246]   LabelSmoothing Loss = 1.8172423839569092\n",
      "[INFO: 2022-02-17 01:20:28,784] Iteration 40300 (DataTime/BatchTime: 0.00122/0.477) losses = 1.9868, lr = [2.201413980259227e-05, 0.0002201413980259227]\n",
      "[INFO: 2022-02-17 01:20:28,784]   LabelSmoothing Loss = 3.148052930831909\n",
      "[INFO: 2022-02-17 01:20:38,322] Iteration 40320 (DataTime/BatchTime: 0.00208/0.477) losses = 1.8374, lr = [2.2008679540136923e-05, 0.0002200867954013692]\n",
      "[INFO: 2022-02-17 01:20:38,323]   LabelSmoothing Loss = 1.2783738374710083\n",
      "[INFO: 2022-02-17 01:20:47,860] Iteration 40340 (DataTime/BatchTime: 0.00325/0.477) losses = 1.7896, lr = [2.200322333866474e-05, 0.00022003223338664738]\n",
      "[INFO: 2022-02-17 01:20:47,860]   LabelSmoothing Loss = 1.9411728382110596\n",
      "[INFO: 2022-02-17 01:20:57,378] Iteration 40360 (DataTime/BatchTime: 0.00319/0.476) losses = 1.7271, lr = [2.1997771193144395e-05, 0.00021997771193144394]\n",
      "[INFO: 2022-02-17 01:20:57,379]   LabelSmoothing Loss = 2.0772688388824463\n",
      "[INFO: 2022-02-17 01:21:06,926] Iteration 40380 (DataTime/BatchTime: 0.00115/0.477) losses = 1.8352, lr = [2.1992323098553292e-05, 0.00021992323098553288]\n",
      "[INFO: 2022-02-17 01:21:06,926]   LabelSmoothing Loss = 1.1816987991333008\n",
      "[INFO: 2022-02-17 01:21:16,469] Iteration 40400 (DataTime/BatchTime: 0.00459/0.477) losses = 1.7661, lr = [2.198687904987752e-05, 0.00021986879049877518]\n",
      "[INFO: 2022-02-17 01:21:16,469]   LabelSmoothing Loss = 1.2790977954864502\n",
      "[INFO: 2022-02-17 01:21:26,007] Iteration 40420 (DataTime/BatchTime: 0.00236/0.477) losses = 1.5597, lr = [2.1981439042111875e-05, 0.00021981439042111873]\n",
      "[INFO: 2022-02-17 01:21:26,007]   LabelSmoothing Loss = 2.278257131576538\n",
      "[INFO: 2022-02-17 01:21:35,671] Iteration 40440 (DataTime/BatchTime: 0.00115/0.483) losses = 1.796, lr = [2.1976003070259803e-05, 0.00021976003070259799]\n",
      "[INFO: 2022-02-17 01:21:35,671]   LabelSmoothing Loss = 1.3265303373336792\n",
      "[INFO: 2022-02-17 01:21:45,251] Iteration 40460 (DataTime/BatchTime: 0.00124/0.479) losses = 1.8122, lr = [2.1970571129333396e-05, 0.00021970571129333394]\n",
      "[INFO: 2022-02-17 01:21:45,251]   LabelSmoothing Loss = 0.8973093628883362\n",
      "[INFO: 2022-02-17 01:21:54,718] Iteration 40480 (DataTime/BatchTime: 0.0011/0.473) losses = 1.6001, lr = [2.1965143214353375e-05, 0.00021965143214353373]\n",
      "[INFO: 2022-02-17 01:21:54,719]   LabelSmoothing Loss = 2.1396946907043457\n",
      "[INFO: 2022-02-17 01:22:04,197] Iteration 40500 (DataTime/BatchTime: 0.00118/0.474) losses = 1.7412, lr = [2.195971932034907e-05, 0.00021959719320349067]\n",
      "[INFO: 2022-02-17 01:22:04,197]   LabelSmoothing Loss = 1.0297154188156128\n",
      "[INFO: 2022-02-17 01:22:13,723] Iteration 40520 (DataTime/BatchTime: 0.00113/0.476) losses = 1.6282, lr = [2.19542994423584e-05, 0.00021954299442358396]\n",
      "[INFO: 2022-02-17 01:22:13,723]   LabelSmoothing Loss = 0.8841761946678162\n",
      "[INFO: 2022-02-17 01:22:23,286] Iteration 40540 (DataTime/BatchTime: 0.00231/0.478) losses = 1.6757, lr = [2.194888357542784e-05, 0.0002194888357542784]\n",
      "[INFO: 2022-02-17 01:22:23,286]   LabelSmoothing Loss = 1.6833443641662598\n",
      "[INFO: 2022-02-17 01:22:32,882] Iteration 40560 (DataTime/BatchTime: 0.00218/0.48) losses = 1.7253, lr = [2.194347171461243e-05, 0.00021943471714612426]\n",
      "[INFO: 2022-02-17 01:22:32,882]   LabelSmoothing Loss = 2.7463290691375732\n",
      "[INFO: 2022-02-17 01:22:42,327] Iteration 40580 (DataTime/BatchTime: 0.00115/0.472) losses = 1.7823, lr = [2.1938063854975726e-05, 0.00021938063854975724]\n",
      "[INFO: 2022-02-17 01:22:42,328]   LabelSmoothing Loss = 1.8723527193069458\n",
      "[INFO: 2022-02-17 01:22:51,770] Iteration 40600 (DataTime/BatchTime: 0.00212/0.472) losses = 1.6324, lr = [2.1932659991589818e-05, 0.00021932659991589815]\n",
      "[INFO: 2022-02-17 01:22:51,771]   LabelSmoothing Loss = 2.8253159523010254\n",
      "[INFO: 2022-02-17 01:23:01,291] Iteration 40620 (DataTime/BatchTime: 0.00237/0.476) losses = 1.6349, lr = [2.192726011953526e-05, 0.00021927260119535257]\n",
      "[INFO: 2022-02-17 01:23:01,291]   LabelSmoothing Loss = 2.007431983947754\n",
      "[INFO: 2022-02-17 01:23:10,746] Iteration 40640 (DataTime/BatchTime: 0.00115/0.473) losses = 1.694, lr = [2.19218642339011e-05, 0.00021921864233901097]\n",
      "[INFO: 2022-02-17 01:23:10,746]   LabelSmoothing Loss = 1.725175380706787\n",
      "[INFO: 2022-02-17 01:23:20,237] Iteration 40660 (DataTime/BatchTime: 0.00381/0.475) losses = 1.7643, lr = [2.1916472329784837e-05, 0.00021916472329784834]\n",
      "[INFO: 2022-02-17 01:23:20,237]   LabelSmoothing Loss = 0.8991972804069519\n",
      "[INFO: 2022-02-17 01:23:29,732] Iteration 40680 (DataTime/BatchTime: 0.00222/0.475) losses = 1.6645, lr = [2.1911084402292404e-05, 0.00021911084402292401]\n",
      "[INFO: 2022-02-17 01:23:29,732]   LabelSmoothing Loss = 1.2445026636123657\n",
      "[INFO: 2022-02-17 01:23:39,267] Iteration 40700 (DataTime/BatchTime: 0.00216/0.477) losses = 1.7443, lr = [2.1905700446538154e-05, 0.0002190570044653815]\n",
      "[INFO: 2022-02-17 01:23:39,268]   LabelSmoothing Loss = 1.9432153701782227\n",
      "[INFO: 2022-02-17 01:23:48,825] Iteration 40720 (DataTime/BatchTime: 0.00109/0.478) losses = 1.6847, lr = [2.190032045764484e-05, 0.00021900320457644837]\n",
      "[INFO: 2022-02-17 01:23:48,825]   LabelSmoothing Loss = 1.1584810018539429\n",
      "[INFO: 2022-02-17 01:23:58,364] Iteration 40740 (DataTime/BatchTime: 0.00108/0.477) losses = 1.8367, lr = [2.1894944430743592e-05, 0.00021894944430743592]\n",
      "[INFO: 2022-02-17 01:23:58,364]   LabelSmoothing Loss = 2.2431116104125977\n",
      "[INFO: 2022-02-17 01:24:07,902] Iteration 40760 (DataTime/BatchTime: 0.00282/0.477) losses = 1.8516, lr = [2.188957236097391e-05, 0.0002188957236097391]\n",
      "[INFO: 2022-02-17 01:24:07,902]   LabelSmoothing Loss = 1.5631650686264038\n",
      "[INFO: 2022-02-17 01:24:17,473] Iteration 40780 (DataTime/BatchTime: 0.00295/0.479) losses = 1.8043, lr = [2.1884204243483626e-05, 0.00021884204243483626]\n",
      "[INFO: 2022-02-17 01:24:17,473]   LabelSmoothing Loss = 2.039350748062134\n",
      "[INFO: 2022-02-17 01:24:26,974] Iteration 40800 (DataTime/BatchTime: 0.00423/0.475) losses = 1.8749, lr = [2.187884007342891e-05, 0.00021878840073428907]\n",
      "[INFO: 2022-02-17 01:24:26,974]   LabelSmoothing Loss = 2.1687488555908203\n",
      "[INFO: 2022-02-17 01:24:36,507] Iteration 40820 (DataTime/BatchTime: 0.00106/0.477) losses = 1.912, lr = [2.1873479845974226e-05, 0.00021873479845974222]\n",
      "[INFO: 2022-02-17 01:24:36,507]   LabelSmoothing Loss = 2.164027690887451\n",
      "[INFO: 2022-02-17 01:24:46,065] Iteration 40840 (DataTime/BatchTime: 0.00188/0.478) losses = 2.0002, lr = [2.186812355629234e-05, 0.00021868123556292334]\n",
      "[INFO: 2022-02-17 01:24:46,065]   LabelSmoothing Loss = 1.339429259300232\n",
      "[INFO: 2022-02-17 01:24:55,592] Iteration 40860 (DataTime/BatchTime: 0.00217/0.476) losses = 1.7915, lr = [2.1862771199564277e-05, 0.00021862771199564275]\n",
      "[INFO: 2022-02-17 01:24:55,593]   LabelSmoothing Loss = 0.8183907866477966\n",
      "[INFO: 2022-02-17 01:25:05,083] Iteration 40880 (DataTime/BatchTime: 0.0031/0.475) losses = 1.8459, lr = [2.1857422770979328e-05, 0.00021857422770979324]\n",
      "[INFO: 2022-02-17 01:25:05,083]   LabelSmoothing Loss = 2.3822145462036133\n",
      "[INFO: 2022-02-17 01:25:14,591] Iteration 40900 (DataTime/BatchTime: 0.00106/0.475) losses = 1.7502, lr = [2.1852078265734998e-05, 0.00021852078265734997]\n",
      "[INFO: 2022-02-17 01:25:14,592]   LabelSmoothing Loss = 2.0532333850860596\n",
      "[INFO: 2022-02-17 01:25:24,104] Iteration 40920 (DataTime/BatchTime: 0.00221/0.476) losses = 1.6588, lr = [2.184673767903703e-05, 0.00021846737679037027]\n",
      "[INFO: 2022-02-17 01:25:24,104]   LabelSmoothing Loss = 1.1234828233718872\n",
      "[INFO: 2022-02-17 01:25:33,604] Iteration 40940 (DataTime/BatchTime: 0.002/0.475) losses = 1.9541, lr = [2.184140100609935e-05, 0.00021841401006099346]\n",
      "[INFO: 2022-02-17 01:25:33,604]   LabelSmoothing Loss = 1.6228629350662231\n",
      "[INFO: 2022-02-17 01:25:43,089] Iteration 40960 (DataTime/BatchTime: 0.00107/0.474) losses = 1.6224, lr = [2.1836068242144068e-05, 0.00021836068242144064]\n",
      "[INFO: 2022-02-17 01:25:43,089]   LabelSmoothing Loss = 1.7489081621170044\n",
      "[INFO: 2022-02-17 01:25:52,645] Iteration 40980 (DataTime/BatchTime: 0.00408/0.478) losses = 1.6929, lr = [2.1830739382401458e-05, 0.00021830739382401455]\n",
      "[INFO: 2022-02-17 01:25:52,645]   LabelSmoothing Loss = 2.585190773010254\n",
      "[INFO: 2022-02-17 01:26:02,243] Iteration 41000 (DataTime/BatchTime: 0.00116/0.48) losses = 1.7869, lr = [2.1825414422109932e-05, 0.00021825414422109928]\n",
      "[INFO: 2022-02-17 01:26:02,243]   LabelSmoothing Loss = 3.068309783935547\n",
      "[INFO: 2022-02-17 01:26:11,921] Iteration 41020 (DataTime/BatchTime: 0.00214/0.484) losses = 1.562, lr = [2.182009335651604e-05, 0.0002182009335651604]\n",
      "[INFO: 2022-02-17 01:26:11,921]   LabelSmoothing Loss = 1.0547624826431274\n",
      "[INFO: 2022-02-17 01:26:21,644] Iteration 41040 (DataTime/BatchTime: 0.00128/0.486) losses = 2.0197, lr = [2.1814776180874427e-05, 0.00021814776180874426]\n",
      "[INFO: 2022-02-17 01:26:21,644]   LabelSmoothing Loss = 2.255674123764038\n",
      "[INFO: 2022-02-17 01:26:31,082] Iteration 41060 (DataTime/BatchTime: 0.00112/0.472) losses = 1.6334, lr = [2.180946289044784e-05, 0.00021809462890447836]\n",
      "[INFO: 2022-02-17 01:26:31,082]   LabelSmoothing Loss = 1.6396267414093018\n",
      "[INFO: 2022-02-17 01:30:05,475] ######## Epoch (VAL)43 ########\n",
      "[INFO: 2022-02-17 01:30:05,475] {'Bleu_1': 0.35967154634719367, 'Bleu_2': 0.22065964674014668, 'Bleu_3': 0.1469294002971982, 'Bleu_4': 0.10324504233012723, 'METEOR': 0.18246840748145438, 'ROUGE_L': 0.2951631722564896, 'CIDEr': 0.3350360886981546}\n",
      "[INFO: 2022-02-17 01:33:40,059] ######## Epoch (TEST)43 ########\n",
      "[INFO: 2022-02-17 01:33:40,059] {'Bleu_1': 0.3339741411264295, 'Bleu_2': 0.19688905595659614, 'Bleu_3': 0.12698928027863116, 'Bleu_4': 0.0866198022214147, 'METEOR': 0.17202470972678166, 'ROUGE_L': 0.28120014858052994, 'CIDEr': 0.27067365818737693}\n",
      "[INFO: 2022-02-17 01:33:48,661] Iteration 41080 (DataTime/BatchTime: 0.0582/0.538) losses = 1.9869, lr = [2.1804153480507085e-05, 0.00021804153480507084]\n",
      "[INFO: 2022-02-17 01:33:48,661]   LabelSmoothing Loss = 2.45352840423584\n",
      "[INFO: 2022-02-17 01:33:58,027] Iteration 41100 (DataTime/BatchTime: 0.00212/0.468) losses = 1.5892, lr = [2.179884794633104e-05, 0.00021798847946331038]\n",
      "[INFO: 2022-02-17 01:33:58,027]   LabelSmoothing Loss = 1.6930698156356812\n",
      "[INFO: 2022-02-17 01:34:07,470] Iteration 41120 (DataTime/BatchTime: 0.00295/0.472) losses = 1.8265, lr = [2.179354628320661e-05, 0.0002179354628320661]\n",
      "[INFO: 2022-02-17 01:34:07,470]   LabelSmoothing Loss = 2.4837682247161865\n",
      "[INFO: 2022-02-17 01:34:16,901] Iteration 41140 (DataTime/BatchTime: 0.00123/0.472) losses = 1.7715, lr = [2.1788248486428725e-05, 0.00021788248486428723]\n",
      "[INFO: 2022-02-17 01:34:16,902]   LabelSmoothing Loss = 1.332366943359375\n",
      "[INFO: 2022-02-17 01:34:26,326] Iteration 41160 (DataTime/BatchTime: 0.00122/0.471) losses = 1.8218, lr = [2.1782954551300303e-05, 0.00021782954551300302]\n",
      "[INFO: 2022-02-17 01:34:26,327]   LabelSmoothing Loss = 1.468984603881836\n",
      "[INFO: 2022-02-17 01:34:35,767] Iteration 41180 (DataTime/BatchTime: 0.00125/0.472) losses = 1.7621, lr = [2.1777664473132267e-05, 0.00021777664473132262]\n",
      "[INFO: 2022-02-17 01:34:35,768]   LabelSmoothing Loss = 2.6805057525634766\n",
      "[INFO: 2022-02-17 01:34:45,257] Iteration 41200 (DataTime/BatchTime: 0.00122/0.475) losses = 2.0068, lr = [2.1772378247243498e-05, 0.00021772378247243495]\n",
      "[INFO: 2022-02-17 01:34:45,258]   LabelSmoothing Loss = 2.1521010398864746\n",
      "[INFO: 2022-02-17 01:34:54,806] Iteration 41220 (DataTime/BatchTime: 0.00121/0.477) losses = 1.7272, lr = [2.1767095868960828e-05, 0.00021767095868960824]\n",
      "[INFO: 2022-02-17 01:34:54,806]   LabelSmoothing Loss = 2.2650973796844482\n",
      "[INFO: 2022-02-17 01:35:04,375] Iteration 41240 (DataTime/BatchTime: 0.00204/0.478) losses = 1.7583, lr = [2.1761817333619023e-05, 0.00021761817333619017]\n",
      "[INFO: 2022-02-17 01:35:04,375]   LabelSmoothing Loss = 0.7123227119445801\n",
      "[INFO: 2022-02-17 01:35:13,986] Iteration 41260 (DataTime/BatchTime: 0.00234/0.481) losses = 2.0116, lr = [2.1756542636560753e-05, 0.00021756542636560753]\n",
      "[INFO: 2022-02-17 01:35:13,986]   LabelSmoothing Loss = 1.359602451324463\n",
      "[INFO: 2022-02-17 01:35:23,482] Iteration 41280 (DataTime/BatchTime: 0.00121/0.475) losses = 1.6537, lr = [2.1751271773136614e-05, 0.00021751271773136612]\n",
      "[INFO: 2022-02-17 01:35:23,483]   LabelSmoothing Loss = 2.238970994949341\n",
      "[INFO: 2022-02-17 01:35:33,001] Iteration 41300 (DataTime/BatchTime: 0.00201/0.476) losses = 1.7475, lr = [2.174600473870505e-05, 0.00021746004738705044]\n",
      "[INFO: 2022-02-17 01:35:33,001]   LabelSmoothing Loss = 2.393533706665039\n",
      "[INFO: 2022-02-17 01:35:42,533] Iteration 41320 (DataTime/BatchTime: 0.00205/0.477) losses = 1.6311, lr = [2.174074152863239e-05, 0.00021740741528632388]\n",
      "[INFO: 2022-02-17 01:35:42,533]   LabelSmoothing Loss = 1.3148592710494995\n",
      "[INFO: 2022-02-17 01:35:52,026] Iteration 41340 (DataTime/BatchTime: 0.00119/0.475) losses = 1.712, lr = [2.1735482138292802e-05, 0.000217354821382928]\n",
      "[INFO: 2022-02-17 01:35:52,027]   LabelSmoothing Loss = 1.927811622619629\n",
      "[INFO: 2022-02-17 01:36:01,616] Iteration 41360 (DataTime/BatchTime: 0.00116/0.479) losses = 1.6982, lr = [2.1730226563068288e-05, 0.00021730226563068284]\n",
      "[INFO: 2022-02-17 01:36:01,616]   LabelSmoothing Loss = 1.2874298095703125\n",
      "[INFO: 2022-02-17 01:36:11,149] Iteration 41380 (DataTime/BatchTime: 0.00121/0.477) losses = 1.6032, lr = [2.1724974798348656e-05, 0.00021724974798348652]\n",
      "[INFO: 2022-02-17 01:36:11,149]   LabelSmoothing Loss = 1.5684016942977905\n",
      "[INFO: 2022-02-17 01:36:20,609] Iteration 41400 (DataTime/BatchTime: 0.00124/0.473) losses = 1.5585, lr = [2.1719726839531518e-05, 0.00021719726839531514]\n",
      "[INFO: 2022-02-17 01:36:20,610]   LabelSmoothing Loss = 2.266817808151245\n",
      "[INFO: 2022-02-17 01:36:30,115] Iteration 41420 (DataTime/BatchTime: 0.00127/0.475) losses = 1.8182, lr = [2.1714482682022253e-05, 0.00021714482682022248]\n",
      "[INFO: 2022-02-17 01:36:30,115]   LabelSmoothing Loss = 2.7908337116241455\n",
      "[INFO: 2022-02-17 01:36:39,553] Iteration 41440 (DataTime/BatchTime: 0.00127/0.472) losses = 1.718, lr = [2.1709242321234013e-05, 0.00021709242321234012]\n",
      "[INFO: 2022-02-17 01:36:39,553]   LabelSmoothing Loss = 2.1093146800994873\n",
      "[INFO: 2022-02-17 01:36:49,075] Iteration 41460 (DataTime/BatchTime: 0.00123/0.476) losses = 1.7208, lr = [2.1704005752587694e-05, 0.0002170400575258769]\n",
      "[INFO: 2022-02-17 01:36:49,075]   LabelSmoothing Loss = 0.7879475951194763\n",
      "[INFO: 2022-02-17 01:36:58,532] Iteration 41480 (DataTime/BatchTime: 0.00123/0.473) losses = 1.7505, lr = [2.1698772971511906e-05, 0.00021698772971511906]\n",
      "[INFO: 2022-02-17 01:36:58,532]   LabelSmoothing Loss = 0.7375798225402832\n",
      "[INFO: 2022-02-17 01:37:07,981] Iteration 41500 (DataTime/BatchTime: 0.00121/0.472) losses = 1.798, lr = [2.1693543973442995e-05, 0.00021693543973442994]\n",
      "[INFO: 2022-02-17 01:37:07,981]   LabelSmoothing Loss = 1.9568867683410645\n",
      "[INFO: 2022-02-17 01:37:17,365] Iteration 41520 (DataTime/BatchTime: 0.00196/0.469) losses = 1.5671, lr = [2.1688318753824977e-05, 0.00021688318753824973]\n",
      "[INFO: 2022-02-17 01:37:17,365]   LabelSmoothing Loss = 0.8631877899169922\n",
      "[INFO: 2022-02-17 01:37:26,908] Iteration 41540 (DataTime/BatchTime: 0.0013/0.477) losses = 1.786, lr = [2.168309730810956e-05, 0.00021683097308109557]\n",
      "[INFO: 2022-02-17 01:37:26,908]   LabelSmoothing Loss = 2.5073909759521484\n",
      "[INFO: 2022-02-17 01:37:36,462] Iteration 41560 (DataTime/BatchTime: 0.00124/0.478) losses = 1.5381, lr = [2.167787963175611e-05, 0.0002167787963175611]\n",
      "[INFO: 2022-02-17 01:37:36,463]   LabelSmoothing Loss = 1.8065109252929688\n",
      "[INFO: 2022-02-17 01:37:46,066] Iteration 41580 (DataTime/BatchTime: 0.00204/0.48) losses = 1.815, lr = [2.1672665720231635e-05, 0.00021672665720231634]\n",
      "[INFO: 2022-02-17 01:37:46,067]   LabelSmoothing Loss = 1.857133150100708\n",
      "[INFO: 2022-02-17 01:37:55,621] Iteration 41600 (DataTime/BatchTime: 0.00208/0.478) losses = 1.826, lr = [2.166745556901078e-05, 0.00021667455569010776]\n",
      "[INFO: 2022-02-17 01:37:55,621]   LabelSmoothing Loss = 1.7836657762527466\n",
      "[INFO: 2022-02-17 01:38:05,145] Iteration 41620 (DataTime/BatchTime: 0.00341/0.476) losses = 1.5669, lr = [2.1662249173575785e-05, 0.00021662249173575783]\n",
      "[INFO: 2022-02-17 01:38:05,145]   LabelSmoothing Loss = 1.3377693891525269\n",
      "[INFO: 2022-02-17 01:38:14,695] Iteration 41640 (DataTime/BatchTime: 0.00125/0.477) losses = 1.6248, lr = [2.1657046529416506e-05, 0.00021657046529416504]\n",
      "[INFO: 2022-02-17 01:38:14,695]   LabelSmoothing Loss = 2.210373640060425\n",
      "[INFO: 2022-02-17 01:38:24,239] Iteration 41660 (DataTime/BatchTime: 0.00138/0.477) losses = 1.4586, lr = [2.1651847632030364e-05, 0.0002165184763203036]\n",
      "[INFO: 2022-02-17 01:38:24,239]   LabelSmoothing Loss = 1.0366322994232178\n",
      "[INFO: 2022-02-17 01:38:33,770] Iteration 41680 (DataTime/BatchTime: 0.00122/0.477) losses = 1.6378, lr = [2.164665247692234e-05, 0.0002164665247692234]\n",
      "[INFO: 2022-02-17 01:38:33,770]   LabelSmoothing Loss = 2.3158199787139893\n",
      "[INFO: 2022-02-17 01:38:43,308] Iteration 41700 (DataTime/BatchTime: 0.0013/0.477) losses = 1.7885, lr = [2.1641461059604976e-05, 0.00021641461059604972]\n",
      "[INFO: 2022-02-17 01:38:43,308]   LabelSmoothing Loss = 1.3992347717285156\n",
      "[INFO: 2022-02-17 01:38:52,882] Iteration 41720 (DataTime/BatchTime: 0.002/0.479) losses = 1.7711, lr = [2.1636273375598327e-05, 0.00021636273375598325]\n",
      "[INFO: 2022-02-17 01:38:52,882]   LabelSmoothing Loss = 1.7219388484954834\n",
      "[INFO: 2022-02-17 01:39:02,521] Iteration 41740 (DataTime/BatchTime: 0.00119/0.482) losses = 1.911, lr = [2.1631089420429977e-05, 0.00021631089420429974]\n",
      "[INFO: 2022-02-17 01:39:02,521]   LabelSmoothing Loss = 1.8946609497070312\n",
      "[INFO: 2022-02-17 01:39:12,070] Iteration 41760 (DataTime/BatchTime: 0.00201/0.477) losses = 1.5933, lr = [2.1625909189634994e-05, 0.0002162590918963499]\n",
      "[INFO: 2022-02-17 01:39:12,070]   LabelSmoothing Loss = 1.4190948009490967\n",
      "[INFO: 2022-02-17 01:39:21,636] Iteration 41780 (DataTime/BatchTime: 0.00118/0.478) losses = 1.6768, lr = [2.162073267875594e-05, 0.00021620732678755936]\n",
      "[INFO: 2022-02-17 01:39:21,636]   LabelSmoothing Loss = 1.9545729160308838\n",
      "[INFO: 2022-02-17 01:39:31,253] Iteration 41800 (DataTime/BatchTime: 0.00121/0.481) losses = 1.7541, lr = [2.1615559883342822e-05, 0.0002161555988334282]\n",
      "[INFO: 2022-02-17 01:39:31,253]   LabelSmoothing Loss = 1.910536766052246\n",
      "[INFO: 2022-02-17 01:39:40,824] Iteration 41820 (DataTime/BatchTime: 0.0023/0.479) losses = 1.903, lr = [2.1610390798953123e-05, 0.0002161039079895312]\n",
      "[INFO: 2022-02-17 01:39:40,825]   LabelSmoothing Loss = 2.2093710899353027\n",
      "[INFO: 2022-02-17 01:39:50,400] Iteration 41840 (DataTime/BatchTime: 0.00128/0.479) losses = 1.6843, lr = [2.1605225421151737e-05, 0.00021605225421151734]\n",
      "[INFO: 2022-02-17 01:39:50,400]   LabelSmoothing Loss = 1.1441768407821655\n",
      "[INFO: 2022-02-17 01:39:59,914] Iteration 41860 (DataTime/BatchTime: 0.0012/0.476) losses = 1.9669, lr = [2.1600063745510992e-05, 0.0002160006374551099]\n",
      "[INFO: 2022-02-17 01:39:59,915]   LabelSmoothing Loss = 2.8532121181488037\n",
      "[INFO: 2022-02-17 01:40:09,482] Iteration 41880 (DataTime/BatchTime: 0.00226/0.478) losses = 1.8185, lr = [2.1594905767610597e-05, 0.00021594905767610595]\n",
      "[INFO: 2022-02-17 01:40:09,482]   LabelSmoothing Loss = 1.5279533863067627\n",
      "[INFO: 2022-02-17 01:40:19,046] Iteration 41900 (DataTime/BatchTime: 0.00125/0.478) losses = 1.6786, lr = [2.158975148303767e-05, 0.00021589751483037665]\n",
      "[INFO: 2022-02-17 01:40:19,046]   LabelSmoothing Loss = 1.3249305486679077\n",
      "[INFO: 2022-02-17 01:40:28,533] Iteration 41920 (DataTime/BatchTime: 0.00118/0.474) losses = 1.7396, lr = [2.1584600887386674e-05, 0.00021584600887386674]\n",
      "[INFO: 2022-02-17 01:40:28,534]   LabelSmoothing Loss = 2.582730770111084\n",
      "[INFO: 2022-02-17 01:40:38,026] Iteration 41940 (DataTime/BatchTime: 0.00213/0.475) losses = 1.6197, lr = [2.1579453976259452e-05, 0.00021579453976259448]\n",
      "[INFO: 2022-02-17 01:40:38,026]   LabelSmoothing Loss = 1.5021613836288452\n",
      "[INFO: 2022-02-17 01:40:47,637] Iteration 41960 (DataTime/BatchTime: 0.00211/0.481) losses = 1.7606, lr = [2.157431074526516e-05, 0.00021574310745265155]\n",
      "[INFO: 2022-02-17 01:40:47,637]   LabelSmoothing Loss = 1.8208787441253662\n",
      "[INFO: 2022-02-17 01:40:57,168] Iteration 41980 (DataTime/BatchTime: 0.00243/0.477) losses = 1.6999, lr = [2.1569171190020286e-05, 0.00021569171190020283]\n",
      "[INFO: 2022-02-17 01:40:57,169]   LabelSmoothing Loss = 2.279642105102539\n",
      "[INFO: 2022-02-17 01:41:06,679] Iteration 42000 (DataTime/BatchTime: 0.00123/0.476) losses = 1.8324, lr = [2.1564035306148632e-05, 0.0002156403530614863]\n",
      "[INFO: 2022-02-17 01:41:06,679]   LabelSmoothing Loss = 1.877448320388794\n",
      "[INFO: 2022-02-17 01:44:45,631] ######## Epoch (VAL)44 ########\n",
      "[INFO: 2022-02-17 01:44:45,631] {'Bleu_1': 0.3615578066006017, 'Bleu_2': 0.22033492171721544, 'Bleu_3': 0.14773883777098792, 'Bleu_4': 0.10450138315075229, 'METEOR': 0.18264053219445534, 'ROUGE_L': 0.2977009138130065, 'CIDEr': 0.32456244388246785}\n",
      "[INFO: 2022-02-17 01:48:20,461] ######## Epoch (TEST)44 ########\n",
      "[INFO: 2022-02-17 01:48:20,461] {'Bleu_1': 0.33793919097127767, 'Bleu_2': 0.19865462342007276, 'Bleu_3': 0.12716885703040162, 'Bleu_4': 0.08575007434814674, 'METEOR': 0.17385072444224658, 'ROUGE_L': 0.2835433481718149, 'CIDEr': 0.28417394904080123}\n",
      "[INFO: 2022-02-17 01:48:22,007] Iteration 42020 (DataTime/BatchTime: 0.93/1.54) losses = 2.0489, lr = [2.155890308928128e-05, 0.00021558903089281277]\n",
      "[INFO: 2022-02-17 01:48:22,007]   LabelSmoothing Loss = 2.0489487648010254\n",
      "[INFO: 2022-02-17 01:48:31,553] Iteration 42040 (DataTime/BatchTime: 0.0013/0.477) losses = 1.7641, lr = [2.1553774535056594e-05, 0.00021553774535056593]\n",
      "[INFO: 2022-02-17 01:48:31,554]   LabelSmoothing Loss = 1.0524007081985474\n",
      "[INFO: 2022-02-17 01:48:41,109] Iteration 42060 (DataTime/BatchTime: 0.00126/0.477) losses = 1.7013, lr = [2.154864963912019e-05, 0.00021548649639120188]\n",
      "[INFO: 2022-02-17 01:48:41,109]   LabelSmoothing Loss = 1.558003306388855\n",
      "[INFO: 2022-02-17 01:48:50,641] Iteration 42080 (DataTime/BatchTime: 0.00208/0.477) losses = 1.9013, lr = [2.1543528397124934e-05, 0.0002154352839712493]\n",
      "[INFO: 2022-02-17 01:48:50,641]   LabelSmoothing Loss = 2.2405452728271484\n",
      "[INFO: 2022-02-17 01:49:00,340] Iteration 42100 (DataTime/BatchTime: 0.00324/0.485) losses = 1.6748, lr = [2.153841080473092e-05, 0.00021538410804730916]\n",
      "[INFO: 2022-02-17 01:49:00,340]   LabelSmoothing Loss = 1.0682628154754639\n",
      "[INFO: 2022-02-17 01:49:09,979] Iteration 42120 (DataTime/BatchTime: 0.00138/0.482) losses = 1.8666, lr = [2.1533296857605455e-05, 0.0002153329685760545]\n",
      "[INFO: 2022-02-17 01:49:09,980]   LabelSmoothing Loss = 2.348757266998291\n",
      "[INFO: 2022-02-17 01:49:19,693] Iteration 42140 (DataTime/BatchTime: 0.00571/0.486) losses = 1.748, lr = [2.1528186551423043e-05, 0.00021528186551423038]\n",
      "[INFO: 2022-02-17 01:49:19,693]   LabelSmoothing Loss = 3.2884771823883057\n",
      "[INFO: 2022-02-17 01:49:29,286] Iteration 42160 (DataTime/BatchTime: 0.00314/0.48) losses = 1.5257, lr = [2.1523079881865364e-05, 0.00021523079881865362]\n",
      "[INFO: 2022-02-17 01:49:29,287]   LabelSmoothing Loss = 1.0190997123718262\n",
      "[INFO: 2022-02-17 01:49:38,945] Iteration 42180 (DataTime/BatchTime: 0.00136/0.483) losses = 1.5962, lr = [2.151797684462128e-05, 0.00021517976844621277]\n",
      "[INFO: 2022-02-17 01:49:38,945]   LabelSmoothing Loss = 1.7787460088729858\n",
      "[INFO: 2022-02-17 01:49:48,599] Iteration 42200 (DataTime/BatchTime: 0.00212/0.483) losses = 1.8035, lr = [2.151287743538679e-05, 0.00021512877435386787]\n",
      "[INFO: 2022-02-17 01:49:48,599]   LabelSmoothing Loss = 1.7484431266784668\n",
      "[INFO: 2022-02-17 01:49:58,271] Iteration 42220 (DataTime/BatchTime: 0.00138/0.483) losses = 1.828, lr = [2.1507781649865038e-05, 0.00021507781649865036]\n",
      "[INFO: 2022-02-17 01:49:58,271]   LabelSmoothing Loss = 0.7908189296722412\n",
      "[INFO: 2022-02-17 01:50:07,954] Iteration 42240 (DataTime/BatchTime: 0.00417/0.485) losses = 1.6426, lr = [2.1502689483766283e-05, 0.00021502689483766281]\n",
      "[INFO: 2022-02-17 01:50:07,954]   LabelSmoothing Loss = 1.6672621965408325\n",
      "[INFO: 2022-02-17 01:50:17,612] Iteration 42260 (DataTime/BatchTime: 0.00133/0.483) losses = 1.6216, lr = [2.1497600932807897e-05, 0.00021497600932807894]\n",
      "[INFO: 2022-02-17 01:50:17,613]   LabelSmoothing Loss = 1.104170322418213\n",
      "[INFO: 2022-02-17 01:50:27,169] Iteration 42280 (DataTime/BatchTime: 0.00136/0.478) losses = 1.7577, lr = [2.149251599271434e-05, 0.00021492515992714337]\n",
      "[INFO: 2022-02-17 01:50:27,169]   LabelSmoothing Loss = 1.3767279386520386\n",
      "[INFO: 2022-02-17 01:50:36,732] Iteration 42300 (DataTime/BatchTime: 0.00127/0.478) losses = 1.551, lr = [2.1487434659217147e-05, 0.00021487434659217143]\n",
      "[INFO: 2022-02-17 01:50:36,732]   LabelSmoothing Loss = 2.423499584197998\n",
      "[INFO: 2022-02-17 01:50:46,317] Iteration 42320 (DataTime/BatchTime: 0.00129/0.479) losses = 1.6543, lr = [2.1482356928054907e-05, 0.00021482356928054905]\n",
      "[INFO: 2022-02-17 01:50:46,317]   LabelSmoothing Loss = 0.6902320384979248\n",
      "[INFO: 2022-02-17 01:50:55,850] Iteration 42340 (DataTime/BatchTime: 0.00126/0.477) losses = 1.6826, lr = [2.147728279497327e-05, 0.0002147728279497327]\n",
      "[INFO: 2022-02-17 01:50:55,850]   LabelSmoothing Loss = 2.043330192565918\n",
      "[INFO: 2022-02-17 01:51:05,372] Iteration 42360 (DataTime/BatchTime: 0.00146/0.476) losses = 1.4625, lr = [2.1472212255724912e-05, 0.0002147221225572491]\n",
      "[INFO: 2022-02-17 01:51:05,372]   LabelSmoothing Loss = 1.1529489755630493\n",
      "[INFO: 2022-02-17 01:51:15,041] Iteration 42380 (DataTime/BatchTime: 0.00329/0.483) losses = 1.8962, lr = [2.1467145306069514e-05, 0.00021467145306069513]\n",
      "[INFO: 2022-02-17 01:51:15,041]   LabelSmoothing Loss = 2.5082688331604004\n",
      "[INFO: 2022-02-17 01:51:24,618] Iteration 42400 (DataTime/BatchTime: 0.00214/0.479) losses = 1.6858, lr = [2.146208194177377e-05, 0.00021462081941773766]\n",
      "[INFO: 2022-02-17 01:51:24,618]   LabelSmoothing Loss = 2.3003323078155518\n",
      "[INFO: 2022-02-17 01:51:34,202] Iteration 42420 (DataTime/BatchTime: 0.00127/0.479) losses = 1.7178, lr = [2.1457022158611353e-05, 0.0002145702215861135]\n",
      "[INFO: 2022-02-17 01:51:34,202]   LabelSmoothing Loss = 1.363036036491394\n",
      "[INFO: 2022-02-17 01:51:43,868] Iteration 42440 (DataTime/BatchTime: 0.0014/0.483) losses = 1.5194, lr = [2.145196595236291e-05, 0.00021451965952362908]\n",
      "[INFO: 2022-02-17 01:51:43,868]   LabelSmoothing Loss = 1.071592092514038\n",
      "[INFO: 2022-02-17 01:51:53,475] Iteration 42460 (DataTime/BatchTime: 0.00141/0.48) losses = 1.6989, lr = [2.1446913318816047e-05, 0.00021446913318816043]\n",
      "[INFO: 2022-02-17 01:51:53,476]   LabelSmoothing Loss = 1.5389046669006348\n",
      "[INFO: 2022-02-17 01:52:03,162] Iteration 42480 (DataTime/BatchTime: 0.00227/0.484) losses = 1.8211, lr = [2.144186425376531e-05, 0.00021441864253765307]\n",
      "[INFO: 2022-02-17 01:52:03,162]   LabelSmoothing Loss = 1.4396103620529175\n",
      "[INFO: 2022-02-17 01:52:12,822] Iteration 42500 (DataTime/BatchTime: 0.00206/0.483) losses = 1.8926, lr = [2.1436818753012172e-05, 0.0002143681875301217]\n",
      "[INFO: 2022-02-17 01:52:12,822]   LabelSmoothing Loss = 1.0801266431808472\n",
      "[INFO: 2022-02-17 01:52:22,417] Iteration 42520 (DataTime/BatchTime: 0.00131/0.48) losses = 1.6677, lr = [2.143177681236502e-05, 0.00021431776812365014]\n",
      "[INFO: 2022-02-17 01:52:22,417]   LabelSmoothing Loss = 0.8954370021820068\n",
      "[INFO: 2022-02-17 01:52:32,052] Iteration 42540 (DataTime/BatchTime: 0.00137/0.482) losses = 1.7363, lr = [2.1426738427639125e-05, 0.00021426738427639125]\n",
      "[INFO: 2022-02-17 01:52:32,052]   LabelSmoothing Loss = 2.277169704437256\n",
      "[INFO: 2022-02-17 01:52:41,625] Iteration 42560 (DataTime/BatchTime: 0.00124/0.479) losses = 1.7866, lr = [2.142170359465667e-05, 0.00021421703594656666]\n",
      "[INFO: 2022-02-17 01:52:41,625]   LabelSmoothing Loss = 1.787178874015808\n",
      "[INFO: 2022-02-17 01:52:51,245] Iteration 42580 (DataTime/BatchTime: 0.00128/0.481) losses = 1.8116, lr = [2.1416672309246675e-05, 0.00021416672309246674]\n",
      "[INFO: 2022-02-17 01:52:51,246]   LabelSmoothing Loss = 2.3429782390594482\n",
      "[INFO: 2022-02-17 01:53:00,796] Iteration 42600 (DataTime/BatchTime: 0.00272/0.478) losses = 1.8064, lr = [2.1411644567245046e-05, 0.00021411644567245042]\n",
      "[INFO: 2022-02-17 01:53:00,796]   LabelSmoothing Loss = 1.5480318069458008\n",
      "[INFO: 2022-02-17 01:53:10,349] Iteration 42620 (DataTime/BatchTime: 0.00208/0.478) losses = 1.8336, lr = [2.1406620364494497e-05, 0.00021406620364494494]\n",
      "[INFO: 2022-02-17 01:53:10,349]   LabelSmoothing Loss = 1.7824153900146484\n",
      "[INFO: 2022-02-17 01:53:19,897] Iteration 42640 (DataTime/BatchTime: 0.00208/0.477) losses = 1.5809, lr = [2.140159969684459e-05, 0.00021401599696844586]\n",
      "[INFO: 2022-02-17 01:53:19,897]   LabelSmoothing Loss = 2.339430332183838\n",
      "[INFO: 2022-02-17 01:53:29,507] Iteration 42660 (DataTime/BatchTime: 0.00222/0.48) losses = 1.8016, lr = [2.1396582560151685e-05, 0.00021396582560151683]\n",
      "[INFO: 2022-02-17 01:53:29,507]   LabelSmoothing Loss = 2.577831506729126\n",
      "[INFO: 2022-02-17 01:53:39,055] Iteration 42680 (DataTime/BatchTime: 0.00132/0.477) losses = 1.5697, lr = [2.1391568950278948e-05, 0.00021391568950278943]\n",
      "[INFO: 2022-02-17 01:53:39,055]   LabelSmoothing Loss = 1.4997835159301758\n",
      "[INFO: 2022-02-17 01:53:48,585] Iteration 42700 (DataTime/BatchTime: 0.0013/0.476) losses = 1.6228, lr = [2.1386558863096322e-05, 0.00021386558863096319]\n",
      "[INFO: 2022-02-17 01:53:48,585]   LabelSmoothing Loss = 1.213157057762146\n",
      "[INFO: 2022-02-17 01:53:58,220] Iteration 42720 (DataTime/BatchTime: 0.00134/0.482) losses = 1.6937, lr = [2.1381552294480515e-05, 0.00021381552294480512]\n",
      "[INFO: 2022-02-17 01:53:58,220]   LabelSmoothing Loss = 0.9693753123283386\n",
      "[INFO: 2022-02-17 01:54:07,749] Iteration 42740 (DataTime/BatchTime: 0.0013/0.476) losses = 1.6866, lr = [2.1376549240314996e-05, 0.00021376549240314995]\n",
      "[INFO: 2022-02-17 01:54:07,749]   LabelSmoothing Loss = 1.9320584535598755\n",
      "[INFO: 2022-02-17 01:54:17,260] Iteration 42760 (DataTime/BatchTime: 0.00127/0.476) losses = 1.8608, lr = [2.137154969648997e-05, 0.00021371549696489966]\n",
      "[INFO: 2022-02-17 01:54:17,260]   LabelSmoothing Loss = 0.7496519088745117\n",
      "[INFO: 2022-02-17 01:54:26,748] Iteration 42780 (DataTime/BatchTime: 0.00127/0.474) losses = 1.7747, lr = [2.136655365890236e-05, 0.0002136655365890236]\n",
      "[INFO: 2022-02-17 01:54:26,749]   LabelSmoothing Loss = 1.3329100608825684\n",
      "[INFO: 2022-02-17 01:54:36,234] Iteration 42800 (DataTime/BatchTime: 0.00126/0.474) losses = 1.801, lr = [2.1361561123455817e-05, 0.00021361561123455815]\n",
      "[INFO: 2022-02-17 01:54:36,234]   LabelSmoothing Loss = 2.366358757019043\n",
      "[INFO: 2022-02-17 01:54:45,790] Iteration 42820 (DataTime/BatchTime: 0.00126/0.478) losses = 1.9217, lr = [2.135657208606067e-05, 0.00021356572086060667]\n",
      "[INFO: 2022-02-17 01:54:45,790]   LabelSmoothing Loss = 2.1524012088775635\n",
      "[INFO: 2022-02-17 01:54:55,330] Iteration 42840 (DataTime/BatchTime: 0.00129/0.477) losses = 1.7923, lr = [2.135158654263395e-05, 0.00021351586542633946]\n",
      "[INFO: 2022-02-17 01:54:55,330]   LabelSmoothing Loss = 2.087956666946411\n",
      "[INFO: 2022-02-17 01:55:04,873] Iteration 42860 (DataTime/BatchTime: 0.00127/0.477) losses = 1.6952, lr = [2.1346604489099335e-05, 0.00021346604489099334]\n",
      "[INFO: 2022-02-17 01:55:04,873]   LabelSmoothing Loss = 1.3762531280517578\n",
      "[INFO: 2022-02-17 01:55:14,397] Iteration 42880 (DataTime/BatchTime: 0.00128/0.476) losses = 1.8593, lr = [2.134162592138718e-05, 0.00021341625921387177]\n",
      "[INFO: 2022-02-17 01:55:14,397]   LabelSmoothing Loss = 2.2886006832122803\n",
      "[INFO: 2022-02-17 01:55:23,907] Iteration 42900 (DataTime/BatchTime: 0.00129/0.476) losses = 1.6692, lr = [2.1336650835434463e-05, 0.0002133665083543446]\n",
      "[INFO: 2022-02-17 01:55:23,908]   LabelSmoothing Loss = 2.009671211242676\n",
      "[INFO: 2022-02-17 01:55:33,478] Iteration 42920 (DataTime/BatchTime: 0.00127/0.479) losses = 1.789, lr = [2.13316792271848e-05, 0.000213316792271848]\n",
      "[INFO: 2022-02-17 01:55:33,478]   LabelSmoothing Loss = 1.5858746767044067\n",
      "[INFO: 2022-02-17 01:55:43,014] Iteration 42940 (DataTime/BatchTime: 0.00129/0.477) losses = 1.7489, lr = [2.132671109258842e-05, 0.00021326711092588418]\n",
      "[INFO: 2022-02-17 01:55:43,014]   LabelSmoothing Loss = 1.5427541732788086\n",
      "[INFO: 2022-02-17 01:55:52,536] Iteration 42960 (DataTime/BatchTime: 0.00128/0.476) losses = 1.4895, lr = [2.132174642760214e-05, 0.00021321746427602136]\n",
      "[INFO: 2022-02-17 01:55:52,536]   LabelSmoothing Loss = 1.6824876070022583\n",
      "[INFO: 2022-02-17 01:59:26,241] ######## Epoch (VAL)45 ########\n",
      "[INFO: 2022-02-17 01:59:26,241] {'Bleu_1': 0.33596509688256965, 'Bleu_2': 0.20310591201921505, 'Bleu_3': 0.13390580139097352, 'Bleu_4': 0.09313723174744638, 'METEOR': 0.18176533447495075, 'ROUGE_L': 0.28689514543428324, 'CIDEr': 0.31647339893690385}\n",
      "[INFO: 2022-02-17 02:03:05,312] ######## Epoch (TEST)45 ########\n",
      "[INFO: 2022-02-17 02:03:05,312] {'Bleu_1': 0.3163532525635414, 'Bleu_2': 0.18063323607280088, 'Bleu_3': 0.1103011368578707, 'Bleu_4': 0.06888474998329205, 'METEOR': 0.17459647813080806, 'ROUGE_L': 0.27399665507825494, 'CIDEr': 0.20359594844679096}\n",
      "[INFO: 2022-02-17 02:03:09,362] Iteration 42980 (DataTime/BatchTime: 0.165/0.675) losses = 1.8033, lr = [2.131678522818938e-05, 0.00021316785228189377]\n",
      "[INFO: 2022-02-17 02:03:09,362]   LabelSmoothing Loss = 2.8726179599761963\n",
      "[INFO: 2022-02-17 02:03:18,875] Iteration 43000 (DataTime/BatchTime: 0.00216/0.476) losses = 1.4615, lr = [2.1311827490320114e-05, 0.0002131182749032011]\n",
      "[INFO: 2022-02-17 02:03:18,875]   LabelSmoothing Loss = 2.0933427810668945\n",
      "[INFO: 2022-02-17 02:03:28,491] Iteration 43020 (DataTime/BatchTime: 0.00329/0.481) losses = 1.8548, lr = [2.1306873209970882e-05, 0.00021306873209970878]\n",
      "[INFO: 2022-02-17 02:03:28,492]   LabelSmoothing Loss = 1.846474289894104\n",
      "[INFO: 2022-02-17 02:03:38,075] Iteration 43040 (DataTime/BatchTime: 0.00284/0.479) losses = 1.7558, lr = [2.1301922383124773e-05, 0.0002130192238312477]\n",
      "[INFO: 2022-02-17 02:03:38,075]   LabelSmoothing Loss = 2.86751127243042\n",
      "[INFO: 2022-02-17 02:03:47,743] Iteration 43060 (DataTime/BatchTime: 0.00376/0.483) losses = 1.6805, lr = [2.1296975005771402e-05, 0.000212969750057714]\n",
      "[INFO: 2022-02-17 02:03:47,743]   LabelSmoothing Loss = 1.019270658493042\n",
      "[INFO: 2022-02-17 02:03:57,331] Iteration 43080 (DataTime/BatchTime: 0.0028/0.479) losses = 1.6739, lr = [2.1292031073906898e-05, 0.00021292031073906896]\n",
      "[INFO: 2022-02-17 02:03:57,331]   LabelSmoothing Loss = 2.1330463886260986\n",
      "[INFO: 2022-02-17 02:04:07,065] Iteration 43100 (DataTime/BatchTime: 0.00412/0.487) losses = 1.9161, lr = [2.1287090583533893e-05, 0.0002128709058353389]\n",
      "[INFO: 2022-02-17 02:04:07,065]   LabelSmoothing Loss = 2.1617417335510254\n",
      "[INFO: 2022-02-17 02:04:16,722] Iteration 43120 (DataTime/BatchTime: 0.00216/0.483) losses = 1.5127, lr = [2.1282153530661516e-05, 0.00021282153530661514]\n",
      "[INFO: 2022-02-17 02:04:16,723]   LabelSmoothing Loss = 1.8916720151901245\n",
      "[INFO: 2022-02-17 02:04:26,273] Iteration 43140 (DataTime/BatchTime: 0.00199/0.478) losses = 1.6127, lr = [2.127721991130537e-05, 0.00021277219911305364]\n",
      "[INFO: 2022-02-17 02:04:26,273]   LabelSmoothing Loss = 1.240580677986145\n",
      "[INFO: 2022-02-17 02:04:35,814] Iteration 43160 (DataTime/BatchTime: 0.00226/0.477) losses = 1.5993, lr = [2.127228972148751e-05, 0.00021272289721487508]\n",
      "[INFO: 2022-02-17 02:04:35,814]   LabelSmoothing Loss = 1.9972763061523438\n",
      "[INFO: 2022-02-17 02:04:45,330] Iteration 43180 (DataTime/BatchTime: 0.00116/0.476) losses = 1.5199, lr = [2.1267362957236452e-05, 0.0002126736295723645]\n",
      "[INFO: 2022-02-17 02:04:45,330]   LabelSmoothing Loss = 1.9211565256118774\n",
      "[INFO: 2022-02-17 02:04:54,938] Iteration 43200 (DataTime/BatchTime: 0.00125/0.48) losses = 1.7304, lr = [2.1262439614587145e-05, 0.00021262439614587144]\n",
      "[INFO: 2022-02-17 02:04:54,938]   LabelSmoothing Loss = 1.6879857778549194\n",
      "[INFO: 2022-02-17 02:05:04,557] Iteration 43220 (DataTime/BatchTime: 0.00132/0.481) losses = 1.7841, lr = [2.1257519689580964e-05, 0.0002125751968958096]\n",
      "[INFO: 2022-02-17 02:05:04,557]   LabelSmoothing Loss = 1.0876461267471313\n",
      "[INFO: 2022-02-17 02:05:14,268] Iteration 43240 (DataTime/BatchTime: 0.00235/0.486) losses = 1.6889, lr = [2.125260317826568e-05, 0.00021252603178265677]\n",
      "[INFO: 2022-02-17 02:05:14,268]   LabelSmoothing Loss = 2.4883947372436523\n",
      "[INFO: 2022-02-17 02:05:23,937] Iteration 43260 (DataTime/BatchTime: 0.00139/0.483) losses = 1.6958, lr = [2.124769007669547e-05, 0.0002124769007669547]\n",
      "[INFO: 2022-02-17 02:05:23,938]   LabelSmoothing Loss = 1.5376880168914795\n",
      "[INFO: 2022-02-17 02:05:33,545] Iteration 43280 (DataTime/BatchTime: 0.00132/0.48) losses = 1.6715, lr = [2.1242780380930897e-05, 0.00021242780380930894]\n",
      "[INFO: 2022-02-17 02:05:33,546]   LabelSmoothing Loss = 1.6780717372894287\n",
      "[INFO: 2022-02-17 02:05:43,200] Iteration 43300 (DataTime/BatchTime: 0.00142/0.483) losses = 1.6817, lr = [2.123787408703888e-05, 0.0002123787408703888]\n",
      "[INFO: 2022-02-17 02:05:43,200]   LabelSmoothing Loss = 2.2571191787719727\n",
      "[INFO: 2022-02-17 02:05:52,879] Iteration 43320 (DataTime/BatchTime: 0.00129/0.484) losses = 1.8092, lr = [2.123297119109271e-05, 0.00021232971191092705]\n",
      "[INFO: 2022-02-17 02:05:52,879]   LabelSmoothing Loss = 1.6183419227600098\n",
      "[INFO: 2022-02-17 02:06:02,500] Iteration 43340 (DataTime/BatchTime: 0.00132/0.481) losses = 1.8882, lr = [2.1228071689172e-05, 0.00021228071689172]\n",
      "[INFO: 2022-02-17 02:06:02,501]   LabelSmoothing Loss = 2.072611093521118\n",
      "[INFO: 2022-02-17 02:06:12,226] Iteration 43360 (DataTime/BatchTime: 0.00139/0.486) losses = 1.679, lr = [2.1223175577362714e-05, 0.00021223175577362712]\n",
      "[INFO: 2022-02-17 02:06:12,226]   LabelSmoothing Loss = 2.6320712566375732\n",
      "[INFO: 2022-02-17 02:06:21,797] Iteration 43380 (DataTime/BatchTime: 0.00129/0.478) losses = 1.6028, lr = [2.121828285175712e-05, 0.0002121828285175712]\n",
      "[INFO: 2022-02-17 02:06:21,797]   LabelSmoothing Loss = 1.1361793279647827\n",
      "[INFO: 2022-02-17 02:06:31,409] Iteration 43400 (DataTime/BatchTime: 0.00327/0.482) losses = 1.7253, lr = [2.1213393508453797e-05, 0.00021213393508453794]\n",
      "[INFO: 2022-02-17 02:06:31,409]   LabelSmoothing Loss = 1.7232952117919922\n",
      "[INFO: 2022-02-17 02:06:41,058] Iteration 43420 (DataTime/BatchTime: 0.00135/0.482) losses = 1.8365, lr = [2.1208507543557598e-05, 0.00021208507543557593]\n",
      "[INFO: 2022-02-17 02:06:41,058]   LabelSmoothing Loss = 2.8954548835754395\n",
      "[INFO: 2022-02-17 02:06:50,610] Iteration 43440 (DataTime/BatchTime: 0.00132/0.478) losses = 1.6785, lr = [2.120362495317967e-05, 0.00021203624953179667]\n",
      "[INFO: 2022-02-17 02:06:50,610]   LabelSmoothing Loss = 2.5865395069122314\n",
      "[INFO: 2022-02-17 02:07:00,210] Iteration 43460 (DataTime/BatchTime: 0.00131/0.48) losses = 1.5802, lr = [2.1198745733437417e-05, 0.00021198745733437416]\n",
      "[INFO: 2022-02-17 02:07:00,211]   LabelSmoothing Loss = 1.4031471014022827\n",
      "[INFO: 2022-02-17 02:07:09,772] Iteration 43480 (DataTime/BatchTime: 0.00132/0.478) losses = 1.7126, lr = [2.1193869880454498e-05, 0.00021193869880454497]\n",
      "[INFO: 2022-02-17 02:07:09,772]   LabelSmoothing Loss = 1.6344085931777954\n",
      "[INFO: 2022-02-17 02:07:19,406] Iteration 43500 (DataTime/BatchTime: 0.00141/0.482) losses = 1.8165, lr = [2.1188997390360804e-05, 0.000211889973903608]\n",
      "[INFO: 2022-02-17 02:07:19,406]   LabelSmoothing Loss = 2.0946688652038574\n",
      "[INFO: 2022-02-17 02:07:29,069] Iteration 43520 (DataTime/BatchTime: 0.00138/0.483) losses = 1.6505, lr = [2.1184128259292458e-05, 0.00021184128259292456]\n",
      "[INFO: 2022-02-17 02:07:29,069]   LabelSmoothing Loss = 1.7286667823791504\n",
      "[INFO: 2022-02-17 02:07:38,627] Iteration 43540 (DataTime/BatchTime: 0.00225/0.478) losses = 1.718, lr = [2.1179262483391794e-05, 0.00021179262483391793]\n",
      "[INFO: 2022-02-17 02:07:38,627]   LabelSmoothing Loss = 0.9833183884620667\n",
      "[INFO: 2022-02-17 02:07:48,295] Iteration 43560 (DataTime/BatchTime: 0.00216/0.483) losses = 1.8151, lr = [2.117440005880734e-05, 0.00021174400058807338]\n",
      "[INFO: 2022-02-17 02:07:48,296]   LabelSmoothing Loss = 1.7608526945114136\n",
      "[INFO: 2022-02-17 02:07:57,806] Iteration 43580 (DataTime/BatchTime: 0.0022/0.476) losses = 1.681, lr = [2.1169540981693816e-05, 0.00021169540981693814]\n",
      "[INFO: 2022-02-17 02:07:57,806]   LabelSmoothing Loss = 1.127663016319275\n",
      "[INFO: 2022-02-17 02:08:07,327] Iteration 43600 (DataTime/BatchTime: 0.0039/0.476) losses = 1.7001, lr = [2.1164685248212116e-05, 0.00021164685248212112]\n",
      "[INFO: 2022-02-17 02:08:07,327]   LabelSmoothing Loss = 1.7949177026748657\n",
      "[INFO: 2022-02-17 02:08:16,851] Iteration 43620 (DataTime/BatchTime: 0.00128/0.476) losses = 1.697, lr = [2.115983285452929e-05, 0.00021159832854529288]\n",
      "[INFO: 2022-02-17 02:08:16,851]   LabelSmoothing Loss = 1.4890493154525757\n",
      "[INFO: 2022-02-17 02:08:26,391] Iteration 43640 (DataTime/BatchTime: 0.00136/0.477) losses = 1.8074, lr = [2.1154983796818547e-05, 0.00021154983796818546]\n",
      "[INFO: 2022-02-17 02:08:26,407]   LabelSmoothing Loss = 2.200505495071411\n",
      "[INFO: 2022-02-17 02:08:35,862] Iteration 43660 (DataTime/BatchTime: 0.002/0.474) losses = 1.6073, lr = [2.1150138071259225e-05, 0.00021150138071259224]\n",
      "[INFO: 2022-02-17 02:08:35,863]   LabelSmoothing Loss = 1.2936965227127075\n",
      "[INFO: 2022-02-17 02:08:45,369] Iteration 43680 (DataTime/BatchTime: 0.0022/0.475) losses = 1.7588, lr = [2.1145295674036783e-05, 0.0002114529567403678]\n",
      "[INFO: 2022-02-17 02:08:45,369]   LabelSmoothing Loss = 1.9065816402435303\n",
      "[INFO: 2022-02-17 02:08:54,882] Iteration 43700 (DataTime/BatchTime: 0.00127/0.476) losses = 1.8612, lr = [2.1140456601342796e-05, 0.00021140456601342794]\n",
      "[INFO: 2022-02-17 02:08:54,882]   LabelSmoothing Loss = 1.536720633506775\n",
      "[INFO: 2022-02-17 02:09:04,374] Iteration 43720 (DataTime/BatchTime: 0.00217/0.475) losses = 1.6821, lr = [2.113562084937493e-05, 0.00021135620849374926]\n",
      "[INFO: 2022-02-17 02:09:04,374]   LabelSmoothing Loss = 0.6613465547561646\n",
      "[INFO: 2022-02-17 02:09:13,866] Iteration 43740 (DataTime/BatchTime: 0.00294/0.475) losses = 1.6448, lr = [2.1130788414336945e-05, 0.00021130788414336945]\n",
      "[INFO: 2022-02-17 02:09:13,866]   LabelSmoothing Loss = 1.6707937717437744\n",
      "[INFO: 2022-02-17 02:09:23,339] Iteration 43760 (DataTime/BatchTime: 0.00293/0.474) losses = 1.6484, lr = [2.1125959292438672e-05, 0.00021125959292438672]\n",
      "[INFO: 2022-02-17 02:09:23,339]   LabelSmoothing Loss = 2.0707602500915527\n",
      "[INFO: 2022-02-17 02:09:32,875] Iteration 43780 (DataTime/BatchTime: 0.00125/0.477) losses = 1.5529, lr = [2.1121133479896e-05, 0.00021121133479895998]\n",
      "[INFO: 2022-02-17 02:09:32,876]   LabelSmoothing Loss = 0.9175631999969482\n",
      "[INFO: 2022-02-17 02:09:42,406] Iteration 43800 (DataTime/BatchTime: 0.00303/0.477) losses = 1.7576, lr = [2.1116310972930866e-05, 0.00021116310972930864]\n",
      "[INFO: 2022-02-17 02:09:42,407]   LabelSmoothing Loss = 2.550842046737671\n",
      "[INFO: 2022-02-17 02:09:51,951] Iteration 43820 (DataTime/BatchTime: 0.00212/0.477) losses = 1.6707, lr = [2.111149176777124e-05, 0.0002111149176777124]\n",
      "[INFO: 2022-02-17 02:09:51,951]   LabelSmoothing Loss = 2.0881378650665283\n",
      "[INFO: 2022-02-17 02:10:01,529] Iteration 43840 (DataTime/BatchTime: 0.00202/0.479) losses = 1.7722, lr = [2.1106675860651127e-05, 0.00021106675860651123]\n",
      "[INFO: 2022-02-17 02:10:01,529]   LabelSmoothing Loss = 1.3052016496658325\n",
      "[INFO: 2022-02-17 02:10:11,078] Iteration 43860 (DataTime/BatchTime: 0.0021/0.477) losses = 1.7878, lr = [2.1101863247810525e-05, 0.00021101863247810523]\n",
      "[INFO: 2022-02-17 02:10:11,079]   LabelSmoothing Loss = 1.4012237787246704\n",
      "[INFO: 2022-02-17 02:10:20,660] Iteration 43880 (DataTime/BatchTime: 0.00205/0.479) losses = 1.8106, lr = [2.109705392549545e-05, 0.0002109705392549545]\n",
      "[INFO: 2022-02-17 02:10:20,660]   LabelSmoothing Loss = 2.529369592666626\n",
      "[INFO: 2022-02-17 02:10:30,169] Iteration 43900 (DataTime/BatchTime: 0.00122/0.475) losses = 1.8161, lr = [2.1092247889957886e-05, 0.00021092247889957884]\n",
      "[INFO: 2022-02-17 02:10:30,169]   LabelSmoothing Loss = 2.5520777702331543\n",
      "[INFO: 2022-02-17 02:10:39,710] Iteration 43920 (DataTime/BatchTime: 0.00125/0.477) losses = 1.6566, lr = [2.1087445137455806e-05, 0.00021087445137455804]\n",
      "[INFO: 2022-02-17 02:10:39,710]   LabelSmoothing Loss = 1.9274201393127441\n",
      "[INFO: 2022-02-17 02:14:15,102] ######## Epoch (VAL)46 ########\n",
      "[INFO: 2022-02-17 02:14:15,102] {'Bleu_1': 0.3387602798619112, 'Bleu_2': 0.1981409814936867, 'Bleu_3': 0.12136010988895102, 'Bleu_4': 0.07652177602032344, 'METEOR': 0.1761720623408269, 'ROUGE_L': 0.2873234786662836, 'CIDEr': 0.23139291004755036}\n",
      "[INFO: 2022-02-17 02:17:53,103] ######## Epoch (TEST)46 ########\n",
      "[INFO: 2022-02-17 02:17:53,103] {'Bleu_1': 0.3125613427934851, 'Bleu_2': 0.1797611677329993, 'Bleu_3': 0.11281915601828775, 'Bleu_4': 0.07408641951011971, 'METEOR': 0.17094725218413806, 'ROUGE_L': 0.27090404699129184, 'CIDEr': 0.22180292548722821}\n",
      "[INFO: 2022-02-17 02:17:59,513] Iteration 43940 (DataTime/BatchTime: 0.104/0.583) losses = 1.6134, lr = [2.1082645664253138e-05, 0.00021082645664253133]\n",
      "[INFO: 2022-02-17 02:17:59,513]   LabelSmoothing Loss = 1.484304666519165\n",
      "[INFO: 2022-02-17 02:18:08,911] Iteration 43960 (DataTime/BatchTime: 0.00134/0.47) losses = 1.4181, lr = [2.107784946661975e-05, 0.0002107784946661975]\n",
      "[INFO: 2022-02-17 02:18:08,911]   LabelSmoothing Loss = 1.1375688314437866\n",
      "[INFO: 2022-02-17 02:18:18,376] Iteration 43980 (DataTime/BatchTime: 0.00137/0.473) losses = 1.5785, lr = [2.1073056540831468e-05, 0.00021073056540831466]\n",
      "[INFO: 2022-02-17 02:18:18,376]   LabelSmoothing Loss = 2.1986236572265625\n",
      "[INFO: 2022-02-17 02:18:27,843] Iteration 44000 (DataTime/BatchTime: 0.00323/0.473) losses = 1.3172, lr = [2.1068266883170036e-05, 0.00021068266883170032]\n",
      "[INFO: 2022-02-17 02:18:27,843]   LabelSmoothing Loss = 0.8719244599342346\n",
      "[INFO: 2022-02-17 02:18:37,295] Iteration 44020 (DataTime/BatchTime: 0.00139/0.473) losses = 1.5274, lr = [2.1063480489923096e-05, 0.00021063480489923091]\n",
      "[INFO: 2022-02-17 02:18:37,295]   LabelSmoothing Loss = 1.1543846130371094\n",
      "[INFO: 2022-02-17 02:18:46,868] Iteration 44040 (DataTime/BatchTime: 0.00131/0.479) losses = 1.8638, lr = [2.1058697357384207e-05, 0.00021058697357384206]\n",
      "[INFO: 2022-02-17 02:18:46,868]   LabelSmoothing Loss = 3.1249160766601562\n",
      "[INFO: 2022-02-17 02:18:56,430] Iteration 44060 (DataTime/BatchTime: 0.00305/0.478) losses = 1.6247, lr = [2.105391748185282e-05, 0.00021053917481852818]\n",
      "[INFO: 2022-02-17 02:18:56,431]   LabelSmoothing Loss = 1.2008354663848877\n",
      "[INFO: 2022-02-17 02:19:06,054] Iteration 44080 (DataTime/BatchTime: 0.00226/0.481) losses = 1.7892, lr = [2.1049140859634244e-05, 0.0002104914085963424]\n",
      "[INFO: 2022-02-17 02:19:06,054]   LabelSmoothing Loss = 1.11443293094635\n",
      "[INFO: 2022-02-17 02:19:15,571] Iteration 44100 (DataTime/BatchTime: 0.00128/0.476) losses = 1.5806, lr = [2.1044367487039673e-05, 0.00021044367487039673]\n",
      "[INFO: 2022-02-17 02:19:15,571]   LabelSmoothing Loss = 1.1156725883483887\n",
      "[INFO: 2022-02-17 02:19:25,173] Iteration 44120 (DataTime/BatchTime: 0.00132/0.48) losses = 1.8325, lr = [2.1039597360386145e-05, 0.00021039597360386143]\n",
      "[INFO: 2022-02-17 02:19:25,173]   LabelSmoothing Loss = 1.44337797164917\n",
      "[INFO: 2022-02-17 02:19:34,678] Iteration 44140 (DataTime/BatchTime: 0.00241/0.475) losses = 1.7585, lr = [2.1034830475996534e-05, 0.00021034830475996532]\n",
      "[INFO: 2022-02-17 02:19:34,678]   LabelSmoothing Loss = 1.5075750350952148\n",
      "[INFO: 2022-02-17 02:19:44,162] Iteration 44160 (DataTime/BatchTime: 0.00134/0.474) losses = 1.5779, lr = [2.1030066830199554e-05, 0.0002103006683019955]\n",
      "[INFO: 2022-02-17 02:19:44,162]   LabelSmoothing Loss = 0.45141932368278503\n",
      "[INFO: 2022-02-17 02:19:53,704] Iteration 44180 (DataTime/BatchTime: 0.00295/0.477) losses = 1.5488, lr = [2.102530641932973e-05, 0.00021025306419329728]\n",
      "[INFO: 2022-02-17 02:19:53,704]   LabelSmoothing Loss = 2.3565421104431152\n",
      "[INFO: 2022-02-17 02:20:03,256] Iteration 44200 (DataTime/BatchTime: 0.00218/0.478) losses = 1.7784, lr = [2.102054923972739e-05, 0.00021020549239727387]\n",
      "[INFO: 2022-02-17 02:20:03,256]   LabelSmoothing Loss = 1.838431477546692\n",
      "[INFO: 2022-02-17 02:20:12,823] Iteration 44220 (DataTime/BatchTime: 0.00234/0.478) losses = 1.5794, lr = [2.1015795287738667e-05, 0.00021015795287738663]\n",
      "[INFO: 2022-02-17 02:20:12,823]   LabelSmoothing Loss = 1.3961411714553833\n",
      "[INFO: 2022-02-17 02:20:22,278] Iteration 44240 (DataTime/BatchTime: 0.00225/0.472) losses = 1.4875, lr = [2.101104455971546e-05, 0.00021011044559715459]\n",
      "[INFO: 2022-02-17 02:20:22,278]   LabelSmoothing Loss = 0.9976365566253662\n",
      "[INFO: 2022-02-17 02:20:31,760] Iteration 44260 (DataTime/BatchTime: 0.00211/0.475) losses = 1.7985, lr = [2.1006297052015454e-05, 0.0002100629705201545]\n",
      "[INFO: 2022-02-17 02:20:31,760]   LabelSmoothing Loss = 2.2168822288513184\n",
      "[INFO: 2022-02-17 02:20:41,314] Iteration 44280 (DataTime/BatchTime: 0.0013/0.478) losses = 1.8005, lr = [2.100155276100208e-05, 0.00021001552761002075]\n",
      "[INFO: 2022-02-17 02:20:41,314]   LabelSmoothing Loss = 2.5457727909088135\n",
      "[INFO: 2022-02-17 02:20:50,739] Iteration 44300 (DataTime/BatchTime: 0.00127/0.471) losses = 1.7396, lr = [2.0996811683044518e-05, 0.00020996811683044516]\n",
      "[INFO: 2022-02-17 02:20:50,739]   LabelSmoothing Loss = 0.9532498717308044\n",
      "[INFO: 2022-02-17 02:21:00,253] Iteration 44320 (DataTime/BatchTime: 0.00309/0.476) losses = 1.7571, lr = [2.0992073814517688e-05, 0.00020992073814517687]\n",
      "[INFO: 2022-02-17 02:21:00,254]   LabelSmoothing Loss = 1.6313925981521606\n",
      "[INFO: 2022-02-17 02:21:09,815] Iteration 44340 (DataTime/BatchTime: 0.00332/0.478) losses = 1.653, lr = [2.098733915180223e-05, 0.0002098733915180223]\n",
      "[INFO: 2022-02-17 02:21:09,816]   LabelSmoothing Loss = 2.4960479736328125\n",
      "[INFO: 2022-02-17 02:21:19,264] Iteration 44360 (DataTime/BatchTime: 0.00127/0.472) losses = 1.8593, lr = [2.09826076912845e-05, 0.00020982607691284497]\n",
      "[INFO: 2022-02-17 02:21:19,264]   LabelSmoothing Loss = 1.799163579940796\n",
      "[INFO: 2022-02-17 02:21:28,746] Iteration 44380 (DataTime/BatchTime: 0.00304/0.474) losses = 1.7088, lr = [2.097787942935655e-05, 0.00020977879429356547]\n",
      "[INFO: 2022-02-17 02:21:28,746]   LabelSmoothing Loss = 1.5686148405075073\n",
      "[INFO: 2022-02-17 02:21:38,281] Iteration 44400 (DataTime/BatchTime: 0.00119/0.477) losses = 1.8058, lr = [2.097315436241611e-05, 0.00020973154362416107]\n",
      "[INFO: 2022-02-17 02:21:38,281]   LabelSmoothing Loss = 2.5517728328704834\n",
      "[INFO: 2022-02-17 02:21:47,777] Iteration 44420 (DataTime/BatchTime: 0.00402/0.475) losses = 1.5322, lr = [2.096843248686661e-05, 0.0002096843248686661]\n",
      "[INFO: 2022-02-17 02:21:47,777]   LabelSmoothing Loss = 1.4327237606048584\n",
      "[INFO: 2022-02-17 02:21:57,143] Iteration 44440 (DataTime/BatchTime: 0.00214/0.468) losses = 1.6579, lr = [2.096371379911713e-05, 0.0002096371379911713]\n",
      "[INFO: 2022-02-17 02:21:57,143]   LabelSmoothing Loss = 1.2101393938064575\n",
      "[INFO: 2022-02-17 02:22:06,724] Iteration 44460 (DataTime/BatchTime: 0.00124/0.479) losses = 1.8273, lr = [2.0958998295582408e-05, 0.00020958998295582404]\n",
      "[INFO: 2022-02-17 02:22:06,724]   LabelSmoothing Loss = 0.9434486031532288\n",
      "[INFO: 2022-02-17 02:22:16,203] Iteration 44480 (DataTime/BatchTime: 0.00213/0.474) losses = 1.6589, lr = [2.095428597268282e-05, 0.00020954285972682817]\n",
      "[INFO: 2022-02-17 02:22:16,204]   LabelSmoothing Loss = 1.1361730098724365\n",
      "[INFO: 2022-02-17 02:22:25,699] Iteration 44500 (DataTime/BatchTime: 0.00205/0.475) losses = 1.8157, lr = [2.0949576826844386e-05, 0.00020949576826844384]\n",
      "[INFO: 2022-02-17 02:22:25,699]   LabelSmoothing Loss = 1.9326311349868774\n",
      "[INFO: 2022-02-17 02:22:35,167] Iteration 44520 (DataTime/BatchTime: 0.00119/0.473) losses = 1.7184, lr = [2.094487085449873e-05, 0.00020944870854498727]\n",
      "[INFO: 2022-02-17 02:22:35,168]   LabelSmoothing Loss = 1.4128894805908203\n",
      "[INFO: 2022-02-17 02:22:44,635] Iteration 44540 (DataTime/BatchTime: 0.00128/0.473) losses = 1.6468, lr = [2.0940168052083096e-05, 0.00020940168052083094]\n",
      "[INFO: 2022-02-17 02:22:44,635]   LabelSmoothing Loss = 0.8552996516227722\n",
      "[INFO: 2022-02-17 02:22:54,109] Iteration 44560 (DataTime/BatchTime: 0.00208/0.474) losses = 1.7018, lr = [2.093546841604032e-05, 0.0002093546841604032]\n",
      "[INFO: 2022-02-17 02:22:54,109]   LabelSmoothing Loss = 1.2320683002471924\n",
      "[INFO: 2022-02-17 02:23:03,680] Iteration 44580 (DataTime/BatchTime: 0.00295/0.479) losses = 1.9322, lr = [2.0930771942818825e-05, 0.0002093077194281882]\n",
      "[INFO: 2022-02-17 02:23:03,680]   LabelSmoothing Loss = 1.5910451412200928\n",
      "[INFO: 2022-02-17 02:23:13,250] Iteration 44600 (DataTime/BatchTime: 0.00205/0.478) losses = 1.7933, lr = [2.0926078628872608e-05, 0.00020926078628872604]\n",
      "[INFO: 2022-02-17 02:23:13,250]   LabelSmoothing Loss = 1.5823287963867188\n",
      "[INFO: 2022-02-17 02:23:22,777] Iteration 44620 (DataTime/BatchTime: 0.00207/0.476) losses = 1.6776, lr = [2.092138847066123e-05, 0.00020921388470661228]\n",
      "[INFO: 2022-02-17 02:23:22,777]   LabelSmoothing Loss = 1.9254283905029297\n",
      "[INFO: 2022-02-17 02:23:32,249] Iteration 44640 (DataTime/BatchTime: 0.00219/0.474) losses = 1.6038, lr = [2.0916701464649805e-05, 0.00020916701464649803]\n",
      "[INFO: 2022-02-17 02:23:32,250]   LabelSmoothing Loss = 1.563511610031128\n",
      "[INFO: 2022-02-17 02:23:41,824] Iteration 44660 (DataTime/BatchTime: 0.00206/0.478) losses = 1.7335, lr = [2.0912017607308985e-05, 0.00020912017607308984]\n",
      "[INFO: 2022-02-17 02:23:41,824]   LabelSmoothing Loss = 2.2922351360321045\n",
      "[INFO: 2022-02-17 02:23:51,405] Iteration 44680 (DataTime/BatchTime: 0.00267/0.48) losses = 1.7686, lr = [2.090733689511496e-05, 0.00020907336895114958]\n",
      "[INFO: 2022-02-17 02:23:51,405]   LabelSmoothing Loss = 1.5582201480865479\n",
      "[INFO: 2022-02-17 02:24:00,946] Iteration 44700 (DataTime/BatchTime: 0.00102/0.477) losses = 1.7422, lr = [2.0902659324549422e-05, 0.0002090265932454942]\n",
      "[INFO: 2022-02-17 02:24:00,946]   LabelSmoothing Loss = 2.5029380321502686\n",
      "[INFO: 2022-02-17 02:24:10,398] Iteration 44720 (DataTime/BatchTime: 0.000909/0.473) losses = 1.6128, lr = [2.0897984892099594e-05, 0.0002089798489209959]\n",
      "[INFO: 2022-02-17 02:24:10,398]   LabelSmoothing Loss = 2.406648635864258\n",
      "[INFO: 2022-02-17 02:24:19,899] Iteration 44740 (DataTime/BatchTime: 0.00107/0.475) losses = 1.768, lr = [2.089331359425817e-05, 0.00020893313594258167]\n",
      "[INFO: 2022-02-17 02:24:19,900]   LabelSmoothing Loss = 2.191999673843384\n",
      "[INFO: 2022-02-17 02:24:29,489] Iteration 44760 (DataTime/BatchTime: 0.000997/0.479) losses = 1.7162, lr = [2.0888645427523348e-05, 0.00020888645427523346]\n",
      "[INFO: 2022-02-17 02:24:29,489]   LabelSmoothing Loss = 1.7616932392120361\n",
      "[INFO: 2022-02-17 02:24:38,918] Iteration 44780 (DataTime/BatchTime: 0.00189/0.471) losses = 1.6004, lr = [2.0883980388398797e-05, 0.00020883980388398794]\n",
      "[INFO: 2022-02-17 02:24:38,918]   LabelSmoothing Loss = 1.3349534273147583\n",
      "[INFO: 2022-02-17 02:24:48,438] Iteration 44800 (DataTime/BatchTime: 0.000908/0.476) losses = 1.8746, lr = [2.087931847339364e-05, 0.00020879318473393635]\n",
      "[INFO: 2022-02-17 02:24:48,438]   LabelSmoothing Loss = 2.341400623321533\n",
      "[INFO: 2022-02-17 02:24:57,962] Iteration 44820 (DataTime/BatchTime: 0.00108/0.476) losses = 1.8729, lr = [2.0874659679022464e-05, 0.0002087465967902246]\n",
      "[INFO: 2022-02-17 02:24:57,962]   LabelSmoothing Loss = 2.196270227432251\n",
      "[INFO: 2022-02-17 02:25:07,378] Iteration 44840 (DataTime/BatchTime: 0.00164/0.471) losses = 1.4532, lr = [2.087000400180529e-05, 0.0002087000400180529]\n",
      "[INFO: 2022-02-17 02:25:07,379]   LabelSmoothing Loss = 1.7697402238845825\n",
      "[INFO: 2022-02-17 02:25:16,739] Iteration 44860 (DataTime/BatchTime: 0.00192/0.468) losses = 1.7836, lr = [2.086535143826757e-05, 0.0002086535143826757]\n",
      "[INFO: 2022-02-17 02:25:16,739]   LabelSmoothing Loss = 0.852138340473175\n",
      "[INFO: 2022-02-17 02:25:26,118] Iteration 44880 (DataTime/BatchTime: 0.0017/0.469) losses = 1.5729, lr = [2.0860701984940185e-05, 0.00020860701984940183]\n",
      "[INFO: 2022-02-17 02:25:26,118]   LabelSmoothing Loss = 1.262418270111084\n",
      "[INFO: 2022-02-17 02:29:00,208] ######## Epoch (VAL)47 ########\n",
      "[INFO: 2022-02-17 02:29:00,208] {'Bleu_1': 0.36093647611123175, 'Bleu_2': 0.21711334423268955, 'Bleu_3': 0.14081736567160202, 'Bleu_4': 0.09575823884304287, 'METEOR': 0.1854488617860113, 'ROUGE_L': 0.28866922179577126, 'CIDEr': 0.2865920624295629}\n",
      "[INFO: 2022-02-17 02:32:38,388] ######## Epoch (TEST)47 ########\n",
      "[INFO: 2022-02-17 02:32:38,388] {'Bleu_1': 0.3292948729000925, 'Bleu_2': 0.1867112000545451, 'Bleu_3': 0.11315983314122903, 'Bleu_4': 0.06963304343702048, 'METEOR': 0.17265388379021954, 'ROUGE_L': 0.27368082506752645, 'CIDEr': 0.2049890681389889}\n",
      "[INFO: 2022-02-17 02:32:47,320] Iteration 44900 (DataTime/BatchTime: 0.0722/0.558) losses = 1.7799, lr = [2.0856055638359413e-05, 0.0002085605563835941]\n",
      "[INFO: 2022-02-17 02:32:47,321]   LabelSmoothing Loss = 1.8041660785675049\n",
      "[INFO: 2022-02-17 02:32:56,874] Iteration 44920 (DataTime/BatchTime: 0.00243/0.478) losses = 1.734, lr = [2.085141239506694e-05, 0.00020851412395066937]\n",
      "[INFO: 2022-02-17 02:32:56,874]   LabelSmoothing Loss = 2.0335302352905273\n",
      "[INFO: 2022-02-17 02:33:06,399] Iteration 44940 (DataTime/BatchTime: 0.00218/0.476) losses = 1.5801, lr = [2.084677225160982e-05, 0.0002084677225160982]\n",
      "[INFO: 2022-02-17 02:33:06,399]   LabelSmoothing Loss = 2.246835708618164\n",
      "[INFO: 2022-02-17 02:33:15,972] Iteration 44960 (DataTime/BatchTime: 0.00213/0.479) losses = 1.7303, lr = [2.0842135204540514e-05, 0.0002084213520454051]\n",
      "[INFO: 2022-02-17 02:33:15,972]   LabelSmoothing Loss = 2.0113461017608643\n",
      "[INFO: 2022-02-17 02:33:25,538] Iteration 44980 (DataTime/BatchTime: 0.00318/0.478) losses = 1.5706, lr = [2.0837501250416815e-05, 0.00020837501250416812]\n",
      "[INFO: 2022-02-17 02:33:25,539]   LabelSmoothing Loss = 1.723175287246704\n",
      "[INFO: 2022-02-17 02:33:35,135] Iteration 45000 (DataTime/BatchTime: 0.00216/0.48) losses = 1.541, lr = [2.0832870385801904e-05, 0.00020832870385801902]\n",
      "[INFO: 2022-02-17 02:33:35,135]   LabelSmoothing Loss = 1.3660672903060913\n",
      "[INFO: 2022-02-17 02:33:44,676] Iteration 45020 (DataTime/BatchTime: 0.00243/0.477) losses = 1.5903, lr = [2.0828242607264276e-05, 0.00020828242607264273]\n",
      "[INFO: 2022-02-17 02:33:44,676]   LabelSmoothing Loss = 0.7143001556396484\n",
      "[INFO: 2022-02-17 02:33:54,289] Iteration 45040 (DataTime/BatchTime: 0.0031/0.481) losses = 1.5982, lr = [2.082361791137778e-05, 0.00020823617911377778]\n",
      "[INFO: 2022-02-17 02:33:54,289]   LabelSmoothing Loss = 2.344996213912964\n",
      "[INFO: 2022-02-17 02:34:03,880] Iteration 45060 (DataTime/BatchTime: 0.00329/0.48) losses = 1.6005, lr = [2.081899629472158e-05, 0.0002081899629472158]\n",
      "[INFO: 2022-02-17 02:34:03,880]   LabelSmoothing Loss = 1.1346057653427124\n",
      "[INFO: 2022-02-17 02:34:13,466] Iteration 45080 (DataTime/BatchTime: 0.00135/0.479) losses = 1.7217, lr = [2.0814377753880152e-05, 0.0002081437775388015]\n",
      "[INFO: 2022-02-17 02:34:13,466]   LabelSmoothing Loss = 1.8021363019943237\n",
      "[INFO: 2022-02-17 02:34:23,028] Iteration 45100 (DataTime/BatchTime: 0.0013/0.478) losses = 1.6535, lr = [2.0809762285443277e-05, 0.00020809762285443277]\n",
      "[INFO: 2022-02-17 02:34:23,028]   LabelSmoothing Loss = 1.810524821281433\n",
      "[INFO: 2022-02-17 02:34:32,571] Iteration 45120 (DataTime/BatchTime: 0.00233/0.477) losses = 1.5223, lr = [2.0805149886006027e-05, 0.00020805149886006023]\n",
      "[INFO: 2022-02-17 02:34:32,571]   LabelSmoothing Loss = 1.8385125398635864\n",
      "[INFO: 2022-02-17 02:34:42,092] Iteration 45140 (DataTime/BatchTime: 0.00235/0.476) losses = 1.5504, lr = [2.080054055216875e-05, 0.00020800540552168745]\n",
      "[INFO: 2022-02-17 02:34:42,092]   LabelSmoothing Loss = 1.0440889596939087\n",
      "[INFO: 2022-02-17 02:34:51,687] Iteration 45160 (DataTime/BatchTime: 0.00247/0.48) losses = 1.7394, lr = [2.079593428053706e-05, 0.00020795934280537056]\n",
      "[INFO: 2022-02-17 02:34:51,687]   LabelSmoothing Loss = 1.7981406450271606\n",
      "[INFO: 2022-02-17 02:35:01,415] Iteration 45180 (DataTime/BatchTime: 0.00226/0.486) losses = 1.8577, lr = [2.0791331067721843e-05, 0.0002079133106772184]\n",
      "[INFO: 2022-02-17 02:35:01,415]   LabelSmoothing Loss = 1.0542082786560059\n",
      "[INFO: 2022-02-17 02:35:10,929] Iteration 45200 (DataTime/BatchTime: 0.00121/0.476) losses = 1.7354, lr = [2.078673091033923e-05, 0.0002078673091033923]\n",
      "[INFO: 2022-02-17 02:35:10,929]   LabelSmoothing Loss = 1.5620888471603394\n",
      "[INFO: 2022-02-17 02:35:20,536] Iteration 45220 (DataTime/BatchTime: 0.0033/0.48) losses = 1.6238, lr = [2.0782133805010585e-05, 0.0002078213380501058]\n",
      "[INFO: 2022-02-17 02:35:20,536]   LabelSmoothing Loss = 2.0163559913635254\n",
      "[INFO: 2022-02-17 02:35:30,150] Iteration 45240 (DataTime/BatchTime: 0.00243/0.481) losses = 1.5891, lr = [2.0777539748362505e-05, 0.00020777539748362503]\n",
      "[INFO: 2022-02-17 02:35:30,150]   LabelSmoothing Loss = 1.5621519088745117\n",
      "[INFO: 2022-02-17 02:35:39,805] Iteration 45260 (DataTime/BatchTime: 0.00192/0.483) losses = 1.5111, lr = [2.0772948737026797e-05, 0.00020772948737026795]\n",
      "[INFO: 2022-02-17 02:35:39,806]   LabelSmoothing Loss = 1.3452867269515991\n",
      "[INFO: 2022-02-17 02:35:49,522] Iteration 45280 (DataTime/BatchTime: 0.00388/0.486) losses = 1.7238, lr = [2.076836076764049e-05, 0.00020768360767640487]\n",
      "[INFO: 2022-02-17 02:35:49,522]   LabelSmoothing Loss = 1.1403502225875854\n",
      "[INFO: 2022-02-17 02:35:59,067] Iteration 45300 (DataTime/BatchTime: 0.00126/0.477) losses = 1.5256, lr = [2.0763775836845798e-05, 0.00020763775836845797]\n",
      "[INFO: 2022-02-17 02:35:59,067]   LabelSmoothing Loss = 1.1026684045791626\n",
      "[INFO: 2022-02-17 02:36:08,703] Iteration 45320 (DataTime/BatchTime: 0.00215/0.482) losses = 1.5391, lr = [2.0759193941290127e-05, 0.00020759193941290125]\n",
      "[INFO: 2022-02-17 02:36:08,703]   LabelSmoothing Loss = 0.9589945077896118\n",
      "[INFO: 2022-02-17 02:36:18,239] Iteration 45340 (DataTime/BatchTime: 0.00122/0.477) losses = 1.6768, lr = [2.0754615077626054e-05, 0.0002075461507762605]\n",
      "[INFO: 2022-02-17 02:36:18,239]   LabelSmoothing Loss = 1.0797220468521118\n",
      "[INFO: 2022-02-17 02:36:27,988] Iteration 45360 (DataTime/BatchTime: 0.00156/0.487) losses = 1.558, lr = [2.075003924251133e-05, 0.00020750039242511327]\n",
      "[INFO: 2022-02-17 02:36:27,988]   LabelSmoothing Loss = 1.0051106214523315\n",
      "[INFO: 2022-02-17 02:36:37,523] Iteration 45380 (DataTime/BatchTime: 0.00204/0.477) losses = 1.6932, lr = [2.074546643260885e-05, 0.00020745466432608848]\n",
      "[INFO: 2022-02-17 02:36:37,523]   LabelSmoothing Loss = 0.6618036031723022\n",
      "[INFO: 2022-02-17 02:36:47,161] Iteration 45400 (DataTime/BatchTime: 0.00148/0.482) losses = 1.81, lr = [2.074089664458667e-05, 0.00020740896644586668]\n",
      "[INFO: 2022-02-17 02:36:47,161]   LabelSmoothing Loss = 1.9417070150375366\n",
      "[INFO: 2022-02-17 02:36:56,746] Iteration 45420 (DataTime/BatchTime: 0.00207/0.479) losses = 1.6915, lr = [2.0736329875117967e-05, 0.00020736329875117965]\n",
      "[INFO: 2022-02-17 02:36:56,746]   LabelSmoothing Loss = 1.7921382188796997\n",
      "[INFO: 2022-02-17 02:37:06,305] Iteration 45440 (DataTime/BatchTime: 0.0012/0.478) losses = 1.7741, lr = [2.073176612088106e-05, 0.00020731766120881054]\n",
      "[INFO: 2022-02-17 02:37:06,306]   LabelSmoothing Loss = 2.302685022354126\n",
      "[INFO: 2022-02-17 02:37:15,912] Iteration 45460 (DataTime/BatchTime: 0.00266/0.48) losses = 1.6058, lr = [2.072720537855936e-05, 0.0002072720537855936]\n",
      "[INFO: 2022-02-17 02:37:15,912]   LabelSmoothing Loss = 1.4045263528823853\n",
      "[INFO: 2022-02-17 02:37:25,467] Iteration 45480 (DataTime/BatchTime: 0.00124/0.478) losses = 1.6734, lr = [2.0722647644841408e-05, 0.00020722647644841406]\n",
      "[INFO: 2022-02-17 02:37:25,467]   LabelSmoothing Loss = 1.6973899602890015\n",
      "[INFO: 2022-02-17 02:37:35,079] Iteration 45500 (DataTime/BatchTime: 0.00221/0.481) losses = 1.8132, lr = [2.071809291642082e-05, 0.00020718092916420817]\n",
      "[INFO: 2022-02-17 02:37:35,079]   LabelSmoothing Loss = 1.7248255014419556\n",
      "[INFO: 2022-02-17 02:37:44,794] Iteration 45520 (DataTime/BatchTime: 0.00242/0.486) losses = 1.7061, lr = [2.0713541189996307e-05, 0.00020713541189996306]\n",
      "[INFO: 2022-02-17 02:37:44,794]   LabelSmoothing Loss = 2.0139317512512207\n",
      "[INFO: 2022-02-17 02:37:54,351] Iteration 45540 (DataTime/BatchTime: 0.00213/0.478) losses = 1.8244, lr = [2.0708992462271656e-05, 0.00020708992462271654]\n",
      "[INFO: 2022-02-17 02:37:54,351]   LabelSmoothing Loss = 2.925612688064575\n",
      "[INFO: 2022-02-17 02:38:03,960] Iteration 45560 (DataTime/BatchTime: 0.00127/0.48) losses = 1.7524, lr = [2.070444672995571e-05, 0.0002070444672995571]\n",
      "[INFO: 2022-02-17 02:38:03,960]   LabelSmoothing Loss = 2.983274221420288\n",
      "[INFO: 2022-02-17 02:38:13,492] Iteration 45580 (DataTime/BatchTime: 0.00122/0.477) losses = 1.6303, lr = [2.0699903989762376e-05, 0.00020699903989762373]\n",
      "[INFO: 2022-02-17 02:38:13,492]   LabelSmoothing Loss = 2.720193862915039\n",
      "[INFO: 2022-02-17 02:38:23,047] Iteration 45600 (DataTime/BatchTime: 0.00299/0.478) losses = 1.665, lr = [2.0695364238410603e-05, 0.000206953642384106]\n",
      "[INFO: 2022-02-17 02:38:23,047]   LabelSmoothing Loss = 0.9082380533218384\n",
      "[INFO: 2022-02-17 02:38:32,678] Iteration 45620 (DataTime/BatchTime: 0.0012/0.482) losses = 1.7402, lr = [2.0690827472624363e-05, 0.0002069082747262436]\n",
      "[INFO: 2022-02-17 02:38:32,679]   LabelSmoothing Loss = 1.2577950954437256\n",
      "[INFO: 2022-02-17 02:38:42,368] Iteration 45640 (DataTime/BatchTime: 0.00142/0.484) losses = 1.9171, lr = [2.0686293689132677e-05, 0.00020686293689132674]\n",
      "[INFO: 2022-02-17 02:38:42,368]   LabelSmoothing Loss = 1.9320613145828247\n",
      "[INFO: 2022-02-17 02:38:52,009] Iteration 45660 (DataTime/BatchTime: 0.00328/0.482) losses = 1.7385, lr = [2.068176288466956e-05, 0.00020681762884669556]\n",
      "[INFO: 2022-02-17 02:38:52,009]   LabelSmoothing Loss = 0.9122807383537292\n",
      "[INFO: 2022-02-17 02:39:01,577] Iteration 45680 (DataTime/BatchTime: 0.00272/0.478) losses = 1.6636, lr = [2.0677235055974043e-05, 0.0002067723505597404]\n",
      "[INFO: 2022-02-17 02:39:01,577]   LabelSmoothing Loss = 2.25777530670166\n",
      "[INFO: 2022-02-17 02:39:11,140] Iteration 45700 (DataTime/BatchTime: 0.00143/0.478) losses = 1.7822, lr = [2.067271019979015e-05, 0.00020672710199790145]\n",
      "[INFO: 2022-02-17 02:39:11,140]   LabelSmoothing Loss = 3.1199848651885986\n",
      "[INFO: 2022-02-17 02:39:20,734] Iteration 45720 (DataTime/BatchTime: 0.00115/0.48) losses = 1.6935, lr = [2.066818831286688e-05, 0.00020668188312866878]\n",
      "[INFO: 2022-02-17 02:39:20,734]   LabelSmoothing Loss = 2.915189027786255\n",
      "[INFO: 2022-02-17 02:39:30,262] Iteration 45740 (DataTime/BatchTime: 0.00196/0.476) losses = 1.6939, lr = [2.0663669391958234e-05, 0.0002066366939195823]\n",
      "[INFO: 2022-02-17 02:39:30,262]   LabelSmoothing Loss = 1.3894615173339844\n",
      "[INFO: 2022-02-17 02:39:39,818] Iteration 45760 (DataTime/BatchTime: 0.00206/0.478) losses = 1.7682, lr = [2.0659153433823142e-05, 0.00020659153433823138]\n",
      "[INFO: 2022-02-17 02:39:39,818]   LabelSmoothing Loss = 2.9523754119873047\n",
      "[INFO: 2022-02-17 02:39:49,336] Iteration 45780 (DataTime/BatchTime: 0.0024/0.476) losses = 1.597, lr = [2.0654640435225525e-05, 0.0002065464043522552]\n",
      "[INFO: 2022-02-17 02:39:49,336]   LabelSmoothing Loss = 1.1915287971496582\n",
      "[INFO: 2022-02-17 02:39:58,900] Iteration 45800 (DataTime/BatchTime: 0.00129/0.478) losses = 1.7595, lr = [2.065013039293423e-05, 0.00020650130392934227]\n",
      "[INFO: 2022-02-17 02:39:58,900]   LabelSmoothing Loss = 1.919512391090393\n",
      "[INFO: 2022-02-17 02:40:08,454] Iteration 45820 (DataTime/BatchTime: 0.00242/0.478) losses = 1.762, lr = [2.064562330372304e-05, 0.0002064562330372304]\n",
      "[INFO: 2022-02-17 02:40:08,454]   LabelSmoothing Loss = 1.5674382448196411\n",
      "[INFO: 2022-02-17 02:43:44,250] ######## Epoch (VAL)48 ########\n",
      "[INFO: 2022-02-17 02:43:44,251] {'Bleu_1': 0.35440566488649633, 'Bleu_2': 0.21414014729178252, 'Bleu_3': 0.14101417117237014, 'Bleu_4': 0.09792104672777584, 'METEOR': 0.1844054529747023, 'ROUGE_L': 0.2916891649075532, 'CIDEr': 0.3191652492458008}\n",
      "[INFO: 2022-02-17 02:47:19,517] ######## Epoch (TEST)48 ########\n",
      "[INFO: 2022-02-17 02:47:19,517] {'Bleu_1': 0.32155181209352973, 'Bleu_2': 0.18259664359123565, 'Bleu_3': 0.1125131968385585, 'Bleu_4': 0.07172070984973476, 'METEOR': 0.17354315222376296, 'ROUGE_L': 0.2750086646760212, 'CIDEr': 0.22507607344122255}\n",
      "[INFO: 2022-02-17 02:47:21,117] Iteration 45840 (DataTime/BatchTime: 1.03/1.6) losses = 1.2221, lr = [2.064111916437068e-05, 0.0002064111916437068]\n",
      "[INFO: 2022-02-17 02:47:21,118]   LabelSmoothing Loss = 1.2221277952194214\n",
      "[INFO: 2022-02-17 02:47:30,658] Iteration 45860 (DataTime/BatchTime: 0.00215/0.477) losses = 1.656, lr = [2.0636617971660782e-05, 0.0002063661797166078]\n",
      "[INFO: 2022-02-17 02:47:30,658]   LabelSmoothing Loss = 1.2898329496383667\n",
      "[INFO: 2022-02-17 02:47:40,172] Iteration 45880 (DataTime/BatchTime: 0.00128/0.476) losses = 1.6426, lr = [2.0632119722381882e-05, 0.0002063211972238188]\n",
      "[INFO: 2022-02-17 02:47:40,172]   LabelSmoothing Loss = 2.1252076625823975\n",
      "[INFO: 2022-02-17 02:47:49,654] Iteration 45900 (DataTime/BatchTime: 0.00123/0.474) losses = 1.619, lr = [2.0627624413327417e-05, 0.00020627624413327415]\n",
      "[INFO: 2022-02-17 02:47:49,654]   LabelSmoothing Loss = 1.538936972618103\n",
      "[INFO: 2022-02-17 02:47:59,244] Iteration 45920 (DataTime/BatchTime: 0.00126/0.48) losses = 1.644, lr = [2.0623132041295723e-05, 0.0002062313204129572]\n",
      "[INFO: 2022-02-17 02:47:59,244]   LabelSmoothing Loss = 1.9033136367797852\n",
      "[INFO: 2022-02-17 02:48:08,854] Iteration 45940 (DataTime/BatchTime: 0.00136/0.481) losses = 1.6246, lr = [2.0618642603089994e-05, 0.00020618642603089992]\n",
      "[INFO: 2022-02-17 02:48:08,855]   LabelSmoothing Loss = 2.2071852684020996\n",
      "[INFO: 2022-02-17 02:48:18,281] Iteration 45960 (DataTime/BatchTime: 0.00126/0.471) losses = 1.6052, lr = [2.0614156095518313e-05, 0.00020614156095518312]\n",
      "[INFO: 2022-02-17 02:48:18,281]   LabelSmoothing Loss = 2.9061014652252197\n",
      "[INFO: 2022-02-17 02:48:27,863] Iteration 45980 (DataTime/BatchTime: 0.00201/0.479) losses = 1.9162, lr = [2.060967251539361e-05, 0.00020609672515393607]\n",
      "[INFO: 2022-02-17 02:48:27,863]   LabelSmoothing Loss = 1.9708081483840942\n",
      "[INFO: 2022-02-17 02:48:37,307] Iteration 46000 (DataTime/BatchTime: 0.00123/0.472) losses = 1.44, lr = [2.0605191859533676e-05, 0.00020605191859533674]\n",
      "[INFO: 2022-02-17 02:48:37,307]   LabelSmoothing Loss = 1.0873692035675049\n",
      "[INFO: 2022-02-17 02:48:46,822] Iteration 46020 (DataTime/BatchTime: 0.00281/0.476) losses = 1.6207, lr = [2.060071412476113e-05, 0.00020600714124761129]\n",
      "[INFO: 2022-02-17 02:48:46,822]   LabelSmoothing Loss = 1.6733331680297852\n",
      "[INFO: 2022-02-17 02:48:56,403] Iteration 46040 (DataTime/BatchTime: 0.00298/0.479) losses = 1.7334, lr = [2.059623930790343e-05, 0.0002059623930790343]\n",
      "[INFO: 2022-02-17 02:48:56,403]   LabelSmoothing Loss = 1.209352970123291\n",
      "[INFO: 2022-02-17 02:49:05,944] Iteration 46060 (DataTime/BatchTime: 0.00227/0.477) losses = 1.8238, lr = [2.0591767405792856e-05, 0.00020591767405792855]\n",
      "[INFO: 2022-02-17 02:49:05,944]   LabelSmoothing Loss = 1.5258564949035645\n",
      "[INFO: 2022-02-17 02:49:15,535] Iteration 46080 (DataTime/BatchTime: 0.00137/0.48) losses = 1.6847, lr = [2.0587298415266498e-05, 0.00020587298415266497]\n",
      "[INFO: 2022-02-17 02:49:15,535]   LabelSmoothing Loss = 1.8295202255249023\n",
      "[INFO: 2022-02-17 02:49:25,094] Iteration 46100 (DataTime/BatchTime: 0.003/0.478) losses = 1.5894, lr = [2.0582832333166257e-05, 0.00020582832333166255]\n",
      "[INFO: 2022-02-17 02:49:25,094]   LabelSmoothing Loss = 2.8221497535705566\n",
      "[INFO: 2022-02-17 02:49:34,692] Iteration 46120 (DataTime/BatchTime: 0.00219/0.48) losses = 1.7318, lr = [2.0578369156338807e-05, 0.00020578369156338804]\n",
      "[INFO: 2022-02-17 02:49:34,692]   LabelSmoothing Loss = 0.9740249514579773\n",
      "[INFO: 2022-02-17 02:49:44,278] Iteration 46140 (DataTime/BatchTime: 0.00141/0.479) losses = 1.7482, lr = [2.0573908881635627e-05, 0.00020573908881635626]\n",
      "[INFO: 2022-02-17 02:49:44,278]   LabelSmoothing Loss = 2.0903239250183105\n",
      "[INFO: 2022-02-17 02:49:53,892] Iteration 46160 (DataTime/BatchTime: 0.00224/0.481) losses = 1.6451, lr = [2.056945150591297e-05, 0.00020569451505912965]\n",
      "[INFO: 2022-02-17 02:49:53,892]   LabelSmoothing Loss = 1.4034520387649536\n",
      "[INFO: 2022-02-17 02:50:03,578] Iteration 46180 (DataTime/BatchTime: 0.00303/0.484) losses = 1.5807, lr = [2.0564997026031835e-05, 0.00020564997026031832]\n",
      "[INFO: 2022-02-17 02:50:03,579]   LabelSmoothing Loss = 1.597226858139038\n",
      "[INFO: 2022-02-17 02:50:13,233] Iteration 46200 (DataTime/BatchTime: 0.00231/0.483) losses = 1.6805, lr = [2.0560545438858003e-05, 0.00020560545438858]\n",
      "[INFO: 2022-02-17 02:50:13,234]   LabelSmoothing Loss = 1.8487569093704224\n",
      "[INFO: 2022-02-17 02:50:22,713] Iteration 46220 (DataTime/BatchTime: 0.00132/0.474) losses = 1.6543, lr = [2.0556096741261982e-05, 0.0002055609674126198]\n",
      "[INFO: 2022-02-17 02:50:22,713]   LabelSmoothing Loss = 0.9772517085075378\n",
      "[INFO: 2022-02-17 02:50:32,321] Iteration 46240 (DataTime/BatchTime: 0.00137/0.48) losses = 1.6231, lr = [2.055165093011903e-05, 0.00020551650930119027]\n",
      "[INFO: 2022-02-17 02:50:32,321]   LabelSmoothing Loss = 2.1914474964141846\n",
      "[INFO: 2022-02-17 02:50:41,932] Iteration 46260 (DataTime/BatchTime: 0.00208/0.481) losses = 1.8819, lr = [2.0547208002309128e-05, 0.00020547208002309126]\n",
      "[INFO: 2022-02-17 02:50:41,932]   LabelSmoothing Loss = 2.790127992630005\n",
      "[INFO: 2022-02-17 02:50:51,576] Iteration 46280 (DataTime/BatchTime: 0.00197/0.482) losses = 1.7756, lr = [2.0542767954716977e-05, 0.00020542767954716973]\n",
      "[INFO: 2022-02-17 02:50:51,576]   LabelSmoothing Loss = 1.1341521739959717\n",
      "[INFO: 2022-02-17 02:51:01,101] Iteration 46300 (DataTime/BatchTime: 0.00118/0.476) losses = 1.5886, lr = [2.053833078423199e-05, 0.00020538330784231987]\n",
      "[INFO: 2022-02-17 02:51:01,101]   LabelSmoothing Loss = 1.0230023860931396\n",
      "[INFO: 2022-02-17 02:51:10,768] Iteration 46320 (DataTime/BatchTime: 0.00124/0.483) losses = 1.9506, lr = [2.053389648774828e-05, 0.00020533896487748277]\n",
      "[INFO: 2022-02-17 02:51:10,769]   LabelSmoothing Loss = 2.082555055618286\n",
      "[INFO: 2022-02-17 02:51:20,246] Iteration 46340 (DataTime/BatchTime: 0.00135/0.474) losses = 1.6448, lr = [2.0529465062164647e-05, 0.00020529465062164645]\n",
      "[INFO: 2022-02-17 02:51:20,265]   LabelSmoothing Loss = 1.94100022315979\n",
      "[INFO: 2022-02-17 02:51:29,838] Iteration 46360 (DataTime/BatchTime: 0.00234/0.479) losses = 1.8313, lr = [2.052503650438459e-05, 0.00020525036504384585]\n",
      "[INFO: 2022-02-17 02:51:29,839]   LabelSmoothing Loss = 0.6666994690895081\n",
      "[INFO: 2022-02-17 02:51:39,486] Iteration 46380 (DataTime/BatchTime: 0.00217/0.483) losses = 1.725, lr = [2.052061081131626e-05, 0.0002052061081131626]\n",
      "[INFO: 2022-02-17 02:51:39,486]   LabelSmoothing Loss = 1.9304238557815552\n",
      "[INFO: 2022-02-17 02:51:49,051] Iteration 46400 (DataTime/BatchTime: 0.00218/0.478) losses = 1.7299, lr = [2.0516187979872494e-05, 0.0002051618797987249]\n",
      "[INFO: 2022-02-17 02:51:49,051]   LabelSmoothing Loss = 2.3059465885162354\n",
      "[INFO: 2022-02-17 02:51:58,574] Iteration 46420 (DataTime/BatchTime: 0.00137/0.476) losses = 1.6821, lr = [2.0511768006970764e-05, 0.00020511768006970763]\n",
      "[INFO: 2022-02-17 02:51:58,574]   LabelSmoothing Loss = 1.6876214742660522\n",
      "[INFO: 2022-02-17 02:52:08,100] Iteration 46440 (DataTime/BatchTime: 0.00131/0.476) losses = 1.8643, lr = [2.0507350889533204e-05, 0.00020507350889533202]\n",
      "[INFO: 2022-02-17 02:52:08,100]   LabelSmoothing Loss = 2.215670347213745\n",
      "[INFO: 2022-02-17 02:52:17,620] Iteration 46460 (DataTime/BatchTime: 0.00129/0.476) losses = 1.5323, lr = [2.050293662448658e-05, 0.00020502936624486578]\n",
      "[INFO: 2022-02-17 02:52:17,620]   LabelSmoothing Loss = 0.8586535453796387\n",
      "[INFO: 2022-02-17 02:52:27,122] Iteration 46480 (DataTime/BatchTime: 0.00126/0.475) losses = 1.6909, lr = [2.0498525208762287e-05, 0.00020498525208762283]\n",
      "[INFO: 2022-02-17 02:52:27,123]   LabelSmoothing Loss = 2.009127378463745\n",
      "[INFO: 2022-02-17 02:52:36,639] Iteration 46500 (DataTime/BatchTime: 0.00215/0.476) losses = 1.6148, lr = [2.0494116639296336e-05, 0.0002049411663929633]\n",
      "[INFO: 2022-02-17 02:52:36,639]   LabelSmoothing Loss = 1.725269079208374\n",
      "[INFO: 2022-02-17 02:52:46,206] Iteration 46520 (DataTime/BatchTime: 0.00131/0.478) losses = 1.6801, lr = [2.048971091302936e-05, 0.00020489710913029356]\n",
      "[INFO: 2022-02-17 02:52:46,206]   LabelSmoothing Loss = 1.2155786752700806\n",
      "[INFO: 2022-02-17 02:52:55,760] Iteration 46540 (DataTime/BatchTime: 0.003/0.478) losses = 1.4153, lr = [2.0485308026906578e-05, 0.00020485308026906577]\n",
      "[INFO: 2022-02-17 02:52:55,760]   LabelSmoothing Loss = 1.0820046663284302\n",
      "[INFO: 2022-02-17 02:53:05,241] Iteration 46560 (DataTime/BatchTime: 0.00137/0.474) losses = 1.5457, lr = [2.0480907977877818e-05, 0.00020480907977877814]\n",
      "[INFO: 2022-02-17 02:53:05,241]   LabelSmoothing Loss = 1.575002908706665\n",
      "[INFO: 2022-02-17 02:53:14,862] Iteration 46580 (DataTime/BatchTime: 0.00136/0.481) losses = 1.8017, lr = [2.047651076289748e-05, 0.00020476510762897475]\n",
      "[INFO: 2022-02-17 02:53:14,862]   LabelSmoothing Loss = 1.8511394262313843\n",
      "[INFO: 2022-02-17 02:53:24,373] Iteration 46600 (DataTime/BatchTime: 0.00134/0.476) losses = 1.7126, lr = [2.0472116378924543e-05, 0.0002047211637892454]\n",
      "[INFO: 2022-02-17 02:53:24,373]   LabelSmoothing Loss = 1.9636931419372559\n",
      "[INFO: 2022-02-17 02:53:33,996] Iteration 46620 (DataTime/BatchTime: 0.00217/0.481) losses = 1.7388, lr = [2.0467724822922557e-05, 0.00020467724822922554]\n",
      "[INFO: 2022-02-17 02:53:33,996]   LabelSmoothing Loss = 2.0720345973968506\n",
      "[INFO: 2022-02-17 02:53:43,576] Iteration 46640 (DataTime/BatchTime: 0.00136/0.479) losses = 1.5334, lr = [2.046333609185962e-05, 0.0002046333609185962]\n",
      "[INFO: 2022-02-17 02:53:43,576]   LabelSmoothing Loss = 2.0511999130249023\n",
      "[INFO: 2022-02-17 02:53:53,086] Iteration 46660 (DataTime/BatchTime: 0.00406/0.476) losses = 1.6454, lr = [2.0458950182708393e-05, 0.0002045895018270839]\n",
      "[INFO: 2022-02-17 02:53:53,087]   LabelSmoothing Loss = 1.2882000207901\n",
      "[INFO: 2022-02-17 02:54:02,621] Iteration 46680 (DataTime/BatchTime: 0.0021/0.477) losses = 1.7125, lr = [2.045456709244606e-05, 0.00020454567092446056]\n",
      "[INFO: 2022-02-17 02:54:02,621]   LabelSmoothing Loss = 1.3321889638900757\n",
      "[INFO: 2022-02-17 02:54:12,223] Iteration 46700 (DataTime/BatchTime: 0.00142/0.48) losses = 1.5333, lr = [2.045018681805435e-05, 0.00020450186818054346]\n",
      "[INFO: 2022-02-17 02:54:12,223]   LabelSmoothing Loss = 0.796184778213501\n",
      "[INFO: 2022-02-17 02:54:21,745] Iteration 46720 (DataTime/BatchTime: 0.00131/0.475) losses = 1.6369, lr = [2.0445809356519503e-05, 0.00020445809356519498]\n",
      "[INFO: 2022-02-17 02:54:21,746]   LabelSmoothing Loss = 1.381296157836914\n",
      "[INFO: 2022-02-17 02:54:31,431] Iteration 46740 (DataTime/BatchTime: 0.00297/0.485) losses = 1.7729, lr = [2.0441434704832284e-05, 0.00020441434704832282]\n",
      "[INFO: 2022-02-17 02:54:31,431]   LabelSmoothing Loss = 0.9570528268814087\n",
      "[INFO: 2022-02-17 02:54:40,947] Iteration 46760 (DataTime/BatchTime: 0.00211/0.476) losses = 1.5446, lr = [2.0437062859987958e-05, 0.00020437062859987956]\n",
      "[INFO: 2022-02-17 02:54:40,948]   LabelSmoothing Loss = 1.6360924243927002\n",
      "[INFO: 2022-02-17 02:54:50,451] Iteration 46780 (DataTime/BatchTime: 0.00226/0.475) losses = 1.591, lr = [2.0432693818986286e-05, 0.00020432693818986286]\n",
      "[INFO: 2022-02-17 02:54:50,451]   LabelSmoothing Loss = 1.0323340892791748\n",
      "[INFO: 2022-02-17 02:58:27,557] ######## Epoch (VAL)49 ########\n",
      "[INFO: 2022-02-17 02:58:27,558] {'Bleu_1': 0.36351979173931387, 'Bleu_2': 0.21947363246398843, 'Bleu_3': 0.14382606341199294, 'Bleu_4': 0.09922056900659366, 'METEOR': 0.18411588206262886, 'ROUGE_L': 0.29125067273867505, 'CIDEr': 0.29170205812627253}\n",
      "[INFO: 2022-02-17 03:02:06,945] ######## Epoch (TEST)49 ########\n",
      "[INFO: 2022-02-17 03:02:06,945] {'Bleu_1': 0.33753996017007754, 'Bleu_2': 0.19376552615535453, 'Bleu_3': 0.11999071940398151, 'Bleu_4': 0.07790442283052498, 'METEOR': 0.1695798156300039, 'ROUGE_L': 0.2743650591327987, 'CIDEr': 0.2342758568740625}\n",
      "[INFO: 2022-02-17 03:02:10,899] Iteration 46800 (DataTime/BatchTime: 0.169/0.659) losses = 1.5314, lr = [2.0428327578831524e-05, 0.0002042832757883152]\n",
      "[INFO: 2022-02-17 03:02:10,899]   LabelSmoothing Loss = 1.4070066213607788\n",
      "[INFO: 2022-02-17 03:02:20,386] Iteration 46820 (DataTime/BatchTime: 0.00117/0.474) losses = 1.7262, lr = [2.0423964136532385e-05, 0.00020423964136532383]\n",
      "[INFO: 2022-02-17 03:02:20,386]   LabelSmoothing Loss = 1.5694862604141235\n",
      "[INFO: 2022-02-17 03:02:29,894] Iteration 46840 (DataTime/BatchTime: 0.00131/0.475) losses = 1.5853, lr = [2.041960348910208e-05, 0.00020419603489102079]\n",
      "[INFO: 2022-02-17 03:02:29,894]   LabelSmoothing Loss = 2.329613447189331\n",
      "[INFO: 2022-02-17 03:02:39,461] Iteration 46860 (DataTime/BatchTime: 0.00212/0.478) losses = 1.6032, lr = [2.0415245633558273e-05, 0.00020415245633558272]\n",
      "[INFO: 2022-02-17 03:02:39,462]   LabelSmoothing Loss = 0.9423822164535522\n",
      "[INFO: 2022-02-17 03:02:49,066] Iteration 46880 (DataTime/BatchTime: 0.00247/0.48) losses = 1.5914, lr = [2.041089056692307e-05, 0.00020410890566923066]\n",
      "[INFO: 2022-02-17 03:02:49,066]   LabelSmoothing Loss = 1.7451452016830444\n",
      "[INFO: 2022-02-17 03:02:58,609] Iteration 46900 (DataTime/BatchTime: 0.00221/0.477) losses = 1.7121, lr = [2.040653828622303e-05, 0.00020406538286223027]\n",
      "[INFO: 2022-02-17 03:02:58,609]   LabelSmoothing Loss = 1.3157669305801392\n",
      "[INFO: 2022-02-17 03:03:08,184] Iteration 46920 (DataTime/BatchTime: 0.00138/0.479) losses = 1.4411, lr = [2.0402188788489157e-05, 0.00020402188788489154]\n",
      "[INFO: 2022-02-17 03:03:08,185]   LabelSmoothing Loss = 0.7534836530685425\n",
      "[INFO: 2022-02-17 03:03:17,792] Iteration 46940 (DataTime/BatchTime: 0.00139/0.48) losses = 1.458, lr = [2.039784207075687e-05, 0.0002039784207075687]\n",
      "[INFO: 2022-02-17 03:03:17,793]   LabelSmoothing Loss = 1.7578332424163818\n",
      "[INFO: 2022-02-17 03:03:27,394] Iteration 46960 (DataTime/BatchTime: 0.00147/0.48) losses = 1.4801, lr = [2.0393498130066014e-05, 0.00020393498130066013]\n",
      "[INFO: 2022-02-17 03:03:27,394]   LabelSmoothing Loss = 1.7297202348709106\n",
      "[INFO: 2022-02-17 03:03:37,083] Iteration 46980 (DataTime/BatchTime: 0.0014/0.484) losses = 1.7328, lr = [2.0389156963460842e-05, 0.00020389156963460838]\n",
      "[INFO: 2022-02-17 03:03:37,084]   LabelSmoothing Loss = 1.646393060684204\n",
      "[INFO: 2022-02-17 03:03:46,678] Iteration 47000 (DataTime/BatchTime: 0.00143/0.48) losses = 1.7692, lr = [2.0384818567990012e-05, 0.0002038481856799001]\n",
      "[INFO: 2022-02-17 03:03:46,678]   LabelSmoothing Loss = 1.5240888595581055\n",
      "[INFO: 2022-02-17 03:03:56,237] Iteration 47020 (DataTime/BatchTime: 0.00304/0.478) losses = 1.6542, lr = [2.038048294070657e-05, 0.00020380482940706568]\n",
      "[INFO: 2022-02-17 03:03:56,237]   LabelSmoothing Loss = 1.363792896270752\n",
      "[INFO: 2022-02-17 03:04:05,857] Iteration 47040 (DataTime/BatchTime: 0.00302/0.481) losses = 1.5472, lr = [2.0376150078667958e-05, 0.00020376150078667957]\n",
      "[INFO: 2022-02-17 03:04:05,857]   LabelSmoothing Loss = 1.4311190843582153\n",
      "[INFO: 2022-02-17 03:04:15,610] Iteration 47060 (DataTime/BatchTime: 0.00306/0.488) losses = 1.6553, lr = [2.037181997893599e-05, 0.00020371819978935986]\n",
      "[INFO: 2022-02-17 03:04:15,610]   LabelSmoothing Loss = 1.4816021919250488\n",
      "[INFO: 2022-02-17 03:04:25,128] Iteration 47080 (DataTime/BatchTime: 0.00216/0.476) losses = 1.6341, lr = [2.036749263857684e-05, 0.00020367492638576838]\n",
      "[INFO: 2022-02-17 03:04:25,129]   LabelSmoothing Loss = 2.3004636764526367\n",
      "[INFO: 2022-02-17 03:04:34,723] Iteration 47100 (DataTime/BatchTime: 0.00134/0.48) losses = 1.5693, lr = [2.036316805466106e-05, 0.00020363168054661056]\n",
      "[INFO: 2022-02-17 03:04:34,723]   LabelSmoothing Loss = 1.3123325109481812\n",
      "[INFO: 2022-02-17 03:04:44,303] Iteration 47120 (DataTime/BatchTime: 0.00216/0.479) losses = 1.8448, lr = [2.0358846224263538e-05, 0.00020358846224263535]\n",
      "[INFO: 2022-02-17 03:04:44,303]   LabelSmoothing Loss = 1.3240238428115845\n",
      "[INFO: 2022-02-17 03:04:53,883] Iteration 47140 (DataTime/BatchTime: 0.00222/0.479) losses = 1.4878, lr = [2.0354527144463516e-05, 0.00020354527144463515]\n",
      "[INFO: 2022-02-17 03:04:53,883]   LabelSmoothing Loss = 2.1054391860961914\n",
      "[INFO: 2022-02-17 03:05:03,498] Iteration 47160 (DataTime/BatchTime: 0.00133/0.481) losses = 1.6628, lr = [2.0350210812344567e-05, 0.00020350210812344565]\n",
      "[INFO: 2022-02-17 03:05:03,498]   LabelSmoothing Loss = 2.0613856315612793\n",
      "[INFO: 2022-02-17 03:05:13,105] Iteration 47180 (DataTime/BatchTime: 0.00134/0.48) losses = 1.7315, lr = [2.03458972249946e-05, 0.00020345897224994597]\n",
      "[INFO: 2022-02-17 03:05:13,105]   LabelSmoothing Loss = 2.5943410396575928\n",
      "[INFO: 2022-02-17 03:05:22,632] Iteration 47200 (DataTime/BatchTime: 0.00133/0.476) losses = 1.7396, lr = [2.0341586379505828e-05, 0.00020341586379505824]\n",
      "[INFO: 2022-02-17 03:05:22,632]   LabelSmoothing Loss = 1.4540150165557861\n",
      "[INFO: 2022-02-17 03:05:32,264] Iteration 47220 (DataTime/BatchTime: 0.0031/0.482) losses = 1.6711, lr = [2.033727827297478e-05, 0.00020337278272974777]\n",
      "[INFO: 2022-02-17 03:05:32,264]   LabelSmoothing Loss = 2.135852575302124\n",
      "[INFO: 2022-02-17 03:05:41,998] Iteration 47240 (DataTime/BatchTime: 0.00142/0.487) losses = 1.6511, lr = [2.03329729025023e-05, 0.00020332972902502297]\n",
      "[INFO: 2022-02-17 03:05:41,998]   LabelSmoothing Loss = 1.6917109489440918\n",
      "[INFO: 2022-02-17 03:05:51,589] Iteration 47260 (DataTime/BatchTime: 0.00132/0.48) losses = 1.8128, lr = [2.0328670265193512e-05, 0.00020328670265193512]\n",
      "[INFO: 2022-02-17 03:05:51,590]   LabelSmoothing Loss = 2.0844614505767822\n",
      "[INFO: 2022-02-17 03:06:01,097] Iteration 47280 (DataTime/BatchTime: 0.00296/0.475) losses = 1.6641, lr = [2.0324370358157832e-05, 0.00020324370358157829]\n",
      "[INFO: 2022-02-17 03:06:01,098]   LabelSmoothing Loss = 2.9607460498809814\n",
      "[INFO: 2022-02-17 03:06:10,687] Iteration 47300 (DataTime/BatchTime: 0.00133/0.479) losses = 1.8425, lr = [2.032007317850895e-05, 0.00020320073178508948]\n",
      "[INFO: 2022-02-17 03:06:10,687]   LabelSmoothing Loss = 1.8552378416061401\n",
      "[INFO: 2022-02-17 03:06:20,282] Iteration 47320 (DataTime/BatchTime: 0.00226/0.48) losses = 1.718, lr = [2.0315778723364825e-05, 0.00020315778723364823]\n",
      "[INFO: 2022-02-17 03:06:20,282]   LabelSmoothing Loss = 2.123629570007324\n",
      "[INFO: 2022-02-17 03:06:29,839] Iteration 47340 (DataTime/BatchTime: 0.00224/0.478) losses = 1.5237, lr = [2.0311486989847695e-05, 0.0002031148698984769]\n",
      "[INFO: 2022-02-17 03:06:29,839]   LabelSmoothing Loss = 0.7498695254325867\n",
      "[INFO: 2022-02-17 03:06:39,429] Iteration 47360 (DataTime/BatchTime: 0.00229/0.479) losses = 1.6349, lr = [2.030719797508403e-05, 0.00020307197975084028]\n",
      "[INFO: 2022-02-17 03:06:39,429]   LabelSmoothing Loss = 1.5272270441055298\n",
      "[INFO: 2022-02-17 03:06:48,974] Iteration 47380 (DataTime/BatchTime: 0.00307/0.477) losses = 1.616, lr = [2.0302911676204554e-05, 0.00020302911676204553]\n",
      "[INFO: 2022-02-17 03:06:48,974]   LabelSmoothing Loss = 1.28875732421875\n",
      "[INFO: 2022-02-17 03:06:58,528] Iteration 47400 (DataTime/BatchTime: 0.00308/0.478) losses = 1.7555, lr = [2.0298628090344235e-05, 0.00020298628090344232]\n",
      "[INFO: 2022-02-17 03:06:58,528]   LabelSmoothing Loss = 2.1419858932495117\n",
      "[INFO: 2022-02-17 03:07:08,053] Iteration 47420 (DataTime/BatchTime: 0.00131/0.476) losses = 1.5677, lr = [2.0294347214642257e-05, 0.00020294347214642254]\n",
      "[INFO: 2022-02-17 03:07:08,053]   LabelSmoothing Loss = 1.5985738039016724\n",
      "[INFO: 2022-02-17 03:07:17,555] Iteration 47440 (DataTime/BatchTime: 0.0013/0.475) losses = 1.6715, lr = [2.0290069046242032e-05, 0.0002029006904624203]\n",
      "[INFO: 2022-02-17 03:07:17,555]   LabelSmoothing Loss = 1.7818337678909302\n",
      "[INFO: 2022-02-17 03:07:27,206] Iteration 47460 (DataTime/BatchTime: 0.00264/0.483) losses = 1.5927, lr = [2.0285793582291196e-05, 0.00020285793582291192]\n",
      "[INFO: 2022-02-17 03:07:27,206]   LabelSmoothing Loss = 1.568609356880188\n",
      "[INFO: 2022-02-17 03:07:36,739] Iteration 47480 (DataTime/BatchTime: 0.00145/0.477) losses = 1.5286, lr = [2.028152081994157e-05, 0.00020281520819941568]\n",
      "[INFO: 2022-02-17 03:07:36,740]   LabelSmoothing Loss = 3.04431414604187\n",
      "[INFO: 2022-02-17 03:07:46,351] Iteration 47500 (DataTime/BatchTime: 0.00138/0.481) losses = 1.7637, lr = [2.0277250756349193e-05, 0.0002027725075634919]\n",
      "[INFO: 2022-02-17 03:07:46,352]   LabelSmoothing Loss = 1.0401729345321655\n",
      "[INFO: 2022-02-17 03:07:56,024] Iteration 47520 (DataTime/BatchTime: 0.0022/0.484) losses = 1.6172, lr = [2.027298338867428e-05, 0.00020272983388674277]\n",
      "[INFO: 2022-02-17 03:07:56,024]   LabelSmoothing Loss = 1.338753342628479\n",
      "[INFO: 2022-02-17 03:08:05,571] Iteration 47540 (DataTime/BatchTime: 0.00134/0.477) losses = 1.6967, lr = [2.026871871408123e-05, 0.00020268718714081227]\n",
      "[INFO: 2022-02-17 03:08:05,571]   LabelSmoothing Loss = 1.154436707496643\n",
      "[INFO: 2022-02-17 03:08:15,164] Iteration 47560 (DataTime/BatchTime: 0.00134/0.48) losses = 1.8278, lr = [2.026445672973862e-05, 0.00020264456729738616]\n",
      "[INFO: 2022-02-17 03:08:15,164]   LabelSmoothing Loss = 2.2779626846313477\n",
      "[INFO: 2022-02-17 03:08:24,677] Iteration 47580 (DataTime/BatchTime: 0.00234/0.476) losses = 1.5566, lr = [2.0260197432819187e-05, 0.00020260197432819186]\n",
      "[INFO: 2022-02-17 03:08:24,677]   LabelSmoothing Loss = 0.9606346487998962\n",
      "[INFO: 2022-02-17 03:08:34,242] Iteration 47600 (DataTime/BatchTime: 0.00141/0.478) losses = 1.4928, lr = [2.0255940820499836e-05, 0.00020255940820499834]\n",
      "[INFO: 2022-02-17 03:08:34,242]   LabelSmoothing Loss = 2.3482301235198975\n",
      "[INFO: 2022-02-17 03:08:43,954] Iteration 47620 (DataTime/BatchTime: 0.00141/0.486) losses = 1.8163, lr = [2.0251686889961613e-05, 0.0002025168688996161]\n",
      "[INFO: 2022-02-17 03:08:43,954]   LabelSmoothing Loss = 2.588196277618408\n",
      "[INFO: 2022-02-17 03:08:53,466] Iteration 47640 (DataTime/BatchTime: 0.00133/0.476) losses = 1.7853, lr = [2.0247435638389706e-05, 0.00020247435638389704]\n",
      "[INFO: 2022-02-17 03:08:53,466]   LabelSmoothing Loss = 1.383908748626709\n",
      "[INFO: 2022-02-17 03:09:03,012] Iteration 47660 (DataTime/BatchTime: 0.0025/0.477) losses = 1.6997, lr = [2.024318706297344e-05, 0.0002024318706297344]\n",
      "[INFO: 2022-02-17 03:09:03,013]   LabelSmoothing Loss = 1.8682740926742554\n",
      "[INFO: 2022-02-17 03:09:12,650] Iteration 47680 (DataTime/BatchTime: 0.00127/0.482) losses = 1.9395, lr = [2.0238941160906274e-05, 0.0002023894116090627]\n",
      "[INFO: 2022-02-17 03:09:12,650]   LabelSmoothing Loss = 1.859236717224121\n",
      "[INFO: 2022-02-17 03:09:22,179] Iteration 47700 (DataTime/BatchTime: 0.00135/0.476) losses = 1.5939, lr = [2.0234697929385773e-05, 0.0002023469792938577]\n",
      "[INFO: 2022-02-17 03:09:22,179]   LabelSmoothing Loss = 1.8707687854766846\n",
      "[INFO: 2022-02-17 03:09:31,703] Iteration 47720 (DataTime/BatchTime: 0.00217/0.476) losses = 1.6077, lr = [2.0230457365613618e-05, 0.00020230457365613618]\n",
      "[INFO: 2022-02-17 03:09:31,703]   LabelSmoothing Loss = 1.8237680196762085\n",
      "[INFO: 2022-02-17 03:09:41,244] Iteration 47740 (DataTime/BatchTime: 0.00133/0.477) losses = 1.6124, lr = [2.0226219466795603e-05, 0.000202262194667956]\n",
      "[INFO: 2022-02-17 03:09:41,244]   LabelSmoothing Loss = 1.684637427330017\n",
      "[INFO: 2022-02-17 03:13:17,292] ######## Epoch (VAL)50 ########\n",
      "[INFO: 2022-02-17 03:13:17,293] {'Bleu_1': 0.3866997854803673, 'Bleu_2': 0.23917380767582852, 'Bleu_3': 0.16244150808333385, 'Bleu_4': 0.11658788663149097, 'METEOR': 0.1929936326123175, 'ROUGE_L': 0.3074158216000527, 'CIDEr': 0.34517694896797535}\n",
      "[INFO: 2022-02-17 03:16:53,065] ######## Epoch (TEST)50 ########\n",
      "[INFO: 2022-02-17 03:16:53,065] {'Bleu_1': 0.3518026161862861, 'Bleu_2': 0.2056567045032227, 'Bleu_3': 0.13148184324026002, 'Bleu_4': 0.08754505437128618, 'METEOR': 0.17807927691221068, 'ROUGE_L': 0.28824400614632156, 'CIDEr': 0.2896254214628751}\n",
      "[INFO: 2022-02-17 03:16:59,430] Iteration 47760 (DataTime/BatchTime: 0.0934/0.579) losses = 1.6049, lr = [2.02219842301416e-05, 0.00020221984230141596]\n",
      "[INFO: 2022-02-17 03:16:59,430]   LabelSmoothing Loss = 2.6931848526000977\n",
      "[INFO: 2022-02-17 03:17:08,827] Iteration 47780 (DataTime/BatchTime: 0.00215/0.47) losses = 1.4668, lr = [2.021775165286558e-05, 0.00020217751652865576]\n",
      "[INFO: 2022-02-17 03:17:08,827]   LabelSmoothing Loss = 1.2235294580459595\n",
      "[INFO: 2022-02-17 03:17:18,295] Iteration 47800 (DataTime/BatchTime: 0.00199/0.473) losses = 1.498, lr = [2.0213521732185593e-05, 0.0002021352173218559]\n",
      "[INFO: 2022-02-17 03:17:18,296]   LabelSmoothing Loss = 1.7656606435775757\n",
      "[INFO: 2022-02-17 03:17:27,894] Iteration 47820 (DataTime/BatchTime: 0.00334/0.479) losses = 1.5744, lr = [2.020929446532376e-05, 0.00020209294465323757]\n",
      "[INFO: 2022-02-17 03:17:27,894]   LabelSmoothing Loss = 1.514331340789795\n",
      "[INFO: 2022-02-17 03:17:37,412] Iteration 47840 (DataTime/BatchTime: 0.00398/0.477) losses = 1.74, lr = [2.0205069849506266e-05, 0.00020205069849506266]\n",
      "[INFO: 2022-02-17 03:17:37,412]   LabelSmoothing Loss = 1.2831685543060303\n",
      "[INFO: 2022-02-17 03:17:47,019] Iteration 47860 (DataTime/BatchTime: 0.00216/0.48) losses = 1.4771, lr = [2.0200847881963363e-05, 0.00020200847881963362]\n",
      "[INFO: 2022-02-17 03:17:47,019]   LabelSmoothing Loss = 1.0121629238128662\n",
      "[INFO: 2022-02-17 03:17:56,584] Iteration 47880 (DataTime/BatchTime: 0.00504/0.478) losses = 1.796, lr = [2.0196628559929336e-05, 0.00020196628559929336]\n",
      "[INFO: 2022-02-17 03:17:56,584]   LabelSmoothing Loss = 2.6293160915374756\n",
      "[INFO: 2022-02-17 03:18:06,099] Iteration 47900 (DataTime/BatchTime: 0.00209/0.476) losses = 1.7252, lr = [2.0192411880642524e-05, 0.0002019241188064252]\n",
      "[INFO: 2022-02-17 03:18:06,100]   LabelSmoothing Loss = 2.5416438579559326\n",
      "[INFO: 2022-02-17 03:18:15,593] Iteration 47920 (DataTime/BatchTime: 0.00237/0.475) losses = 1.6699, lr = [2.01881978413453e-05, 0.00020188197841345296]\n",
      "[INFO: 2022-02-17 03:18:15,593]   LabelSmoothing Loss = 2.7418978214263916\n",
      "[INFO: 2022-02-17 03:18:25,115] Iteration 47940 (DataTime/BatchTime: 0.0012/0.476) losses = 1.6097, lr = [2.018398643928405e-05, 0.00020183986439284047]\n",
      "[INFO: 2022-02-17 03:18:25,116]   LabelSmoothing Loss = 1.8453850746154785\n",
      "[INFO: 2022-02-17 03:18:34,619] Iteration 47960 (DataTime/BatchTime: 0.00233/0.475) losses = 1.6316, lr = [2.0179777671709202e-05, 0.000201797776717092]\n",
      "[INFO: 2022-02-17 03:18:34,619]   LabelSmoothing Loss = 1.2891082763671875\n",
      "[INFO: 2022-02-17 03:18:44,090] Iteration 47980 (DataTime/BatchTime: 0.002/0.474) losses = 1.4739, lr = [2.0175571535875175e-05, 0.00020175571535875172]\n",
      "[INFO: 2022-02-17 03:18:44,091]   LabelSmoothing Loss = 1.3671751022338867\n",
      "[INFO: 2022-02-17 03:18:53,632] Iteration 48000 (DataTime/BatchTime: 0.00118/0.477) losses = 1.7953, lr = [2.0171368029040403e-05, 0.00020171368029040402]\n",
      "[INFO: 2022-02-17 03:18:53,632]   LabelSmoothing Loss = 1.4051363468170166\n",
      "[INFO: 2022-02-17 03:19:03,119] Iteration 48020 (DataTime/BatchTime: 0.00199/0.474) losses = 1.419, lr = [2.0167167148467317e-05, 0.00020167167148467315]\n",
      "[INFO: 2022-02-17 03:19:03,119]   LabelSmoothing Loss = 1.4412271976470947\n",
      "[INFO: 2022-02-17 03:19:12,632] Iteration 48040 (DataTime/BatchTime: 0.00117/0.476) losses = 1.6848, lr = [2.0162968891422338e-05, 0.00020162968891422335]\n",
      "[INFO: 2022-02-17 03:19:12,632]   LabelSmoothing Loss = 1.3885679244995117\n",
      "[INFO: 2022-02-17 03:19:22,147] Iteration 48060 (DataTime/BatchTime: 0.00118/0.476) losses = 1.6819, lr = [2.015877325517586e-05, 0.00020158773255175854]\n",
      "[INFO: 2022-02-17 03:19:22,147]   LabelSmoothing Loss = 2.529520273208618\n",
      "[INFO: 2022-02-17 03:19:31,634] Iteration 48080 (DataTime/BatchTime: 0.00119/0.474) losses = 1.5386, lr = [2.0154580237002252e-05, 0.0002015458023700225]\n",
      "[INFO: 2022-02-17 03:19:31,634]   LabelSmoothing Loss = 1.5965296030044556\n",
      "[INFO: 2022-02-17 03:19:41,103] Iteration 48100 (DataTime/BatchTime: 0.00119/0.473) losses = 1.5675, lr = [2.015038983417987e-05, 0.00020150389834179867]\n",
      "[INFO: 2022-02-17 03:19:41,103]   LabelSmoothing Loss = 2.2165703773498535\n",
      "[INFO: 2022-02-17 03:19:50,562] Iteration 48120 (DataTime/BatchTime: 0.0012/0.473) losses = 1.5848, lr = [2.0146202043990997e-05, 0.00020146202043990995]\n",
      "[INFO: 2022-02-17 03:19:50,563]   LabelSmoothing Loss = 1.6489896774291992\n",
      "[INFO: 2022-02-17 03:20:00,151] Iteration 48140 (DataTime/BatchTime: 0.00117/0.479) losses = 1.8957, lr = [2.0142016863721893e-05, 0.00020142016863721891]\n",
      "[INFO: 2022-02-17 03:20:00,152]   LabelSmoothing Loss = 1.989884853363037\n",
      "[INFO: 2022-02-17 03:20:09,640] Iteration 48160 (DataTime/BatchTime: 0.00116/0.474) losses = 1.6412, lr = [2.013783429066276e-05, 0.00020137834290662757]\n",
      "[INFO: 2022-02-17 03:20:09,640]   LabelSmoothing Loss = 1.737436056137085\n",
      "[INFO: 2022-02-17 03:20:19,172] Iteration 48180 (DataTime/BatchTime: 0.00232/0.477) losses = 1.6691, lr = [2.0133654322107725e-05, 0.0002013365432210772]\n",
      "[INFO: 2022-02-17 03:20:19,173]   LabelSmoothing Loss = 1.6123688220977783\n",
      "[INFO: 2022-02-17 03:20:28,690] Iteration 48200 (DataTime/BatchTime: 0.00118/0.476) losses = 1.6816, lr = [2.0129476955354853e-05, 0.00020129476955354852]\n",
      "[INFO: 2022-02-17 03:20:28,690]   LabelSmoothing Loss = 1.5194681882858276\n",
      "[INFO: 2022-02-17 03:20:38,131] Iteration 48220 (DataTime/BatchTime: 0.00117/0.472) losses = 1.6876, lr = [2.0125302187706134e-05, 0.0002012530218770613]\n",
      "[INFO: 2022-02-17 03:20:38,131]   LabelSmoothing Loss = 1.9730757474899292\n",
      "[INFO: 2022-02-17 03:20:47,615] Iteration 48240 (DataTime/BatchTime: 0.00118/0.474) losses = 1.6641, lr = [2.0121130016467467e-05, 0.00020121130016467466]\n",
      "[INFO: 2022-02-17 03:20:47,615]   LabelSmoothing Loss = 1.7844502925872803\n",
      "[INFO: 2022-02-17 03:20:57,065] Iteration 48260 (DataTime/BatchTime: 0.002/0.472) losses = 1.7419, lr = [2.0116960438948663e-05, 0.0002011696043894866]\n",
      "[INFO: 2022-02-17 03:20:57,065]   LabelSmoothing Loss = 1.9468783140182495\n",
      "[INFO: 2022-02-17 03:21:06,579] Iteration 48280 (DataTime/BatchTime: 0.00116/0.476) losses = 1.5654, lr = [2.011279345246343e-05, 0.00020112793452463427]\n",
      "[INFO: 2022-02-17 03:21:06,579]   LabelSmoothing Loss = 1.3733298778533936\n",
      "[INFO: 2022-02-17 03:21:16,063] Iteration 48300 (DataTime/BatchTime: 0.00279/0.474) losses = 1.6086, lr = [2.0108629054329373e-05, 0.0002010862905432937]\n",
      "[INFO: 2022-02-17 03:21:16,063]   LabelSmoothing Loss = 1.4273617267608643\n",
      "[INFO: 2022-02-17 03:21:25,550] Iteration 48320 (DataTime/BatchTime: 0.00116/0.473) losses = 1.672, lr = [2.0104467241867985e-05, 0.00020104467241867981]\n",
      "[INFO: 2022-02-17 03:21:25,550]   LabelSmoothing Loss = 2.365791082382202\n",
      "[INFO: 2022-02-17 03:21:35,107] Iteration 48340 (DataTime/BatchTime: 0.00427/0.479) losses = 1.5342, lr = [2.0100308012404635e-05, 0.00020100308012404631]\n",
      "[INFO: 2022-02-17 03:21:35,107]   LabelSmoothing Loss = 1.7372608184814453\n",
      "[INFO: 2022-02-17 03:21:44,701] Iteration 48360 (DataTime/BatchTime: 0.00287/0.48) losses = 1.6006, lr = [2.0096151363268557e-05, 0.00020096151363268555]\n",
      "[INFO: 2022-02-17 03:21:44,701]   LabelSmoothing Loss = 1.7909191846847534\n",
      "[INFO: 2022-02-17 03:21:54,369] Iteration 48380 (DataTime/BatchTime: 0.00142/0.483) losses = 1.5652, lr = [2.0091997291792864e-05, 0.00020091997291792863]\n",
      "[INFO: 2022-02-17 03:21:54,369]   LabelSmoothing Loss = 1.4474600553512573\n",
      "[INFO: 2022-02-17 03:22:03,923] Iteration 48400 (DataTime/BatchTime: 0.00129/0.478) losses = 1.5551, lr = [2.0087845795314516e-05, 0.00020087845795314512]\n",
      "[INFO: 2022-02-17 03:22:03,923]   LabelSmoothing Loss = 1.5884101390838623\n",
      "[INFO: 2022-02-17 03:22:13,518] Iteration 48420 (DataTime/BatchTime: 0.00133/0.48) losses = 1.8172, lr = [2.0083696871174323e-05, 0.0002008369687117432]\n",
      "[INFO: 2022-02-17 03:22:13,518]   LabelSmoothing Loss = 1.8989267349243164\n",
      "[INFO: 2022-02-17 03:22:23,218] Iteration 48440 (DataTime/BatchTime: 0.00137/0.485) losses = 1.5619, lr = [2.0079550516716945e-05, 0.0002007955051671694]\n",
      "[INFO: 2022-02-17 03:22:23,218]   LabelSmoothing Loss = 1.3376697301864624\n",
      "[INFO: 2022-02-17 03:22:32,841] Iteration 48460 (DataTime/BatchTime: 0.00151/0.481) losses = 1.6797, lr = [2.0075406729290872e-05, 0.0002007540672929087]\n",
      "[INFO: 2022-02-17 03:22:32,842]   LabelSmoothing Loss = 2.146392583847046\n",
      "[INFO: 2022-02-17 03:22:42,447] Iteration 48480 (DataTime/BatchTime: 0.00307/0.48) losses = 1.9379, lr = [2.007126550624842e-05, 0.00020071265506248418]\n",
      "[INFO: 2022-02-17 03:22:42,447]   LabelSmoothing Loss = 2.178032398223877\n",
      "[INFO: 2022-02-17 03:22:52,056] Iteration 48500 (DataTime/BatchTime: 0.00119/0.48) losses = 1.5045, lr = [2.006712684494574e-05, 0.00020067126844945738]\n",
      "[INFO: 2022-02-17 03:22:52,056]   LabelSmoothing Loss = 1.663333773612976\n",
      "[INFO: 2022-02-17 03:23:01,589] Iteration 48520 (DataTime/BatchTime: 0.00223/0.477) losses = 1.5603, lr = [2.006299074274278e-05, 0.0002006299074274278]\n",
      "[INFO: 2022-02-17 03:23:01,589]   LabelSmoothing Loss = 1.600525140762329\n",
      "[INFO: 2022-02-17 03:23:11,165] Iteration 48540 (DataTime/BatchTime: 0.00121/0.479) losses = 1.7512, lr = [2.005885719700331e-05, 0.00020058857197003307]\n",
      "[INFO: 2022-02-17 03:23:11,165]   LabelSmoothing Loss = 2.4168412685394287\n",
      "[INFO: 2022-02-17 03:23:20,730] Iteration 48560 (DataTime/BatchTime: 0.0012/0.478) losses = 1.7205, lr = [2.005472620509489e-05, 0.0002005472620509489]\n",
      "[INFO: 2022-02-17 03:23:20,730]   LabelSmoothing Loss = 2.4188480377197266\n",
      "[INFO: 2022-02-17 03:23:30,237] Iteration 48580 (DataTime/BatchTime: 0.00119/0.475) losses = 1.5326, lr = [2.005059776438888e-05, 0.00020050597764388877]\n",
      "[INFO: 2022-02-17 03:23:30,237]   LabelSmoothing Loss = 1.2096869945526123\n",
      "[INFO: 2022-02-17 03:23:39,817] Iteration 48600 (DataTime/BatchTime: 0.00281/0.479) losses = 1.6028, lr = [2.0046471872260424e-05, 0.00020046471872260422]\n",
      "[INFO: 2022-02-17 03:23:39,818]   LabelSmoothing Loss = 1.1492360830307007\n",
      "[INFO: 2022-02-17 03:23:49,485] Iteration 48620 (DataTime/BatchTime: 0.00136/0.483) losses = 1.6634, lr = [2.0042348526088444e-05, 0.0002004234852608844]\n",
      "[INFO: 2022-02-17 03:23:49,486]   LabelSmoothing Loss = 1.9833617210388184\n",
      "[INFO: 2022-02-17 03:23:59,153] Iteration 48640 (DataTime/BatchTime: 0.00208/0.483) losses = 1.9279, lr = [2.0038227723255638e-05, 0.00020038227723255634]\n",
      "[INFO: 2022-02-17 03:23:59,153]   LabelSmoothing Loss = 2.0932722091674805\n",
      "[INFO: 2022-02-17 03:24:08,720] Iteration 48660 (DataTime/BatchTime: 0.00121/0.478) losses = 1.6293, lr = [2.0034109461148463e-05, 0.0002003410946114846]\n",
      "[INFO: 2022-02-17 03:24:08,720]   LabelSmoothing Loss = 1.3072259426116943\n",
      "[INFO: 2022-02-17 03:24:18,312] Iteration 48680 (DataTime/BatchTime: 0.00297/0.48) losses = 1.6047, lr = [2.0029993737157145e-05, 0.00020029993737157142]\n",
      "[INFO: 2022-02-17 03:24:18,313]   LabelSmoothing Loss = 2.1790952682495117\n",
      "[INFO: 2022-02-17 03:24:27,710] Iteration 48700 (DataTime/BatchTime: 0.00117/0.47) losses = 1.711, lr = [2.0025880548675647e-05, 0.00020025880548675646]\n",
      "[INFO: 2022-02-17 03:24:27,710]   LabelSmoothing Loss = 1.2104768753051758\n",
      "[INFO: 2022-02-17 03:27:59,700] ######## Epoch (VAL)51 ########\n",
      "[INFO: 2022-02-17 03:27:59,700] {'Bleu_1': 0.32343656246454255, 'Bleu_2': 0.19023326527886628, 'Bleu_3': 0.12294751815690962, 'Bleu_4': 0.08364459243977833, 'METEOR': 0.172549857883499, 'ROUGE_L': 0.28284286862446056, 'CIDEr': 0.2672526129558856}\n",
      "[INFO: 2022-02-17 03:31:33,916] ######## Epoch (TEST)51 ########\n",
      "[INFO: 2022-02-17 03:31:33,916] {'Bleu_1': 0.2988526347652721, 'Bleu_2': 0.16873432499992497, 'Bleu_3': 0.10393295740720171, 'Bleu_4': 0.06629447059555126, 'METEOR': 0.16368312776705124, 'ROUGE_L': 0.2725776106585315, 'CIDEr': 0.22319848203194154}\n",
      "[INFO: 2022-02-17 03:31:42,654] Iteration 48720 (DataTime/BatchTime: 0.0612/0.546) losses = 1.7825, lr = [2.002176989310169e-05, 0.00020021769893101686]\n",
      "[INFO: 2022-02-17 03:31:42,655]   LabelSmoothing Loss = 0.8493228554725647\n",
      "[INFO: 2022-02-17 03:31:52,187] Iteration 48740 (DataTime/BatchTime: 0.00392/0.477) losses = 1.566, lr = [2.001766176783673e-05, 0.00020017661767836726]\n",
      "[INFO: 2022-02-17 03:31:52,203]   LabelSmoothing Loss = 1.7152633666992188\n",
      "[INFO: 2022-02-17 03:32:01,668] Iteration 48760 (DataTime/BatchTime: 0.00294/0.474) losses = 1.7581, lr = [2.0013556170285942e-05, 0.00020013556170285938]\n",
      "[INFO: 2022-02-17 03:32:01,668]   LabelSmoothing Loss = 1.400613784790039\n",
      "[INFO: 2022-02-17 03:32:11,125] Iteration 48780 (DataTime/BatchTime: 0.00215/0.473) losses = 1.6852, lr = [2.000945309785824e-05, 0.00020009453097858236]\n",
      "[INFO: 2022-02-17 03:32:11,125]   LabelSmoothing Loss = 1.9182742834091187\n",
      "[INFO: 2022-02-17 03:32:20,598] Iteration 48800 (DataTime/BatchTime: 0.00131/0.474) losses = 1.7486, lr = [2.0005352547966246e-05, 0.00020005352547966242]\n",
      "[INFO: 2022-02-17 03:32:20,598]   LabelSmoothing Loss = 2.0529043674468994\n",
      "[INFO: 2022-02-17 03:32:30,087] Iteration 48820 (DataTime/BatchTime: 0.00136/0.474) losses = 1.6649, lr = [2.000125451802629e-05, 0.0002000125451802629]\n",
      "[INFO: 2022-02-17 03:32:30,087]   LabelSmoothing Loss = 1.4595577716827393\n",
      "[INFO: 2022-02-17 03:32:39,632] Iteration 48840 (DataTime/BatchTime: 0.00134/0.477) losses = 1.6954, lr = [1.9997159005458423e-05, 0.0001999715900545842]\n",
      "[INFO: 2022-02-17 03:32:39,632]   LabelSmoothing Loss = 1.8716529607772827\n",
      "[INFO: 2022-02-17 03:32:49,203] Iteration 48860 (DataTime/BatchTime: 0.00295/0.479) losses = 1.5487, lr = [1.9993066007686374e-05, 0.0001999306600768637]\n",
      "[INFO: 2022-02-17 03:32:49,204]   LabelSmoothing Loss = 1.6317991018295288\n",
      "[INFO: 2022-02-17 03:32:58,731] Iteration 48880 (DataTime/BatchTime: 0.00308/0.476) losses = 1.6986, lr = [1.998897552213756e-05, 0.00019988975522137556]\n",
      "[INFO: 2022-02-17 03:32:58,731]   LabelSmoothing Loss = 1.673508882522583\n",
      "[INFO: 2022-02-17 03:33:08,172] Iteration 48900 (DataTime/BatchTime: 0.0013/0.472) losses = 1.5614, lr = [1.9984887546243094e-05, 0.00019984887546243093]\n",
      "[INFO: 2022-02-17 03:33:08,172]   LabelSmoothing Loss = 0.8481091856956482\n",
      "[INFO: 2022-02-17 03:33:17,756] Iteration 48920 (DataTime/BatchTime: 0.00148/0.479) losses = 1.3658, lr = [1.9980802077437757e-05, 0.00019980802077437755]\n",
      "[INFO: 2022-02-17 03:33:17,756]   LabelSmoothing Loss = 1.5825331211090088\n",
      "[INFO: 2022-02-17 03:33:27,325] Iteration 48940 (DataTime/BatchTime: 0.00214/0.478) losses = 1.7315, lr = [1.9976719113160004e-05, 0.00019976719113160002]\n",
      "[INFO: 2022-02-17 03:33:27,325]   LabelSmoothing Loss = 2.3481385707855225\n",
      "[INFO: 2022-02-17 03:33:36,919] Iteration 48960 (DataTime/BatchTime: 0.00255/0.48) losses = 1.7641, lr = [1.997263865085195e-05, 0.00019972638650851948]\n",
      "[INFO: 2022-02-17 03:33:36,919]   LabelSmoothing Loss = 1.747201919555664\n",
      "[INFO: 2022-02-17 03:33:46,596] Iteration 48980 (DataTime/BatchTime: 0.00226/0.484) losses = 1.6858, lr = [1.996856068795936e-05, 0.00019968560687959357]\n",
      "[INFO: 2022-02-17 03:33:46,596]   LabelSmoothing Loss = 1.3914059400558472\n",
      "[INFO: 2022-02-17 03:33:56,194] Iteration 49000 (DataTime/BatchTime: 0.00136/0.48) losses = 1.6549, lr = [1.996448522193166e-05, 0.0001996448522193166]\n",
      "[INFO: 2022-02-17 03:33:56,194]   LabelSmoothing Loss = 1.6422874927520752\n",
      "[INFO: 2022-02-17 03:34:05,729] Iteration 49020 (DataTime/BatchTime: 0.00238/0.477) losses = 1.6673, lr = [1.9960412250221907e-05, 0.00019960412250221904]\n",
      "[INFO: 2022-02-17 03:34:05,729]   LabelSmoothing Loss = 2.0808634757995605\n",
      "[INFO: 2022-02-17 03:34:15,324] Iteration 49040 (DataTime/BatchTime: 0.00149/0.48) losses = 1.6087, lr = [1.9956341770286805e-05, 0.00019956341770286802]\n",
      "[INFO: 2022-02-17 03:34:15,324]   LabelSmoothing Loss = 1.2164338827133179\n",
      "[INFO: 2022-02-17 03:34:24,902] Iteration 49060 (DataTime/BatchTime: 0.00138/0.479) losses = 1.7131, lr = [1.995227377958668e-05, 0.00019952273779586676]\n",
      "[INFO: 2022-02-17 03:34:24,902]   LabelSmoothing Loss = 0.6949276328086853\n",
      "[INFO: 2022-02-17 03:34:34,434] Iteration 49080 (DataTime/BatchTime: 0.00208/0.477) losses = 1.6297, lr = [1.9948208275585475e-05, 0.00019948208275585473]\n",
      "[INFO: 2022-02-17 03:34:34,434]   LabelSmoothing Loss = 2.0150561332702637\n",
      "[INFO: 2022-02-17 03:34:44,008] Iteration 49100 (DataTime/BatchTime: 0.00141/0.479) losses = 1.5731, lr = [1.994414525575076e-05, 0.00019944145255750757]\n",
      "[INFO: 2022-02-17 03:34:44,009]   LabelSmoothing Loss = 1.1778992414474487\n",
      "[INFO: 2022-02-17 03:34:53,565] Iteration 49120 (DataTime/BatchTime: 0.00215/0.478) losses = 1.5797, lr = [1.994008471755371e-05, 0.0001994008471755371]\n",
      "[INFO: 2022-02-17 03:34:53,565]   LabelSmoothing Loss = 1.7060941457748413\n",
      "[INFO: 2022-02-17 03:35:03,122] Iteration 49140 (DataTime/BatchTime: 0.00138/0.478) losses = 1.6084, lr = [1.9936026658469103e-05, 0.00019936026658469102]\n",
      "[INFO: 2022-02-17 03:35:03,122]   LabelSmoothing Loss = 2.0978751182556152\n",
      "[INFO: 2022-02-17 03:35:12,653] Iteration 49160 (DataTime/BatchTime: 0.00297/0.477) losses = 1.623, lr = [1.9931971075975307e-05, 0.00019931971075975305]\n",
      "[INFO: 2022-02-17 03:35:12,653]   LabelSmoothing Loss = 1.0215480327606201\n",
      "[INFO: 2022-02-17 03:35:22,220] Iteration 49180 (DataTime/BatchTime: 0.00232/0.478) losses = 1.5417, lr = [1.9927917967554286e-05, 0.00019927917967554285]\n",
      "[INFO: 2022-02-17 03:35:22,220]   LabelSmoothing Loss = 1.6853471994400024\n",
      "[INFO: 2022-02-17 03:35:31,741] Iteration 49200 (DataTime/BatchTime: 0.00225/0.476) losses = 1.6086, lr = [1.992386733069159e-05, 0.00019923867330691588]\n",
      "[INFO: 2022-02-17 03:35:31,741]   LabelSmoothing Loss = 1.9865410327911377\n",
      "[INFO: 2022-02-17 03:35:41,314] Iteration 49220 (DataTime/BatchTime: 0.00323/0.479) losses = 1.5774, lr = [1.9919819162876335e-05, 0.00019919819162876335]\n",
      "[INFO: 2022-02-17 03:35:41,314]   LabelSmoothing Loss = 1.9193750619888306\n",
      "[INFO: 2022-02-17 03:35:50,866] Iteration 49240 (DataTime/BatchTime: 0.00131/0.478) losses = 1.7449, lr = [1.9915773461601216e-05, 0.00019915773461601214]\n",
      "[INFO: 2022-02-17 03:35:50,866]   LabelSmoothing Loss = 1.7691388130187988\n",
      "[INFO: 2022-02-17 03:36:00,445] Iteration 49260 (DataTime/BatchTime: 0.0014/0.479) losses = 1.582, lr = [1.991173022436248e-05, 0.00019911730224362478]\n",
      "[INFO: 2022-02-17 03:36:00,445]   LabelSmoothing Loss = 1.0436012744903564\n",
      "[INFO: 2022-02-17 03:36:09,970] Iteration 49280 (DataTime/BatchTime: 0.00138/0.476) losses = 1.6544, lr = [1.9907689448659944e-05, 0.00019907689448659944]\n",
      "[INFO: 2022-02-17 03:36:09,970]   LabelSmoothing Loss = 1.5125744342803955\n",
      "[INFO: 2022-02-17 03:36:19,581] Iteration 49300 (DataTime/BatchTime: 0.00209/0.481) losses = 1.703, lr = [1.9903651131996966e-05, 0.00019903651131996964]\n",
      "[INFO: 2022-02-17 03:36:19,581]   LabelSmoothing Loss = 1.7128266096115112\n",
      "[INFO: 2022-02-17 03:36:29,328] Iteration 49320 (DataTime/BatchTime: 0.00141/0.487) losses = 1.8522, lr = [1.9899615271880455e-05, 0.00019899615271880454]\n",
      "[INFO: 2022-02-17 03:36:29,328]   LabelSmoothing Loss = 2.530717372894287\n",
      "[INFO: 2022-02-17 03:36:38,832] Iteration 49340 (DataTime/BatchTime: 0.00372/0.475) losses = 1.5677, lr = [1.989558186582085e-05, 0.00019895581865820848]\n",
      "[INFO: 2022-02-17 03:36:38,832]   LabelSmoothing Loss = 1.1726865768432617\n",
      "[INFO: 2022-02-17 03:36:48,421] Iteration 49360 (DataTime/BatchTime: 0.00237/0.479) losses = 1.459, lr = [1.989155091133212e-05, 0.00019891550911332116]\n",
      "[INFO: 2022-02-17 03:36:48,422]   LabelSmoothing Loss = 1.6361746788024902\n",
      "[INFO: 2022-02-17 03:36:58,015] Iteration 49380 (DataTime/BatchTime: 0.00125/0.48) losses = 1.629, lr = [1.9887522405931767e-05, 0.00019887522405931767]\n",
      "[INFO: 2022-02-17 03:36:58,015]   LabelSmoothing Loss = 1.2778723239898682\n",
      "[INFO: 2022-02-17 03:37:07,620] Iteration 49400 (DataTime/BatchTime: 0.0022/0.48) losses = 1.6245, lr = [1.9883496347140806e-05, 0.00019883496347140804]\n",
      "[INFO: 2022-02-17 03:37:07,620]   LabelSmoothing Loss = 1.1278413534164429\n",
      "[INFO: 2022-02-17 03:37:17,189] Iteration 49420 (DataTime/BatchTime: 0.00209/0.478) losses = 1.6517, lr = [1.9879472732483764e-05, 0.0001987947273248376]\n",
      "[INFO: 2022-02-17 03:37:17,189]   LabelSmoothing Loss = 1.061972737312317\n",
      "[INFO: 2022-02-17 03:37:26,677] Iteration 49440 (DataTime/BatchTime: 0.00116/0.474) losses = 1.6199, lr = [1.987545155948867e-05, 0.00019875451559488668]\n",
      "[INFO: 2022-02-17 03:37:26,677]   LabelSmoothing Loss = 1.678228497505188\n",
      "[INFO: 2022-02-17 03:37:36,217] Iteration 49460 (DataTime/BatchTime: 0.00122/0.477) losses = 1.6388, lr = [1.987143282568705e-05, 0.0001987143282568705]\n",
      "[INFO: 2022-02-17 03:37:36,218]   LabelSmoothing Loss = 0.9195316433906555\n",
      "[INFO: 2022-02-17 03:37:45,721] Iteration 49480 (DataTime/BatchTime: 0.00234/0.475) losses = 1.6805, lr = [1.986741652861394e-05, 0.00019867416528613938]\n",
      "[INFO: 2022-02-17 03:37:45,722]   LabelSmoothing Loss = 1.2881706953048706\n",
      "[INFO: 2022-02-17 03:37:55,276] Iteration 49500 (DataTime/BatchTime: 0.00222/0.478) losses = 1.4462, lr = [1.9863402665807835e-05, 0.00019863402665807833]\n",
      "[INFO: 2022-02-17 03:37:55,276]   LabelSmoothing Loss = 1.1078810691833496\n",
      "[INFO: 2022-02-17 03:38:04,908] Iteration 49520 (DataTime/BatchTime: 0.00211/0.482) losses = 1.796, lr = [1.9859391234810733e-05, 0.0001985939123481073]\n",
      "[INFO: 2022-02-17 03:38:04,909]   LabelSmoothing Loss = 1.622570514678955\n",
      "[INFO: 2022-02-17 03:38:14,451] Iteration 49540 (DataTime/BatchTime: 0.00333/0.477) losses = 1.5447, lr = [1.985538223316809e-05, 0.00019855382233168088]\n",
      "[INFO: 2022-02-17 03:38:14,451]   LabelSmoothing Loss = 1.94968843460083\n",
      "[INFO: 2022-02-17 03:38:24,079] Iteration 49560 (DataTime/BatchTime: 0.00127/0.481) losses = 1.4399, lr = [1.985137565842884e-05, 0.00019851375658428837]\n",
      "[INFO: 2022-02-17 03:38:24,079]   LabelSmoothing Loss = 1.1210994720458984\n",
      "[INFO: 2022-02-17 03:38:33,626] Iteration 49580 (DataTime/BatchTime: 0.00126/0.477) losses = 1.7369, lr = [1.9847371508145368e-05, 0.00019847371508145367]\n",
      "[INFO: 2022-02-17 03:38:33,626]   LabelSmoothing Loss = 1.2513973712921143\n",
      "[INFO: 2022-02-17 03:38:43,212] Iteration 49600 (DataTime/BatchTime: 0.00127/0.479) losses = 1.7077, lr = [1.9843369779873523e-05, 0.0001984336977987352]\n",
      "[INFO: 2022-02-17 03:38:43,212]   LabelSmoothing Loss = 2.0087616443634033\n",
      "[INFO: 2022-02-17 03:38:52,722] Iteration 49620 (DataTime/BatchTime: 0.00299/0.475) losses = 1.5025, lr = [1.9839370471172593e-05, 0.0001983937047117259]\n",
      "[INFO: 2022-02-17 03:38:52,722]   LabelSmoothing Loss = 0.8598278164863586\n",
      "[INFO: 2022-02-17 03:39:02,188] Iteration 49640 (DataTime/BatchTime: 0.00122/0.473) losses = 1.5143, lr = [1.9835373579605312e-05, 0.00019835373579605312]\n",
      "[INFO: 2022-02-17 03:39:02,188]   LabelSmoothing Loss = 1.5614114999771118\n",
      "[INFO: 2022-02-17 03:42:39,197] ######## Epoch (VAL)52 ########\n",
      "[INFO: 2022-02-17 03:42:39,197] {'Bleu_1': 0.348551228238872, 'Bleu_2': 0.2097491496266475, 'Bleu_3': 0.13797733137907664, 'Bleu_4': 0.09608279309625391, 'METEOR': 0.17928666157572923, 'ROUGE_L': 0.2890588509847598, 'CIDEr': 0.3356213541862266}\n",
      "[INFO: 2022-02-17 03:46:14,310] ######## Epoch (TEST)52 ########\n",
      "[INFO: 2022-02-17 03:46:14,311] {'Bleu_1': 0.3227732575442557, 'Bleu_2': 0.1785686130780816, 'Bleu_3': 0.10526074266785712, 'Bleu_4': 0.0611300686823987, 'METEOR': 0.16983698138886563, 'ROUGE_L': 0.2685525156010363, 'CIDEr': 0.15771209904481207}\n",
      "[INFO: 2022-02-17 03:46:15,954] Iteration 49660 (DataTime/BatchTime: 1.11/1.64) losses = 1.3061, lr = [1.9831379102737857e-05, 0.00019831379102737854]\n",
      "[INFO: 2022-02-17 03:46:15,954]   LabelSmoothing Loss = 1.3061089515686035\n",
      "[INFO: 2022-02-17 03:46:25,541] Iteration 49680 (DataTime/BatchTime: 0.0011/0.479) losses = 1.5896, lr = [1.982738703813982e-05, 0.00019827387038139817]\n",
      "[INFO: 2022-02-17 03:46:25,542]   LabelSmoothing Loss = 1.9770493507385254\n",
      "[INFO: 2022-02-17 03:46:35,068] Iteration 49700 (DataTime/BatchTime: 0.00101/0.476) losses = 1.6847, lr = [1.982339738338423e-05, 0.00019823397383384229]\n",
      "[INFO: 2022-02-17 03:46:35,068]   LabelSmoothing Loss = 1.3630290031433105\n",
      "[INFO: 2022-02-17 03:46:44,640] Iteration 49720 (DataTime/BatchTime: 0.00111/0.479) losses = 1.6417, lr = [1.9819410136047524e-05, 0.0001981941013604752]\n",
      "[INFO: 2022-02-17 03:46:44,640]   LabelSmoothing Loss = 1.490041732788086\n",
      "[INFO: 2022-02-17 03:46:54,186] Iteration 49740 (DataTime/BatchTime: 0.00188/0.477) losses = 1.4922, lr = [1.9815425293709554e-05, 0.0001981542529370955]\n",
      "[INFO: 2022-02-17 03:46:54,186]   LabelSmoothing Loss = 2.6182169914245605\n",
      "[INFO: 2022-02-17 03:47:03,806] Iteration 49760 (DataTime/BatchTime: 0.00114/0.481) losses = 1.7286, lr = [1.9811442853953575e-05, 0.00019811442853953572]\n",
      "[INFO: 2022-02-17 03:47:03,806]   LabelSmoothing Loss = 1.9989675283432007\n",
      "[INFO: 2022-02-17 03:47:13,289] Iteration 49780 (DataTime/BatchTime: 0.00302/0.474) losses = 1.6953, lr = [1.9807462814366243e-05, 0.00019807462814366242]\n",
      "[INFO: 2022-02-17 03:47:13,289]   LabelSmoothing Loss = 2.2869808673858643\n",
      "[INFO: 2022-02-17 03:47:22,862] Iteration 49800 (DataTime/BatchTime: 0.00312/0.479) losses = 1.6965, lr = [1.98034851725376e-05, 0.00019803485172537597]\n",
      "[INFO: 2022-02-17 03:47:22,863]   LabelSmoothing Loss = 1.3123914003372192\n",
      "[INFO: 2022-02-17 03:47:32,418] Iteration 49820 (DataTime/BatchTime: 0.00195/0.478) losses = 1.6746, lr = [1.979950992606109e-05, 0.00019799509926061087]\n",
      "[INFO: 2022-02-17 03:47:32,419]   LabelSmoothing Loss = 1.5843920707702637\n",
      "[INFO: 2022-02-17 03:47:41,970] Iteration 49840 (DataTime/BatchTime: 0.00207/0.478) losses = 1.5952, lr = [1.9795537072533513e-05, 0.0001979553707253351]\n",
      "[INFO: 2022-02-17 03:47:41,971]   LabelSmoothing Loss = 2.5689268112182617\n",
      "[INFO: 2022-02-17 03:47:51,554] Iteration 49860 (DataTime/BatchTime: 0.00194/0.479) losses = 1.7987, lr = [1.9791566609555066e-05, 0.00019791566609555063]\n",
      "[INFO: 2022-02-17 03:47:51,554]   LabelSmoothing Loss = 1.8933554887771606\n",
      "[INFO: 2022-02-17 03:48:01,185] Iteration 49880 (DataTime/BatchTime: 0.00447/0.482) losses = 1.7109, lr = [1.9787598534729302e-05, 0.000197875985347293]\n",
      "[INFO: 2022-02-17 03:48:01,185]   LabelSmoothing Loss = 1.8896490335464478\n",
      "[INFO: 2022-02-17 03:48:10,823] Iteration 49900 (DataTime/BatchTime: 0.0012/0.482) losses = 1.5547, lr = [1.9783632845663138e-05, 0.00019783632845663134]\n",
      "[INFO: 2022-02-17 03:48:10,823]   LabelSmoothing Loss = 1.1921876668930054\n",
      "[INFO: 2022-02-17 03:48:20,476] Iteration 49920 (DataTime/BatchTime: 0.00222/0.483) losses = 1.6058, lr = [1.9779669539966846e-05, 0.00019779669539966843]\n",
      "[INFO: 2022-02-17 03:48:20,477]   LabelSmoothing Loss = 2.5062272548675537\n",
      "[INFO: 2022-02-17 03:48:30,122] Iteration 49940 (DataTime/BatchTime: 0.00319/0.482) losses = 1.5156, lr = [1.977570861525405e-05, 0.0001977570861525405]\n",
      "[INFO: 2022-02-17 03:48:30,123]   LabelSmoothing Loss = 1.9614554643630981\n",
      "[INFO: 2022-02-17 03:48:39,721] Iteration 49960 (DataTime/BatchTime: 0.00117/0.48) losses = 1.8049, lr = [1.9771750069141716e-05, 0.00019771750069141715]\n",
      "[INFO: 2022-02-17 03:48:39,722]   LabelSmoothing Loss = 1.410057544708252\n",
      "[INFO: 2022-02-17 03:48:49,397] Iteration 49980 (DataTime/BatchTime: 0.00226/0.484) losses = 1.6232, lr = [1.9767793899250155e-05, 0.00019767793899250154]\n",
      "[INFO: 2022-02-17 03:48:49,397]   LabelSmoothing Loss = 1.110664963722229\n",
      "[INFO: 2022-02-17 03:48:58,931] Iteration 50000 (DataTime/BatchTime: 0.0011/0.477) losses = 1.4631, lr = [1.9763840103203e-05, 0.00019763840103203]\n",
      "[INFO: 2022-02-17 03:48:58,931]   LabelSmoothing Loss = 1.50851571559906\n",
      "[INFO: 2022-02-17 03:49:08,471] Iteration 50020 (DataTime/BatchTime: 0.00111/0.477) losses = 1.6055, lr = [1.975988867862721e-05, 0.00019759888678627207]\n",
      "[INFO: 2022-02-17 03:49:08,471]   LabelSmoothing Loss = 0.4954245090484619\n",
      "[INFO: 2022-02-17 03:49:17,948] Iteration 50040 (DataTime/BatchTime: 0.00194/0.474) losses = 1.5212, lr = [1.9755939623153068e-05, 0.00019755939623153067]\n",
      "[INFO: 2022-02-17 03:49:17,949]   LabelSmoothing Loss = 1.300495982170105\n",
      "[INFO: 2022-02-17 03:49:27,549] Iteration 50060 (DataTime/BatchTime: 0.00203/0.48) losses = 1.6906, lr = [1.9751992934414175e-05, 0.00019751992934414174]\n",
      "[INFO: 2022-02-17 03:49:27,549]   LabelSmoothing Loss = 1.6017411947250366\n",
      "[INFO: 2022-02-17 03:49:37,268] Iteration 50080 (DataTime/BatchTime: 0.00316/0.486) losses = 1.6216, lr = [1.974804861004743e-05, 0.00019748048610047429]\n",
      "[INFO: 2022-02-17 03:49:37,268]   LabelSmoothing Loss = 1.4351212978363037\n",
      "[INFO: 2022-02-17 03:49:46,892] Iteration 50100 (DataTime/BatchTime: 0.00234/0.481) losses = 1.6076, lr = [1.9744106647693043e-05, 0.0001974410664769304]\n",
      "[INFO: 2022-02-17 03:49:46,892]   LabelSmoothing Loss = 2.07833194732666\n",
      "[INFO: 2022-02-17 03:49:56,471] Iteration 50120 (DataTime/BatchTime: 0.00232/0.479) losses = 1.4125, lr = [1.974016704499451e-05, 0.0001974016704499451]\n",
      "[INFO: 2022-02-17 03:49:56,471]   LabelSmoothing Loss = 0.9661216139793396\n",
      "[INFO: 2022-02-17 03:50:06,086] Iteration 50140 (DataTime/BatchTime: 0.0053/0.481) losses = 1.4131, lr = [1.9736229799598626e-05, 0.00019736229799598623]\n",
      "[INFO: 2022-02-17 03:50:06,086]   LabelSmoothing Loss = 1.275879144668579\n",
      "[INFO: 2022-02-17 03:50:15,729] Iteration 50160 (DataTime/BatchTime: 0.00328/0.481) losses = 1.5592, lr = [1.9732294909155466e-05, 0.00019732294909155466]\n",
      "[INFO: 2022-02-17 03:50:15,729]   LabelSmoothing Loss = 1.5567809343338013\n",
      "[INFO: 2022-02-17 03:50:25,490] Iteration 50180 (DataTime/BatchTime: 0.00253/0.489) losses = 1.7523, lr = [1.9728362371318392e-05, 0.00019728362371318389]\n",
      "[INFO: 2022-02-17 03:50:25,490]   LabelSmoothing Loss = 1.4308873414993286\n",
      "[INFO: 2022-02-17 03:50:35,244] Iteration 50200 (DataTime/BatchTime: 0.00149/0.488) losses = 1.6242, lr = [1.972443218374402e-05, 0.00019724432183744017]\n",
      "[INFO: 2022-02-17 03:50:35,244]   LabelSmoothing Loss = 0.9098171591758728\n",
      "[INFO: 2022-02-17 03:50:44,980] Iteration 50220 (DataTime/BatchTime: 0.00244/0.487) losses = 1.4693, lr = [1.9720504344092247e-05, 0.00019720504344092243]\n",
      "[INFO: 2022-02-17 03:50:44,980]   LabelSmoothing Loss = 0.8693861961364746\n",
      "[INFO: 2022-02-17 03:50:54,748] Iteration 50240 (DataTime/BatchTime: 0.00244/0.488) losses = 1.7519, lr = [1.971657885002623e-05, 0.00019716578850026225]\n",
      "[INFO: 2022-02-17 03:50:54,748]   LabelSmoothing Loss = 1.5105758905410767\n",
      "[INFO: 2022-02-17 03:51:04,406] Iteration 50260 (DataTime/BatchTime: 0.00157/0.483) losses = 1.5445, lr = [1.9712655699212368e-05, 0.00019712655699212367]\n",
      "[INFO: 2022-02-17 03:51:04,406]   LabelSmoothing Loss = 1.4319801330566406\n",
      "[INFO: 2022-02-17 03:51:14,144] Iteration 50280 (DataTime/BatchTime: 0.00247/0.487) losses = 1.8233, lr = [1.9708734889320335e-05, 0.00019708734889320331]\n",
      "[INFO: 2022-02-17 03:51:14,145]   LabelSmoothing Loss = 2.3996493816375732\n",
      "[INFO: 2022-02-17 03:51:23,867] Iteration 50300 (DataTime/BatchTime: 0.00164/0.486) losses = 1.7395, lr = [1.9704816418023016e-05, 0.00019704816418023016]\n",
      "[INFO: 2022-02-17 03:51:23,868]   LabelSmoothing Loss = 1.7316657304763794\n",
      "[INFO: 2022-02-17 03:51:33,591] Iteration 50320 (DataTime/BatchTime: 0.00254/0.486) losses = 1.8216, lr = [1.970090028299656e-05, 0.0001970090028299656]\n",
      "[INFO: 2022-02-17 03:51:33,591]   LabelSmoothing Loss = 2.7162413597106934\n",
      "[INFO: 2022-02-17 03:51:43,395] Iteration 50340 (DataTime/BatchTime: 0.00346/0.49) losses = 1.5586, lr = [1.9696986481920337e-05, 0.00019696986481920336]\n",
      "[INFO: 2022-02-17 03:51:43,395]   LabelSmoothing Loss = 2.0497536659240723\n",
      "[INFO: 2022-02-17 03:51:53,117] Iteration 50360 (DataTime/BatchTime: 0.00173/0.486) losses = 1.4975, lr = [1.969307501247694e-05, 0.00019693075012476937]\n",
      "[INFO: 2022-02-17 03:51:53,118]   LabelSmoothing Loss = 0.6926617622375488\n",
      "[INFO: 2022-02-17 03:52:02,973] Iteration 50380 (DataTime/BatchTime: 0.00166/0.493) losses = 1.7279, lr = [1.968916587235218e-05, 0.00019689165872352178]\n",
      "[INFO: 2022-02-17 03:52:02,973]   LabelSmoothing Loss = 1.874480128288269\n",
      "[INFO: 2022-02-17 03:52:12,562] Iteration 50400 (DataTime/BatchTime: 0.00143/0.479) losses = 1.5225, lr = [1.9685259059235098e-05, 0.00019685259059235095]\n",
      "[INFO: 2022-02-17 03:52:12,562]   LabelSmoothing Loss = 1.7225075960159302\n",
      "[INFO: 2022-02-17 03:52:22,493] Iteration 50420 (DataTime/BatchTime: 0.00159/0.497) losses = 1.5855, lr = [1.9681354570817924e-05, 0.0001968135457081792]\n",
      "[INFO: 2022-02-17 03:52:22,493]   LabelSmoothing Loss = 1.2389488220214844\n",
      "[INFO: 2022-02-17 03:52:32,201] Iteration 50440 (DataTime/BatchTime: 0.00243/0.485) losses = 1.5984, lr = [1.96774524047961e-05, 0.000196774524047961]\n",
      "[INFO: 2022-02-17 03:52:32,201]   LabelSmoothing Loss = 1.3818081617355347\n",
      "[INFO: 2022-02-17 03:52:41,818] Iteration 50460 (DataTime/BatchTime: 0.00231/0.481) losses = 1.6663, lr = [1.9673552558868272e-05, 0.0001967355255886827]\n",
      "[INFO: 2022-02-17 03:52:41,819]   LabelSmoothing Loss = 1.6858867406845093\n",
      "[INFO: 2022-02-17 03:52:51,575] Iteration 50480 (DataTime/BatchTime: 0.00243/0.488) losses = 1.7084, lr = [1.966965503073627e-05, 0.00019669655030736267]\n",
      "[INFO: 2022-02-17 03:52:51,575]   LabelSmoothing Loss = 1.9434195756912231\n",
      "[INFO: 2022-02-17 03:53:01,298] Iteration 50500 (DataTime/BatchTime: 0.00153/0.486) losses = 1.8673, lr = [1.96657598181051e-05, 0.00019665759818105098]\n",
      "[INFO: 2022-02-17 03:53:01,298]   LabelSmoothing Loss = 2.5979177951812744\n",
      "[INFO: 2022-02-17 03:53:11,050] Iteration 50520 (DataTime/BatchTime: 0.00248/0.488) losses = 1.636, lr = [1.9661866918682972e-05, 0.0001966186691868297]\n",
      "[INFO: 2022-02-17 03:53:11,050]   LabelSmoothing Loss = 1.4246835708618164\n",
      "[INFO: 2022-02-17 03:53:20,981] Iteration 50540 (DataTime/BatchTime: 0.0033/0.497) losses = 1.7016, lr = [1.9657976330181247e-05, 0.00019657976330181244]\n",
      "[INFO: 2022-02-17 03:53:20,981]   LabelSmoothing Loss = 1.2642741203308105\n",
      "[INFO: 2022-02-17 03:53:30,730] Iteration 50560 (DataTime/BatchTime: 0.00244/0.487) losses = 1.6931, lr = [1.9654088050314468e-05, 0.00019654088050314466]\n",
      "[INFO: 2022-02-17 03:53:30,730]   LabelSmoothing Loss = 1.3901392221450806\n",
      "[INFO: 2022-02-17 03:53:40,387] Iteration 50580 (DataTime/BatchTime: 0.00427/0.483) losses = 1.3761, lr = [1.9650202076800338e-05, 0.00019650202076800335]\n",
      "[INFO: 2022-02-17 03:53:40,387]   LabelSmoothing Loss = 1.7915350198745728\n",
      "[INFO: 2022-02-17 03:53:50,215] Iteration 50600 (DataTime/BatchTime: 0.00155/0.491) losses = 1.5474, lr = [1.9646318407359718e-05, 0.00019646318407359715]\n",
      "[INFO: 2022-02-17 03:53:50,215]   LabelSmoothing Loss = 1.3097597360610962\n",
      "[INFO: 2022-02-17 03:57:33,557] ######## Epoch (VAL)53 ########\n",
      "[INFO: 2022-02-17 03:57:33,558] {'Bleu_1': 0.30669033290384945, 'Bleu_2': 0.17505985130173657, 'Bleu_3': 0.10849400204596256, 'Bleu_4': 0.06895437014712785, 'METEOR': 0.16835649735462688, 'ROUGE_L': 0.27642741332290155, 'CIDEr': 0.24959092953102763}\n",
      "[INFO: 2022-02-17 04:01:10,777] ######## Epoch (TEST)53 ########\n",
      "[INFO: 2022-02-17 04:01:10,778] {'Bleu_1': 0.28897698265102467, 'Bleu_2': 0.15833891358142876, 'Bleu_3': 0.09171120105153513, 'Bleu_4': 0.05060085442998065, 'METEOR': 0.16146786135997584, 'ROUGE_L': 0.26343329898761336, 'CIDEr': 0.14863137807179325}\n",
      "[INFO: 2022-02-17 04:01:14,872] Iteration 50620 (DataTime/BatchTime: 0.194/0.682) losses = 1.3596, lr = [1.9642437039716617e-05, 0.00019642437039716615]\n",
      "[INFO: 2022-02-17 04:01:14,873]   LabelSmoothing Loss = 0.7239598035812378\n",
      "[INFO: 2022-02-17 04:01:24,349] Iteration 50640 (DataTime/BatchTime: 0.00191/0.474) losses = 1.6038, lr = [1.9638557971598196e-05, 0.00019638557971598194]\n",
      "[INFO: 2022-02-17 04:01:24,350]   LabelSmoothing Loss = 1.3362374305725098\n",
      "[INFO: 2022-02-17 04:01:33,860] Iteration 50660 (DataTime/BatchTime: 0.00221/0.476) losses = 1.4052, lr = [1.9634681200734752e-05, 0.0001963468120073475]\n",
      "[INFO: 2022-02-17 04:01:33,861]   LabelSmoothing Loss = 1.1060588359832764\n",
      "[INFO: 2022-02-17 04:01:43,377] Iteration 50680 (DataTime/BatchTime: 0.00297/0.476) losses = 1.5622, lr = [1.9630806724859722e-05, 0.0001963080672485972]\n",
      "[INFO: 2022-02-17 04:01:43,377]   LabelSmoothing Loss = 1.1919413805007935\n",
      "[INFO: 2022-02-17 04:01:52,816] Iteration 50700 (DataTime/BatchTime: 0.002/0.472) losses = 1.4585, lr = [1.962693454170967e-05, 0.00019626934541709667]\n",
      "[INFO: 2022-02-17 04:01:52,816]   LabelSmoothing Loss = 1.2520860433578491\n",
      "[INFO: 2022-02-17 04:02:02,429] Iteration 50720 (DataTime/BatchTime: 0.00509/0.481) losses = 1.6938, lr = [1.962306464902428e-05, 0.00019623064649024278]\n",
      "[INFO: 2022-02-17 04:02:02,429]   LabelSmoothing Loss = 1.3890728950500488\n",
      "[INFO: 2022-02-17 04:02:11,938] Iteration 50740 (DataTime/BatchTime: 0.00113/0.475) losses = 1.5784, lr = [1.9619197044546363e-05, 0.00019619197044546362]\n",
      "[INFO: 2022-02-17 04:02:11,938]   LabelSmoothing Loss = 1.3315500020980835\n",
      "[INFO: 2022-02-17 04:02:21,493] Iteration 50760 (DataTime/BatchTime: 0.002/0.478) losses = 1.5976, lr = [1.9615331726021832e-05, 0.0001961533172602183]\n",
      "[INFO: 2022-02-17 04:02:21,493]   LabelSmoothing Loss = 2.5154595375061035\n",
      "[INFO: 2022-02-17 04:02:30,994] Iteration 50780 (DataTime/BatchTime: 0.00108/0.475) losses = 1.5696, lr = [1.961146869119972e-05, 0.0001961146869119972]\n",
      "[INFO: 2022-02-17 04:02:30,994]   LabelSmoothing Loss = 2.3704044818878174\n",
      "[INFO: 2022-02-17 04:02:40,591] Iteration 50800 (DataTime/BatchTime: 0.0022/0.48) losses = 1.8055, lr = [1.9607607937832156e-05, 0.00019607607937832154]\n",
      "[INFO: 2022-02-17 04:02:40,591]   LabelSmoothing Loss = 3.600252866744995\n",
      "[INFO: 2022-02-17 04:02:50,097] Iteration 50820 (DataTime/BatchTime: 0.00194/0.475) losses = 1.6331, lr = [1.960374946367436e-05, 0.00019603749463674357]\n",
      "[INFO: 2022-02-17 04:02:50,098]   LabelSmoothing Loss = 1.0022822618484497\n",
      "[INFO: 2022-02-17 04:02:59,610] Iteration 50840 (DataTime/BatchTime: 0.00111/0.476) losses = 1.62, lr = [1.959989326648465e-05, 0.00019599893266484647]\n",
      "[INFO: 2022-02-17 04:02:59,610]   LabelSmoothing Loss = 1.5071706771850586\n",
      "[INFO: 2022-02-17 04:03:09,106] Iteration 50860 (DataTime/BatchTime: 0.00109/0.475) losses = 1.5928, lr = [1.9596039344024427e-05, 0.00019596039344024424]\n",
      "[INFO: 2022-02-17 04:03:09,106]   LabelSmoothing Loss = 0.9285681247711182\n",
      "[INFO: 2022-02-17 04:03:18,673] Iteration 50880 (DataTime/BatchTime: 0.0011/0.478) losses = 1.8167, lr = [1.9592187694058173e-05, 0.00019592187694058173]\n",
      "[INFO: 2022-02-17 04:03:18,673]   LabelSmoothing Loss = 1.4378985166549683\n",
      "[INFO: 2022-02-17 04:03:28,239] Iteration 50900 (DataTime/BatchTime: 0.00111/0.478) losses = 1.6229, lr = [1.9588338314353447e-05, 0.00019588338314353444]\n",
      "[INFO: 2022-02-17 04:03:28,240]   LabelSmoothing Loss = 0.9443346858024597\n",
      "[INFO: 2022-02-17 04:03:37,735] Iteration 50920 (DataTime/BatchTime: 0.00216/0.475) losses = 1.5885, lr = [1.958449120268087e-05, 0.00019584491202680868]\n",
      "[INFO: 2022-02-17 04:03:37,735]   LabelSmoothing Loss = 1.214339017868042\n",
      "[INFO: 2022-02-17 04:03:47,210] Iteration 50940 (DataTime/BatchTime: 0.0011/0.474) losses = 1.5701, lr = [1.958064635681413e-05, 0.00019580646356814129]\n",
      "[INFO: 2022-02-17 04:03:47,210]   LabelSmoothing Loss = 1.8605374097824097\n",
      "[INFO: 2022-02-17 04:03:56,735] Iteration 50960 (DataTime/BatchTime: 0.00109/0.476) losses = 1.6519, lr = [1.957680377452998e-05, 0.00019576803774529978]\n",
      "[INFO: 2022-02-17 04:03:56,735]   LabelSmoothing Loss = 1.7649590969085693\n",
      "[INFO: 2022-02-17 04:04:06,234] Iteration 50980 (DataTime/BatchTime: 0.0011/0.475) losses = 1.5889, lr = [1.9572963453608213e-05, 0.0001957296345360821]\n",
      "[INFO: 2022-02-17 04:04:06,235]   LabelSmoothing Loss = 2.305314779281616\n",
      "[INFO: 2022-02-17 04:04:15,769] Iteration 51000 (DataTime/BatchTime: 0.00107/0.477) losses = 1.4193, lr = [1.9569125391831682e-05, 0.0001956912539183168]\n",
      "[INFO: 2022-02-17 04:04:15,769]   LabelSmoothing Loss = 1.2411357164382935\n",
      "[INFO: 2022-02-17 04:04:25,269] Iteration 51020 (DataTime/BatchTime: 0.00109/0.475) losses = 1.5947, lr = [1.9565289586986274e-05, 0.00019565289586986274]\n",
      "[INFO: 2022-02-17 04:04:25,269]   LabelSmoothing Loss = 2.1711862087249756\n",
      "[INFO: 2022-02-17 04:04:34,728] Iteration 51040 (DataTime/BatchTime: 0.00111/0.473) losses = 1.4371, lr = [1.9561456036860918e-05, 0.00019561456036860914]\n",
      "[INFO: 2022-02-17 04:04:34,728]   LabelSmoothing Loss = 1.725488305091858\n",
      "[INFO: 2022-02-17 04:04:44,328] Iteration 51060 (DataTime/BatchTime: 0.00113/0.48) losses = 1.7424, lr = [1.9557624739247564e-05, 0.00019557624739247563]\n",
      "[INFO: 2022-02-17 04:04:44,328]   LabelSmoothing Loss = 2.1936118602752686\n",
      "[INFO: 2022-02-17 04:04:53,810] Iteration 51080 (DataTime/BatchTime: 0.00112/0.474) losses = 1.7102, lr = [1.955379569194121e-05, 0.00019553795691941206]\n",
      "[INFO: 2022-02-17 04:04:53,810]   LabelSmoothing Loss = 2.086068630218506\n",
      "[INFO: 2022-02-17 04:05:03,382] Iteration 51100 (DataTime/BatchTime: 0.00232/0.479) losses = 1.6828, lr = [1.954996889273985e-05, 0.00019549968892739847]\n",
      "[INFO: 2022-02-17 04:05:03,382]   LabelSmoothing Loss = 2.26513671875\n",
      "[INFO: 2022-02-17 04:05:12,890] Iteration 51120 (DataTime/BatchTime: 0.00273/0.475) losses = 1.6652, lr = [1.9546144339444506e-05, 0.00019546144339444504]\n",
      "[INFO: 2022-02-17 04:05:12,890]   LabelSmoothing Loss = 1.3477997779846191\n",
      "[INFO: 2022-02-17 04:05:22,375] Iteration 51140 (DataTime/BatchTime: 0.00114/0.474) losses = 1.5957, lr = [1.954232202985921e-05, 0.0001954232202985921]\n",
      "[INFO: 2022-02-17 04:05:22,375]   LabelSmoothing Loss = 1.8583579063415527\n",
      "[INFO: 2022-02-17 04:05:31,890] Iteration 51160 (DataTime/BatchTime: 0.00207/0.476) losses = 1.674, lr = [1.9538501961790996e-05, 0.00019538501961790996]\n",
      "[INFO: 2022-02-17 04:05:31,890]   LabelSmoothing Loss = 1.5202025175094604\n",
      "[INFO: 2022-02-17 04:05:41,375] Iteration 51180 (DataTime/BatchTime: 0.00117/0.474) losses = 1.5199, lr = [1.95346841330499e-05, 0.00019534684133049897]\n",
      "[INFO: 2022-02-17 04:05:41,375]   LabelSmoothing Loss = 1.9108041524887085\n",
      "[INFO: 2022-02-17 04:05:50,885] Iteration 51200 (DataTime/BatchTime: 0.00119/0.476) losses = 1.5546, lr = [1.9530868541448948e-05, 0.00019530868541448946]\n",
      "[INFO: 2022-02-17 04:05:50,886]   LabelSmoothing Loss = 0.9943529367446899\n",
      "[INFO: 2022-02-17 04:06:00,383] Iteration 51220 (DataTime/BatchTime: 0.00119/0.475) losses = 1.5965, lr = [1.9527055184804163e-05, 0.0001952705518480416]\n",
      "[INFO: 2022-02-17 04:06:00,383]   LabelSmoothing Loss = 1.3398369550704956\n",
      "[INFO: 2022-02-17 04:06:09,903] Iteration 51240 (DataTime/BatchTime: 0.00203/0.476) losses = 1.6238, lr = [1.952324406093454e-05, 0.00019523244060934539]\n",
      "[INFO: 2022-02-17 04:06:09,903]   LabelSmoothing Loss = 1.5373097658157349\n",
      "[INFO: 2022-02-17 04:06:19,359] Iteration 51260 (DataTime/BatchTime: 0.00205/0.473) losses = 1.5863, lr = [1.9519435167662068e-05, 0.00019519435167662065]\n",
      "[INFO: 2022-02-17 04:06:19,360]   LabelSmoothing Loss = 1.0774034261703491\n",
      "[INFO: 2022-02-17 04:06:28,886] Iteration 51280 (DataTime/BatchTime: 0.00436/0.476) losses = 1.8333, lr = [1.951562850281169e-05, 0.00019515628502811687]\n",
      "[INFO: 2022-02-17 04:06:28,886]   LabelSmoothing Loss = 1.8710111379623413\n",
      "[INFO: 2022-02-17 04:06:38,364] Iteration 51300 (DataTime/BatchTime: 0.00121/0.474) losses = 1.475, lr = [1.9511824064211336e-05, 0.00019511824064211332]\n",
      "[INFO: 2022-02-17 04:06:38,365]   LabelSmoothing Loss = 1.2733545303344727\n",
      "[INFO: 2022-02-17 04:06:47,819] Iteration 51320 (DataTime/BatchTime: 0.00123/0.473) losses = 1.5852, lr = [1.9508021849691883e-05, 0.0001950802184969188]\n",
      "[INFO: 2022-02-17 04:06:47,819]   LabelSmoothing Loss = 1.247602105140686\n",
      "[INFO: 2022-02-17 04:06:57,361] Iteration 51340 (DataTime/BatchTime: 0.00201/0.477) losses = 1.7807, lr = [1.9504221857087184e-05, 0.0001950422185708718]\n",
      "[INFO: 2022-02-17 04:06:57,361]   LabelSmoothing Loss = 2.338010549545288\n",
      "[INFO: 2022-02-17 04:07:06,926] Iteration 51360 (DataTime/BatchTime: 0.00121/0.478) losses = 1.7065, lr = [1.950042408423402e-05, 0.00019500424084234016]\n",
      "[INFO: 2022-02-17 04:07:06,927]   LabelSmoothing Loss = 2.1633129119873047\n",
      "[INFO: 2022-02-17 04:07:16,402] Iteration 51380 (DataTime/BatchTime: 0.00117/0.474) losses = 1.5732, lr = [1.9496628528972142e-05, 0.0001949662852897214]\n",
      "[INFO: 2022-02-17 04:07:16,402]   LabelSmoothing Loss = 1.7409878969192505\n",
      "[INFO: 2022-02-17 04:07:25,911] Iteration 51400 (DataTime/BatchTime: 0.00123/0.475) losses = 1.6795, lr = [1.9492835189144236e-05, 0.00019492835189144234]\n",
      "[INFO: 2022-02-17 04:07:25,911]   LabelSmoothing Loss = 1.052288293838501\n",
      "[INFO: 2022-02-17 04:07:35,358] Iteration 51420 (DataTime/BatchTime: 0.0012/0.472) losses = 1.5647, lr = [1.9489044062595917e-05, 0.00019489044062595914]\n",
      "[INFO: 2022-02-17 04:07:35,358]   LabelSmoothing Loss = 1.6173243522644043\n",
      "[INFO: 2022-02-17 04:07:44,810] Iteration 51440 (DataTime/BatchTime: 0.00121/0.473) losses = 1.5915, lr = [1.948525514717574e-05, 0.00019485255147175736]\n",
      "[INFO: 2022-02-17 04:07:44,810]   LabelSmoothing Loss = 2.1847305297851562\n",
      "[INFO: 2022-02-17 04:07:54,282] Iteration 51460 (DataTime/BatchTime: 0.00118/0.474) losses = 1.6513, lr = [1.9481468440735182e-05, 0.00019481468440735178]\n",
      "[INFO: 2022-02-17 04:07:54,282]   LabelSmoothing Loss = 2.356100082397461\n",
      "[INFO: 2022-02-17 04:08:03,864] Iteration 51480 (DataTime/BatchTime: 0.00137/0.479) losses = 1.4471, lr = [1.947768394112865e-05, 0.00019477683941128646]\n",
      "[INFO: 2022-02-17 04:08:03,864]   LabelSmoothing Loss = 1.4150769710540771\n",
      "[INFO: 2022-02-17 04:08:13,582] Iteration 51500 (DataTime/BatchTime: 0.00133/0.486) losses = 1.77, lr = [1.9473901646213456e-05, 0.00019473901646213453]\n",
      "[INFO: 2022-02-17 04:08:13,582]   LabelSmoothing Loss = 3.089298725128174\n",
      "[INFO: 2022-02-17 04:08:23,218] Iteration 51520 (DataTime/BatchTime: 0.00211/0.482) losses = 1.7596, lr = [1.9470121553849836e-05, 0.00019470121553849835]\n",
      "[INFO: 2022-02-17 04:08:23,218]   LabelSmoothing Loss = 0.8761685490608215\n",
      "[INFO: 2022-02-17 04:08:32,803] Iteration 51540 (DataTime/BatchTime: 0.00306/0.479) losses = 1.4832, lr = [1.946634366190092e-05, 0.00019466343661900918]\n",
      "[INFO: 2022-02-17 04:08:32,804]   LabelSmoothing Loss = 2.457052230834961\n",
      "[INFO: 2022-02-17 04:08:42,338] Iteration 51560 (DataTime/BatchTime: 0.00223/0.477) losses = 1.5191, lr = [1.946256796823275e-05, 0.00019462567968232746]\n",
      "[INFO: 2022-02-17 04:08:42,338]   LabelSmoothing Loss = 1.974905014038086\n",
      "[INFO: 2022-02-17 04:12:18,609] ######## Epoch (VAL)54 ########\n",
      "[INFO: 2022-02-17 04:12:18,609] {'Bleu_1': 0.3519471800591605, 'Bleu_2': 0.2097601417027563, 'Bleu_3': 0.13898769918625187, 'Bleu_4': 0.09848435832586563, 'METEOR': 0.1828242911151315, 'ROUGE_L': 0.2876390609989104, 'CIDEr': 0.32907910594666123}\n",
      "[INFO: 2022-02-17 04:15:53,683] ######## Epoch (TEST)54 ########\n",
      "[INFO: 2022-02-17 04:15:53,683] {'Bleu_1': 0.32979360822433273, 'Bleu_2': 0.18148373605873808, 'Bleu_3': 0.10798306096658125, 'Bleu_4': 0.0629598893041053, 'METEOR': 0.1721373544482412, 'ROUGE_L': 0.26650623077201213, 'CIDEr': 0.16378137596058967}\n",
      "[INFO: 2022-02-17 04:16:00,073] Iteration 51580 (DataTime/BatchTime: 0.101/0.581) losses = 1.6144, lr = [1.9458794470714248e-05, 0.00019458794470714246]\n",
      "[INFO: 2022-02-17 04:16:00,073]   LabelSmoothing Loss = 0.8459771871566772\n",
      "[INFO: 2022-02-17 04:16:09,453] Iteration 51600 (DataTime/BatchTime: 0.00208/0.469) losses = 1.6527, lr = [1.945502316721725e-05, 0.00019455023167217248]\n",
      "[INFO: 2022-02-17 04:16:09,453]   LabelSmoothing Loss = 1.5799124240875244\n",
      "[INFO: 2022-02-17 04:16:18,998] Iteration 51620 (DataTime/BatchTime: 0.00138/0.477) losses = 1.5402, lr = [1.9451254055616463e-05, 0.00019451254055616462]\n",
      "[INFO: 2022-02-17 04:16:18,998]   LabelSmoothing Loss = 1.9403303861618042\n",
      "[INFO: 2022-02-17 04:16:28,662] Iteration 51640 (DataTime/BatchTime: 0.00148/0.483) losses = 1.7791, lr = [1.9447487133789475e-05, 0.00019447487133789472]\n",
      "[INFO: 2022-02-17 04:16:28,662]   LabelSmoothing Loss = 2.2067320346832275\n",
      "[INFO: 2022-02-17 04:16:38,174] Iteration 51660 (DataTime/BatchTime: 0.00137/0.476) losses = 1.3822, lr = [1.944372239961676e-05, 0.00019443722399616758]\n",
      "[INFO: 2022-02-17 04:16:38,174]   LabelSmoothing Loss = 1.7570918798446655\n",
      "[INFO: 2022-02-17 04:16:47,809] Iteration 51680 (DataTime/BatchTime: 0.00129/0.481) losses = 1.6169, lr = [1.943995985098165e-05, 0.00019439959850981646]\n",
      "[INFO: 2022-02-17 04:16:47,809]   LabelSmoothing Loss = 2.684471368789673\n",
      "[INFO: 2022-02-17 04:16:57,412] Iteration 51700 (DataTime/BatchTime: 0.00221/0.481) losses = 1.5751, lr = [1.943619948577035e-05, 0.00019436199485770348]\n",
      "[INFO: 2022-02-17 04:16:57,412]   LabelSmoothing Loss = 1.325482726097107\n",
      "[INFO: 2022-02-17 04:17:06,847] Iteration 51720 (DataTime/BatchTime: 0.00132/0.472) losses = 1.4826, lr = [1.9432441301871933e-05, 0.0001943244130187193]\n",
      "[INFO: 2022-02-17 04:17:06,847]   LabelSmoothing Loss = 1.4259051084518433\n",
      "[INFO: 2022-02-17 04:17:16,346] Iteration 51740 (DataTime/BatchTime: 0.0013/0.475) losses = 1.6553, lr = [1.9428685297178313e-05, 0.00019428685297178308]\n",
      "[INFO: 2022-02-17 04:17:16,346]   LabelSmoothing Loss = 2.1339380741119385\n",
      "[INFO: 2022-02-17 04:17:25,873] Iteration 51760 (DataTime/BatchTime: 0.0021/0.476) losses = 1.7361, lr = [1.9424931469584264e-05, 0.00019424931469584262]\n",
      "[INFO: 2022-02-17 04:17:25,874]   LabelSmoothing Loss = 0.8786353468894958\n",
      "[INFO: 2022-02-17 04:17:35,378] Iteration 51780 (DataTime/BatchTime: 0.00133/0.475) losses = 1.493, lr = [1.9421179816987407e-05, 0.00019421179816987404]\n",
      "[INFO: 2022-02-17 04:17:35,378]   LabelSmoothing Loss = 0.9782834053039551\n",
      "[INFO: 2022-02-17 04:17:44,868] Iteration 51800 (DataTime/BatchTime: 0.00304/0.475) losses = 1.3704, lr = [1.9417430337288198e-05, 0.00019417430337288197]\n",
      "[INFO: 2022-02-17 04:17:44,868]   LabelSmoothing Loss = 0.9755324721336365\n",
      "[INFO: 2022-02-17 04:17:54,359] Iteration 51820 (DataTime/BatchTime: 0.00134/0.475) losses = 1.6127, lr = [1.9413683028389943e-05, 0.0001941368302838994]\n",
      "[INFO: 2022-02-17 04:17:54,359]   LabelSmoothing Loss = 0.9607505798339844\n",
      "[INFO: 2022-02-17 04:18:03,805] Iteration 51840 (DataTime/BatchTime: 0.00219/0.472) losses = 1.3629, lr = [1.9409937888198762e-05, 0.0001940993788819876]\n",
      "[INFO: 2022-02-17 04:18:03,805]   LabelSmoothing Loss = 1.113391637802124\n",
      "[INFO: 2022-02-17 04:18:13,316] Iteration 51860 (DataTime/BatchTime: 0.00134/0.476) losses = 1.5942, lr = [1.9406194914623613e-05, 0.0001940619491462361]\n",
      "[INFO: 2022-02-17 04:18:13,317]   LabelSmoothing Loss = 1.7884293794631958\n",
      "[INFO: 2022-02-17 04:18:22,852] Iteration 51880 (DataTime/BatchTime: 0.00131/0.477) losses = 1.689, lr = [1.9402454105576264e-05, 0.0001940245410557626]\n",
      "[INFO: 2022-02-17 04:18:22,852]   LabelSmoothing Loss = 1.1951566934585571\n",
      "[INFO: 2022-02-17 04:18:32,421] Iteration 51900 (DataTime/BatchTime: 0.00141/0.478) losses = 1.6971, lr = [1.939871545897132e-05, 0.00019398715458971317]\n",
      "[INFO: 2022-02-17 04:18:32,421]   LabelSmoothing Loss = 1.5027414560317993\n",
      "[INFO: 2022-02-17 04:18:41,868] Iteration 51920 (DataTime/BatchTime: 0.00228/0.472) losses = 1.3656, lr = [1.939497897272617e-05, 0.0001939497897272617]\n",
      "[INFO: 2022-02-17 04:18:41,868]   LabelSmoothing Loss = 1.1587713956832886\n",
      "[INFO: 2022-02-17 04:18:51,400] Iteration 51940 (DataTime/BatchTime: 0.00131/0.477) losses = 1.7293, lr = [1.9391244644761044e-05, 0.0001939124464476104]\n",
      "[INFO: 2022-02-17 04:18:51,400]   LabelSmoothing Loss = 2.106710195541382\n",
      "[INFO: 2022-02-17 04:19:00,935] Iteration 51960 (DataTime/BatchTime: 0.00135/0.477) losses = 1.7881, lr = [1.9387512472998942e-05, 0.0001938751247299894]\n",
      "[INFO: 2022-02-17 04:19:00,935]   LabelSmoothing Loss = 1.784741759300232\n",
      "[INFO: 2022-02-17 04:19:10,474] Iteration 51980 (DataTime/BatchTime: 0.0013/0.477) losses = 1.6933, lr = [1.9383782455365675e-05, 0.00019383782455365672]\n",
      "[INFO: 2022-02-17 04:19:10,474]   LabelSmoothing Loss = 1.5346355438232422\n",
      "[INFO: 2022-02-17 04:19:19,992] Iteration 52000 (DataTime/BatchTime: 0.0013/0.476) losses = 1.5933, lr = [1.938005458978985e-05, 0.00019380054589789847]\n",
      "[INFO: 2022-02-17 04:19:19,992]   LabelSmoothing Loss = 0.8574445843696594\n",
      "[INFO: 2022-02-17 04:19:29,485] Iteration 52020 (DataTime/BatchTime: 0.00128/0.475) losses = 1.6793, lr = [1.9376328874202857e-05, 0.00019376328874202853]\n",
      "[INFO: 2022-02-17 04:19:29,485]   LabelSmoothing Loss = 1.7419040203094482\n",
      "[INFO: 2022-02-17 04:19:39,107] Iteration 52040 (DataTime/BatchTime: 0.00139/0.481) losses = 1.7338, lr = [1.9372605306538864e-05, 0.00019372605306538864]\n",
      "[INFO: 2022-02-17 04:19:39,107]   LabelSmoothing Loss = 2.0935051441192627\n",
      "[INFO: 2022-02-17 04:19:48,696] Iteration 52060 (DataTime/BatchTime: 0.0013/0.479) losses = 1.5799, lr = [1.9368883884734828e-05, 0.00019368883884734824]\n",
      "[INFO: 2022-02-17 04:19:48,697]   LabelSmoothing Loss = 2.2163708209991455\n",
      "[INFO: 2022-02-17 04:19:58,336] Iteration 52080 (DataTime/BatchTime: 0.00133/0.482) losses = 1.7356, lr = [1.936516460673047e-05, 0.00019365164606730467]\n",
      "[INFO: 2022-02-17 04:19:58,336]   LabelSmoothing Loss = 2.6062207221984863\n",
      "[INFO: 2022-02-17 04:20:07,891] Iteration 52100 (DataTime/BatchTime: 0.00128/0.478) losses = 1.7163, lr = [1.9361447470468278e-05, 0.00019361447470468278]\n",
      "[INFO: 2022-02-17 04:20:07,891]   LabelSmoothing Loss = 1.9858371019363403\n",
      "[INFO: 2022-02-17 04:20:17,476] Iteration 52120 (DataTime/BatchTime: 0.00127/0.479) losses = 1.7141, lr = [1.935773247389352e-05, 0.00019357732473893519]\n",
      "[INFO: 2022-02-17 04:20:17,476]   LabelSmoothing Loss = 1.858453392982483\n",
      "[INFO: 2022-02-17 04:20:27,021] Iteration 52140 (DataTime/BatchTime: 0.00133/0.477) losses = 1.4082, lr = [1.9354019614954197e-05, 0.00019354019614954194]\n",
      "[INFO: 2022-02-17 04:20:27,021]   LabelSmoothing Loss = 1.1153359413146973\n",
      "[INFO: 2022-02-17 04:20:36,556] Iteration 52160 (DataTime/BatchTime: 0.00131/0.477) losses = 1.6338, lr = [1.9350308891601085e-05, 0.00019350308891601082]\n",
      "[INFO: 2022-02-17 04:20:36,556]   LabelSmoothing Loss = 2.5422751903533936\n",
      "[INFO: 2022-02-17 04:20:46,093] Iteration 52180 (DataTime/BatchTime: 0.0013/0.477) losses = 1.6331, lr = [1.9346600301787694e-05, 0.0001934660030178769]\n",
      "[INFO: 2022-02-17 04:20:46,093]   LabelSmoothing Loss = 2.9922220706939697\n",
      "[INFO: 2022-02-17 04:20:55,657] Iteration 52200 (DataTime/BatchTime: 0.00303/0.478) losses = 1.4264, lr = [1.9342893843470298e-05, 0.00019342893843470296]\n",
      "[INFO: 2022-02-17 04:20:55,657]   LabelSmoothing Loss = 1.064717411994934\n",
      "[INFO: 2022-02-17 04:21:05,232] Iteration 52220 (DataTime/BatchTime: 0.0013/0.479) losses = 1.6272, lr = [1.9339189514607887e-05, 0.00019339189514607885]\n",
      "[INFO: 2022-02-17 04:21:05,233]   LabelSmoothing Loss = 1.7531490325927734\n",
      "[INFO: 2022-02-17 04:21:14,790] Iteration 52240 (DataTime/BatchTime: 0.00129/0.478) losses = 1.6584, lr = [1.9335487313162205e-05, 0.00019335487313162204]\n",
      "[INFO: 2022-02-17 04:21:14,791]   LabelSmoothing Loss = 1.12588369846344\n",
      "[INFO: 2022-02-17 04:21:24,284] Iteration 52260 (DataTime/BatchTime: 0.0013/0.475) losses = 1.5464, lr = [1.933178723709772e-05, 0.00019331787237097717]\n",
      "[INFO: 2022-02-17 04:21:24,284]   LabelSmoothing Loss = 1.8707832098007202\n",
      "[INFO: 2022-02-17 04:21:33,864] Iteration 52280 (DataTime/BatchTime: 0.00125/0.479) losses = 1.6549, lr = [1.9328089284381617e-05, 0.00019328089284381615]\n",
      "[INFO: 2022-02-17 04:21:33,864]   LabelSmoothing Loss = 0.9057324528694153\n",
      "[INFO: 2022-02-17 04:21:43,405] Iteration 52300 (DataTime/BatchTime: 0.00132/0.477) losses = 1.5826, lr = [1.932439345298382e-05, 0.00019324393452983815]\n",
      "[INFO: 2022-02-17 04:21:43,405]   LabelSmoothing Loss = 2.1519577503204346\n",
      "[INFO: 2022-02-17 04:21:53,009] Iteration 52320 (DataTime/BatchTime: 0.00151/0.48) losses = 1.4544, lr = [1.9320699740876947e-05, 0.00019320699740876945]\n",
      "[INFO: 2022-02-17 04:21:53,009]   LabelSmoothing Loss = 0.7477995157241821\n",
      "[INFO: 2022-02-17 04:22:02,522] Iteration 52340 (DataTime/BatchTime: 0.0013/0.476) losses = 1.5143, lr = [1.931700814603635e-05, 0.00019317008146036346]\n",
      "[INFO: 2022-02-17 04:22:02,523]   LabelSmoothing Loss = 1.1528269052505493\n",
      "[INFO: 2022-02-17 04:22:12,127] Iteration 52360 (DataTime/BatchTime: 0.00135/0.48) losses = 1.5675, lr = [1.9313318666440074e-05, 0.00019313318666440072]\n",
      "[INFO: 2022-02-17 04:22:12,127]   LabelSmoothing Loss = 1.069273829460144\n",
      "[INFO: 2022-02-17 04:22:21,799] Iteration 52380 (DataTime/BatchTime: 0.00138/0.484) losses = 1.5945, lr = [1.930963130006887e-05, 0.00019309631300068868]\n",
      "[INFO: 2022-02-17 04:22:21,800]   LabelSmoothing Loss = 1.929410457611084\n",
      "[INFO: 2022-02-17 04:22:31,344] Iteration 52400 (DataTime/BatchTime: 0.00132/0.477) losses = 1.473, lr = [1.9305946044906187e-05, 0.00019305946044906184]\n",
      "[INFO: 2022-02-17 04:22:31,344]   LabelSmoothing Loss = 2.2622687816619873\n",
      "[INFO: 2022-02-17 04:22:40,869] Iteration 52420 (DataTime/BatchTime: 0.00131/0.476) losses = 1.5582, lr = [1.9302262898938163e-05, 0.00019302262898938163]\n",
      "[INFO: 2022-02-17 04:22:40,869]   LabelSmoothing Loss = 1.5816677808761597\n",
      "[INFO: 2022-02-17 04:22:50,552] Iteration 52440 (DataTime/BatchTime: 0.00291/0.484) losses = 1.8844, lr = [1.929858186015363e-05, 0.00019298581860153628]\n",
      "[INFO: 2022-02-17 04:22:50,552]   LabelSmoothing Loss = 1.477186918258667\n",
      "[INFO: 2022-02-17 04:23:00,260] Iteration 52460 (DataTime/BatchTime: 0.00169/0.485) losses = 1.6371, lr = [1.9294902926544102e-05, 0.00019294902926544102]\n",
      "[INFO: 2022-02-17 04:23:00,260]   LabelSmoothing Loss = 2.2166011333465576\n",
      "[INFO: 2022-02-17 04:23:09,794] Iteration 52480 (DataTime/BatchTime: 0.00129/0.477) losses = 1.5075, lr = [1.929122609610377e-05, 0.0001929122609610377]\n",
      "[INFO: 2022-02-17 04:23:09,794]   LabelSmoothing Loss = 1.7615227699279785\n",
      "[INFO: 2022-02-17 04:23:19,460] Iteration 52500 (DataTime/BatchTime: 0.00133/0.483) losses = 1.6125, lr = [1.9287551366829503e-05, 0.000192875513668295]\n",
      "[INFO: 2022-02-17 04:23:19,460]   LabelSmoothing Loss = 0.9287929534912109\n",
      "[INFO: 2022-02-17 04:23:28,895] Iteration 52520 (DataTime/BatchTime: 0.00117/0.472) losses = 1.8564, lr = [1.9283878736720838e-05, 0.00019283878736720838]\n",
      "[INFO: 2022-02-17 04:23:28,896]   LabelSmoothing Loss = 1.815934658050537\n",
      "[INFO: 2022-02-17 04:27:00,526] ######## Epoch (VAL)55 ########\n",
      "[INFO: 2022-02-17 04:27:00,526] {'Bleu_1': 0.3471212988400757, 'Bleu_2': 0.21058493844147697, 'Bleu_3': 0.1400319345316031, 'Bleu_4': 0.09798603075394732, 'METEOR': 0.1839294293681203, 'ROUGE_L': 0.29270809934519915, 'CIDEr': 0.3615169214900403}\n",
      "[INFO: 2022-02-17 04:30:33,372] ######## Epoch (TEST)55 ########\n",
      "[INFO: 2022-02-17 04:30:33,372] {'Bleu_1': 0.3204883297593066, 'Bleu_2': 0.1764290925968712, 'Bleu_3': 0.1036418177878664, 'Bleu_4': 0.06057769517195858, 'METEOR': 0.16842377979888004, 'ROUGE_L': 0.26485205112850363, 'CIDEr': 0.16051943614632533}\n",
      "[INFO: 2022-02-17 04:30:42,008] Iteration 52540 (DataTime/BatchTime: 0.0621/0.54) losses = 1.545, lr = [1.928020820377998e-05, 0.00019280208203779979]\n",
      "[INFO: 2022-02-17 04:30:42,008]   LabelSmoothing Loss = 1.6573827266693115\n",
      "[INFO: 2022-02-17 04:30:51,454] Iteration 52560 (DataTime/BatchTime: 0.00201/0.472) losses = 1.4897, lr = [1.9276539766011787e-05, 0.00019276539766011782]\n",
      "[INFO: 2022-02-17 04:30:51,454]   LabelSmoothing Loss = 0.5398030281066895\n",
      "[INFO: 2022-02-17 04:31:00,904] Iteration 52580 (DataTime/BatchTime: 0.00119/0.473) losses = 1.535, lr = [1.927287342142378e-05, 0.00019272873421423778]\n",
      "[INFO: 2022-02-17 04:31:00,904]   LabelSmoothing Loss = 1.4249701499938965\n",
      "[INFO: 2022-02-17 04:31:10,470] Iteration 52600 (DataTime/BatchTime: 0.00223/0.478) losses = 1.7016, lr = [1.926920916802613e-05, 0.00019269209168026126]\n",
      "[INFO: 2022-02-17 04:31:10,471]   LabelSmoothing Loss = 1.3288159370422363\n",
      "[INFO: 2022-02-17 04:31:20,064] Iteration 52620 (DataTime/BatchTime: 0.00146/0.48) losses = 1.4802, lr = [1.926554700383166e-05, 0.00019265547003831658]\n",
      "[INFO: 2022-02-17 04:31:20,064]   LabelSmoothing Loss = 1.3546308279037476\n",
      "[INFO: 2022-02-17 04:31:29,806] Iteration 52640 (DataTime/BatchTime: 0.00141/0.487) losses = 1.7458, lr = [1.926188692685583e-05, 0.00019261886926855826]\n",
      "[INFO: 2022-02-17 04:31:29,806]   LabelSmoothing Loss = 1.578547477722168\n",
      "[INFO: 2022-02-17 04:31:39,403] Iteration 52660 (DataTime/BatchTime: 0.00393/0.48) losses = 1.5958, lr = [1.9258228935116735e-05, 0.00019258228935116733]\n",
      "[INFO: 2022-02-17 04:31:39,403]   LabelSmoothing Loss = 2.102325201034546\n",
      "[INFO: 2022-02-17 04:31:49,320] Iteration 52680 (DataTime/BatchTime: 0.00215/0.496) losses = 1.6352, lr = [1.9254573026635117e-05, 0.00019254573026635113]\n",
      "[INFO: 2022-02-17 04:31:49,320]   LabelSmoothing Loss = 1.0263400077819824\n",
      "[INFO: 2022-02-17 04:31:58,939] Iteration 52700 (DataTime/BatchTime: 0.00194/0.481) losses = 1.5842, lr = [1.9250919199434325e-05, 0.00019250919199434324]\n",
      "[INFO: 2022-02-17 04:31:58,939]   LabelSmoothing Loss = 1.828139305114746\n",
      "[INFO: 2022-02-17 04:32:08,605] Iteration 52720 (DataTime/BatchTime: 0.00131/0.483) losses = 1.7102, lr = [1.924726745154036e-05, 0.00019247267451540356]\n",
      "[INFO: 2022-02-17 04:32:08,605]   LabelSmoothing Loss = 1.239215612411499\n",
      "[INFO: 2022-02-17 04:32:18,205] Iteration 52740 (DataTime/BatchTime: 0.00132/0.48) losses = 1.5355, lr = [1.924361778098182e-05, 0.00019243617780981818]\n",
      "[INFO: 2022-02-17 04:32:18,205]   LabelSmoothing Loss = 1.400648832321167\n",
      "[INFO: 2022-02-17 04:32:27,811] Iteration 52760 (DataTime/BatchTime: 0.00136/0.48) losses = 1.352, lr = [1.923997018578993e-05, 0.0001923997018578993]\n",
      "[INFO: 2022-02-17 04:32:27,812]   LabelSmoothing Loss = 1.517362117767334\n",
      "[INFO: 2022-02-17 04:32:37,423] Iteration 52780 (DataTime/BatchTime: 0.00139/0.481) losses = 1.5355, lr = [1.923632466399853e-05, 0.00019236324663998526]\n",
      "[INFO: 2022-02-17 04:32:37,424]   LabelSmoothing Loss = 1.5134477615356445\n",
      "[INFO: 2022-02-17 04:32:47,089] Iteration 52800 (DataTime/BatchTime: 0.0029/0.483) losses = 1.5397, lr = [1.9232681213644052e-05, 0.0001923268121364405]\n",
      "[INFO: 2022-02-17 04:32:47,089]   LabelSmoothing Loss = 0.9957866072654724\n",
      "[INFO: 2022-02-17 04:32:56,715] Iteration 52820 (DataTime/BatchTime: 0.00127/0.481) losses = 1.8055, lr = [1.922903983276554e-05, 0.00019229039832765538]\n",
      "[INFO: 2022-02-17 04:32:56,715]   LabelSmoothing Loss = 2.177905559539795\n",
      "[INFO: 2022-02-17 04:33:06,329] Iteration 52840 (DataTime/BatchTime: 0.00132/0.481) losses = 1.7879, lr = [1.9225400519404643e-05, 0.00019225400519404638]\n",
      "[INFO: 2022-02-17 04:33:06,330]   LabelSmoothing Loss = 1.514041781425476\n",
      "[INFO: 2022-02-17 04:33:15,839] Iteration 52860 (DataTime/BatchTime: 0.00131/0.475) losses = 1.5335, lr = [1.922176327160559e-05, 0.00019221763271605585]\n",
      "[INFO: 2022-02-17 04:33:15,839]   LabelSmoothing Loss = 1.572109341621399\n",
      "[INFO: 2022-02-17 04:33:25,451] Iteration 52880 (DataTime/BatchTime: 0.00319/0.481) losses = 1.6953, lr = [1.9218128087415208e-05, 0.00019218128087415204]\n",
      "[INFO: 2022-02-17 04:33:25,452]   LabelSmoothing Loss = 1.0901567935943604\n",
      "[INFO: 2022-02-17 04:33:35,028] Iteration 52900 (DataTime/BatchTime: 0.00304/0.479) losses = 1.2898, lr = [1.92144949648829e-05, 0.00019214494964882897]\n",
      "[INFO: 2022-02-17 04:33:35,028]   LabelSmoothing Loss = 1.6269986629486084\n",
      "[INFO: 2022-02-17 04:33:44,637] Iteration 52920 (DataTime/BatchTime: 0.00209/0.48) losses = 1.7008, lr = [1.921086390206066e-05, 0.00019210863902060658]\n",
      "[INFO: 2022-02-17 04:33:44,637]   LabelSmoothing Loss = 2.618229866027832\n",
      "[INFO: 2022-02-17 04:33:54,234] Iteration 52940 (DataTime/BatchTime: 0.00266/0.479) losses = 1.4873, lr = [1.9207234897003054e-05, 0.00019207234897003053]\n",
      "[INFO: 2022-02-17 04:33:54,234]   LabelSmoothing Loss = 1.1937952041625977\n",
      "[INFO: 2022-02-17 04:34:03,784] Iteration 52960 (DataTime/BatchTime: 0.00211/0.478) losses = 1.6211, lr = [1.920360794776721e-05, 0.00019203607947767209]\n",
      "[INFO: 2022-02-17 04:34:03,784]   LabelSmoothing Loss = 1.3994323015213013\n",
      "[INFO: 2022-02-17 04:34:13,405] Iteration 52980 (DataTime/BatchTime: 0.00132/0.481) losses = 1.671, lr = [1.9199983052412843e-05, 0.00019199983052412838]\n",
      "[INFO: 2022-02-17 04:34:13,405]   LabelSmoothing Loss = 0.9915809035301208\n",
      "[INFO: 2022-02-17 04:34:23,039] Iteration 53000 (DataTime/BatchTime: 0.0013/0.482) losses = 1.5798, lr = [1.919636020900221e-05, 0.00019196360209002206]\n",
      "[INFO: 2022-02-17 04:34:23,039]   LabelSmoothing Loss = 1.906158685684204\n",
      "[INFO: 2022-02-17 04:34:32,574] Iteration 53020 (DataTime/BatchTime: 0.00159/0.477) losses = 1.5176, lr = [1.919273941560014e-05, 0.00019192739415600137]\n",
      "[INFO: 2022-02-17 04:34:32,574]   LabelSmoothing Loss = 1.7243024110794067\n",
      "[INFO: 2022-02-17 04:34:42,174] Iteration 53040 (DataTime/BatchTime: 0.0022/0.48) losses = 1.3751, lr = [1.918912067027401e-05, 0.0001918912067027401]\n",
      "[INFO: 2022-02-17 04:34:42,175]   LabelSmoothing Loss = 1.9895086288452148\n",
      "[INFO: 2022-02-17 04:34:51,859] Iteration 53060 (DataTime/BatchTime: 0.00145/0.484) losses = 1.9123, lr = [1.918550397109375e-05, 0.0001918550397109375]\n",
      "[INFO: 2022-02-17 04:34:51,859]   LabelSmoothing Loss = 1.9271228313446045\n",
      "[INFO: 2022-02-17 04:35:01,442] Iteration 53080 (DataTime/BatchTime: 0.00207/0.479) losses = 1.7709, lr = [1.9181889316131832e-05, 0.0001918188931613183]\n",
      "[INFO: 2022-02-17 04:35:01,442]   LabelSmoothing Loss = 2.3271963596343994\n",
      "[INFO: 2022-02-17 04:35:10,953] Iteration 53100 (DataTime/BatchTime: 0.0021/0.476) losses = 1.575, lr = [1.9178276703463275e-05, 0.00019178276703463274]\n",
      "[INFO: 2022-02-17 04:35:10,954]   LabelSmoothing Loss = 1.8793525695800781\n",
      "[INFO: 2022-02-17 04:35:20,512] Iteration 53120 (DataTime/BatchTime: 0.00205/0.478) losses = 1.4089, lr = [1.917466613116563e-05, 0.00019174666131165625]\n",
      "[INFO: 2022-02-17 04:35:20,512]   LabelSmoothing Loss = 2.0599052906036377\n",
      "[INFO: 2022-02-17 04:35:30,157] Iteration 53140 (DataTime/BatchTime: 0.00131/0.482) losses = 1.8183, lr = [1.9171057597318973e-05, 0.0001917105759731897]\n",
      "[INFO: 2022-02-17 04:35:30,157]   LabelSmoothing Loss = 1.3658127784729004\n",
      "[INFO: 2022-02-17 04:35:39,710] Iteration 53160 (DataTime/BatchTime: 0.00138/0.478) losses = 1.5962, lr = [1.916745110000593e-05, 0.0001916745110000593]\n",
      "[INFO: 2022-02-17 04:35:39,710]   LabelSmoothing Loss = 1.607641339302063\n",
      "[INFO: 2022-02-17 04:35:49,314] Iteration 53180 (DataTime/BatchTime: 0.00134/0.48) losses = 1.6294, lr = [1.9163846637311632e-05, 0.00019163846637311628]\n",
      "[INFO: 2022-02-17 04:35:49,314]   LabelSmoothing Loss = 1.332076907157898\n",
      "[INFO: 2022-02-17 04:35:58,821] Iteration 53200 (DataTime/BatchTime: 0.00129/0.475) losses = 1.6257, lr = [1.916024420732373e-05, 0.0001916024420732373]\n",
      "[INFO: 2022-02-17 04:35:58,821]   LabelSmoothing Loss = 1.2461202144622803\n",
      "[INFO: 2022-02-17 04:36:08,374] Iteration 53220 (DataTime/BatchTime: 0.00133/0.478) losses = 1.6123, lr = [1.915664380813241e-05, 0.00019156643808132407]\n",
      "[INFO: 2022-02-17 04:36:08,374]   LabelSmoothing Loss = 1.0870112180709839\n",
      "[INFO: 2022-02-17 04:36:17,937] Iteration 53240 (DataTime/BatchTime: 0.00126/0.478) losses = 1.6077, lr = [1.915304543783034e-05, 0.00019153045437830338]\n",
      "[INFO: 2022-02-17 04:36:17,937]   LabelSmoothing Loss = 1.0133206844329834\n",
      "[INFO: 2022-02-17 04:36:27,474] Iteration 53260 (DataTime/BatchTime: 0.00127/0.477) losses = 1.698, lr = [1.9149449094512713e-05, 0.00019149449094512711]\n",
      "[INFO: 2022-02-17 04:36:27,474]   LabelSmoothing Loss = 1.7130244970321655\n",
      "[INFO: 2022-02-17 04:36:36,974] Iteration 53280 (DataTime/BatchTime: 0.00124/0.475) losses = 1.5755, lr = [1.9145854776277232e-05, 0.0001914585477627723]\n",
      "[INFO: 2022-02-17 04:36:36,974]   LabelSmoothing Loss = 1.1855233907699585\n",
      "[INFO: 2022-02-17 04:36:46,473] Iteration 53300 (DataTime/BatchTime: 0.00126/0.475) losses = 1.5239, lr = [1.9142262481224077e-05, 0.00019142262481224075]\n",
      "[INFO: 2022-02-17 04:36:46,473]   LabelSmoothing Loss = 1.9860535860061646\n",
      "[INFO: 2022-02-17 04:36:55,941] Iteration 53320 (DataTime/BatchTime: 0.00127/0.473) losses = 1.4614, lr = [1.9138672207455937e-05, 0.00019138672207455934]\n",
      "[INFO: 2022-02-17 04:36:55,941]   LabelSmoothing Loss = 2.0562140941619873\n",
      "[INFO: 2022-02-17 04:37:05,538] Iteration 53340 (DataTime/BatchTime: 0.00127/0.48) losses = 1.5381, lr = [1.913508395307799e-05, 0.00019135083953077987]\n",
      "[INFO: 2022-02-17 04:37:05,538]   LabelSmoothing Loss = 2.1329307556152344\n",
      "[INFO: 2022-02-17 04:37:15,090] Iteration 53360 (DataTime/BatchTime: 0.00124/0.478) losses = 1.8226, lr = [1.9131497716197893e-05, 0.0001913149771619789]\n",
      "[INFO: 2022-02-17 04:37:15,090]   LabelSmoothing Loss = 1.3113051652908325\n",
      "[INFO: 2022-02-17 04:37:24,548] Iteration 53380 (DataTime/BatchTime: 0.00125/0.473) losses = 1.488, lr = [1.9127913494925795e-05, 0.00019127913494925791]\n",
      "[INFO: 2022-02-17 04:37:24,548]   LabelSmoothing Loss = 2.0841493606567383\n",
      "[INFO: 2022-02-17 04:37:34,034] Iteration 53400 (DataTime/BatchTime: 0.00125/0.474) losses = 1.373, lr = [1.9124331287374312e-05, 0.0001912433128737431]\n",
      "[INFO: 2022-02-17 04:37:34,034]   LabelSmoothing Loss = 0.9013360142707825\n",
      "[INFO: 2022-02-17 04:37:43,500] Iteration 53420 (DataTime/BatchTime: 0.00125/0.473) losses = 1.3542, lr = [1.9120751091658537e-05, 0.00019120751091658537]\n",
      "[INFO: 2022-02-17 04:37:43,500]   LabelSmoothing Loss = 1.250962734222412\n",
      "[INFO: 2022-02-17 04:37:53,033] Iteration 53440 (DataTime/BatchTime: 0.00126/0.477) losses = 1.6777, lr = [1.911717290589604e-05, 0.00019117172905896035]\n",
      "[INFO: 2022-02-17 04:37:53,033]   LabelSmoothing Loss = 1.1429705619812012\n",
      "[INFO: 2022-02-17 04:38:02,512] Iteration 53460 (DataTime/BatchTime: 0.00223/0.474) losses = 1.7573, lr = [1.9113596728206837e-05, 0.00019113596728206835]\n",
      "[INFO: 2022-02-17 04:38:02,512]   LabelSmoothing Loss = 1.4943653345108032\n",
      "[INFO: 2022-02-17 04:41:38,477] ######## Epoch (VAL)56 ########\n",
      "[INFO: 2022-02-17 04:41:38,478] {'Bleu_1': 0.359527320868207, 'Bleu_2': 0.21826557944828945, 'Bleu_3': 0.1440930251549521, 'Bleu_4': 0.10013551449995738, 'METEOR': 0.18686046406038442, 'ROUGE_L': 0.2920249051331039, 'CIDEr': 0.3152602099111442}\n",
      "[INFO: 2022-02-17 04:45:16,339] ######## Epoch (TEST)56 ########\n",
      "[INFO: 2022-02-17 04:45:16,340] {'Bleu_1': 0.3305044241793925, 'Bleu_2': 0.1907217169959578, 'Bleu_3': 0.11804943332569993, 'Bleu_4': 0.0751420367889762, 'METEOR': 0.17215866311581343, 'ROUGE_L': 0.2727073478048211, 'CIDEr': 0.1970861328560445}\n",
      "[INFO: 2022-02-17 04:45:17,849] Iteration 53480 (DataTime/BatchTime: 0.921/1.51) losses = 1.89, lr = [1.9110022556713426e-05, 0.00019110022556713424]\n",
      "[INFO: 2022-02-17 04:45:17,850]   LabelSmoothing Loss = 1.8899624347686768\n",
      "[INFO: 2022-02-17 04:45:27,383] Iteration 53500 (DataTime/BatchTime: 0.0013/0.477) losses = 1.6322, lr = [1.910645038954075e-05, 0.00019106450389540745]\n",
      "[INFO: 2022-02-17 04:45:27,383]   LabelSmoothing Loss = 1.0549932718276978\n",
      "[INFO: 2022-02-17 04:45:37,010] Iteration 53520 (DataTime/BatchTime: 0.00135/0.481) losses = 1.7809, lr = [1.9102880224816207e-05, 0.00019102880224816204]\n",
      "[INFO: 2022-02-17 04:45:37,010]   LabelSmoothing Loss = 1.4511842727661133\n",
      "[INFO: 2022-02-17 04:45:46,591] Iteration 53540 (DataTime/BatchTime: 0.00408/0.479) losses = 1.5124, lr = [1.9099312060669644e-05, 0.00019099312060669643]\n",
      "[INFO: 2022-02-17 04:45:46,591]   LabelSmoothing Loss = 1.9923853874206543\n",
      "[INFO: 2022-02-17 04:45:56,249] Iteration 53560 (DataTime/BatchTime: 0.00232/0.483) losses = 1.3517, lr = [1.909574589523335e-05, 0.0001909574589523335]\n",
      "[INFO: 2022-02-17 04:45:56,250]   LabelSmoothing Loss = 1.3158864974975586\n",
      "[INFO: 2022-02-17 04:46:05,805] Iteration 53580 (DataTime/BatchTime: 0.00217/0.478) losses = 1.4633, lr = [1.9092181726642062e-05, 0.0001909218172664206]\n",
      "[INFO: 2022-02-17 04:46:05,805]   LabelSmoothing Loss = 2.574406385421753\n",
      "[INFO: 2022-02-17 04:46:15,444] Iteration 53600 (DataTime/BatchTime: 0.00132/0.482) losses = 1.6663, lr = [1.908861955303294e-05, 0.00019088619553032937]\n",
      "[INFO: 2022-02-17 04:46:15,444]   LabelSmoothing Loss = 0.9611889719963074\n",
      "[INFO: 2022-02-17 04:46:25,148] Iteration 53620 (DataTime/BatchTime: 0.00143/0.485) losses = 1.539, lr = [1.9085059372545588e-05, 0.00019085059372545585]\n",
      "[INFO: 2022-02-17 04:46:25,148]   LabelSmoothing Loss = 1.7247360944747925\n",
      "[INFO: 2022-02-17 04:46:34,703] Iteration 53640 (DataTime/BatchTime: 0.00216/0.478) losses = 1.6336, lr = [1.9081501183322026e-05, 0.00019081501183322022]\n",
      "[INFO: 2022-02-17 04:46:34,703]   LabelSmoothing Loss = 1.570430040359497\n",
      "[INFO: 2022-02-17 04:46:44,273] Iteration 53660 (DataTime/BatchTime: 0.00128/0.478) losses = 1.43, lr = [1.9077944983506712e-05, 0.00019077944983506712]\n",
      "[INFO: 2022-02-17 04:46:44,273]   LabelSmoothing Loss = 2.1824793815612793\n",
      "[INFO: 2022-02-17 04:46:53,798] Iteration 53680 (DataTime/BatchTime: 0.00207/0.476) losses = 1.6228, lr = [1.9074390771246515e-05, 0.00019074390771246512]\n",
      "[INFO: 2022-02-17 04:46:53,798]   LabelSmoothing Loss = 1.5040063858032227\n",
      "[INFO: 2022-02-17 04:47:03,411] Iteration 53700 (DataTime/BatchTime: 0.00169/0.481) losses = 1.5138, lr = [1.9070838544690725e-05, 0.0001907083854469072]\n",
      "[INFO: 2022-02-17 04:47:03,411]   LabelSmoothing Loss = 2.0583384037017822\n",
      "[INFO: 2022-02-17 04:47:13,030] Iteration 53720 (DataTime/BatchTime: 0.00244/0.481) losses = 1.5841, lr = [1.906728830199103e-05, 0.00019067288301991028]\n",
      "[INFO: 2022-02-17 04:47:13,031]   LabelSmoothing Loss = 1.5938113927841187\n",
      "[INFO: 2022-02-17 04:47:22,661] Iteration 53740 (DataTime/BatchTime: 0.0014/0.482) losses = 1.6111, lr = [1.9063740041301545e-05, 0.00019063740041301542]\n",
      "[INFO: 2022-02-17 04:47:22,661]   LabelSmoothing Loss = 1.9035961627960205\n",
      "[INFO: 2022-02-17 04:47:32,322] Iteration 53760 (DataTime/BatchTime: 0.00143/0.483) losses = 1.4476, lr = [1.9060193760778778e-05, 0.00019060193760778776]\n",
      "[INFO: 2022-02-17 04:47:32,322]   LabelSmoothing Loss = 1.7362043857574463\n",
      "[INFO: 2022-02-17 04:47:41,890] Iteration 53780 (DataTime/BatchTime: 0.00142/0.478) losses = 1.6373, lr = [1.905664945858164e-05, 0.00019056649458581637]\n",
      "[INFO: 2022-02-17 04:47:41,890]   LabelSmoothing Loss = 1.7551664113998413\n",
      "[INFO: 2022-02-17 04:47:51,556] Iteration 53800 (DataTime/BatchTime: 0.00148/0.483) losses = 1.6119, lr = [1.9053107132871427e-05, 0.00019053107132871425]\n",
      "[INFO: 2022-02-17 04:47:51,557]   LabelSmoothing Loss = 1.1034009456634521\n",
      "[INFO: 2022-02-17 04:48:01,106] Iteration 53820 (DataTime/BatchTime: 0.00305/0.477) losses = 1.6197, lr = [1.9049566781811846e-05, 0.00019049566781811843]\n",
      "[INFO: 2022-02-17 04:48:01,107]   LabelSmoothing Loss = 1.290058970451355\n",
      "[INFO: 2022-02-17 04:48:10,719] Iteration 53840 (DataTime/BatchTime: 0.00135/0.481) losses = 1.627, lr = [1.9046028403568977e-05, 0.00019046028403568976]\n",
      "[INFO: 2022-02-17 04:48:10,720]   LabelSmoothing Loss = 1.0930922031402588\n",
      "[INFO: 2022-02-17 04:48:20,315] Iteration 53860 (DataTime/BatchTime: 0.00142/0.48) losses = 1.558, lr = [1.9042491996311288e-05, 0.00019042491996311284]\n",
      "[INFO: 2022-02-17 04:48:20,315]   LabelSmoothing Loss = 1.1379573345184326\n",
      "[INFO: 2022-02-17 04:48:30,218] Iteration 53880 (DataTime/BatchTime: 0.00172/0.495) losses = 1.7081, lr = [1.9038957558209624e-05, 0.0001903895755820962]\n",
      "[INFO: 2022-02-17 04:48:30,218]   LabelSmoothing Loss = 1.883034348487854\n",
      "[INFO: 2022-02-17 04:48:40,000] Iteration 53900 (DataTime/BatchTime: 0.00168/0.489) losses = 1.5729, lr = [1.9035425087437208e-05, 0.00019035425087437206]\n",
      "[INFO: 2022-02-17 04:48:40,000]   LabelSmoothing Loss = 0.8767242431640625\n",
      "[INFO: 2022-02-17 04:48:49,697] Iteration 53920 (DataTime/BatchTime: 0.00147/0.485) losses = 1.5444, lr = [1.903189458216964e-05, 0.00019031894582169638]\n",
      "[INFO: 2022-02-17 04:48:49,697]   LabelSmoothing Loss = 2.3988218307495117\n",
      "[INFO: 2022-02-17 04:48:59,338] Iteration 53940 (DataTime/BatchTime: 0.00138/0.482) losses = 1.8294, lr = [1.9028366040584878e-05, 0.00019028366040584876]\n",
      "[INFO: 2022-02-17 04:48:59,338]   LabelSmoothing Loss = 1.2887794971466064\n",
      "[INFO: 2022-02-17 04:49:09,050] Iteration 53960 (DataTime/BatchTime: 0.00248/0.486) losses = 1.7796, lr = [1.902483946086325e-05, 0.00019024839460863246]\n",
      "[INFO: 2022-02-17 04:49:09,050]   LabelSmoothing Loss = 2.463059186935425\n",
      "[INFO: 2022-02-17 04:49:18,706] Iteration 53980 (DataTime/BatchTime: 0.00138/0.483) losses = 1.6612, lr = [1.9021314841187436e-05, 0.00019021314841187435]\n",
      "[INFO: 2022-02-17 04:49:18,707]   LabelSmoothing Loss = 1.0969239473342896\n",
      "[INFO: 2022-02-17 04:49:28,395] Iteration 54000 (DataTime/BatchTime: 0.00146/0.484) losses = 1.6552, lr = [1.9017792179742486e-05, 0.00019017792179742485]\n",
      "[INFO: 2022-02-17 04:49:28,395]   LabelSmoothing Loss = 1.5431714057922363\n",
      "[INFO: 2022-02-17 04:49:38,027] Iteration 54020 (DataTime/BatchTime: 0.00246/0.482) losses = 1.5593, lr = [1.9014271474715793e-05, 0.00019014271474715789]\n",
      "[INFO: 2022-02-17 04:49:38,028]   LabelSmoothing Loss = 1.3842157125473022\n",
      "[INFO: 2022-02-17 04:49:47,741] Iteration 54040 (DataTime/BatchTime: 0.00147/0.486) losses = 1.3098, lr = [1.901075272429709e-05, 0.0001901075272429709]\n",
      "[INFO: 2022-02-17 04:49:47,741]   LabelSmoothing Loss = 0.5385622978210449\n",
      "[INFO: 2022-02-17 04:49:57,267] Iteration 54060 (DataTime/BatchTime: 0.00221/0.476) losses = 1.4855, lr = [1.9007235926678475e-05, 0.00019007235926678473]\n",
      "[INFO: 2022-02-17 04:49:57,268]   LabelSmoothing Loss = 1.806225299835205\n",
      "[INFO: 2022-02-17 04:50:06,988] Iteration 54080 (DataTime/BatchTime: 0.00234/0.486) losses = 1.5179, lr = [1.900372108005437e-05, 0.00019003721080054368]\n",
      "[INFO: 2022-02-17 04:50:06,989]   LabelSmoothing Loss = 2.8026058673858643\n",
      "[INFO: 2022-02-17 04:50:16,585] Iteration 54100 (DataTime/BatchTime: 0.00139/0.48) losses = 1.6413, lr = [1.9000208182621533e-05, 0.0001900020818262153]\n",
      "[INFO: 2022-02-17 04:50:16,585]   LabelSmoothing Loss = 1.862346887588501\n",
      "[INFO: 2022-02-17 04:50:26,124] Iteration 54120 (DataTime/BatchTime: 0.00219/0.477) losses = 1.3885, lr = [1.8996697232579065e-05, 0.00018996697232579062]\n",
      "[INFO: 2022-02-17 04:50:26,124]   LabelSmoothing Loss = 2.035107374191284\n",
      "[INFO: 2022-02-17 04:50:35,804] Iteration 54140 (DataTime/BatchTime: 0.00396/0.484) losses = 1.8095, lr = [1.8993188228128385e-05, 0.00018993188228128382]\n",
      "[INFO: 2022-02-17 04:50:35,804]   LabelSmoothing Loss = 2.8141846656799316\n",
      "[INFO: 2022-02-17 04:50:45,585] Iteration 54160 (DataTime/BatchTime: 0.00238/0.489) losses = 1.5902, lr = [1.8989681167473247e-05, 0.00018989681167473247]\n",
      "[INFO: 2022-02-17 04:50:45,585]   LabelSmoothing Loss = 2.758296489715576\n",
      "[INFO: 2022-02-17 04:50:55,240] Iteration 54180 (DataTime/BatchTime: 0.00145/0.483) losses = 1.5604, lr = [1.8986176048819715e-05, 0.00018986176048819715]\n",
      "[INFO: 2022-02-17 04:50:55,241]   LabelSmoothing Loss = 1.2720239162445068\n",
      "[INFO: 2022-02-17 04:51:04,854] Iteration 54200 (DataTime/BatchTime: 0.00145/0.481) losses = 1.6152, lr = [1.8982672870376183e-05, 0.00018982672870376178]\n",
      "[INFO: 2022-02-17 04:51:04,855]   LabelSmoothing Loss = 1.5806130170822144\n",
      "[INFO: 2022-02-17 04:51:14,539] Iteration 54220 (DataTime/BatchTime: 0.00231/0.484) losses = 1.5268, lr = [1.897917163035334e-05, 0.0001897917163035334]\n",
      "[INFO: 2022-02-17 04:51:14,540]   LabelSmoothing Loss = 2.1352505683898926\n",
      "[INFO: 2022-02-17 04:51:24,135] Iteration 54240 (DataTime/BatchTime: 0.00332/0.48) losses = 1.6578, lr = [1.8975672326964203e-05, 0.000189756723269642]\n",
      "[INFO: 2022-02-17 04:51:24,135]   LabelSmoothing Loss = 2.390277624130249\n",
      "[INFO: 2022-02-17 04:51:33,822] Iteration 54260 (DataTime/BatchTime: 0.00238/0.484) losses = 1.3496, lr = [1.8972174958424085e-05, 0.00018972174958424082]\n",
      "[INFO: 2022-02-17 04:51:33,822]   LabelSmoothing Loss = 1.7962734699249268\n",
      "[INFO: 2022-02-17 04:51:43,414] Iteration 54280 (DataTime/BatchTime: 0.00245/0.48) losses = 1.6678, lr = [1.89686795229506e-05, 0.00018968679522950597]\n",
      "[INFO: 2022-02-17 04:51:43,414]   LabelSmoothing Loss = 1.6731393337249756\n",
      "[INFO: 2022-02-17 04:51:53,072] Iteration 54300 (DataTime/BatchTime: 0.00141/0.483) losses = 1.6971, lr = [1.896518601876366e-05, 0.00018965186018763658]\n",
      "[INFO: 2022-02-17 04:51:53,072]   LabelSmoothing Loss = 2.65742826461792\n",
      "[INFO: 2022-02-17 04:52:02,648] Iteration 54320 (DataTime/BatchTime: 0.00316/0.479) losses = 1.4386, lr = [1.8961694444085475e-05, 0.00018961694444085471]\n",
      "[INFO: 2022-02-17 04:52:02,648]   LabelSmoothing Loss = 0.6551409959793091\n",
      "[INFO: 2022-02-17 04:52:12,422] Iteration 54340 (DataTime/BatchTime: 0.00144/0.489) losses = 1.6686, lr = [1.8958204797140547e-05, 0.00018958204797140546]\n",
      "[INFO: 2022-02-17 04:52:12,423]   LabelSmoothing Loss = 2.093726634979248\n",
      "[INFO: 2022-02-17 04:52:22,203] Iteration 54360 (DataTime/BatchTime: 0.00249/0.489) losses = 1.5649, lr = [1.8954717076155658e-05, 0.00018954717076155657]\n",
      "[INFO: 2022-02-17 04:52:22,203]   LabelSmoothing Loss = 2.2771873474121094\n",
      "[INFO: 2022-02-17 04:52:31,825] Iteration 54380 (DataTime/BatchTime: 0.00233/0.481) losses = 1.4998, lr = [1.8951231279359876e-05, 0.00018951231279359875]\n",
      "[INFO: 2022-02-17 04:52:31,826]   LabelSmoothing Loss = 0.9506330490112305\n",
      "[INFO: 2022-02-17 04:52:41,420] Iteration 54400 (DataTime/BatchTime: 0.00141/0.48) losses = 1.5869, lr = [1.8947747404984548e-05, 0.00018947747404984545]\n",
      "[INFO: 2022-02-17 04:52:41,420]   LabelSmoothing Loss = 1.5067347288131714\n",
      "[INFO: 2022-02-17 04:52:50,947] Iteration 54420 (DataTime/BatchTime: 0.00139/0.476) losses = 1.4586, lr = [1.8944265451263286e-05, 0.00018944265451263285]\n",
      "[INFO: 2022-02-17 04:52:50,947]   LabelSmoothing Loss = 1.2737321853637695\n",
      "[INFO: 2022-02-17 04:56:32,768] ######## Epoch (VAL)57 ########\n",
      "[INFO: 2022-02-17 04:56:32,768] {'Bleu_1': 0.3082331622914141, 'Bleu_2': 0.18380859756631332, 'Bleu_3': 0.1204792561031338, 'Bleu_4': 0.08322645567104153, 'METEOR': 0.1689806818025887, 'ROUGE_L': 0.30126386748231365, 'CIDEr': 0.3455123770232683}\n",
      "[INFO: 2022-02-17 05:00:09,216] ######## Epoch (TEST)57 ########\n",
      "[INFO: 2022-02-17 05:00:09,217] {'Bleu_1': 0.294978025472759, 'Bleu_2': 0.16854393428283573, 'Bleu_3': 0.1052211739276604, 'Bleu_4': 0.06864553880558494, 'METEOR': 0.1606797489683947, 'ROUGE_L': 0.2785843365573748, 'CIDEr': 0.2482065255225251}\n",
      "[INFO: 2022-02-17 05:00:13,262] Iteration 54440 (DataTime/BatchTime: 0.184/0.674) losses = 1.5894, lr = [1.8940785416431997e-05, 0.00018940785416431995]\n",
      "[INFO: 2022-02-17 05:00:13,262]   LabelSmoothing Loss = 1.9063618183135986\n",
      "[INFO: 2022-02-17 05:00:22,666] Iteration 54460 (DataTime/BatchTime: 0.00117/0.47) losses = 1.6242, lr = [1.8937307298728834e-05, 0.0001893730729872883]\n",
      "[INFO: 2022-02-17 05:00:22,666]   LabelSmoothing Loss = 1.93728506565094\n",
      "[INFO: 2022-02-17 05:00:32,139] Iteration 54480 (DataTime/BatchTime: 0.00209/0.474) losses = 1.6147, lr = [1.893383109639422e-05, 0.00018933831096394217]\n",
      "[INFO: 2022-02-17 05:00:32,140]   LabelSmoothing Loss = 2.0586564540863037\n",
      "[INFO: 2022-02-17 05:00:41,647] Iteration 54500 (DataTime/BatchTime: 0.00237/0.475) losses = 1.4556, lr = [1.8930356807670846e-05, 0.00018930356807670844]\n",
      "[INFO: 2022-02-17 05:00:41,647]   LabelSmoothing Loss = 1.0743637084960938\n",
      "[INFO: 2022-02-17 05:00:51,151] Iteration 54520 (DataTime/BatchTime: 0.00122/0.475) losses = 1.5257, lr = [1.892688443080364e-05, 0.00018926884430803639]\n",
      "[INFO: 2022-02-17 05:00:51,152]   LabelSmoothing Loss = 2.0990254878997803\n",
      "[INFO: 2022-02-17 05:01:00,684] Iteration 54540 (DataTime/BatchTime: 0.00207/0.477) losses = 1.6521, lr = [1.8923413964039813e-05, 0.0001892341396403981]\n",
      "[INFO: 2022-02-17 05:01:00,684]   LabelSmoothing Loss = 1.3936841487884521\n",
      "[INFO: 2022-02-17 05:01:10,205] Iteration 54560 (DataTime/BatchTime: 0.00122/0.476) losses = 1.6074, lr = [1.891994540562879e-05, 0.00018919945405628788]\n",
      "[INFO: 2022-02-17 05:01:10,205]   LabelSmoothing Loss = 1.970462441444397\n",
      "[INFO: 2022-02-17 05:01:19,685] Iteration 54580 (DataTime/BatchTime: 0.00124/0.474) losses = 1.5335, lr = [1.891647875382227e-05, 0.0001891647875382227]\n",
      "[INFO: 2022-02-17 05:01:19,685]   LabelSmoothing Loss = 0.960130512714386\n",
      "[INFO: 2022-02-17 05:01:29,123] Iteration 54600 (DataTime/BatchTime: 0.00118/0.472) losses = 1.4393, lr = [1.8913014006874182e-05, 0.0001891301400687418]\n",
      "[INFO: 2022-02-17 05:01:29,123]   LabelSmoothing Loss = 1.2397791147232056\n",
      "[INFO: 2022-02-17 05:01:38,642] Iteration 54620 (DataTime/BatchTime: 0.0012/0.476) losses = 1.6712, lr = [1.890955116304069e-05, 0.00018909551163040687]\n",
      "[INFO: 2022-02-17 05:01:38,642]   LabelSmoothing Loss = 2.2938897609710693\n",
      "[INFO: 2022-02-17 05:01:48,181] Iteration 54640 (DataTime/BatchTime: 0.00117/0.477) losses = 1.5736, lr = [1.890609022058019e-05, 0.00018906090220580188]\n",
      "[INFO: 2022-02-17 05:01:48,181]   LabelSmoothing Loss = 1.4999769926071167\n",
      "[INFO: 2022-02-17 05:01:57,697] Iteration 54660 (DataTime/BatchTime: 0.00118/0.476) losses = 1.3857, lr = [1.8902631177753322e-05, 0.0001890263117775332]\n",
      "[INFO: 2022-02-17 05:01:57,697]   LabelSmoothing Loss = 2.4191482067108154\n",
      "[INFO: 2022-02-17 05:02:07,340] Iteration 54680 (DataTime/BatchTime: 0.00116/0.482) losses = 1.6703, lr = [1.8899174032822943e-05, 0.00018899174032822942]\n",
      "[INFO: 2022-02-17 05:02:07,341]   LabelSmoothing Loss = 2.2415852546691895\n",
      "[INFO: 2022-02-17 05:02:16,904] Iteration 54700 (DataTime/BatchTime: 0.00119/0.478) losses = 1.7193, lr = [1.8895718784054135e-05, 0.0001889571878405413]\n",
      "[INFO: 2022-02-17 05:02:16,904]   LabelSmoothing Loss = 2.4055635929107666\n",
      "[INFO: 2022-02-17 05:02:26,394] Iteration 54720 (DataTime/BatchTime: 0.00117/0.474) losses = 1.2589, lr = [1.8892265429714193e-05, 0.00018892265429714192]\n",
      "[INFO: 2022-02-17 05:02:26,394]   LabelSmoothing Loss = 1.4580683708190918\n",
      "[INFO: 2022-02-17 05:02:35,927] Iteration 54740 (DataTime/BatchTime: 0.00116/0.477) losses = 1.5807, lr = [1.888881396807264e-05, 0.0001888881396807264]\n",
      "[INFO: 2022-02-17 05:02:35,928]   LabelSmoothing Loss = 2.1381773948669434\n",
      "[INFO: 2022-02-17 05:02:45,395] Iteration 54760 (DataTime/BatchTime: 0.00123/0.473) losses = 1.5669, lr = [1.8885364397401206e-05, 0.00018885364397401203]\n",
      "[INFO: 2022-02-17 05:02:45,396]   LabelSmoothing Loss = 1.071751356124878\n",
      "[INFO: 2022-02-17 05:02:54,949] Iteration 54780 (DataTime/BatchTime: 0.0012/0.478) losses = 1.5725, lr = [1.8881916715973823e-05, 0.0001888191671597382]\n",
      "[INFO: 2022-02-17 05:02:54,972]   LabelSmoothing Loss = 1.6407840251922607\n",
      "[INFO: 2022-02-17 05:03:04,386] Iteration 54800 (DataTime/BatchTime: 0.00236/0.472) losses = 1.5729, lr = [1.887847092206664e-05, 0.00018878470922066638]\n",
      "[INFO: 2022-02-17 05:03:04,386]   LabelSmoothing Loss = 1.1064611673355103\n",
      "[INFO: 2022-02-17 05:03:13,943] Iteration 54820 (DataTime/BatchTime: 0.00119/0.477) losses = 1.5511, lr = [1.8875027013957994e-05, 0.00018875027013957993]\n",
      "[INFO: 2022-02-17 05:03:13,943]   LabelSmoothing Loss = 2.0360774993896484\n",
      "[INFO: 2022-02-17 05:03:23,458] Iteration 54840 (DataTime/BatchTime: 0.00223/0.477) losses = 1.7407, lr = [1.887158498992844e-05, 0.00018871584989928436]\n",
      "[INFO: 2022-02-17 05:03:23,458]   LabelSmoothing Loss = 1.8311278820037842\n",
      "[INFO: 2022-02-17 05:03:32,965] Iteration 54860 (DataTime/BatchTime: 0.00118/0.475) losses = 1.5574, lr = [1.8868144848260698e-05, 0.00018868144848260696]\n",
      "[INFO: 2022-02-17 05:03:32,965]   LabelSmoothing Loss = 1.6587830781936646\n",
      "[INFO: 2022-02-17 05:03:42,460] Iteration 54880 (DataTime/BatchTime: 0.00202/0.475) losses = 1.5517, lr = [1.8864706587239705e-05, 0.000188647065872397]\n",
      "[INFO: 2022-02-17 05:03:42,460]   LabelSmoothing Loss = 1.0685839653015137\n",
      "[INFO: 2022-02-17 05:03:52,007] Iteration 54900 (DataTime/BatchTime: 0.00119/0.477) losses = 1.6638, lr = [1.886127020515257e-05, 0.00018861270205152567]\n",
      "[INFO: 2022-02-17 05:03:52,007]   LabelSmoothing Loss = 1.2052630186080933\n",
      "[INFO: 2022-02-17 05:04:01,495] Iteration 54920 (DataTime/BatchTime: 0.00118/0.474) losses = 1.435, lr = [1.885783570028859e-05, 0.00018857835700288587]\n",
      "[INFO: 2022-02-17 05:04:01,495]   LabelSmoothing Loss = 2.4081685543060303\n",
      "[INFO: 2022-02-17 05:04:11,029] Iteration 54940 (DataTime/BatchTime: 0.00237/0.477) losses = 1.6595, lr = [1.885440307093924e-05, 0.0001885440307093924]\n",
      "[INFO: 2022-02-17 05:04:11,030]   LabelSmoothing Loss = 2.032693862915039\n",
      "[INFO: 2022-02-17 05:04:20,485] Iteration 54960 (DataTime/BatchTime: 0.00118/0.473) losses = 1.2785, lr = [1.885097231539818e-05, 0.00018850972315398177]\n",
      "[INFO: 2022-02-17 05:04:20,486]   LabelSmoothing Loss = 1.0835968255996704\n",
      "[INFO: 2022-02-17 05:04:30,004] Iteration 54980 (DataTime/BatchTime: 0.0012/0.475) losses = 1.4196, lr = [1.8847543431961226e-05, 0.00018847543431961224]\n",
      "[INFO: 2022-02-17 05:04:30,004]   LabelSmoothing Loss = 1.3179000616073608\n",
      "[INFO: 2022-02-17 05:04:39,566] Iteration 55000 (DataTime/BatchTime: 0.00208/0.479) losses = 1.5133, lr = [1.8844116418926377e-05, 0.00018844116418926377]\n",
      "[INFO: 2022-02-17 05:04:39,566]   LabelSmoothing Loss = 1.372654914855957\n",
      "[INFO: 2022-02-17 05:04:49,076] Iteration 55020 (DataTime/BatchTime: 0.00118/0.476) losses = 1.7977, lr = [1.8840691274593793e-05, 0.00018840691274593792]\n",
      "[INFO: 2022-02-17 05:04:49,077]   LabelSmoothing Loss = 1.9917155504226685\n",
      "[INFO: 2022-02-17 05:04:58,640] Iteration 55040 (DataTime/BatchTime: 0.00232/0.478) losses = 1.7731, lr = [1.8837267997265797e-05, 0.00018837267997265792]\n",
      "[INFO: 2022-02-17 05:04:58,640]   LabelSmoothing Loss = 0.9680896401405334\n",
      "[INFO: 2022-02-17 05:05:08,177] Iteration 55060 (DataTime/BatchTime: 0.00214/0.477) losses = 1.6511, lr = [1.883384658524686e-05, 0.00018833846585246858]\n",
      "[INFO: 2022-02-17 05:05:08,177]   LabelSmoothing Loss = 1.0983061790466309\n",
      "[INFO: 2022-02-17 05:05:17,691] Iteration 55080 (DataTime/BatchTime: 0.00116/0.476) losses = 1.6728, lr = [1.8830427036843628e-05, 0.00018830427036843628]\n",
      "[INFO: 2022-02-17 05:05:17,691]   LabelSmoothing Loss = 2.010769844055176\n",
      "[INFO: 2022-02-17 05:05:27,216] Iteration 55100 (DataTime/BatchTime: 0.00231/0.476) losses = 1.6304, lr = [1.8827009350364885e-05, 0.00018827009350364882]\n",
      "[INFO: 2022-02-17 05:05:27,216]   LabelSmoothing Loss = 1.6412090063095093\n",
      "[INFO: 2022-02-17 05:05:36,709] Iteration 55120 (DataTime/BatchTime: 0.00114/0.475) losses = 1.5649, lr = [1.8823593524121566e-05, 0.00018823593524121564]\n",
      "[INFO: 2022-02-17 05:05:36,709]   LabelSmoothing Loss = 2.1087212562561035\n",
      "[INFO: 2022-02-17 05:05:46,395] Iteration 55140 (DataTime/BatchTime: 0.00136/0.484) losses = 1.5882, lr = [1.8820179556426747e-05, 0.00018820179556426744]\n",
      "[INFO: 2022-02-17 05:05:46,395]   LabelSmoothing Loss = 1.8254733085632324\n",
      "[INFO: 2022-02-17 05:05:56,015] Iteration 55160 (DataTime/BatchTime: 0.00203/0.481) losses = 1.4565, lr = [1.8816767445595647e-05, 0.00018816767445595643]\n",
      "[INFO: 2022-02-17 05:05:56,015]   LabelSmoothing Loss = 1.0419961214065552\n",
      "[INFO: 2022-02-17 05:06:05,574] Iteration 55180 (DataTime/BatchTime: 0.00291/0.478) losses = 1.5788, lr = [1.8813357189945625e-05, 0.00018813357189945623]\n",
      "[INFO: 2022-02-17 05:06:05,574]   LabelSmoothing Loss = 1.459261178970337\n",
      "[INFO: 2022-02-17 05:06:15,175] Iteration 55200 (DataTime/BatchTime: 0.00131/0.48) losses = 1.6865, lr = [1.880994878779617e-05, 0.0001880994878779617]\n",
      "[INFO: 2022-02-17 05:06:15,175]   LabelSmoothing Loss = 1.891492247581482\n",
      "[INFO: 2022-02-17 05:06:24,809] Iteration 55220 (DataTime/BatchTime: 0.00139/0.482) losses = 1.5645, lr = [1.8806542237468907e-05, 0.00018806542237468905]\n",
      "[INFO: 2022-02-17 05:06:24,810]   LabelSmoothing Loss = 2.111750841140747\n",
      "[INFO: 2022-02-17 05:06:34,357] Iteration 55240 (DataTime/BatchTime: 0.00218/0.477) losses = 1.5839, lr = [1.8803137537287585e-05, 0.0001880313753728758]\n",
      "[INFO: 2022-02-17 05:06:34,358]   LabelSmoothing Loss = 1.2121471166610718\n",
      "[INFO: 2022-02-17 05:06:43,980] Iteration 55260 (DataTime/BatchTime: 0.00135/0.481) losses = 1.643, lr = [1.879973468557807e-05, 0.0001879973468557807]\n",
      "[INFO: 2022-02-17 05:06:43,981]   LabelSmoothing Loss = 1.3892000913619995\n",
      "[INFO: 2022-02-17 05:06:53,586] Iteration 55280 (DataTime/BatchTime: 0.00225/0.48) losses = 1.7327, lr = [1.879633368066836e-05, 0.00018796333680668357]\n",
      "[INFO: 2022-02-17 05:06:53,586]   LabelSmoothing Loss = 2.6779625415802\n",
      "[INFO: 2022-02-17 05:07:03,155] Iteration 55300 (DataTime/BatchTime: 0.00127/0.478) losses = 1.5078, lr = [1.879293452088856e-05, 0.00018792934520888558]\n",
      "[INFO: 2022-02-17 05:07:03,155]   LabelSmoothing Loss = 1.428118348121643\n",
      "[INFO: 2022-02-17 05:07:12,795] Iteration 55320 (DataTime/BatchTime: 0.00132/0.482) losses = 1.6015, lr = [1.8789537204570893e-05, 0.0001878953720457089]\n",
      "[INFO: 2022-02-17 05:07:12,796]   LabelSmoothing Loss = 1.4554076194763184\n",
      "[INFO: 2022-02-17 05:07:22,312] Iteration 55340 (DataTime/BatchTime: 0.00205/0.476) losses = 1.4737, lr = [1.8786141730049693e-05, 0.0001878614173004969]\n",
      "[INFO: 2022-02-17 05:07:22,313]   LabelSmoothing Loss = 1.1853244304656982\n",
      "[INFO: 2022-02-17 05:07:31,951] Iteration 55360 (DataTime/BatchTime: 0.00131/0.482) losses = 1.5394, lr = [1.878274809566139e-05, 0.00018782748095661387]\n",
      "[INFO: 2022-02-17 05:07:31,951]   LabelSmoothing Loss = 0.4375196695327759\n",
      "[INFO: 2022-02-17 05:07:41,469] Iteration 55380 (DataTime/BatchTime: 0.00154/0.476) losses = 1.3661, lr = [1.8779356299744528e-05, 0.00018779356299744525]\n",
      "[INFO: 2022-02-17 05:07:41,469]   LabelSmoothing Loss = 1.606339693069458\n",
      "[INFO: 2022-02-17 05:11:19,535] ######## Epoch (VAL)58 ########\n",
      "[INFO: 2022-02-17 05:11:19,536] {'Bleu_1': 0.3351737340666462, 'Bleu_2': 0.20035935726749407, 'Bleu_3': 0.13014564958853295, 'Bleu_4': 0.090714331182446, 'METEOR': 0.18247472811198165, 'ROUGE_L': 0.28653191763573843, 'CIDEr': 0.29878771125175285}\n",
      "[INFO: 2022-02-17 05:14:59,675] ######## Epoch (TEST)58 ########\n",
      "[INFO: 2022-02-17 05:14:59,676] {'Bleu_1': 0.3059826027934482, 'Bleu_2': 0.1743190762368705, 'Bleu_3': 0.10562012305893385, 'Bleu_4': 0.06578155741707753, 'METEOR': 0.17165160360011225, 'ROUGE_L': 0.26832881237152406, 'CIDEr': 0.18577664278819572}\n",
      "[INFO: 2022-02-17 05:15:05,955] Iteration 55400 (DataTime/BatchTime: 0.083/0.571) losses = 1.5597, lr = [1.877596634063975e-05, 0.0001877596634063975]\n",
      "[INFO: 2022-02-17 05:15:05,955]   LabelSmoothing Loss = 1.4007413387298584\n",
      "[INFO: 2022-02-17 05:15:15,478] Iteration 55420 (DataTime/BatchTime: 0.00227/0.476) losses = 1.5485, lr = [1.8772578216689788e-05, 0.00018772578216689784]\n",
      "[INFO: 2022-02-17 05:15:15,478]   LabelSmoothing Loss = 1.7730121612548828\n",
      "[INFO: 2022-02-17 05:15:25,030] Iteration 55440 (DataTime/BatchTime: 0.0031/0.478) losses = 1.5565, lr = [1.876919192623947e-05, 0.0001876919192623947]\n",
      "[INFO: 2022-02-17 05:15:25,030]   LabelSmoothing Loss = 1.107008695602417\n",
      "[INFO: 2022-02-17 05:15:34,576] Iteration 55460 (DataTime/BatchTime: 0.00229/0.476) losses = 1.4618, lr = [1.876580746763572e-05, 0.0001876580746763572]\n",
      "[INFO: 2022-02-17 05:15:34,576]   LabelSmoothing Loss = 0.9251173138618469\n",
      "[INFO: 2022-02-17 05:15:44,279] Iteration 55480 (DataTime/BatchTime: 0.00242/0.486) losses = 1.5077, lr = [1.8762424839227536e-05, 0.00018762424839227534]\n",
      "[INFO: 2022-02-17 05:15:44,280]   LabelSmoothing Loss = 0.583458423614502\n",
      "[INFO: 2022-02-17 05:15:53,870] Iteration 55500 (DataTime/BatchTime: 0.00347/0.48) losses = 1.443, lr = [1.8759044039366007e-05, 0.00018759044039366005]\n",
      "[INFO: 2022-02-17 05:15:53,871]   LabelSmoothing Loss = 1.0741571187973022\n",
      "[INFO: 2022-02-17 05:16:03,520] Iteration 55520 (DataTime/BatchTime: 0.00324/0.482) losses = 1.6347, lr = [1.8755665066404295e-05, 0.00018755665066404293]\n",
      "[INFO: 2022-02-17 05:16:03,520]   LabelSmoothing Loss = 1.0021848678588867\n",
      "[INFO: 2022-02-17 05:16:13,301] Iteration 55540 (DataTime/BatchTime: 0.00236/0.489) losses = 1.7074, lr = [1.8752287918697638e-05, 0.00018752287918697637]\n",
      "[INFO: 2022-02-17 05:16:13,301]   LabelSmoothing Loss = 0.9584323763847351\n",
      "[INFO: 2022-02-17 05:16:22,817] Iteration 55560 (DataTime/BatchTime: 0.00415/0.476) losses = 1.4704, lr = [1.874891259460336e-05, 0.00018748912594603357]\n",
      "[INFO: 2022-02-17 05:16:22,818]   LabelSmoothing Loss = 1.3458993434906006\n",
      "[INFO: 2022-02-17 05:16:32,462] Iteration 55580 (DataTime/BatchTime: 0.00254/0.482) losses = 1.4445, lr = [1.8745539092480835e-05, 0.0001874553909248083]\n",
      "[INFO: 2022-02-17 05:16:32,462]   LabelSmoothing Loss = 1.3020563125610352\n",
      "[INFO: 2022-02-17 05:16:42,181] Iteration 55600 (DataTime/BatchTime: 0.00148/0.486) losses = 1.5111, lr = [1.874216741069151e-05, 0.00018742167410691504]\n",
      "[INFO: 2022-02-17 05:16:42,182]   LabelSmoothing Loss = 1.010270595550537\n",
      "[INFO: 2022-02-17 05:16:51,818] Iteration 55620 (DataTime/BatchTime: 0.00236/0.482) losses = 1.8196, lr = [1.8738797547598895e-05, 0.00018738797547598893]\n",
      "[INFO: 2022-02-17 05:16:51,818]   LabelSmoothing Loss = 0.6218541264533997\n",
      "[INFO: 2022-02-17 05:17:01,417] Iteration 55640 (DataTime/BatchTime: 0.00162/0.48) losses = 1.5728, lr = [1.8735429501568567e-05, 0.00018735429501568564]\n",
      "[INFO: 2022-02-17 05:17:01,417]   LabelSmoothing Loss = 0.7562885880470276\n",
      "[INFO: 2022-02-17 05:17:11,116] Iteration 55660 (DataTime/BatchTime: 0.00283/0.485) losses = 1.5502, lr = [1.873206327096814e-05, 0.00018732063270968135]\n",
      "[INFO: 2022-02-17 05:17:11,116]   LabelSmoothing Loss = 1.7881847620010376\n",
      "[INFO: 2022-02-17 05:17:20,764] Iteration 55680 (DataTime/BatchTime: 0.00301/0.482) losses = 1.6518, lr = [1.8728698854167296e-05, 0.00018728698854167294]\n",
      "[INFO: 2022-02-17 05:17:20,764]   LabelSmoothing Loss = 2.119412422180176\n",
      "[INFO: 2022-02-17 05:17:30,293] Iteration 55700 (DataTime/BatchTime: 0.00255/0.476) losses = 1.3484, lr = [1.8725336249537763e-05, 0.00018725336249537762]\n",
      "[INFO: 2022-02-17 05:17:30,293]   LabelSmoothing Loss = 1.4287806749343872\n",
      "[INFO: 2022-02-17 05:17:39,995] Iteration 55720 (DataTime/BatchTime: 0.00119/0.485) losses = 1.7907, lr = [1.872197545545331e-05, 0.00018721975455453306]\n",
      "[INFO: 2022-02-17 05:17:39,996]   LabelSmoothing Loss = 2.144343137741089\n",
      "[INFO: 2022-02-17 05:17:49,583] Iteration 55740 (DataTime/BatchTime: 0.00249/0.479) losses = 1.501, lr = [1.871861647028975e-05, 0.00018718616470289747]\n",
      "[INFO: 2022-02-17 05:17:49,584]   LabelSmoothing Loss = 1.6033605337142944\n",
      "[INFO: 2022-02-17 05:17:59,197] Iteration 55760 (DataTime/BatchTime: 0.00285/0.481) losses = 1.4813, lr = [1.8715259292424936e-05, 0.00018715259292424936]\n",
      "[INFO: 2022-02-17 05:17:59,197]   LabelSmoothing Loss = 1.9596600532531738\n",
      "[INFO: 2022-02-17 05:18:08,769] Iteration 55780 (DataTime/BatchTime: 0.00217/0.479) losses = 1.5886, lr = [1.8711903920238764e-05, 0.00018711903920238761]\n",
      "[INFO: 2022-02-17 05:18:08,770]   LabelSmoothing Loss = 1.8102911710739136\n",
      "[INFO: 2022-02-17 05:18:18,270] Iteration 55800 (DataTime/BatchTime: 0.0012/0.475) losses = 1.4875, lr = [1.8708550352113147e-05, 0.00018708550352113142]\n",
      "[INFO: 2022-02-17 05:18:18,270]   LabelSmoothing Loss = 1.8074231147766113\n",
      "[INFO: 2022-02-17 05:18:27,868] Iteration 55820 (DataTime/BatchTime: 0.00326/0.48) losses = 1.4341, lr = [1.8705198586432036e-05, 0.00018705198586432034]\n",
      "[INFO: 2022-02-17 05:18:27,869]   LabelSmoothing Loss = 1.597778558731079\n",
      "[INFO: 2022-02-17 05:18:37,452] Iteration 55840 (DataTime/BatchTime: 0.00211/0.479) losses = 1.4078, lr = [1.8701848621581412e-05, 0.0001870184862158141]\n",
      "[INFO: 2022-02-17 05:18:37,452]   LabelSmoothing Loss = 2.2099905014038086\n",
      "[INFO: 2022-02-17 05:18:46,968] Iteration 55860 (DataTime/BatchTime: 0.00199/0.476) losses = 1.4284, lr = [1.869850045594927e-05, 0.00018698500455949268]\n",
      "[INFO: 2022-02-17 05:18:46,968]   LabelSmoothing Loss = 1.5786932706832886\n",
      "[INFO: 2022-02-17 05:18:56,510] Iteration 55880 (DataTime/BatchTime: 0.00131/0.477) losses = 1.7308, lr = [1.8695154087925633e-05, 0.0001869515408792563]\n",
      "[INFO: 2022-02-17 05:18:56,510]   LabelSmoothing Loss = 2.004606246948242\n",
      "[INFO: 2022-02-17 05:19:05,989] Iteration 55900 (DataTime/BatchTime: 0.00115/0.474) losses = 1.346, lr = [1.869180951590253e-05, 0.00018691809515902527]\n",
      "[INFO: 2022-02-17 05:19:05,989]   LabelSmoothing Loss = 0.9707071781158447\n",
      "[INFO: 2022-02-17 05:19:15,492] Iteration 55920 (DataTime/BatchTime: 0.00116/0.475) losses = 1.6984, lr = [1.8688466738274014e-05, 0.00018688466738274012]\n",
      "[INFO: 2022-02-17 05:19:15,492]   LabelSmoothing Loss = 1.2534027099609375\n",
      "[INFO: 2022-02-17 05:19:24,981] Iteration 55940 (DataTime/BatchTime: 0.00233/0.474) losses = 1.5452, lr = [1.8685125753436142e-05, 0.0001868512575343614]\n",
      "[INFO: 2022-02-17 05:19:24,981]   LabelSmoothing Loss = 1.6437842845916748\n",
      "[INFO: 2022-02-17 05:19:34,558] Iteration 55960 (DataTime/BatchTime: 0.00131/0.479) losses = 1.5308, lr = [1.8681786559786978e-05, 0.00018681786559786976]\n",
      "[INFO: 2022-02-17 05:19:34,558]   LabelSmoothing Loss = 1.847650170326233\n",
      "[INFO: 2022-02-17 05:19:44,151] Iteration 55980 (DataTime/BatchTime: 0.00127/0.48) losses = 1.4801, lr = [1.8678449155726585e-05, 0.00018678449155726584]\n",
      "[INFO: 2022-02-17 05:19:44,151]   LabelSmoothing Loss = 2.061877489089966\n",
      "[INFO: 2022-02-17 05:19:53,732] Iteration 56000 (DataTime/BatchTime: 0.00125/0.479) losses = 1.5236, lr = [1.8675113539657036e-05, 0.00018675113539657034]\n",
      "[INFO: 2022-02-17 05:19:53,732]   LabelSmoothing Loss = 2.220424175262451\n",
      "[INFO: 2022-02-17 05:20:03,302] Iteration 56020 (DataTime/BatchTime: 0.00119/0.478) losses = 1.5589, lr = [1.8671779709982392e-05, 0.0001867177970998239]\n",
      "[INFO: 2022-02-17 05:20:03,302]   LabelSmoothing Loss = 2.1198573112487793\n",
      "[INFO: 2022-02-17 05:20:12,882] Iteration 56040 (DataTime/BatchTime: 0.0027/0.479) losses = 1.5076, lr = [1.866844766510871e-05, 0.00018668447665108707]\n",
      "[INFO: 2022-02-17 05:20:12,882]   LabelSmoothing Loss = 2.2575912475585938\n",
      "[INFO: 2022-02-17 05:20:22,497] Iteration 56060 (DataTime/BatchTime: 0.00118/0.481) losses = 1.5458, lr = [1.866511740344404e-05, 0.00018665117403444037]\n",
      "[INFO: 2022-02-17 05:20:22,497]   LabelSmoothing Loss = 1.2482125759124756\n",
      "[INFO: 2022-02-17 05:20:32,099] Iteration 56080 (DataTime/BatchTime: 0.00204/0.48) losses = 1.6885, lr = [1.8661788923398418e-05, 0.00018661788923398414]\n",
      "[INFO: 2022-02-17 05:20:32,099]   LabelSmoothing Loss = 1.9869239330291748\n",
      "[INFO: 2022-02-17 05:20:41,694] Iteration 56100 (DataTime/BatchTime: 0.00121/0.48) losses = 1.6458, lr = [1.8658462223383856e-05, 0.00018658462223383854]\n",
      "[INFO: 2022-02-17 05:20:41,694]   LabelSmoothing Loss = 2.1858417987823486\n",
      "[INFO: 2022-02-17 05:20:51,346] Iteration 56120 (DataTime/BatchTime: 0.00282/0.483) losses = 1.6822, lr = [1.8655137301814368e-05, 0.00018655137301814366]\n",
      "[INFO: 2022-02-17 05:20:51,346]   LabelSmoothing Loss = 2.890099048614502\n",
      "[INFO: 2022-02-17 05:21:00,886] Iteration 56140 (DataTime/BatchTime: 0.00126/0.477) losses = 1.5409, lr = [1.8651814157105918e-05, 0.00018651814157105915]\n",
      "[INFO: 2022-02-17 05:21:00,887]   LabelSmoothing Loss = 2.002823829650879\n",
      "[INFO: 2022-02-17 05:21:10,360] Iteration 56160 (DataTime/BatchTime: 0.00193/0.474) losses = 1.3549, lr = [1.8648492787676464e-05, 0.00018648492787676462]\n",
      "[INFO: 2022-02-17 05:21:10,360]   LabelSmoothing Loss = 1.483293056488037\n",
      "[INFO: 2022-02-17 05:21:19,887] Iteration 56180 (DataTime/BatchTime: 0.00113/0.476) losses = 1.768, lr = [1.864517319194593e-05, 0.00018645173191945928]\n",
      "[INFO: 2022-02-17 05:21:19,887]   LabelSmoothing Loss = 1.284073829650879\n",
      "[INFO: 2022-02-17 05:21:29,395] Iteration 56200 (DataTime/BatchTime: 0.00199/0.475) losses = 1.6597, lr = [1.8641855368336206e-05, 0.00018641855368336206]\n",
      "[INFO: 2022-02-17 05:21:29,395]   LabelSmoothing Loss = 0.8387703895568848\n",
      "[INFO: 2022-02-17 05:21:38,951] Iteration 56220 (DataTime/BatchTime: 0.0012/0.478) losses = 1.4675, lr = [1.8638539315271153e-05, 0.00018638539315271152]\n",
      "[INFO: 2022-02-17 05:21:38,951]   LabelSmoothing Loss = 2.3101325035095215\n",
      "[INFO: 2022-02-17 05:21:48,505] Iteration 56240 (DataTime/BatchTime: 0.00125/0.478) losses = 1.7346, lr = [1.8635225031176585e-05, 0.00018635225031176584]\n",
      "[INFO: 2022-02-17 05:21:48,505]   LabelSmoothing Loss = 2.2261271476745605\n",
      "[INFO: 2022-02-17 05:21:58,103] Iteration 56260 (DataTime/BatchTime: 0.00137/0.48) losses = 1.5468, lr = [1.8631912514480284e-05, 0.0001863191251448028]\n",
      "[INFO: 2022-02-17 05:21:58,103]   LabelSmoothing Loss = 1.070335030555725\n",
      "[INFO: 2022-02-17 05:22:07,625] Iteration 56280 (DataTime/BatchTime: 0.00136/0.476) losses = 1.4745, lr = [1.8628601763611975e-05, 0.00018628601763611975]\n",
      "[INFO: 2022-02-17 05:22:07,625]   LabelSmoothing Loss = 1.7962850332260132\n",
      "[INFO: 2022-02-17 05:22:17,207] Iteration 56300 (DataTime/BatchTime: 0.00223/0.479) losses = 1.548, lr = [1.8625292777003354e-05, 0.0001862529277700335]\n",
      "[INFO: 2022-02-17 05:22:17,207]   LabelSmoothing Loss = 1.5905033349990845\n",
      "[INFO: 2022-02-17 05:22:26,873] Iteration 56320 (DataTime/BatchTime: 0.00137/0.483) losses = 1.5101, lr = [1.8621985553088047e-05, 0.00018621985553088043]\n",
      "[INFO: 2022-02-17 05:22:26,874]   LabelSmoothing Loss = 1.8265959024429321\n",
      "[INFO: 2022-02-17 05:22:36,376] Iteration 56340 (DataTime/BatchTime: 0.00131/0.475) losses = 1.8282, lr = [1.8618680090301637e-05, 0.00018618680090301637]\n",
      "[INFO: 2022-02-17 05:22:36,377]   LabelSmoothing Loss = 0.8522452116012573\n",
      "[INFO: 2022-02-17 05:26:07,783] ######## Epoch (VAL)59 ########\n",
      "[INFO: 2022-02-17 05:26:07,783] {'Bleu_1': 0.37581394249142774, 'Bleu_2': 0.2299444239293509, 'Bleu_3': 0.15496202922745966, 'Bleu_4': 0.11007659463298526, 'METEOR': 0.190547883384764, 'ROUGE_L': 0.30331436872750783, 'CIDEr': 0.3573950336235383}\n",
      "[INFO: 2022-02-17 05:29:45,309] ######## Epoch (TEST)59 ########\n",
      "[INFO: 2022-02-17 05:29:45,309] {'Bleu_1': 0.35162768462230154, 'Bleu_2': 0.2043081905115046, 'Bleu_3': 0.13060195018674414, 'Bleu_4': 0.08786270373940724, 'METEOR': 0.18001322519552035, 'ROUGE_L': 0.2881004962162176, 'CIDEr': 0.31046197870017767}\n",
      "[INFO: 2022-02-17 05:29:54,167] Iteration 56360 (DataTime/BatchTime: 0.0728/0.554) losses = 1.5608, lr = [1.8615376387081655e-05, 0.00018615376387081653]\n",
      "[INFO: 2022-02-17 05:29:54,168]   LabelSmoothing Loss = 1.365317940711975\n",
      "[INFO: 2022-02-17 05:30:03,663] Iteration 56380 (DataTime/BatchTime: 0.00241/0.475) losses = 1.4567, lr = [1.8612074441867557e-05, 0.00018612074441867556]\n",
      "[INFO: 2022-02-17 05:30:03,663]   LabelSmoothing Loss = 1.4571177959442139\n",
      "[INFO: 2022-02-17 05:30:13,236] Iteration 56400 (DataTime/BatchTime: 0.00248/0.479) losses = 1.5043, lr = [1.8608774253100745e-05, 0.00018608774253100745]\n",
      "[INFO: 2022-02-17 05:30:13,236]   LabelSmoothing Loss = 2.0651931762695312\n",
      "[INFO: 2022-02-17 05:30:22,661] Iteration 56420 (DataTime/BatchTime: 0.00109/0.471) losses = 1.3602, lr = [1.8605475819224562e-05, 0.0001860547581922456]\n",
      "[INFO: 2022-02-17 05:30:22,662]   LabelSmoothing Loss = 0.9198423027992249\n",
      "[INFO: 2022-02-17 05:30:32,147] Iteration 56440 (DataTime/BatchTime: 0.00227/0.474) losses = 1.5404, lr = [1.8602179138684266e-05, 0.00018602179138684264]\n",
      "[INFO: 2022-02-17 05:30:32,147]   LabelSmoothing Loss = 1.9791920185089111\n",
      "[INFO: 2022-02-17 05:30:41,592] Iteration 56460 (DataTime/BatchTime: 0.00357/0.471) losses = 1.5115, lr = [1.8598884209927052e-05, 0.0001859888420992705]\n",
      "[INFO: 2022-02-17 05:30:41,592]   LabelSmoothing Loss = 1.8535432815551758\n",
      "[INFO: 2022-02-17 05:30:51,094] Iteration 56480 (DataTime/BatchTime: 0.00272/0.476) losses = 1.694, lr = [1.859559103140204e-05, 0.0001859559103140204]\n",
      "[INFO: 2022-02-17 05:30:51,094]   LabelSmoothing Loss = 1.876756191253662\n",
      "[INFO: 2022-02-17 05:31:00,666] Iteration 56500 (DataTime/BatchTime: 0.00274/0.479) losses = 1.6995, lr = [1.8592299601560267e-05, 0.00018592299601560264]\n",
      "[INFO: 2022-02-17 05:31:00,666]   LabelSmoothing Loss = 1.9972350597381592\n",
      "[INFO: 2022-02-17 05:31:10,208] Iteration 56520 (DataTime/BatchTime: 0.00343/0.477) losses = 1.5301, lr = [1.8589009918854693e-05, 0.0001858900991885469]\n",
      "[INFO: 2022-02-17 05:31:10,208]   LabelSmoothing Loss = 1.9069346189498901\n",
      "[INFO: 2022-02-17 05:31:19,743] Iteration 56540 (DataTime/BatchTime: 0.00122/0.477) losses = 1.4249, lr = [1.8585721981740193e-05, 0.0001858572198174019]\n",
      "[INFO: 2022-02-17 05:31:19,743]   LabelSmoothing Loss = 1.9166278839111328\n",
      "[INFO: 2022-02-17 05:31:29,360] Iteration 56560 (DataTime/BatchTime: 0.00121/0.481) losses = 1.6363, lr = [1.8582435788673545e-05, 0.00018582435788673545]\n",
      "[INFO: 2022-02-17 05:31:29,361]   LabelSmoothing Loss = 0.6263189911842346\n",
      "[INFO: 2022-02-17 05:31:38,833] Iteration 56580 (DataTime/BatchTime: 0.002/0.474) losses = 1.5536, lr = [1.8579151338113458e-05, 0.00018579151338113457]\n",
      "[INFO: 2022-02-17 05:31:38,833]   LabelSmoothing Loss = 1.6328738927841187\n",
      "[INFO: 2022-02-17 05:31:48,376] Iteration 56600 (DataTime/BatchTime: 0.00117/0.477) losses = 1.4372, lr = [1.8575868628520526e-05, 0.00018575868628520524]\n",
      "[INFO: 2022-02-17 05:31:48,376]   LabelSmoothing Loss = 1.250780701637268\n",
      "[INFO: 2022-02-17 05:31:57,816] Iteration 56620 (DataTime/BatchTime: 0.00114/0.472) losses = 1.4903, lr = [1.857258765835725e-05, 0.0001857258765835725]\n",
      "[INFO: 2022-02-17 05:31:57,816]   LabelSmoothing Loss = 1.6160914897918701\n",
      "[INFO: 2022-02-17 05:32:07,253] Iteration 56640 (DataTime/BatchTime: 0.003/0.472) losses = 1.4846, lr = [1.8569308426088042e-05, 0.0001856930842608804]\n",
      "[INFO: 2022-02-17 05:32:07,253]   LabelSmoothing Loss = 1.9595803022384644\n",
      "[INFO: 2022-02-17 05:32:16,792] Iteration 56660 (DataTime/BatchTime: 0.00114/0.477) losses = 1.5837, lr = [1.8566030930179202e-05, 0.000185660309301792]\n",
      "[INFO: 2022-02-17 05:32:16,792]   LabelSmoothing Loss = 0.9439386129379272\n",
      "[INFO: 2022-02-17 05:32:26,211] Iteration 56680 (DataTime/BatchTime: 0.00193/0.471) losses = 1.3743, lr = [1.8562755169098925e-05, 0.00018562755169098923]\n",
      "[INFO: 2022-02-17 05:32:26,211]   LabelSmoothing Loss = 1.9657514095306396\n",
      "[INFO: 2022-02-17 05:32:35,651] Iteration 56700 (DataTime/BatchTime: 0.003/0.472) losses = 1.6357, lr = [1.85594811413173e-05, 0.00018559481141317298]\n",
      "[INFO: 2022-02-17 05:32:35,652]   LabelSmoothing Loss = 1.7859163284301758\n",
      "[INFO: 2022-02-17 05:32:45,175] Iteration 56720 (DataTime/BatchTime: 0.00111/0.476) losses = 1.3318, lr = [1.8556208845306303e-05, 0.000185562088453063]\n",
      "[INFO: 2022-02-17 05:32:45,175]   LabelSmoothing Loss = 1.2684717178344727\n",
      "[INFO: 2022-02-17 05:32:54,728] Iteration 56740 (DataTime/BatchTime: 0.000979/0.478) losses = 1.6831, lr = [1.8552938279539796e-05, 0.00018552938279539792]\n",
      "[INFO: 2022-02-17 05:32:54,728]   LabelSmoothing Loss = 1.8844164609909058\n",
      "[INFO: 2022-02-17 05:33:04,263] Iteration 56760 (DataTime/BatchTime: 0.00093/0.477) losses = 1.4103, lr = [1.854966944249352e-05, 0.00018549669442493517]\n",
      "[INFO: 2022-02-17 05:33:04,264]   LabelSmoothing Loss = 0.9070273637771606\n",
      "[INFO: 2022-02-17 05:33:13,717] Iteration 56780 (DataTime/BatchTime: 0.0021/0.473) losses = 1.5154, lr = [1.8546402332645103e-05, 0.00018546402332645103]\n",
      "[INFO: 2022-02-17 05:33:13,717]   LabelSmoothing Loss = 1.1907390356063843\n",
      "[INFO: 2022-02-17 05:33:23,333] Iteration 56800 (DataTime/BatchTime: 0.00107/0.481) losses = 1.6587, lr = [1.8543136948474044e-05, 0.0001854313694847404]\n",
      "[INFO: 2022-02-17 05:33:23,333]   LabelSmoothing Loss = 1.7471258640289307\n",
      "[INFO: 2022-02-17 05:33:32,905] Iteration 56820 (DataTime/BatchTime: 0.0041/0.479) losses = 1.5689, lr = [1.8539873288461706e-05, 0.00018539873288461704]\n",
      "[INFO: 2022-02-17 05:33:32,906]   LabelSmoothing Loss = 0.7423725724220276\n",
      "[INFO: 2022-02-17 05:33:42,426] Iteration 56840 (DataTime/BatchTime: 0.00213/0.476) losses = 1.6929, lr = [1.853661135109134e-05, 0.00018536611351091336]\n",
      "[INFO: 2022-02-17 05:33:42,426]   LabelSmoothing Loss = 1.3477222919464111\n",
      "[INFO: 2022-02-17 05:33:51,885] Iteration 56860 (DataTime/BatchTime: 0.00121/0.473) losses = 1.4623, lr = [1.853335113484805e-05, 0.00018533351134848047]\n",
      "[INFO: 2022-02-17 05:33:51,886]   LabelSmoothing Loss = 0.9407942891120911\n",
      "[INFO: 2022-02-17 05:34:01,459] Iteration 56880 (DataTime/BatchTime: 0.00244/0.479) losses = 1.4208, lr = [1.853009263821882e-05, 0.00018530092638218817]\n",
      "[INFO: 2022-02-17 05:34:01,459]   LabelSmoothing Loss = 1.254904866218567\n",
      "[INFO: 2022-02-17 05:34:11,085] Iteration 56900 (DataTime/BatchTime: 0.00237/0.481) losses = 1.5367, lr = [1.8526835859692477e-05, 0.00018526835859692477]\n",
      "[INFO: 2022-02-17 05:34:11,085]   LabelSmoothing Loss = 2.502756118774414\n",
      "[INFO: 2022-02-17 05:34:20,497] Iteration 56920 (DataTime/BatchTime: 0.00386/0.471) losses = 1.4215, lr = [1.8523580797759718e-05, 0.00018523580797759717]\n",
      "[INFO: 2022-02-17 05:34:20,497]   LabelSmoothing Loss = 1.1891937255859375\n",
      "[INFO: 2022-02-17 05:34:29,898] Iteration 56940 (DataTime/BatchTime: 0.00383/0.47) losses = 1.414, lr = [1.8520327450913097e-05, 0.00018520327450913094]\n",
      "[INFO: 2022-02-17 05:34:29,898]   LabelSmoothing Loss = 1.467484951019287\n",
      "[INFO: 2022-02-17 05:34:39,344] Iteration 56960 (DataTime/BatchTime: 0.00123/0.472) losses = 1.6619, lr = [1.8517075817647007e-05, 0.00018517075817647006]\n",
      "[INFO: 2022-02-17 05:34:39,344]   LabelSmoothing Loss = 2.1423211097717285\n",
      "[INFO: 2022-02-17 05:34:48,888] Iteration 56980 (DataTime/BatchTime: 0.00119/0.477) losses = 1.6139, lr = [1.851382589645771e-05, 0.00018513825896457708]\n",
      "[INFO: 2022-02-17 05:34:48,888]   LabelSmoothing Loss = 1.1756128072738647\n",
      "[INFO: 2022-02-17 05:34:58,349] Iteration 57000 (DataTime/BatchTime: 0.0031/0.473) losses = 1.6029, lr = [1.85105776858433e-05, 0.000185105776858433]\n",
      "[INFO: 2022-02-17 05:34:58,349]   LabelSmoothing Loss = 2.087026834487915\n",
      "[INFO: 2022-02-17 05:35:07,894] Iteration 57020 (DataTime/BatchTime: 0.00118/0.477) losses = 1.6267, lr = [1.8507331184303723e-05, 0.00018507331184303721]\n",
      "[INFO: 2022-02-17 05:35:07,894]   LabelSmoothing Loss = 1.5383639335632324\n",
      "[INFO: 2022-02-17 05:35:17,459] Iteration 57040 (DataTime/BatchTime: 0.00119/0.478) losses = 1.6871, lr = [1.8504086390340764e-05, 0.0001850408639034076]\n",
      "[INFO: 2022-02-17 05:35:17,459]   LabelSmoothing Loss = 1.1732510328292847\n",
      "[INFO: 2022-02-17 05:35:26,884] Iteration 57060 (DataTime/BatchTime: 0.00383/0.471) losses = 1.4425, lr = [1.8500843302458042e-05, 0.0001850084330245804]\n",
      "[INFO: 2022-02-17 05:35:26,884]   LabelSmoothing Loss = 1.7439682483673096\n",
      "[INFO: 2022-02-17 05:35:36,345] Iteration 57080 (DataTime/BatchTime: 0.00204/0.473) losses = 1.6752, lr = [1.8497601919161015e-05, 0.00018497601919161013]\n",
      "[INFO: 2022-02-17 05:35:36,345]   LabelSmoothing Loss = 1.390981674194336\n",
      "[INFO: 2022-02-17 05:35:45,812] Iteration 57100 (DataTime/BatchTime: 0.00124/0.473) losses = 1.7314, lr = [1.8494362238956973e-05, 0.0001849436223895697]\n",
      "[INFO: 2022-02-17 05:35:45,812]   LabelSmoothing Loss = 1.8908028602600098\n",
      "[INFO: 2022-02-17 05:35:55,357] Iteration 57120 (DataTime/BatchTime: 0.00203/0.477) losses = 1.7462, lr = [1.8491124260355033e-05, 0.00018491124260355032]\n",
      "[INFO: 2022-02-17 05:35:55,357]   LabelSmoothing Loss = 1.7040446996688843\n",
      "[INFO: 2022-02-17 05:36:04,706] Iteration 57140 (DataTime/BatchTime: 0.00135/0.467) losses = 1.5144, lr = [1.8487887981866143e-05, 0.0001848788798186614]\n",
      "[INFO: 2022-02-17 05:36:04,707]   LabelSmoothing Loss = 0.8197701573371887\n",
      "[INFO: 2022-02-17 05:36:14,250] Iteration 57160 (DataTime/BatchTime: 0.00116/0.477) losses = 1.5581, lr = [1.8484653402003074e-05, 0.0001848465340200307]\n",
      "[INFO: 2022-02-17 05:36:14,251]   LabelSmoothing Loss = 1.2662187814712524\n",
      "[INFO: 2022-02-17 05:36:23,756] Iteration 57180 (DataTime/BatchTime: 0.0022/0.475) losses = 1.5474, lr = [1.848142051928041e-05, 0.00018481420519280407]\n",
      "[INFO: 2022-02-17 05:36:23,756]   LabelSmoothing Loss = 1.4012868404388428\n",
      "[INFO: 2022-02-17 05:36:33,251] Iteration 57200 (DataTime/BatchTime: 0.00213/0.475) losses = 1.5645, lr = [1.847818933221456e-05, 0.00018478189332214558]\n",
      "[INFO: 2022-02-17 05:36:33,251]   LabelSmoothing Loss = 1.6294289827346802\n",
      "[INFO: 2022-02-17 05:36:42,766] Iteration 57220 (DataTime/BatchTime: 0.00123/0.476) losses = 1.4724, lr = [1.8474959839323754e-05, 0.0001847495983932375]\n",
      "[INFO: 2022-02-17 05:36:42,766]   LabelSmoothing Loss = 1.3477245569229126\n",
      "[INFO: 2022-02-17 05:36:52,153] Iteration 57240 (DataTime/BatchTime: 0.00218/0.469) losses = 1.5003, lr = [1.8471732039128022e-05, 0.0001847173203912802]\n",
      "[INFO: 2022-02-17 05:36:52,153]   LabelSmoothing Loss = 1.9783774614334106\n",
      "[INFO: 2022-02-17 05:37:01,673] Iteration 57260 (DataTime/BatchTime: 0.00337/0.476) losses = 1.7469, lr = [1.8468505930149205e-05, 0.00018468505930149202]\n",
      "[INFO: 2022-02-17 05:37:01,673]   LabelSmoothing Loss = 2.264683485031128\n",
      "[INFO: 2022-02-17 05:37:11,149] Iteration 57280 (DataTime/BatchTime: 0.00122/0.474) losses = 1.5682, lr = [1.846528151091096e-05, 0.0001846528151091096]\n",
      "[INFO: 2022-02-17 05:37:11,149]   LabelSmoothing Loss = 1.1727474927902222\n",
      "[INFO: 2022-02-17 05:40:53,196] ######## Epoch (VAL)60 ########\n",
      "[INFO: 2022-02-17 05:40:53,196] {'Bleu_1': 0.3612609454256348, 'Bleu_2': 0.22013542627545432, 'Bleu_3': 0.14626533004327236, 'Bleu_4': 0.10298350017945743, 'METEOR': 0.18774328553987105, 'ROUGE_L': 0.29471555196157856, 'CIDEr': 0.33142318787362296}\n",
      "[INFO: 2022-02-17 05:44:33,552] ######## Epoch (TEST)60 ########\n",
      "[INFO: 2022-02-17 05:44:33,552] {'Bleu_1': 0.32868827752007934, 'Bleu_2': 0.18066975782303052, 'Bleu_3': 0.10649210930527282, 'Bleu_4': 0.0627157882875887, 'METEOR': 0.17182110486668742, 'ROUGE_L': 0.2686883913501368, 'CIDEr': 0.15961573454026964}\n",
      "[INFO: 2022-02-17 05:44:35,113] Iteration 57300 (DataTime/BatchTime: 1.03/1.56) losses = 1.3947, lr = [1.846205877993874e-05, 0.00018462058779938737]\n",
      "[INFO: 2022-02-17 05:44:35,113]   LabelSmoothing Loss = 1.394670844078064\n",
      "[INFO: 2022-02-17 05:44:44,669] Iteration 57320 (DataTime/BatchTime: 0.00198/0.478) losses = 1.6662, lr = [1.8458837735759796e-05, 0.00018458837735759793]\n",
      "[INFO: 2022-02-17 05:44:44,669]   LabelSmoothing Loss = 1.6131736040115356\n",
      "[INFO: 2022-02-17 05:44:54,219] Iteration 57340 (DataTime/BatchTime: 0.00281/0.478) losses = 1.4871, lr = [1.8455618376903186e-05, 0.00018455618376903184]\n",
      "[INFO: 2022-02-17 05:44:54,219]   LabelSmoothing Loss = 1.7361726760864258\n",
      "[INFO: 2022-02-17 05:45:03,732] Iteration 57360 (DataTime/BatchTime: 0.00283/0.476) losses = 1.5168, lr = [1.8452400701899757e-05, 0.00018452400701899756]\n",
      "[INFO: 2022-02-17 05:45:03,733]   LabelSmoothing Loss = 1.6694382429122925\n",
      "[INFO: 2022-02-17 05:45:13,228] Iteration 57380 (DataTime/BatchTime: 0.00208/0.475) losses = 1.5488, lr = [1.8449184709282153e-05, 0.0001844918470928215]\n",
      "[INFO: 2022-02-17 05:45:13,228]   LabelSmoothing Loss = 1.4361337423324585\n",
      "[INFO: 2022-02-17 05:45:22,716] Iteration 57400 (DataTime/BatchTime: 0.00212/0.474) losses = 1.4477, lr = [1.84459703975848e-05, 0.00018445970397584798]\n",
      "[INFO: 2022-02-17 05:45:22,716]   LabelSmoothing Loss = 0.7183869481086731\n",
      "[INFO: 2022-02-17 05:45:32,182] Iteration 57420 (DataTime/BatchTime: 0.00144/0.473) losses = 1.3275, lr = [1.844275776534392e-05, 0.00018442757765343916]\n",
      "[INFO: 2022-02-17 05:45:32,182]   LabelSmoothing Loss = 1.5444576740264893\n",
      "[INFO: 2022-02-17 05:45:41,761] Iteration 57440 (DataTime/BatchTime: 0.00129/0.479) losses = 1.5541, lr = [1.8439546811097504e-05, 0.00018439546811097502]\n",
      "[INFO: 2022-02-17 05:45:41,761]   LabelSmoothing Loss = 0.9969907999038696\n",
      "[INFO: 2022-02-17 05:45:51,242] Iteration 57460 (DataTime/BatchTime: 0.00128/0.474) losses = 1.2834, lr = [1.8436337533385347e-05, 0.00018436337533385343]\n",
      "[INFO: 2022-02-17 05:45:51,242]   LabelSmoothing Loss = 2.605616807937622\n",
      "[INFO: 2022-02-17 05:46:00,740] Iteration 57480 (DataTime/BatchTime: 0.00205/0.475) losses = 1.6701, lr = [1.8433129930749006e-05, 0.00018433129930749001]\n",
      "[INFO: 2022-02-17 05:46:00,740]   LabelSmoothing Loss = 1.7330402135849\n",
      "[INFO: 2022-02-17 05:46:10,275] Iteration 57500 (DataTime/BatchTime: 0.00127/0.477) losses = 1.5895, lr = [1.842992400173181e-05, 0.00018429924001731805]\n",
      "[INFO: 2022-02-17 05:46:10,275]   LabelSmoothing Loss = 1.999433994293213\n",
      "[INFO: 2022-02-17 05:46:19,834] Iteration 57520 (DataTime/BatchTime: 0.0013/0.478) losses = 1.5786, lr = [1.8426719744878873e-05, 0.0001842671974487887]\n",
      "[INFO: 2022-02-17 05:46:19,834]   LabelSmoothing Loss = 1.2972880601882935\n",
      "[INFO: 2022-02-17 05:46:29,396] Iteration 57540 (DataTime/BatchTime: 0.00131/0.478) losses = 1.6372, lr = [1.842351715873708e-05, 0.00018423517158737076]\n",
      "[INFO: 2022-02-17 05:46:29,396]   LabelSmoothing Loss = 1.0308051109313965\n",
      "[INFO: 2022-02-17 05:46:39,041] Iteration 57560 (DataTime/BatchTime: 0.0013/0.482) losses = 1.4632, lr = [1.842031624185507e-05, 0.0001842031624185507]\n",
      "[INFO: 2022-02-17 05:46:39,042]   LabelSmoothing Loss = 2.1075196266174316\n",
      "[INFO: 2022-02-17 05:46:48,622] Iteration 57580 (DataTime/BatchTime: 0.00212/0.479) losses = 1.7881, lr = [1.841711699278326e-05, 0.00018417116992783256]\n",
      "[INFO: 2022-02-17 05:46:48,622]   LabelSmoothing Loss = 1.3012611865997314\n",
      "[INFO: 2022-02-17 05:46:58,120] Iteration 57600 (DataTime/BatchTime: 0.00216/0.475) losses = 1.4315, lr = [1.8413919410073815e-05, 0.00018413919410073813]\n",
      "[INFO: 2022-02-17 05:46:58,120]   LabelSmoothing Loss = 1.5784968137741089\n",
      "[INFO: 2022-02-17 05:47:07,631] Iteration 57620 (DataTime/BatchTime: 0.00293/0.476) losses = 1.8101, lr = [1.8410723492280668e-05, 0.00018410723492280666]\n",
      "[INFO: 2022-02-17 05:47:07,631]   LabelSmoothing Loss = 1.6179983615875244\n",
      "[INFO: 2022-02-17 05:47:17,137] Iteration 57640 (DataTime/BatchTime: 0.0013/0.475) losses = 1.3943, lr = [1.8407529237959516e-05, 0.00018407529237959513]\n",
      "[INFO: 2022-02-17 05:47:17,137]   LabelSmoothing Loss = 1.7020022869110107\n",
      "[INFO: 2022-02-17 05:47:26,648] Iteration 57660 (DataTime/BatchTime: 0.00131/0.476) losses = 1.4947, lr = [1.840433664566779e-05, 0.00018404336645667785]\n",
      "[INFO: 2022-02-17 05:47:26,648]   LabelSmoothing Loss = 1.13150155544281\n",
      "[INFO: 2022-02-17 05:47:36,164] Iteration 57680 (DataTime/BatchTime: 0.0013/0.476) losses = 1.4227, lr = [1.8401145713964687e-05, 0.00018401145713964684]\n",
      "[INFO: 2022-02-17 05:47:36,165]   LabelSmoothing Loss = 0.803645670413971\n",
      "[INFO: 2022-02-17 05:47:45,728] Iteration 57700 (DataTime/BatchTime: 0.00136/0.478) losses = 1.4239, lr = [1.8397956441411144e-05, 0.00018397956441411142]\n",
      "[INFO: 2022-02-17 05:47:45,728]   LabelSmoothing Loss = 0.6749756932258606\n",
      "[INFO: 2022-02-17 05:47:55,287] Iteration 57720 (DataTime/BatchTime: 0.0013/0.478) losses = 1.5968, lr = [1.839476882656985e-05, 0.00018394768826569848]\n",
      "[INFO: 2022-02-17 05:47:55,287]   LabelSmoothing Loss = 1.463279366493225\n",
      "[INFO: 2022-02-17 05:48:04,872] Iteration 57740 (DataTime/BatchTime: 0.00129/0.479) losses = 1.5626, lr = [1.8391582868005235e-05, 0.00018391582868005233]\n",
      "[INFO: 2022-02-17 05:48:04,872]   LabelSmoothing Loss = 2.179014205932617\n",
      "[INFO: 2022-02-17 05:48:14,480] Iteration 57760 (DataTime/BatchTime: 0.00141/0.48) losses = 1.5421, lr = [1.838839856428346e-05, 0.00018388398564283458]\n",
      "[INFO: 2022-02-17 05:48:14,480]   LabelSmoothing Loss = 2.278925657272339\n",
      "[INFO: 2022-02-17 05:48:23,965] Iteration 57780 (DataTime/BatchTime: 0.0014/0.474) losses = 1.6165, lr = [1.8385215913972436e-05, 0.00018385215913972432]\n",
      "[INFO: 2022-02-17 05:48:23,965]   LabelSmoothing Loss = 1.2929767370224\n",
      "[INFO: 2022-02-17 05:48:33,493] Iteration 57800 (DataTime/BatchTime: 0.00134/0.476) losses = 1.2863, lr = [1.83820349156418e-05, 0.00018382034915641798]\n",
      "[INFO: 2022-02-17 05:48:33,493]   LabelSmoothing Loss = 2.143829107284546\n",
      "[INFO: 2022-02-17 05:48:43,027] Iteration 57820 (DataTime/BatchTime: 0.00128/0.477) losses = 1.5549, lr = [1.8378855567862924e-05, 0.00018378855567862922]\n",
      "[INFO: 2022-02-17 05:48:43,027]   LabelSmoothing Loss = 2.4352431297302246\n",
      "[INFO: 2022-02-17 05:48:52,637] Iteration 57840 (DataTime/BatchTime: 0.00133/0.481) losses = 1.6844, lr = [1.8375677869208905e-05, 0.00018375677869208903]\n",
      "[INFO: 2022-02-17 05:48:52,637]   LabelSmoothing Loss = 2.5577054023742676\n",
      "[INFO: 2022-02-17 05:49:02,159] Iteration 57860 (DataTime/BatchTime: 0.0013/0.476) losses = 1.5926, lr = [1.8372501818254576e-05, 0.00018372501818254575]\n",
      "[INFO: 2022-02-17 05:49:02,159]   LabelSmoothing Loss = 2.0823445320129395\n",
      "[INFO: 2022-02-17 05:49:11,774] Iteration 57880 (DataTime/BatchTime: 0.00128/0.481) losses = 1.7355, lr = [1.836932741357649e-05, 0.00018369327413576486]\n",
      "[INFO: 2022-02-17 05:49:11,774]   LabelSmoothing Loss = 1.9190841913223267\n",
      "[INFO: 2022-02-17 05:49:21,254] Iteration 57900 (DataTime/BatchTime: 0.0013/0.474) losses = 1.4708, lr = [1.8366154653752905e-05, 0.00018366154653752905]\n",
      "[INFO: 2022-02-17 05:49:21,254]   LabelSmoothing Loss = 0.9395180940628052\n",
      "[INFO: 2022-02-17 05:49:30,738] Iteration 57920 (DataTime/BatchTime: 0.0013/0.474) losses = 1.5073, lr = [1.8362983537363824e-05, 0.00018362983537363822]\n",
      "[INFO: 2022-02-17 05:49:30,738]   LabelSmoothing Loss = 1.4381688833236694\n",
      "[INFO: 2022-02-17 05:49:40,337] Iteration 57940 (DataTime/BatchTime: 0.00128/0.48) losses = 1.6445, lr = [1.8359814062990945e-05, 0.00018359814062990945]\n",
      "[INFO: 2022-02-17 05:49:40,337]   LabelSmoothing Loss = 1.2070204019546509\n",
      "[INFO: 2022-02-17 05:49:49,851] Iteration 57960 (DataTime/BatchTime: 0.00324/0.476) losses = 1.639, lr = [1.8356646229217692e-05, 0.00018356646229217692]\n",
      "[INFO: 2022-02-17 05:49:49,851]   LabelSmoothing Loss = 2.1381661891937256\n",
      "[INFO: 2022-02-17 05:49:59,370] Iteration 57980 (DataTime/BatchTime: 0.00131/0.476) losses = 1.4467, lr = [1.835348003462919e-05, 0.00018353480034629188]\n",
      "[INFO: 2022-02-17 05:49:59,370]   LabelSmoothing Loss = 1.5738635063171387\n",
      "[INFO: 2022-02-17 05:50:08,813] Iteration 58000 (DataTime/BatchTime: 0.00129/0.472) losses = 1.4123, lr = [1.835031547781228e-05, 0.00018350315477812275]\n",
      "[INFO: 2022-02-17 05:50:08,813]   LabelSmoothing Loss = 0.865626871585846\n",
      "[INFO: 2022-02-17 05:50:18,275] Iteration 58020 (DataTime/BatchTime: 0.00127/0.473) losses = 1.4691, lr = [1.8347152557355494e-05, 0.00018347152557355494]\n",
      "[INFO: 2022-02-17 05:50:18,275]   LabelSmoothing Loss = 1.4851489067077637\n",
      "[INFO: 2022-02-17 05:50:27,786] Iteration 58040 (DataTime/BatchTime: 0.00125/0.476) losses = 1.6811, lr = [1.8343991271849086e-05, 0.00018343991271849085]\n",
      "[INFO: 2022-02-17 05:50:27,786]   LabelSmoothing Loss = 0.2945133149623871\n",
      "[INFO: 2022-02-17 05:50:37,257] Iteration 58060 (DataTime/BatchTime: 0.00127/0.474) losses = 1.3106, lr = [1.8340831619884996e-05, 0.00018340831619884996]\n",
      "[INFO: 2022-02-17 05:50:37,257]   LabelSmoothing Loss = 1.3168562650680542\n",
      "[INFO: 2022-02-17 05:50:46,723] Iteration 58080 (DataTime/BatchTime: 0.00128/0.473) losses = 1.3091, lr = [1.8337673600056864e-05, 0.0001833767360005686]\n",
      "[INFO: 2022-02-17 05:50:46,723]   LabelSmoothing Loss = 1.1747112274169922\n",
      "[INFO: 2022-02-17 05:50:56,281] Iteration 58100 (DataTime/BatchTime: 0.00129/0.478) losses = 1.5822, lr = [1.833451721096003e-05, 0.00018334517210960027]\n",
      "[INFO: 2022-02-17 05:50:56,281]   LabelSmoothing Loss = 1.5030947923660278\n",
      "[INFO: 2022-02-17 05:51:05,856] Iteration 58120 (DataTime/BatchTime: 0.0022/0.479) losses = 1.5667, lr = [1.833136245119151e-05, 0.0001833136245119151]\n",
      "[INFO: 2022-02-17 05:51:05,857]   LabelSmoothing Loss = 1.5764085054397583\n",
      "[INFO: 2022-02-17 05:51:15,377] Iteration 58140 (DataTime/BatchTime: 0.00219/0.476) losses = 1.4143, lr = [1.832820931935004e-05, 0.00018328209319350036]\n",
      "[INFO: 2022-02-17 05:51:15,377]   LabelSmoothing Loss = 1.707464575767517\n",
      "[INFO: 2022-02-17 05:51:24,923] Iteration 58160 (DataTime/BatchTime: 0.0013/0.477) losses = 1.533, lr = [1.8325057814036004e-05, 0.00018325057814036]\n",
      "[INFO: 2022-02-17 05:51:24,923]   LabelSmoothing Loss = 1.117734432220459\n",
      "[INFO: 2022-02-17 05:51:34,467] Iteration 58180 (DataTime/BatchTime: 0.00211/0.477) losses = 1.8423, lr = [1.8321907933851494e-05, 0.0001832190793385149]\n",
      "[INFO: 2022-02-17 05:51:34,467]   LabelSmoothing Loss = 2.863886594772339\n",
      "[INFO: 2022-02-17 05:51:43,986] Iteration 58200 (DataTime/BatchTime: 0.0013/0.476) losses = 1.6319, lr = [1.8318759677400284e-05, 0.00018318759677400282]\n",
      "[INFO: 2022-02-17 05:51:43,986]   LabelSmoothing Loss = 1.4910504817962646\n",
      "[INFO: 2022-02-17 05:51:53,496] Iteration 58220 (DataTime/BatchTime: 0.00223/0.475) losses = 1.4296, lr = [1.831561304328782e-05, 0.00018315613043287817]\n",
      "[INFO: 2022-02-17 05:51:53,496]   LabelSmoothing Loss = 1.176001787185669\n",
      "[INFO: 2022-02-17 05:52:03,058] Iteration 58240 (DataTime/BatchTime: 0.00121/0.478) losses = 1.7807, lr = [1.831246803012122e-05, 0.0001831246803012122]\n",
      "[INFO: 2022-02-17 05:52:03,059]   LabelSmoothing Loss = 1.8596497774124146\n",
      "[INFO: 2022-02-17 05:55:43,628] ######## Epoch (VAL)61 ########\n",
      "[INFO: 2022-02-17 05:55:43,628] {'Bleu_1': 0.3522315379913373, 'Bleu_2': 0.20981991929836422, 'Bleu_3': 0.13371644764956725, 'Bleu_4': 0.09027015200797454, 'METEOR': 0.1845388414656559, 'ROUGE_L': 0.2848968423985958, 'CIDEr': 0.275993223950085}\n",
      "[INFO: 2022-02-17 05:59:25,757] ######## Epoch (TEST)61 ########\n",
      "[INFO: 2022-02-17 05:59:25,758] {'Bleu_1': 0.313673925889567, 'Bleu_2': 0.17598075409339184, 'Bleu_3': 0.10355550912254234, 'Bleu_4': 0.06053347942363859, 'METEOR': 0.16909097769424464, 'ROUGE_L': 0.2626453256409488, 'CIDEr': 0.1601368512088879}\n",
      "[INFO: 2022-02-17 05:59:29,661] Iteration 58260 (DataTime/BatchTime: 0.154/0.65) losses = 1.4638, lr = [1.830932463650929e-05, 0.00018309324636509288]\n",
      "[INFO: 2022-02-17 05:59:29,661]   LabelSmoothing Loss = 1.8427704572677612\n",
      "[INFO: 2022-02-17 05:59:39,251] Iteration 58280 (DataTime/BatchTime: 0.00156/0.48) losses = 1.3313, lr = [1.8306182861062495e-05, 0.00018306182861062493]\n",
      "[INFO: 2022-02-17 05:59:39,251]   LabelSmoothing Loss = 0.8180238604545593\n",
      "[INFO: 2022-02-17 05:59:48,885] Iteration 58300 (DataTime/BatchTime: 0.00358/0.482) losses = 1.6088, lr = [1.8303042702392967e-05, 0.00018303042702392966]\n",
      "[INFO: 2022-02-17 05:59:48,885]   LabelSmoothing Loss = 2.1353931427001953\n",
      "[INFO: 2022-02-17 05:59:58,536] Iteration 58320 (DataTime/BatchTime: 0.00375/0.483) losses = 1.3752, lr = [1.8299904159114517e-05, 0.00018299904159114515]\n",
      "[INFO: 2022-02-17 05:59:58,536]   LabelSmoothing Loss = 1.0828237533569336\n",
      "[INFO: 2022-02-17 06:00:08,181] Iteration 58340 (DataTime/BatchTime: 0.00287/0.482) losses = 1.5216, lr = [1.82967672298426e-05, 0.000182967672298426]\n",
      "[INFO: 2022-02-17 06:00:08,181]   LabelSmoothing Loss = 1.4169598817825317\n",
      "[INFO: 2022-02-17 06:00:17,923] Iteration 58360 (DataTime/BatchTime: 0.00259/0.487) losses = 1.6047, lr = [1.8293631913194357e-05, 0.00018293631913194355]\n",
      "[INFO: 2022-02-17 06:00:17,924]   LabelSmoothing Loss = 1.6708720922470093\n",
      "[INFO: 2022-02-17 06:00:27,591] Iteration 58380 (DataTime/BatchTime: 0.00339/0.483) losses = 1.548, lr = [1.829049820778856e-05, 0.0001829049820778856]\n",
      "[INFO: 2022-02-17 06:00:27,591]   LabelSmoothing Loss = 1.7068113088607788\n",
      "[INFO: 2022-02-17 06:00:37,334] Iteration 58400 (DataTime/BatchTime: 0.00267/0.487) losses = 1.6059, lr = [1.828736611224566e-05, 0.00018287366112245657]\n",
      "[INFO: 2022-02-17 06:00:37,334]   LabelSmoothing Loss = 1.7373217344284058\n",
      "[INFO: 2022-02-17 06:00:47,109] Iteration 58420 (DataTime/BatchTime: 0.00173/0.489) losses = 1.8798, lr = [1.8284235625187743e-05, 0.00018284235625187743]\n",
      "[INFO: 2022-02-17 06:00:47,110]   LabelSmoothing Loss = 2.3258917331695557\n",
      "[INFO: 2022-02-17 06:00:56,849] Iteration 58440 (DataTime/BatchTime: 0.00373/0.487) losses = 1.5481, lr = [1.828110674523856e-05, 0.0001828110674523856]\n",
      "[INFO: 2022-02-17 06:00:56,849]   LabelSmoothing Loss = 1.6092650890350342\n",
      "[INFO: 2022-02-17 06:01:06,591] Iteration 58460 (DataTime/BatchTime: 0.00165/0.487) losses = 1.3704, lr = [1.82779794710235e-05, 0.00018277979471023495]\n",
      "[INFO: 2022-02-17 06:01:06,591]   LabelSmoothing Loss = 1.7777501344680786\n",
      "[INFO: 2022-02-17 06:01:16,414] Iteration 58480 (DataTime/BatchTime: 0.00255/0.491) losses = 1.4835, lr = [1.8274853801169594e-05, 0.00018274853801169592]\n",
      "[INFO: 2022-02-17 06:01:16,415]   LabelSmoothing Loss = 1.2927186489105225\n",
      "[INFO: 2022-02-17 06:01:26,135] Iteration 58500 (DataTime/BatchTime: 0.0025/0.486) losses = 1.6699, lr = [1.8271729734305533e-05, 0.0001827172973430553]\n",
      "[INFO: 2022-02-17 06:01:26,135]   LabelSmoothing Loss = 2.34073805809021\n",
      "[INFO: 2022-02-17 06:01:35,844] Iteration 58520 (DataTime/BatchTime: 0.00151/0.485) losses = 1.5084, lr = [1.8268607269061634e-05, 0.00018268607269061632]\n",
      "[INFO: 2022-02-17 06:01:35,844]   LabelSmoothing Loss = 1.091378092765808\n",
      "[INFO: 2022-02-17 06:01:45,522] Iteration 58540 (DataTime/BatchTime: 0.00242/0.484) losses = 1.4191, lr = [1.826548640406986e-05, 0.00018265486404069856]\n",
      "[INFO: 2022-02-17 06:01:45,522]   LabelSmoothing Loss = 1.984716773033142\n",
      "[INFO: 2022-02-17 06:01:55,355] Iteration 58560 (DataTime/BatchTime: 0.00341/0.492) losses = 1.5275, lr = [1.82623671379638e-05, 0.00018262367137963798]\n",
      "[INFO: 2022-02-17 06:01:55,355]   LabelSmoothing Loss = 1.257088303565979\n",
      "[INFO: 2022-02-17 06:02:04,998] Iteration 58580 (DataTime/BatchTime: 0.00159/0.482) losses = 1.5532, lr = [1.8259249469378687e-05, 0.00018259249469378683]\n",
      "[INFO: 2022-02-17 06:02:04,998]   LabelSmoothing Loss = 0.7769952416419983\n",
      "[INFO: 2022-02-17 06:02:14,812] Iteration 58600 (DataTime/BatchTime: 0.00151/0.491) losses = 1.587, lr = [1.825613339695137e-05, 0.00018256133396951367]\n",
      "[INFO: 2022-02-17 06:02:14,813]   LabelSmoothing Loss = 1.7585028409957886\n",
      "[INFO: 2022-02-17 06:02:24,524] Iteration 58620 (DataTime/BatchTime: 0.00157/0.486) losses = 1.5158, lr = [1.825301891932034e-05, 0.0001825301891932034]\n",
      "[INFO: 2022-02-17 06:02:24,525]   LabelSmoothing Loss = 2.4139974117279053\n",
      "[INFO: 2022-02-17 06:02:34,201] Iteration 58640 (DataTime/BatchTime: 0.00153/0.484) losses = 1.5955, lr = [1.8249906035125714e-05, 0.00018249906035125712]\n",
      "[INFO: 2022-02-17 06:02:34,201]   LabelSmoothing Loss = 1.4272099733352661\n",
      "[INFO: 2022-02-17 06:02:43,928] Iteration 58660 (DataTime/BatchTime: 0.00156/0.486) losses = 1.7338, lr = [1.8246794743009214e-05, 0.00018246794743009213]\n",
      "[INFO: 2022-02-17 06:02:43,928]   LabelSmoothing Loss = 1.4576400518417358\n",
      "[INFO: 2022-02-17 06:02:53,578] Iteration 58680 (DataTime/BatchTime: 0.00156/0.482) losses = 1.4991, lr = [1.8243685041614205e-05, 0.000182436850416142]\n",
      "[INFO: 2022-02-17 06:02:53,578]   LabelSmoothing Loss = 0.7146883606910706\n",
      "[INFO: 2022-02-17 06:03:03,269] Iteration 58700 (DataTime/BatchTime: 0.0024/0.485) losses = 1.5334, lr = [1.824057692958565e-05, 0.00018240576929585647]\n",
      "[INFO: 2022-02-17 06:03:03,269]   LabelSmoothing Loss = 1.7319098711013794\n",
      "[INFO: 2022-02-17 06:03:12,906] Iteration 58720 (DataTime/BatchTime: 0.00154/0.482) losses = 1.6281, lr = [1.8237470405570137e-05, 0.00018237470405570137]\n",
      "[INFO: 2022-02-17 06:03:12,906]   LabelSmoothing Loss = 2.2191779613494873\n",
      "[INFO: 2022-02-17 06:03:22,519] Iteration 58740 (DataTime/BatchTime: 0.00136/0.481) losses = 1.4979, lr = [1.8234365468215876e-05, 0.00018234365468215873]\n",
      "[INFO: 2022-02-17 06:03:22,520]   LabelSmoothing Loss = 2.4280991554260254\n",
      "[INFO: 2022-02-17 06:03:32,155] Iteration 58760 (DataTime/BatchTime: 0.00221/0.482) losses = 1.7343, lr = [1.823126211617267e-05, 0.0001823126211617267]\n",
      "[INFO: 2022-02-17 06:03:32,156]   LabelSmoothing Loss = 2.5302367210388184\n",
      "[INFO: 2022-02-17 06:03:41,659] Iteration 58780 (DataTime/BatchTime: 0.00111/0.475) losses = 1.3048, lr = [1.822816034809194e-05, 0.00018228160348091936]\n",
      "[INFO: 2022-02-17 06:03:41,660]   LabelSmoothing Loss = 1.5351413488388062\n",
      "[INFO: 2022-02-17 06:03:51,192] Iteration 58800 (DataTime/BatchTime: 0.00278/0.477) losses = 1.5167, lr = [1.8225060162626704e-05, 0.00018225060162626702]\n",
      "[INFO: 2022-02-17 06:03:51,192]   LabelSmoothing Loss = 2.2081000804901123\n",
      "[INFO: 2022-02-17 06:04:00,766] Iteration 58820 (DataTime/BatchTime: 0.00197/0.479) losses = 1.3779, lr = [1.82219615584316e-05, 0.00018221961558431598]\n",
      "[INFO: 2022-02-17 06:04:00,766]   LabelSmoothing Loss = 2.2284066677093506\n",
      "[INFO: 2022-02-17 06:04:10,288] Iteration 58840 (DataTime/BatchTime: 0.00197/0.476) losses = 1.6946, lr = [1.8218864534162857e-05, 0.00018218864534162854]\n",
      "[INFO: 2022-02-17 06:04:10,288]   LabelSmoothing Loss = 2.376300096511841\n",
      "[INFO: 2022-02-17 06:04:19,751] Iteration 58860 (DataTime/BatchTime: 0.00283/0.473) losses = 1.4579, lr = [1.8215769088478285e-05, 0.00018215769088478283]\n",
      "[INFO: 2022-02-17 06:04:19,751]   LabelSmoothing Loss = 1.0745751857757568\n",
      "[INFO: 2022-02-17 06:04:29,254] Iteration 58880 (DataTime/BatchTime: 0.00113/0.475) losses = 1.5829, lr = [1.8212675220037324e-05, 0.0001821267522003732]\n",
      "[INFO: 2022-02-17 06:04:29,254]   LabelSmoothing Loss = 2.303658962249756\n",
      "[INFO: 2022-02-17 06:04:38,743] Iteration 58900 (DataTime/BatchTime: 0.00189/0.474) losses = 1.3834, lr = [1.820958292750098e-05, 0.00018209582927500978]\n",
      "[INFO: 2022-02-17 06:04:38,743]   LabelSmoothing Loss = 1.5990396738052368\n",
      "[INFO: 2022-02-17 06:04:48,224] Iteration 58920 (DataTime/BatchTime: 0.0028/0.474) losses = 1.4838, lr = [1.820649220953186e-05, 0.00018206492209531857]\n",
      "[INFO: 2022-02-17 06:04:48,224]   LabelSmoothing Loss = 1.8016159534454346\n",
      "[INFO: 2022-02-17 06:04:57,683] Iteration 58940 (DataTime/BatchTime: 0.00191/0.473) losses = 1.5191, lr = [1.8203403064794162e-05, 0.0001820340306479416]\n",
      "[INFO: 2022-02-17 06:04:57,683]   LabelSmoothing Loss = 1.863294005393982\n",
      "[INFO: 2022-02-17 06:05:07,273] Iteration 58960 (DataTime/BatchTime: 0.0031/0.479) losses = 1.5506, lr = [1.820031549195366e-05, 0.0001820031549195366]\n",
      "[INFO: 2022-02-17 06:05:07,273]   LabelSmoothing Loss = 1.1124267578125\n",
      "[INFO: 2022-02-17 06:05:16,720] Iteration 58980 (DataTime/BatchTime: 0.00093/0.472) losses = 1.5809, lr = [1.8197229489677728e-05, 0.00018197229489677724]\n",
      "[INFO: 2022-02-17 06:05:16,720]   LabelSmoothing Loss = 1.5502005815505981\n",
      "[INFO: 2022-02-17 06:05:26,157] Iteration 59000 (DataTime/BatchTime: 0.00178/0.472) losses = 1.4563, lr = [1.8194145056635305e-05, 0.00018194145056635302]\n",
      "[INFO: 2022-02-17 06:05:26,157]   LabelSmoothing Loss = 1.316912055015564\n",
      "[INFO: 2022-02-17 06:05:35,649] Iteration 59020 (DataTime/BatchTime: 0.00115/0.475) losses = 1.5924, lr = [1.8191062191496913e-05, 0.0001819106219149691]\n",
      "[INFO: 2022-02-17 06:05:35,649]   LabelSmoothing Loss = 1.1432660818099976\n",
      "[INFO: 2022-02-17 06:05:45,150] Iteration 59040 (DataTime/BatchTime: 0.00105/0.475) losses = 1.5243, lr = [1.8187980892934657e-05, 0.00018187980892934655]\n",
      "[INFO: 2022-02-17 06:05:45,150]   LabelSmoothing Loss = 1.7791248559951782\n",
      "[INFO: 2022-02-17 06:05:54,640] Iteration 59060 (DataTime/BatchTime: 0.00217/0.475) losses = 1.4989, lr = [1.818490115962221e-05, 0.00018184901159622207]\n",
      "[INFO: 2022-02-17 06:05:54,640]   LabelSmoothing Loss = 1.5779917240142822\n",
      "[INFO: 2022-02-17 06:06:04,242] Iteration 59080 (DataTime/BatchTime: 0.00227/0.48) losses = 1.6136, lr = [1.8181822990234817e-05, 0.00018181822990234815]\n",
      "[INFO: 2022-02-17 06:06:04,242]   LabelSmoothing Loss = 1.928656816482544\n",
      "[INFO: 2022-02-17 06:06:13,769] Iteration 59100 (DataTime/BatchTime: 0.00284/0.476) losses = 1.5605, lr = [1.8178746383449296e-05, 0.00018178746383449296]\n",
      "[INFO: 2022-02-17 06:06:13,769]   LabelSmoothing Loss = 1.2903751134872437\n",
      "[INFO: 2022-02-17 06:06:23,271] Iteration 59120 (DataTime/BatchTime: 0.00348/0.474) losses = 1.5683, lr = [1.817567133794403e-05, 0.00018175671337944025]\n",
      "[INFO: 2022-02-17 06:06:23,271]   LabelSmoothing Loss = 0.6125671863555908\n",
      "[INFO: 2022-02-17 06:06:32,799] Iteration 59140 (DataTime/BatchTime: 0.00295/0.477) losses = 1.5451, lr = [1.8172597852398956e-05, 0.00018172597852398955]\n",
      "[INFO: 2022-02-17 06:06:32,799]   LabelSmoothing Loss = 2.338364839553833\n",
      "[INFO: 2022-02-17 06:06:42,338] Iteration 59160 (DataTime/BatchTime: 0.00111/0.477) losses = 1.4927, lr = [1.8169525925495592e-05, 0.0001816952592549559]\n",
      "[INFO: 2022-02-17 06:06:42,338]   LabelSmoothing Loss = 1.9580118656158447\n",
      "[INFO: 2022-02-17 06:06:51,852] Iteration 59180 (DataTime/BatchTime: 0.00118/0.476) losses = 1.4765, lr = [1.8166455555917003e-05, 0.00018166455555916998]\n",
      "[INFO: 2022-02-17 06:06:51,852]   LabelSmoothing Loss = 2.327864408493042\n",
      "[INFO: 2022-02-17 06:07:01,330] Iteration 59200 (DataTime/BatchTime: 0.00107/0.474) losses = 1.529, lr = [1.8163386742347815e-05, 0.00018163386742347813]\n",
      "[INFO: 2022-02-17 06:07:01,330]   LabelSmoothing Loss = 1.5829076766967773\n",
      "[INFO: 2022-02-17 06:10:36,296] ######## Epoch (VAL)62 ########\n",
      "[INFO: 2022-02-17 06:10:36,296] {'Bleu_1': 0.3503807540694962, 'Bleu_2': 0.21750076397004692, 'Bleu_3': 0.1485244363604553, 'Bleu_4': 0.10623305038876892, 'METEOR': 0.18314833826544136, 'ROUGE_L': 0.30327343424677444, 'CIDEr': 0.40513695037537445}\n",
      "[INFO: 2022-02-17 06:14:11,853] ######## Epoch (TEST)62 ########\n",
      "[INFO: 2022-02-17 06:14:11,853] {'Bleu_1': 0.31495325009978836, 'Bleu_2': 0.17844989560745633, 'Bleu_3': 0.10893081565024912, 'Bleu_4': 0.06882558287814124, 'METEOR': 0.16813800145590127, 'ROUGE_L': 0.27728128121286894, 'CIDEr': 0.18656565515626175}\n",
      "[INFO: 2022-02-17 06:14:18,182] Iteration 59220 (DataTime/BatchTime: 0.0929/0.575) losses = 1.5632, lr = [1.8160319483474204e-05, 0.00018160319483474202]\n",
      "[INFO: 2022-02-17 06:14:18,182]   LabelSmoothing Loss = 1.2439624071121216\n",
      "[INFO: 2022-02-17 06:14:27,846] Iteration 59240 (DataTime/BatchTime: 0.00203/0.483) losses = 1.7905, lr = [1.8157253777983907e-05, 0.00018157253777983904]\n",
      "[INFO: 2022-02-17 06:14:27,846]   LabelSmoothing Loss = 2.4272758960723877\n",
      "[INFO: 2022-02-17 06:14:37,441] Iteration 59260 (DataTime/BatchTime: 0.00217/0.48) losses = 1.7299, lr = [1.8154189624566208e-05, 0.00018154189624566204]\n",
      "[INFO: 2022-02-17 06:14:37,442]   LabelSmoothing Loss = 1.6099042892456055\n",
      "[INFO: 2022-02-17 06:14:46,985] Iteration 59280 (DataTime/BatchTime: 0.00215/0.477) losses = 1.3241, lr = [1.8151127021911933e-05, 0.0001815112702191193]\n",
      "[INFO: 2022-02-17 06:14:46,985]   LabelSmoothing Loss = 1.7929630279541016\n",
      "[INFO: 2022-02-17 06:14:56,440] Iteration 59300 (DataTime/BatchTime: 0.00127/0.473) losses = 1.4929, lr = [1.8148065968713463e-05, 0.0001814806596871346]\n",
      "[INFO: 2022-02-17 06:14:56,440]   LabelSmoothing Loss = 2.0767080783843994\n",
      "[INFO: 2022-02-17 06:15:06,004] Iteration 59320 (DataTime/BatchTime: 0.00124/0.478) losses = 1.6321, lr = [1.814500646366471e-05, 0.00018145006463664707]\n",
      "[INFO: 2022-02-17 06:15:06,004]   LabelSmoothing Loss = 2.259911060333252\n",
      "[INFO: 2022-02-17 06:15:15,527] Iteration 59340 (DataTime/BatchTime: 0.00234/0.476) losses = 1.3777, lr = [1.8141948505461143e-05, 0.0001814194850546114]\n",
      "[INFO: 2022-02-17 06:15:15,527]   LabelSmoothing Loss = 1.840004563331604\n",
      "[INFO: 2022-02-17 06:15:25,091] Iteration 59360 (DataTime/BatchTime: 0.00127/0.478) losses = 1.4627, lr = [1.8138892092799756e-05, 0.00018138892092799754]\n",
      "[INFO: 2022-02-17 06:15:25,091]   LabelSmoothing Loss = 1.9297288656234741\n",
      "[INFO: 2022-02-17 06:15:34,700] Iteration 59380 (DataTime/BatchTime: 0.0013/0.48) losses = 1.4468, lr = [1.8135837224379083e-05, 0.0001813583722437908]\n",
      "[INFO: 2022-02-17 06:15:34,700]   LabelSmoothing Loss = 0.5100910663604736\n",
      "[INFO: 2022-02-17 06:15:44,220] Iteration 59400 (DataTime/BatchTime: 0.00128/0.476) losses = 1.6302, lr = [1.813278389889919e-05, 0.0001813278389889919]\n",
      "[INFO: 2022-02-17 06:15:44,220]   LabelSmoothing Loss = 1.8352314233779907\n",
      "[INFO: 2022-02-17 06:15:53,745] Iteration 59420 (DataTime/BatchTime: 0.00129/0.476) losses = 1.3496, lr = [1.8129732115061685e-05, 0.0001812973211506168]\n",
      "[INFO: 2022-02-17 06:15:53,745]   LabelSmoothing Loss = 0.6968309879302979\n",
      "[INFO: 2022-02-17 06:16:03,408] Iteration 59440 (DataTime/BatchTime: 0.00219/0.483) losses = 1.603, lr = [1.8126681871569688e-05, 0.00018126681871569685]\n",
      "[INFO: 2022-02-17 06:16:03,408]   LabelSmoothing Loss = 1.0817689895629883\n",
      "[INFO: 2022-02-17 06:16:12,978] Iteration 59460 (DataTime/BatchTime: 0.00219/0.478) losses = 1.5511, lr = [1.812363316712786e-05, 0.00018123633167127861]\n",
      "[INFO: 2022-02-17 06:16:12,978]   LabelSmoothing Loss = 2.2490718364715576\n",
      "[INFO: 2022-02-17 06:16:22,612] Iteration 59480 (DataTime/BatchTime: 0.0013/0.482) losses = 1.5773, lr = [1.8120586000442384e-05, 0.00018120586000442383]\n",
      "[INFO: 2022-02-17 06:16:22,612]   LabelSmoothing Loss = 1.621657371520996\n",
      "[INFO: 2022-02-17 06:16:32,159] Iteration 59500 (DataTime/BatchTime: 0.00128/0.477) losses = 1.5041, lr = [1.8117540370220954e-05, 0.00018117540370220955]\n",
      "[INFO: 2022-02-17 06:16:32,159]   LabelSmoothing Loss = 0.9632464647293091\n",
      "[INFO: 2022-02-17 06:16:41,783] Iteration 59520 (DataTime/BatchTime: 0.00241/0.481) losses = 1.6079, lr = [1.81144962751728e-05, 0.000181144962751728]\n",
      "[INFO: 2022-02-17 06:16:41,783]   LabelSmoothing Loss = 3.062166213989258\n",
      "[INFO: 2022-02-17 06:16:51,354] Iteration 59540 (DataTime/BatchTime: 0.00125/0.479) losses = 1.6895, lr = [1.811145371400866e-05, 0.0001811145371400866]\n",
      "[INFO: 2022-02-17 06:16:51,354]   LabelSmoothing Loss = 1.2138195037841797\n",
      "[INFO: 2022-02-17 06:17:00,973] Iteration 59560 (DataTime/BatchTime: 0.00125/0.481) losses = 1.5207, lr = [1.810841268544079e-05, 0.00018108412685440787]\n",
      "[INFO: 2022-02-17 06:17:00,973]   LabelSmoothing Loss = 1.2444913387298584\n",
      "[INFO: 2022-02-17 06:17:10,596] Iteration 59580 (DataTime/BatchTime: 0.00206/0.481) losses = 1.7469, lr = [1.810537318818296e-05, 0.00018105373188182956]\n",
      "[INFO: 2022-02-17 06:17:10,596]   LabelSmoothing Loss = 1.837404489517212\n",
      "[INFO: 2022-02-17 06:17:20,290] Iteration 59600 (DataTime/BatchTime: 0.00208/0.485) losses = 1.5117, lr = [1.810233522095044e-05, 0.00018102335220950436]\n",
      "[INFO: 2022-02-17 06:17:20,290]   LabelSmoothing Loss = 1.5444302558898926\n",
      "[INFO: 2022-02-17 06:17:29,983] Iteration 59620 (DataTime/BatchTime: 0.00136/0.485) losses = 1.7158, lr = [1.809929878246003e-05, 0.00018099298782460027]\n",
      "[INFO: 2022-02-17 06:17:29,983]   LabelSmoothing Loss = 1.8318878412246704\n",
      "[INFO: 2022-02-17 06:17:39,603] Iteration 59640 (DataTime/BatchTime: 0.00136/0.481) losses = 1.4985, lr = [1.8096263871430014e-05, 0.00018096263871430012]\n",
      "[INFO: 2022-02-17 06:17:39,604]   LabelSmoothing Loss = 1.8196594715118408\n",
      "[INFO: 2022-02-17 06:17:49,238] Iteration 59660 (DataTime/BatchTime: 0.00217/0.482) losses = 1.4515, lr = [1.8093230486580198e-05, 0.00018093230486580195]\n",
      "[INFO: 2022-02-17 06:17:49,238]   LabelSmoothing Loss = 1.2505158185958862\n",
      "[INFO: 2022-02-17 06:17:58,860] Iteration 59680 (DataTime/BatchTime: 0.00131/0.481) losses = 1.5234, lr = [1.8090198626631874e-05, 0.00018090198626631872]\n",
      "[INFO: 2022-02-17 06:17:58,860]   LabelSmoothing Loss = 1.5945504903793335\n",
      "[INFO: 2022-02-17 06:18:08,391] Iteration 59700 (DataTime/BatchTime: 0.00127/0.477) losses = 1.4588, lr = [1.8087168290307845e-05, 0.00018087168290307844]\n",
      "[INFO: 2022-02-17 06:18:08,392]   LabelSmoothing Loss = 0.8477568626403809\n",
      "[INFO: 2022-02-17 06:18:17,921] Iteration 59720 (DataTime/BatchTime: 0.00218/0.476) losses = 1.5057, lr = [1.8084139476332412e-05, 0.00018084139476332408]\n",
      "[INFO: 2022-02-17 06:18:17,921]   LabelSmoothing Loss = 1.4455915689468384\n",
      "[INFO: 2022-02-17 06:18:27,519] Iteration 59740 (DataTime/BatchTime: 0.00222/0.48) losses = 1.5324, lr = [1.8081112183431356e-05, 0.0001808111218343135]\n",
      "[INFO: 2022-02-17 06:18:27,519]   LabelSmoothing Loss = 1.6567294597625732\n",
      "[INFO: 2022-02-17 06:18:37,116] Iteration 59760 (DataTime/BatchTime: 0.00142/0.48) losses = 1.4505, lr = [1.8078086410331963e-05, 0.00018078086410331962]\n",
      "[INFO: 2022-02-17 06:18:37,116]   LabelSmoothing Loss = 0.8544806838035583\n",
      "[INFO: 2022-02-17 06:18:46,746] Iteration 59780 (DataTime/BatchTime: 0.00128/0.481) losses = 1.6676, lr = [1.807506215576301e-05, 0.00018075062155763007]\n",
      "[INFO: 2022-02-17 06:18:46,746]   LabelSmoothing Loss = 1.4674880504608154\n",
      "[INFO: 2022-02-17 06:18:56,337] Iteration 59800 (DataTime/BatchTime: 0.00129/0.48) losses = 1.4889, lr = [1.807203941845476e-05, 0.0001807203941845476]\n",
      "[INFO: 2022-02-17 06:18:56,337]   LabelSmoothing Loss = 2.2614119052886963\n",
      "[INFO: 2022-02-17 06:19:05,882] Iteration 59820 (DataTime/BatchTime: 0.00121/0.477) losses = 1.6729, lr = [1.8069018197138958e-05, 0.00018069018197138954]\n",
      "[INFO: 2022-02-17 06:19:05,882]   LabelSmoothing Loss = 1.4992300271987915\n",
      "[INFO: 2022-02-17 06:19:15,479] Iteration 59840 (DataTime/BatchTime: 0.00224/0.48) losses = 1.5036, lr = [1.8065998490548836e-05, 0.00018065998490548834]\n",
      "[INFO: 2022-02-17 06:19:15,479]   LabelSmoothing Loss = 2.278895854949951\n",
      "[INFO: 2022-02-17 06:19:24,958] Iteration 59860 (DataTime/BatchTime: 0.00125/0.474) losses = 1.3366, lr = [1.8062980297419107e-05, 0.00018062980297419107]\n",
      "[INFO: 2022-02-17 06:19:24,958]   LabelSmoothing Loss = 1.436152458190918\n",
      "[INFO: 2022-02-17 06:19:34,585] Iteration 59880 (DataTime/BatchTime: 0.00127/0.481) losses = 1.4661, lr = [1.8059963616485963e-05, 0.0001805996361648596]\n",
      "[INFO: 2022-02-17 06:19:34,585]   LabelSmoothing Loss = 0.9927466511726379\n",
      "[INFO: 2022-02-17 06:19:44,116] Iteration 59900 (DataTime/BatchTime: 0.00235/0.477) losses = 1.3722, lr = [1.8056948446487073e-05, 0.00018056948446487073]\n",
      "[INFO: 2022-02-17 06:19:44,116]   LabelSmoothing Loss = 1.1916699409484863\n",
      "[INFO: 2022-02-17 06:19:53,715] Iteration 59920 (DataTime/BatchTime: 0.0014/0.48) losses = 1.4373, lr = [1.805393478616158e-05, 0.0001805393478616158]\n",
      "[INFO: 2022-02-17 06:19:53,715]   LabelSmoothing Loss = 1.8358936309814453\n",
      "[INFO: 2022-02-17 06:20:03,410] Iteration 59940 (DataTime/BatchTime: 0.0033/0.485) losses = 1.5491, lr = [1.805092263425011e-05, 0.00018050922634250106]\n",
      "[INFO: 2022-02-17 06:20:03,410]   LabelSmoothing Loss = 1.5766191482543945\n",
      "[INFO: 2022-02-17 06:20:13,243] Iteration 59960 (DataTime/BatchTime: 0.00162/0.492) losses = 1.5374, lr = [1.8047911989494735e-05, 0.00018047911989494731]\n",
      "[INFO: 2022-02-17 06:20:13,244]   LabelSmoothing Loss = 0.9917783141136169\n",
      "[INFO: 2022-02-17 06:20:22,787] Iteration 59980 (DataTime/BatchTime: 0.00223/0.477) losses = 1.464, lr = [1.8044902850639017e-05, 0.00018044902850639015]\n",
      "[INFO: 2022-02-17 06:20:22,788]   LabelSmoothing Loss = 2.3638813495635986\n",
      "[INFO: 2022-02-17 06:20:32,380] Iteration 60000 (DataTime/BatchTime: 0.00228/0.48) losses = 1.4838, lr = [1.804189521642798e-05, 0.00018041895216427977]\n",
      "[INFO: 2022-02-17 06:20:32,380]   LabelSmoothing Loss = 1.6613496541976929\n",
      "[INFO: 2022-02-17 06:20:41,940] Iteration 60020 (DataTime/BatchTime: 0.00136/0.478) losses = 1.3103, lr = [1.8038889085608103e-05, 0.000180388890856081]\n",
      "[INFO: 2022-02-17 06:20:41,940]   LabelSmoothing Loss = 1.6310054063796997\n",
      "[INFO: 2022-02-17 06:20:51,906] Iteration 60040 (DataTime/BatchTime: 0.00158/0.498) losses = 1.4169, lr = [1.803588445692733e-05, 0.0001803588445692733]\n",
      "[INFO: 2022-02-17 06:20:51,906]   LabelSmoothing Loss = 0.9057005047798157\n",
      "[INFO: 2022-02-17 06:21:01,501] Iteration 60060 (DataTime/BatchTime: 0.0022/0.48) losses = 1.5413, lr = [1.8032881329135078e-05, 0.00018032881329135077]\n",
      "[INFO: 2022-02-17 06:21:01,501]   LabelSmoothing Loss = 1.683111548423767\n",
      "[INFO: 2022-02-17 06:21:11,082] Iteration 60080 (DataTime/BatchTime: 0.00136/0.479) losses = 1.4755, lr = [1.8029879700982198e-05, 0.00018029879700982195]\n",
      "[INFO: 2022-02-17 06:21:11,082]   LabelSmoothing Loss = 1.7813456058502197\n",
      "[INFO: 2022-02-17 06:21:20,598] Iteration 60100 (DataTime/BatchTime: 0.00333/0.476) losses = 1.399, lr = [1.802687957122101e-05, 0.00018026879571221007]\n",
      "[INFO: 2022-02-17 06:21:20,599]   LabelSmoothing Loss = 1.6472373008728027\n",
      "[INFO: 2022-02-17 06:21:30,207] Iteration 60120 (DataTime/BatchTime: 0.00133/0.48) losses = 1.4785, lr = [1.802388093860529e-05, 0.00018023880938605288]\n",
      "[INFO: 2022-02-17 06:21:30,207]   LabelSmoothing Loss = 0.8741836547851562\n",
      "[INFO: 2022-02-17 06:21:39,802] Iteration 60140 (DataTime/BatchTime: 0.00137/0.48) losses = 1.4553, lr = [1.8020883801890254e-05, 0.00018020883801890251]\n",
      "[INFO: 2022-02-17 06:21:39,802]   LabelSmoothing Loss = 0.9967542886734009\n",
      "[INFO: 2022-02-17 06:21:49,259] Iteration 60160 (DataTime/BatchTime: 0.0031/0.473) losses = 1.5498, lr = [1.8017888159832572e-05, 0.0001801788815983257]\n",
      "[INFO: 2022-02-17 06:21:49,259]   LabelSmoothing Loss = 1.3569802045822144\n",
      "[INFO: 2022-02-17 06:25:23,366] ######## Epoch (VAL)63 ########\n",
      "[INFO: 2022-02-17 06:25:23,367] {'Bleu_1': 0.3267448737626938, 'Bleu_2': 0.18831534325798924, 'Bleu_3': 0.11607140301996507, 'Bleu_4': 0.07319673896709653, 'METEOR': 0.17529997651241752, 'ROUGE_L': 0.2780863942251655, 'CIDEr': 0.22732136072067718}\n",
      "[INFO: 2022-02-17 06:29:02,404] ######## Epoch (TEST)63 ########\n",
      "[INFO: 2022-02-17 06:29:02,404] {'Bleu_1': 0.296792526973291, 'Bleu_2': 0.16275794476094116, 'Bleu_3': 0.09593258717990348, 'Bleu_4': 0.05637416329399166, 'METEOR': 0.16451866098842144, 'ROUGE_L': 0.2601929165594764, 'CIDEr': 0.18545374610963844}\n",
      "[INFO: 2022-02-17 06:29:11,237] Iteration 60180 (DataTime/BatchTime: 0.0738/0.552) losses = 1.4417, lr = [1.8014894011190362e-05, 0.00018014894011190362]\n",
      "[INFO: 2022-02-17 06:29:11,237]   LabelSmoothing Loss = 1.6369589567184448\n",
      "[INFO: 2022-02-17 06:29:20,776] Iteration 60200 (DataTime/BatchTime: 0.00135/0.477) losses = 1.5014, lr = [1.8011901354723184e-05, 0.00018011901354723182]\n",
      "[INFO: 2022-02-17 06:29:20,776]   LabelSmoothing Loss = 1.191381812095642\n",
      "[INFO: 2022-02-17 06:29:30,341] Iteration 60220 (DataTime/BatchTime: 0.0013/0.478) losses = 1.3579, lr = [1.8008910189192033e-05, 0.0001800891018919203]\n",
      "[INFO: 2022-02-17 06:29:30,342]   LabelSmoothing Loss = 1.6370691061019897\n",
      "[INFO: 2022-02-17 06:29:39,854] Iteration 60240 (DataTime/BatchTime: 0.00129/0.476) losses = 1.4937, lr = [1.800592051335936e-05, 0.00018005920513359356]\n",
      "[INFO: 2022-02-17 06:29:39,854]   LabelSmoothing Loss = 1.5257080793380737\n",
      "[INFO: 2022-02-17 06:29:49,298] Iteration 60260 (DataTime/BatchTime: 0.00131/0.472) losses = 1.2959, lr = [1.8002932325989037e-05, 0.00018002932325989033]\n",
      "[INFO: 2022-02-17 06:29:49,298]   LabelSmoothing Loss = 1.1613520383834839\n",
      "[INFO: 2022-02-17 06:29:58,688] Iteration 60280 (DataTime/BatchTime: 0.00135/0.469) losses = 1.5447, lr = [1.7999945625846383e-05, 0.0001799994562584638]\n",
      "[INFO: 2022-02-17 06:29:58,688]   LabelSmoothing Loss = 1.2686545848846436\n",
      "[INFO: 2022-02-17 06:30:08,208] Iteration 60300 (DataTime/BatchTime: 0.0023/0.476) losses = 1.4577, lr = [1.7996960411698146e-05, 0.00017996960411698144]\n",
      "[INFO: 2022-02-17 06:30:08,208]   LabelSmoothing Loss = 1.1873657703399658\n",
      "[INFO: 2022-02-17 06:30:17,636] Iteration 60320 (DataTime/BatchTime: 0.00121/0.471) losses = 1.3573, lr = [1.7993976682312505e-05, 0.00017993976682312504]\n",
      "[INFO: 2022-02-17 06:30:17,636]   LabelSmoothing Loss = 0.7418324947357178\n",
      "[INFO: 2022-02-17 06:30:27,109] Iteration 60340 (DataTime/BatchTime: 0.00213/0.473) losses = 1.5397, lr = [1.7990994436459067e-05, 0.00017990994436459064]\n",
      "[INFO: 2022-02-17 06:30:27,109]   LabelSmoothing Loss = 1.7082414627075195\n",
      "[INFO: 2022-02-17 06:30:36,548] Iteration 60360 (DataTime/BatchTime: 0.00279/0.473) losses = 1.4392, lr = [1.798801367290887e-05, 0.00017988013672908866]\n",
      "[INFO: 2022-02-17 06:30:36,548]   LabelSmoothing Loss = 1.1098929643630981\n",
      "[INFO: 2022-02-17 06:30:46,001] Iteration 60380 (DataTime/BatchTime: 0.00274/0.473) losses = 1.5176, lr = [1.798503439043437e-05, 0.00017985034390434368]\n",
      "[INFO: 2022-02-17 06:30:46,002]   LabelSmoothing Loss = 1.964052438735962\n",
      "[INFO: 2022-02-17 06:30:55,422] Iteration 60400 (DataTime/BatchTime: 0.00209/0.471) losses = 1.6434, lr = [1.7982056587809456e-05, 0.00017982056587809451]\n",
      "[INFO: 2022-02-17 06:30:55,422]   LabelSmoothing Loss = 1.2141274213790894\n",
      "[INFO: 2022-02-17 06:31:04,820] Iteration 60420 (DataTime/BatchTime: 0.00202/0.47) losses = 1.4665, lr = [1.7979080263809425e-05, 0.00017979080263809424]\n",
      "[INFO: 2022-02-17 06:31:04,820]   LabelSmoothing Loss = 1.0815420150756836\n",
      "[INFO: 2022-02-17 06:31:14,338] Iteration 60440 (DataTime/BatchTime: 0.00125/0.475) losses = 1.5122, lr = [1.7976105417211e-05, 0.00017976105417210998]\n",
      "[INFO: 2022-02-17 06:31:14,338]   LabelSmoothing Loss = 0.909178614616394\n",
      "[INFO: 2022-02-17 06:31:23,794] Iteration 60460 (DataTime/BatchTime: 0.00349/0.474) losses = 1.5682, lr = [1.797313204679233e-05, 0.00017973132046792325]\n",
      "[INFO: 2022-02-17 06:31:23,794]   LabelSmoothing Loss = 1.5464245080947876\n",
      "[INFO: 2022-02-17 06:31:33,284] Iteration 60480 (DataTime/BatchTime: 0.00227/0.474) losses = 1.1991, lr = [1.7970160151332956e-05, 0.00017970160151332954]\n",
      "[INFO: 2022-02-17 06:31:33,284]   LabelSmoothing Loss = 1.3500455617904663\n",
      "[INFO: 2022-02-17 06:31:42,868] Iteration 60500 (DataTime/BatchTime: 0.00233/0.479) losses = 1.5493, lr = [1.7967189729613848e-05, 0.00017967189729613844]\n",
      "[INFO: 2022-02-17 06:31:42,868]   LabelSmoothing Loss = 1.2528092861175537\n",
      "[INFO: 2022-02-17 06:31:52,399] Iteration 60520 (DataTime/BatchTime: 0.00139/0.477) losses = 1.5682, lr = [1.7964220780417375e-05, 0.00017964220780417373]\n",
      "[INFO: 2022-02-17 06:31:52,400]   LabelSmoothing Loss = 1.251812219619751\n",
      "[INFO: 2022-02-17 06:32:01,944] Iteration 60540 (DataTime/BatchTime: 0.00136/0.477) losses = 1.5399, lr = [1.796125330252733e-05, 0.00017961253302527328]\n",
      "[INFO: 2022-02-17 06:32:01,944]   LabelSmoothing Loss = 1.0548945665359497\n",
      "[INFO: 2022-02-17 06:32:11,509] Iteration 60560 (DataTime/BatchTime: 0.0013/0.478) losses = 1.5909, lr = [1.7958287294728897e-05, 0.00017958287294728893]\n",
      "[INFO: 2022-02-17 06:32:11,510]   LabelSmoothing Loss = 0.8829845786094666\n",
      "[INFO: 2022-02-17 06:32:21,061] Iteration 60580 (DataTime/BatchTime: 0.00244/0.478) losses = 1.5816, lr = [1.7955322755808665e-05, 0.00017955322755808663]\n",
      "[INFO: 2022-02-17 06:32:21,061]   LabelSmoothing Loss = 1.7072288990020752\n",
      "[INFO: 2022-02-17 06:32:30,609] Iteration 60600 (DataTime/BatchTime: 0.00214/0.477) losses = 1.5017, lr = [1.7952359684554632e-05, 0.00017952359684554627]\n",
      "[INFO: 2022-02-17 06:32:30,609]   LabelSmoothing Loss = 1.393966794013977\n",
      "[INFO: 2022-02-17 06:32:40,171] Iteration 60620 (DataTime/BatchTime: 0.00136/0.478) losses = 1.4323, lr = [1.7949398079756188e-05, 0.00017949398079756187]\n",
      "[INFO: 2022-02-17 06:32:40,171]   LabelSmoothing Loss = 2.4470484256744385\n",
      "[INFO: 2022-02-17 06:32:49,774] Iteration 60640 (DataTime/BatchTime: 0.00222/0.48) losses = 1.6096, lr = [1.794643794020413e-05, 0.0001794643794020413]\n",
      "[INFO: 2022-02-17 06:32:49,793]   LabelSmoothing Loss = 2.3905396461486816\n",
      "[INFO: 2022-02-17 06:32:59,329] Iteration 60660 (DataTime/BatchTime: 0.00307/0.478) losses = 1.4794, lr = [1.7943479264690645e-05, 0.00017943479264690643]\n",
      "[INFO: 2022-02-17 06:32:59,347]   LabelSmoothing Loss = 1.1509205102920532\n",
      "[INFO: 2022-02-17 06:33:08,987] Iteration 60680 (DataTime/BatchTime: 0.00419/0.483) losses = 1.6125, lr = [1.794052205200931e-05, 0.00017940522052009307]\n",
      "[INFO: 2022-02-17 06:33:08,987]   LabelSmoothing Loss = 2.65895938873291\n",
      "[INFO: 2022-02-17 06:33:18,509] Iteration 60700 (DataTime/BatchTime: 0.00135/0.476) losses = 1.5414, lr = [1.7937566300955095e-05, 0.00017937566300955094]\n",
      "[INFO: 2022-02-17 06:33:18,509]   LabelSmoothing Loss = 2.779688596725464\n",
      "[INFO: 2022-02-17 06:33:28,097] Iteration 60720 (DataTime/BatchTime: 0.00136/0.479) losses = 1.4843, lr = [1.7934612010324365e-05, 0.0001793461201032436]\n",
      "[INFO: 2022-02-17 06:33:28,098]   LabelSmoothing Loss = 1.1829067468643188\n",
      "[INFO: 2022-02-17 06:33:37,574] Iteration 60740 (DataTime/BatchTime: 0.00291/0.474) losses = 1.1763, lr = [1.7931659178914867e-05, 0.00017931659178914864]\n",
      "[INFO: 2022-02-17 06:33:37,574]   LabelSmoothing Loss = 0.860779345035553\n",
      "[INFO: 2022-02-17 06:33:47,118] Iteration 60760 (DataTime/BatchTime: 0.00135/0.477) losses = 1.3558, lr = [1.7928707805525733e-05, 0.0001792870780552573]\n",
      "[INFO: 2022-02-17 06:33:47,118]   LabelSmoothing Loss = 0.721730649471283\n",
      "[INFO: 2022-02-17 06:33:56,662] Iteration 60780 (DataTime/BatchTime: 0.00133/0.477) losses = 1.4587, lr = [1.792575788895748e-05, 0.00017925757888957475]\n",
      "[INFO: 2022-02-17 06:33:56,662]   LabelSmoothing Loss = 1.5127893686294556\n",
      "[INFO: 2022-02-17 06:34:06,131] Iteration 60800 (DataTime/BatchTime: 0.00137/0.473) losses = 1.6048, lr = [1.7922809428012e-05, 0.00017922809428012]\n",
      "[INFO: 2022-02-17 06:34:06,131]   LabelSmoothing Loss = 1.7695332765579224\n",
      "[INFO: 2022-02-17 06:34:15,661] Iteration 60820 (DataTime/BatchTime: 0.00401/0.476) losses = 1.6546, lr = [1.791986242149258e-05, 0.00017919862421492578]\n",
      "[INFO: 2022-02-17 06:34:15,661]   LabelSmoothing Loss = 1.4017246961593628\n",
      "[INFO: 2022-02-17 06:34:25,208] Iteration 60840 (DataTime/BatchTime: 0.00403/0.477) losses = 1.7436, lr = [1.7916916868203867e-05, 0.00017916916868203862]\n",
      "[INFO: 2022-02-17 06:34:25,208]   LabelSmoothing Loss = 0.5138483047485352\n",
      "[INFO: 2022-02-17 06:34:34,827] Iteration 60860 (DataTime/BatchTime: 0.00133/0.481) losses = 1.3905, lr = [1.791397276695189e-05, 0.00017913972766951889]\n",
      "[INFO: 2022-02-17 06:34:34,827]   LabelSmoothing Loss = 1.7337535619735718\n",
      "[INFO: 2022-02-17 06:34:44,244] Iteration 60880 (DataTime/BatchTime: 0.00218/0.471) losses = 1.5767, lr = [1.791103011654405e-05, 0.0001791103011654405]\n",
      "[INFO: 2022-02-17 06:34:44,244]   LabelSmoothing Loss = 1.6500403881072998\n",
      "[INFO: 2022-02-17 06:34:53,733] Iteration 60900 (DataTime/BatchTime: 0.00211/0.474) losses = 1.5765, lr = [1.790808891578912e-05, 0.00017908088915789117]\n",
      "[INFO: 2022-02-17 06:34:53,734]   LabelSmoothing Loss = 1.3904911279678345\n",
      "[INFO: 2022-02-17 06:35:03,198] Iteration 60920 (DataTime/BatchTime: 0.00233/0.473) losses = 1.43, lr = [1.790514916349724e-05, 0.00017905149163497237]\n",
      "[INFO: 2022-02-17 06:35:03,198]   LabelSmoothing Loss = 1.4975508451461792\n",
      "[INFO: 2022-02-17 06:35:12,674] Iteration 60940 (DataTime/BatchTime: 0.00134/0.474) losses = 1.4251, lr = [1.7902210858479917e-05, 0.00017902210858479915]\n",
      "[INFO: 2022-02-17 06:35:12,674]   LabelSmoothing Loss = 0.8452515602111816\n",
      "[INFO: 2022-02-17 06:35:22,220] Iteration 60960 (DataTime/BatchTime: 0.00138/0.477) losses = 1.582, lr = [1.7899273999550028e-05, 0.00017899273999550026]\n",
      "[INFO: 2022-02-17 06:35:22,220]   LabelSmoothing Loss = 0.9786555767059326\n",
      "[INFO: 2022-02-17 06:35:31,665] Iteration 60980 (DataTime/BatchTime: 0.0013/0.472) losses = 1.4317, lr = [1.7896338585521802e-05, 0.000178963385855218]\n",
      "[INFO: 2022-02-17 06:35:31,665]   LabelSmoothing Loss = 0.3918725252151489\n",
      "[INFO: 2022-02-17 06:35:41,263] Iteration 61000 (DataTime/BatchTime: 0.00213/0.48) losses = 1.5044, lr = [1.7893404615210836e-05, 0.00017893404615210834]\n",
      "[INFO: 2022-02-17 06:35:41,263]   LabelSmoothing Loss = 2.434276580810547\n",
      "[INFO: 2022-02-17 06:35:50,798] Iteration 61020 (DataTime/BatchTime: 0.00313/0.477) losses = 1.5262, lr = [1.7890472087434093e-05, 0.0001789047208743409]\n",
      "[INFO: 2022-02-17 06:35:50,798]   LabelSmoothing Loss = 1.6054320335388184\n",
      "[INFO: 2022-02-17 06:36:00,309] Iteration 61040 (DataTime/BatchTime: 0.0022/0.476) losses = 1.5426, lr = [1.7887541001009873e-05, 0.00017887541001009873]\n",
      "[INFO: 2022-02-17 06:36:00,309]   LabelSmoothing Loss = 1.1969279050827026\n",
      "[INFO: 2022-02-17 06:36:09,827] Iteration 61060 (DataTime/BatchTime: 0.00226/0.476) losses = 1.6888, lr = [1.788461135475785e-05, 0.0001788461135475785]\n",
      "[INFO: 2022-02-17 06:36:09,828]   LabelSmoothing Loss = 1.1402010917663574\n",
      "[INFO: 2022-02-17 06:36:19,343] Iteration 61080 (DataTime/BatchTime: 0.00395/0.476) losses = 1.5083, lr = [1.7881683147499043e-05, 0.0001788168314749904]\n",
      "[INFO: 2022-02-17 06:36:19,343]   LabelSmoothing Loss = 1.5182055234909058\n",
      "[INFO: 2022-02-17 06:36:28,844] Iteration 61100 (DataTime/BatchTime: 0.00136/0.475) losses = 1.5832, lr = [1.7878756378055818e-05, 0.00017878756378055815]\n",
      "[INFO: 2022-02-17 06:36:28,844]   LabelSmoothing Loss = 2.4158947467803955\n",
      "[INFO: 2022-02-17 06:40:10,992] ######## Epoch (VAL)64 ########\n",
      "[INFO: 2022-02-17 06:40:10,993] {'Bleu_1': 0.36440628444596074, 'Bleu_2': 0.21951374444766553, 'Bleu_3': 0.1473643082160101, 'Bleu_4': 0.10426350299081173, 'METEOR': 0.1825033863914506, 'ROUGE_L': 0.2949717555668533, 'CIDEr': 0.3455283391323563}\n",
      "[INFO: 2022-02-17 06:43:48,932] ######## Epoch (TEST)64 ########\n",
      "[INFO: 2022-02-17 06:43:48,932] {'Bleu_1': 0.327653570653318, 'Bleu_2': 0.18639132645987172, 'Bleu_3': 0.11530960653226464, 'Bleu_4': 0.07252467921522392, 'METEOR': 0.16723202727312855, 'ROUGE_L': 0.2711895513540959, 'CIDEr': 0.18111161605942291}\n",
      "[INFO: 2022-02-17 06:43:50,537] Iteration 61120 (DataTime/BatchTime: 0.986/1.6) losses = 1.8429, lr = [1.78758310452519e-05, 0.00017875831045251894]\n",
      "[INFO: 2022-02-17 06:43:50,537]   LabelSmoothing Loss = 1.8428688049316406\n",
      "[INFO: 2022-02-17 06:43:59,965] Iteration 61140 (DataTime/BatchTime: 0.00109/0.471) losses = 1.394, lr = [1.7872907147912344e-05, 0.00017872907147912343]\n",
      "[INFO: 2022-02-17 06:43:59,984]   LabelSmoothing Loss = 0.5824996829032898\n",
      "[INFO: 2022-02-17 06:44:09,478] Iteration 61160 (DataTime/BatchTime: 0.00317/0.476) losses = 1.448, lr = [1.786998468486357e-05, 0.00017869984684863567]\n",
      "[INFO: 2022-02-17 06:44:09,479]   LabelSmoothing Loss = 1.3003997802734375\n",
      "[INFO: 2022-02-17 06:44:19,036] Iteration 61180 (DataTime/BatchTime: 0.00311/0.478) losses = 1.3468, lr = [1.7867063654933328e-05, 0.00017867063654933326]\n",
      "[INFO: 2022-02-17 06:44:19,036]   LabelSmoothing Loss = 1.707666277885437\n",
      "[INFO: 2022-02-17 06:44:28,591] Iteration 61200 (DataTime/BatchTime: 0.0021/0.478) losses = 1.6059, lr = [1.7864144056950712e-05, 0.00017864144056950712]\n",
      "[INFO: 2022-02-17 06:44:28,591]   LabelSmoothing Loss = 0.8340550065040588\n",
      "[INFO: 2022-02-17 06:44:38,137] Iteration 61220 (DataTime/BatchTime: 0.00297/0.477) losses = 1.1921, lr = [1.7861225889746155e-05, 0.00017861225889746155]\n",
      "[INFO: 2022-02-17 06:44:38,137]   LabelSmoothing Loss = 0.9765647649765015\n",
      "[INFO: 2022-02-17 06:44:47,704] Iteration 61240 (DataTime/BatchTime: 0.00135/0.478) losses = 1.4175, lr = [1.7858309152151427e-05, 0.00017858309152151425]\n",
      "[INFO: 2022-02-17 06:44:47,704]   LabelSmoothing Loss = 0.7583721876144409\n",
      "[INFO: 2022-02-17 06:44:57,282] Iteration 61260 (DataTime/BatchTime: 0.00401/0.479) losses = 1.539, lr = [1.7855393842999633e-05, 0.00017855393842999633]\n",
      "[INFO: 2022-02-17 06:44:57,282]   LabelSmoothing Loss = 1.4094916582107544\n",
      "[INFO: 2022-02-17 06:45:06,919] Iteration 61280 (DataTime/BatchTime: 0.00141/0.482) losses = 1.5306, lr = [1.7852479961125214e-05, 0.0001785247996112521]\n",
      "[INFO: 2022-02-17 06:45:06,920]   LabelSmoothing Loss = 1.4758689403533936\n",
      "[INFO: 2022-02-17 06:45:16,496] Iteration 61300 (DataTime/BatchTime: 0.00215/0.479) losses = 1.5095, lr = [1.7849567505363935e-05, 0.00017849567505363932]\n",
      "[INFO: 2022-02-17 06:45:16,496]   LabelSmoothing Loss = 2.326045513153076\n",
      "[INFO: 2022-02-17 06:45:26,038] Iteration 61320 (DataTime/BatchTime: 0.00217/0.477) losses = 1.5158, lr = [1.7846656474552895e-05, 0.00017846656474552891]\n",
      "[INFO: 2022-02-17 06:45:26,038]   LabelSmoothing Loss = 1.072891354560852\n",
      "[INFO: 2022-02-17 06:45:35,590] Iteration 61340 (DataTime/BatchTime: 0.00216/0.478) losses = 1.6624, lr = [1.7843746867530517e-05, 0.00017843746867530515]\n",
      "[INFO: 2022-02-17 06:45:35,590]   LabelSmoothing Loss = 0.9694668054580688\n",
      "[INFO: 2022-02-17 06:45:45,151] Iteration 61360 (DataTime/BatchTime: 0.00135/0.478) losses = 1.4291, lr = [1.7840838683136552e-05, 0.0001784083868313655]\n",
      "[INFO: 2022-02-17 06:45:45,151]   LabelSmoothing Loss = 1.9877763986587524\n",
      "[INFO: 2022-02-17 06:45:54,605] Iteration 61380 (DataTime/BatchTime: 0.00133/0.473) losses = 1.503, lr = [1.783793192021208e-05, 0.00017837931920212078]\n",
      "[INFO: 2022-02-17 06:45:54,605]   LabelSmoothing Loss = 1.8172643184661865\n",
      "[INFO: 2022-02-17 06:46:04,115] Iteration 61400 (DataTime/BatchTime: 0.00223/0.476) losses = 1.2892, lr = [1.783502657759949e-05, 0.00017835026577599488]\n",
      "[INFO: 2022-02-17 06:46:04,115]   LabelSmoothing Loss = 0.9844310283660889\n",
      "[INFO: 2022-02-17 06:46:13,663] Iteration 61420 (DataTime/BatchTime: 0.00315/0.477) losses = 1.6391, lr = [1.7832122654142493e-05, 0.00017832122654142492]\n",
      "[INFO: 2022-02-17 06:46:13,663]   LabelSmoothing Loss = 2.0476999282836914\n",
      "[INFO: 2022-02-17 06:46:23,176] Iteration 61440 (DataTime/BatchTime: 0.00133/0.476) losses = 1.453, lr = [1.782922014868613e-05, 0.00017829220148686127]\n",
      "[INFO: 2022-02-17 06:46:23,176]   LabelSmoothing Loss = 0.9549446105957031\n",
      "[INFO: 2022-02-17 06:46:32,742] Iteration 61460 (DataTime/BatchTime: 0.00223/0.478) losses = 1.6485, lr = [1.7826319060076748e-05, 0.00017826319060076744]\n",
      "[INFO: 2022-02-17 06:46:32,743]   LabelSmoothing Loss = 2.459001302719116\n",
      "[INFO: 2022-02-17 06:46:42,299] Iteration 61480 (DataTime/BatchTime: 0.00214/0.478) losses = 1.6438, lr = [1.7823419387161997e-05, 0.00017823419387161994]\n",
      "[INFO: 2022-02-17 06:46:42,299]   LabelSmoothing Loss = 1.643075704574585\n",
      "[INFO: 2022-02-17 06:46:51,866] Iteration 61500 (DataTime/BatchTime: 0.00211/0.478) losses = 1.5142, lr = [1.7820521128790855e-05, 0.00017820521128790855]\n",
      "[INFO: 2022-02-17 06:46:51,866]   LabelSmoothing Loss = 2.5318078994750977\n",
      "[INFO: 2022-02-17 06:47:01,400] Iteration 61520 (DataTime/BatchTime: 0.00222/0.477) losses = 1.6352, lr = [1.781762428381361e-05, 0.0001781762428381361]\n",
      "[INFO: 2022-02-17 06:47:01,400]   LabelSmoothing Loss = 2.4272801876068115\n",
      "[INFO: 2022-02-17 06:47:10,968] Iteration 61540 (DataTime/BatchTime: 0.00132/0.478) losses = 1.4622, lr = [1.7814728851081847e-05, 0.00017814728851081845]\n",
      "[INFO: 2022-02-17 06:47:10,968]   LabelSmoothing Loss = 1.8475241661071777\n",
      "[INFO: 2022-02-17 06:47:20,477] Iteration 61560 (DataTime/BatchTime: 0.00213/0.475) losses = 1.4251, lr = [1.7811834829448463e-05, 0.0001781183482944846]\n",
      "[INFO: 2022-02-17 06:47:20,477]   LabelSmoothing Loss = 1.8960562944412231\n",
      "[INFO: 2022-02-17 06:47:30,041] Iteration 61580 (DataTime/BatchTime: 0.0013/0.478) losses = 1.6693, lr = [1.7808942217767657e-05, 0.00017808942217767653]\n",
      "[INFO: 2022-02-17 06:47:30,041]   LabelSmoothing Loss = 2.50593638420105\n",
      "[INFO: 2022-02-17 06:47:39,582] Iteration 61600 (DataTime/BatchTime: 0.00302/0.477) losses = 1.5222, lr = [1.7806051014894934e-05, 0.0001780605101489493]\n",
      "[INFO: 2022-02-17 06:47:39,582]   LabelSmoothing Loss = 1.1301056146621704\n",
      "[INFO: 2022-02-17 06:47:49,144] Iteration 61620 (DataTime/BatchTime: 0.00132/0.478) losses = 1.3618, lr = [1.780316121968709e-05, 0.00017803161219687088]\n",
      "[INFO: 2022-02-17 06:47:49,144]   LabelSmoothing Loss = 0.7290387749671936\n",
      "[INFO: 2022-02-17 06:47:58,683] Iteration 61640 (DataTime/BatchTime: 0.00296/0.477) losses = 1.6627, lr = [1.7800272831002235e-05, 0.00017800272831002234]\n",
      "[INFO: 2022-02-17 06:47:58,683]   LabelSmoothing Loss = 1.6680704355239868\n",
      "[INFO: 2022-02-17 06:48:08,203] Iteration 61660 (DataTime/BatchTime: 0.00133/0.476) losses = 1.4, lr = [1.779738584769976e-05, 0.0001779738584769976]\n",
      "[INFO: 2022-02-17 06:48:08,203]   LabelSmoothing Loss = 1.6402850151062012\n",
      "[INFO: 2022-02-17 06:48:17,707] Iteration 61680 (DataTime/BatchTime: 0.00242/0.475) losses = 1.3741, lr = [1.779450026864036e-05, 0.00017794500268640355]\n",
      "[INFO: 2022-02-17 06:48:17,707]   LabelSmoothing Loss = 2.411363124847412\n",
      "[INFO: 2022-02-17 06:48:27,198] Iteration 61700 (DataTime/BatchTime: 0.00209/0.475) losses = 1.3964, lr = [1.7791616092686016e-05, 0.00017791616092686013]\n",
      "[INFO: 2022-02-17 06:48:27,198]   LabelSmoothing Loss = 1.2604539394378662\n",
      "[INFO: 2022-02-17 06:48:36,820] Iteration 61720 (DataTime/BatchTime: 0.00127/0.481) losses = 1.6385, lr = [1.7788733318700004e-05, 0.00017788733318700002]\n",
      "[INFO: 2022-02-17 06:48:36,820]   LabelSmoothing Loss = 2.0214922428131104\n",
      "[INFO: 2022-02-17 06:48:46,350] Iteration 61740 (DataTime/BatchTime: 0.00223/0.477) losses = 1.5198, lr = [1.778585194554689e-05, 0.00017785851945546885]\n",
      "[INFO: 2022-02-17 06:48:46,350]   LabelSmoothing Loss = 0.7665185928344727\n",
      "[INFO: 2022-02-17 06:48:56,038] Iteration 61760 (DataTime/BatchTime: 0.00139/0.484) losses = 1.4346, lr = [1.7782971972092517e-05, 0.00017782971972092515]\n",
      "[INFO: 2022-02-17 06:48:56,038]   LabelSmoothing Loss = 1.7170885801315308\n",
      "[INFO: 2022-02-17 06:49:05,625] Iteration 61780 (DataTime/BatchTime: 0.00133/0.479) losses = 1.6009, lr = [1.7780093397204036e-05, 0.00017780093397204032]\n",
      "[INFO: 2022-02-17 06:49:05,625]   LabelSmoothing Loss = 2.365190029144287\n",
      "[INFO: 2022-02-17 06:49:15,169] Iteration 61800 (DataTime/BatchTime: 0.00133/0.477) losses = 1.4204, lr = [1.7777216219749854e-05, 0.00017777216219749852]\n",
      "[INFO: 2022-02-17 06:49:15,170]   LabelSmoothing Loss = 0.3874794542789459\n",
      "[INFO: 2022-02-17 06:49:24,736] Iteration 61820 (DataTime/BatchTime: 0.00138/0.478) losses = 1.5848, lr = [1.777434043859967e-05, 0.0001777434043859967]\n",
      "[INFO: 2022-02-17 06:49:24,737]   LabelSmoothing Loss = 2.6636157035827637\n",
      "[INFO: 2022-02-17 06:49:34,300] Iteration 61840 (DataTime/BatchTime: 0.00217/0.478) losses = 1.4199, lr = [1.7771466052624478e-05, 0.00017771466052624477]\n",
      "[INFO: 2022-02-17 06:49:34,300]   LabelSmoothing Loss = 0.8536823987960815\n",
      "[INFO: 2022-02-17 06:49:43,824] Iteration 61860 (DataTime/BatchTime: 0.0013/0.476) losses = 1.5777, lr = [1.7768593060696523e-05, 0.0001776859306069652]\n",
      "[INFO: 2022-02-17 06:49:43,824]   LabelSmoothing Loss = 0.8952270150184631\n",
      "[INFO: 2022-02-17 06:49:53,469] Iteration 61880 (DataTime/BatchTime: 0.00245/0.482) losses = 1.4423, lr = [1.7765721461689344e-05, 0.0001776572146168934]\n",
      "[INFO: 2022-02-17 06:49:53,469]   LabelSmoothing Loss = 1.2893034219741821\n",
      "[INFO: 2022-02-17 06:50:03,145] Iteration 61900 (DataTime/BatchTime: 0.00314/0.484) losses = 1.4262, lr = [1.7762851254477745e-05, 0.00017762851254477744]\n",
      "[INFO: 2022-02-17 06:50:03,146]   LabelSmoothing Loss = 1.1877210140228271\n",
      "[INFO: 2022-02-17 06:50:12,918] Iteration 61920 (DataTime/BatchTime: 0.00156/0.489) losses = 1.6218, lr = [1.775998243793781e-05, 0.00017759982437937807]\n",
      "[INFO: 2022-02-17 06:50:12,918]   LabelSmoothing Loss = 2.233522415161133\n",
      "[INFO: 2022-02-17 06:50:22,521] Iteration 61940 (DataTime/BatchTime: 0.00142/0.48) losses = 1.4727, lr = [1.7757115010946885e-05, 0.0001775711501094688]\n",
      "[INFO: 2022-02-17 06:50:22,521]   LabelSmoothing Loss = 1.6364713907241821\n",
      "[INFO: 2022-02-17 06:50:32,159] Iteration 61960 (DataTime/BatchTime: 0.00137/0.482) losses = 1.4685, lr = [1.775424897238359e-05, 0.00017754248972383588]\n",
      "[INFO: 2022-02-17 06:50:32,159]   LabelSmoothing Loss = 1.388527750968933\n",
      "[INFO: 2022-02-17 06:50:41,882] Iteration 61980 (DataTime/BatchTime: 0.00266/0.486) losses = 1.5547, lr = [1.775138432112781e-05, 0.00017751384321127808]\n",
      "[INFO: 2022-02-17 06:50:41,882]   LabelSmoothing Loss = 0.6919224858283997\n",
      "[INFO: 2022-02-17 06:50:51,504] Iteration 62000 (DataTime/BatchTime: 0.00248/0.481) losses = 1.562, lr = [1.7748521056060698e-05, 0.00017748521056060697]\n",
      "[INFO: 2022-02-17 06:50:51,505]   LabelSmoothing Loss = 1.7972354888916016\n",
      "[INFO: 2022-02-17 06:51:01,129] Iteration 62020 (DataTime/BatchTime: 0.00133/0.481) losses = 1.6393, lr = [1.7745659176064658e-05, 0.00017745659176064655]\n",
      "[INFO: 2022-02-17 06:51:01,130]   LabelSmoothing Loss = 1.7254375219345093\n",
      "[INFO: 2022-02-17 06:51:10,812] Iteration 62040 (DataTime/BatchTime: 0.00136/0.484) losses = 1.5145, lr = [1.7742798680023366e-05, 0.00017742798680023364]\n",
      "[INFO: 2022-02-17 06:51:10,812]   LabelSmoothing Loss = 1.8765760660171509\n",
      "[INFO: 2022-02-17 06:51:20,457] Iteration 62060 (DataTime/BatchTime: 0.00133/0.482) losses = 1.6198, lr = [1.773993956682176e-05, 0.00017739939566821758]\n",
      "[INFO: 2022-02-17 06:51:20,457]   LabelSmoothing Loss = 0.959644079208374\n",
      "[INFO: 2022-02-17 06:54:58,465] ######## Epoch (VAL)65 ########\n",
      "[INFO: 2022-02-17 06:54:58,466] {'Bleu_1': 0.329321162788924, 'Bleu_2': 0.19160834211982478, 'Bleu_3': 0.12009571440698896, 'Bleu_4': 0.07839425785534188, 'METEOR': 0.17768832954911834, 'ROUGE_L': 0.27015410723782957, 'CIDEr': 0.23427604982307354}\n",
      "[INFO: 2022-02-17 06:58:32,050] ######## Epoch (TEST)65 ########\n",
      "[INFO: 2022-02-17 06:58:32,051] {'Bleu_1': 0.3069051166865657, 'Bleu_2': 0.16769100183322, 'Bleu_3': 0.09478393878471854, 'Bleu_4': 0.04967038072117183, 'METEOR': 0.16571465364488777, 'ROUGE_L': 0.254030476640455, 'CIDEr': 0.14301138812986885}\n",
      "[INFO: 2022-02-17 06:58:35,946] Iteration 62080 (DataTime/BatchTime: 0.153/0.649) losses = 1.6136, lr = [1.7737081835346025e-05, 0.00017737081835346024]\n",
      "[INFO: 2022-02-17 06:58:35,946]   LabelSmoothing Loss = 1.1550148725509644\n",
      "[INFO: 2022-02-17 06:58:45,481] Iteration 62100 (DataTime/BatchTime: 0.0011/0.477) losses = 1.6377, lr = [1.773422548448361e-05, 0.00017734225484483608]\n",
      "[INFO: 2022-02-17 06:58:45,481]   LabelSmoothing Loss = 1.426011085510254\n",
      "[INFO: 2022-02-17 06:58:55,021] Iteration 62120 (DataTime/BatchTime: 0.0011/0.477) losses = 1.526, lr = [1.773137051312321e-05, 0.00017731370513123206]\n",
      "[INFO: 2022-02-17 06:58:55,021]   LabelSmoothing Loss = 3.2659964561462402\n",
      "[INFO: 2022-02-17 06:59:04,481] Iteration 62140 (DataTime/BatchTime: 0.0011/0.473) losses = 1.3247, lr = [1.7728516920154776e-05, 0.00017728516920154772]\n",
      "[INFO: 2022-02-17 06:59:04,482]   LabelSmoothing Loss = 1.0125973224639893\n",
      "[INFO: 2022-02-17 06:59:13,949] Iteration 62160 (DataTime/BatchTime: 0.00226/0.473) losses = 1.2902, lr = [1.7725664704469513e-05, 0.00017725664704469512]\n",
      "[INFO: 2022-02-17 06:59:13,949]   LabelSmoothing Loss = 1.5341265201568604\n",
      "[INFO: 2022-02-17 06:59:23,461] Iteration 62180 (DataTime/BatchTime: 0.00111/0.476) losses = 1.5435, lr = [1.7722813864959872e-05, 0.0001772281386495987]\n",
      "[INFO: 2022-02-17 06:59:23,462]   LabelSmoothing Loss = 1.160335659980774\n",
      "[INFO: 2022-02-17 06:59:32,957] Iteration 62200 (DataTime/BatchTime: 0.00202/0.475) losses = 1.4624, lr = [1.7719964400519547e-05, 0.00017719964400519545]\n",
      "[INFO: 2022-02-17 06:59:32,957]   LabelSmoothing Loss = 1.195199966430664\n",
      "[INFO: 2022-02-17 06:59:42,449] Iteration 62220 (DataTime/BatchTime: 0.00194/0.475) losses = 1.4641, lr = [1.7717116310043475e-05, 0.00017717116310043472]\n",
      "[INFO: 2022-02-17 06:59:42,449]   LabelSmoothing Loss = 2.1930150985717773\n",
      "[INFO: 2022-02-17 06:59:51,892] Iteration 62240 (DataTime/BatchTime: 0.00306/0.472) losses = 1.3986, lr = [1.7714269592427843e-05, 0.00017714269592427842]\n",
      "[INFO: 2022-02-17 06:59:51,892]   LabelSmoothing Loss = 1.5975267887115479\n",
      "[INFO: 2022-02-17 07:00:01,428] Iteration 62260 (DataTime/BatchTime: 0.00224/0.477) losses = 1.5297, lr = [1.7711424246570075e-05, 0.00017711424246570073]\n",
      "[INFO: 2022-02-17 07:00:01,428]   LabelSmoothing Loss = 2.5854809284210205\n",
      "[INFO: 2022-02-17 07:00:10,982] Iteration 62280 (DataTime/BatchTime: 0.00203/0.478) losses = 1.5155, lr = [1.7708580271368838e-05, 0.00017708580271368836]\n",
      "[INFO: 2022-02-17 07:00:10,982]   LabelSmoothing Loss = 1.8471041917800903\n",
      "[INFO: 2022-02-17 07:00:20,528] Iteration 62300 (DataTime/BatchTime: 0.00118/0.477) losses = 1.598, lr = [1.7705737665724034e-05, 0.0001770573766572403]\n",
      "[INFO: 2022-02-17 07:00:20,528]   LabelSmoothing Loss = 0.9432260990142822\n",
      "[INFO: 2022-02-17 07:00:30,065] Iteration 62320 (DataTime/BatchTime: 0.00121/0.477) losses = 1.437, lr = [1.7702896428536796e-05, 0.00017702896428536792]\n",
      "[INFO: 2022-02-17 07:00:30,066]   LabelSmoothing Loss = 1.8292006254196167\n",
      "[INFO: 2022-02-17 07:00:39,608] Iteration 62340 (DataTime/BatchTime: 0.00203/0.477) losses = 1.5272, lr = [1.7700056558709495e-05, 0.00017700056558709495]\n",
      "[INFO: 2022-02-17 07:00:39,609]   LabelSmoothing Loss = 2.2151551246643066\n",
      "[INFO: 2022-02-17 07:00:49,112] Iteration 62360 (DataTime/BatchTime: 0.002/0.475) losses = 1.386, lr = [1.7697218055145738e-05, 0.00017697218055145737]\n",
      "[INFO: 2022-02-17 07:00:49,112]   LabelSmoothing Loss = 1.146973967552185\n",
      "[INFO: 2022-02-17 07:00:58,650] Iteration 62380 (DataTime/BatchTime: 0.00118/0.477) losses = 1.5441, lr = [1.769438091675036e-05, 0.00017694380916750355]\n",
      "[INFO: 2022-02-17 07:00:58,651]   LabelSmoothing Loss = 1.5901849269866943\n",
      "[INFO: 2022-02-17 07:01:08,237] Iteration 62400 (DataTime/BatchTime: 0.0012/0.479) losses = 1.526, lr = [1.7691545142429415e-05, 0.00017691545142429411]\n",
      "[INFO: 2022-02-17 07:01:08,237]   LabelSmoothing Loss = 1.101449728012085\n",
      "[INFO: 2022-02-17 07:01:17,783] Iteration 62420 (DataTime/BatchTime: 0.00201/0.477) losses = 1.5787, lr = [1.7688710731090203e-05, 0.000176887107310902]\n",
      "[INFO: 2022-02-17 07:01:17,784]   LabelSmoothing Loss = 0.6570780873298645\n",
      "[INFO: 2022-02-17 07:01:27,270] Iteration 62440 (DataTime/BatchTime: 0.00134/0.474) losses = 1.4057, lr = [1.7685877681641233e-05, 0.0001768587768164123]\n",
      "[INFO: 2022-02-17 07:01:27,270]   LabelSmoothing Loss = 1.5917460918426514\n",
      "[INFO: 2022-02-17 07:01:36,841] Iteration 62460 (DataTime/BatchTime: 0.00118/0.479) losses = 1.5725, lr = [1.768304599299224e-05, 0.0001768304599299224]\n",
      "[INFO: 2022-02-17 07:01:36,841]   LabelSmoothing Loss = 1.578965663909912\n",
      "[INFO: 2022-02-17 07:01:46,364] Iteration 62480 (DataTime/BatchTime: 0.00198/0.476) losses = 1.3732, lr = [1.768021566405419e-05, 0.0001768021566405419]\n",
      "[INFO: 2022-02-17 07:01:46,364]   LabelSmoothing Loss = 1.450758695602417\n",
      "[INFO: 2022-02-17 07:01:55,915] Iteration 62500 (DataTime/BatchTime: 0.00204/0.478) losses = 1.4792, lr = [1.767738669373926e-05, 0.00017677386693739258]\n",
      "[INFO: 2022-02-17 07:01:55,915]   LabelSmoothing Loss = 1.8539644479751587\n",
      "[INFO: 2022-02-17 07:02:05,515] Iteration 62520 (DataTime/BatchTime: 0.00199/0.48) losses = 1.5514, lr = [1.7674559080960842e-05, 0.00017674559080960842]\n",
      "[INFO: 2022-02-17 07:02:05,515]   LabelSmoothing Loss = 2.238340377807617\n",
      "[INFO: 2022-02-17 07:02:15,104] Iteration 62540 (DataTime/BatchTime: 0.003/0.479) losses = 1.5552, lr = [1.7671732824633557e-05, 0.00017671732824633556]\n",
      "[INFO: 2022-02-17 07:02:15,104]   LabelSmoothing Loss = 1.9235788583755493\n",
      "[INFO: 2022-02-17 07:02:24,611] Iteration 62560 (DataTime/BatchTime: 0.00119/0.475) losses = 1.4268, lr = [1.766890792367323e-05, 0.00017668907923673225]\n",
      "[INFO: 2022-02-17 07:02:24,611]   LabelSmoothing Loss = 1.8410042524337769\n",
      "[INFO: 2022-02-17 07:02:34,161] Iteration 62580 (DataTime/BatchTime: 0.00119/0.478) losses = 1.5424, lr = [1.7666084376996895e-05, 0.00017666084376996894]\n",
      "[INFO: 2022-02-17 07:02:34,161]   LabelSmoothing Loss = 0.8059041500091553\n",
      "[INFO: 2022-02-17 07:02:43,747] Iteration 62600 (DataTime/BatchTime: 0.00119/0.479) losses = 1.4296, lr = [1.766326218352281e-05, 0.00017663262183522808]\n",
      "[INFO: 2022-02-17 07:02:43,747]   LabelSmoothing Loss = 2.02799916267395\n",
      "[INFO: 2022-02-17 07:02:53,340] Iteration 62620 (DataTime/BatchTime: 0.00117/0.48) losses = 1.5066, lr = [1.766044134217044e-05, 0.0001766044134217044]\n",
      "[INFO: 2022-02-17 07:02:53,341]   LabelSmoothing Loss = 1.2947460412979126\n",
      "[INFO: 2022-02-17 07:03:02,980] Iteration 62640 (DataTime/BatchTime: 0.00122/0.482) losses = 1.5747, lr = [1.7657621851860445e-05, 0.00017657621851860445]\n",
      "[INFO: 2022-02-17 07:03:02,980]   LabelSmoothing Loss = 2.1878623962402344\n",
      "[INFO: 2022-02-17 07:03:12,535] Iteration 62660 (DataTime/BatchTime: 0.00194/0.478) losses = 1.5089, lr = [1.7654803711514703e-05, 0.000176548037115147]\n",
      "[INFO: 2022-02-17 07:03:12,535]   LabelSmoothing Loss = 1.0387153625488281\n",
      "[INFO: 2022-02-17 07:03:22,137] Iteration 62680 (DataTime/BatchTime: 0.00117/0.48) losses = 1.525, lr = [1.7651986920056293e-05, 0.0001765198692005629]\n",
      "[INFO: 2022-02-17 07:03:22,137]   LabelSmoothing Loss = 2.4164609909057617\n",
      "[INFO: 2022-02-17 07:03:31,712] Iteration 62700 (DataTime/BatchTime: 0.00123/0.479) losses = 1.4288, lr = [1.7649171476409498e-05, 0.00017649171476409494]\n",
      "[INFO: 2022-02-17 07:03:31,712]   LabelSmoothing Loss = 1.0301214456558228\n",
      "[INFO: 2022-02-17 07:03:41,577] Iteration 62720 (DataTime/BatchTime: 0.00248/0.493) losses = 1.4024, lr = [1.764635737949979e-05, 0.00017646357379499787]\n",
      "[INFO: 2022-02-17 07:03:41,577]   LabelSmoothing Loss = 1.5663378238677979\n",
      "[INFO: 2022-02-17 07:03:51,108] Iteration 62740 (DataTime/BatchTime: 0.00121/0.477) losses = 1.4296, lr = [1.764354462825386e-05, 0.00017643544628253858]\n",
      "[INFO: 2022-02-17 07:03:51,109]   LabelSmoothing Loss = 1.4206162691116333\n",
      "[INFO: 2022-02-17 07:04:00,638] Iteration 62760 (DataTime/BatchTime: 0.0021/0.476) losses = 1.4883, lr = [1.7640733221599583e-05, 0.00017640733221599582]\n",
      "[INFO: 2022-02-17 07:04:00,638]   LabelSmoothing Loss = 1.3789682388305664\n",
      "[INFO: 2022-02-17 07:04:10,248] Iteration 62780 (DataTime/BatchTime: 0.00118/0.48) losses = 1.6205, lr = [1.7637923158466026e-05, 0.00017637923158466025]\n",
      "[INFO: 2022-02-17 07:04:10,248]   LabelSmoothing Loss = 1.832358717918396\n",
      "[INFO: 2022-02-17 07:04:19,777] Iteration 62800 (DataTime/BatchTime: 0.00119/0.476) losses = 1.4277, lr = [1.7635114437783465e-05, 0.0001763511443778346]\n",
      "[INFO: 2022-02-17 07:04:19,777]   LabelSmoothing Loss = 0.9506420493125916\n",
      "[INFO: 2022-02-17 07:04:29,312] Iteration 62820 (DataTime/BatchTime: 0.00128/0.477) losses = 1.5569, lr = [1.7632307058483352e-05, 0.0001763230705848335]\n",
      "[INFO: 2022-02-17 07:04:29,312]   LabelSmoothing Loss = 1.0592962503433228\n",
      "[INFO: 2022-02-17 07:04:38,917] Iteration 62840 (DataTime/BatchTime: 0.00129/0.48) losses = 1.6128, lr = [1.7629501019498337e-05, 0.00017629501019498334]\n",
      "[INFO: 2022-02-17 07:04:38,917]   LabelSmoothing Loss = 2.6448800563812256\n",
      "[INFO: 2022-02-17 07:04:48,543] Iteration 62860 (DataTime/BatchTime: 0.00126/0.481) losses = 1.6534, lr = [1.762669631976226e-05, 0.0001762669631976226]\n",
      "[INFO: 2022-02-17 07:04:48,543]   LabelSmoothing Loss = 1.100305199623108\n",
      "[INFO: 2022-02-17 07:04:58,170] Iteration 62880 (DataTime/BatchTime: 0.00285/0.481) losses = 1.461, lr = [1.7623892958210146e-05, 0.00017623892958210143]\n",
      "[INFO: 2022-02-17 07:04:58,171]   LabelSmoothing Loss = 1.2688466310501099\n",
      "[INFO: 2022-02-17 07:05:07,722] Iteration 62900 (DataTime/BatchTime: 0.00128/0.478) losses = 1.3561, lr = [1.7621090933778204e-05, 0.000176210909337782]\n",
      "[INFO: 2022-02-17 07:05:07,722]   LabelSmoothing Loss = 0.8795154690742493\n",
      "[INFO: 2022-02-17 07:05:17,268] Iteration 62920 (DataTime/BatchTime: 0.00126/0.477) losses = 1.5371, lr = [1.7618290245403825e-05, 0.00017618290245403824]\n",
      "[INFO: 2022-02-17 07:05:17,268]   LabelSmoothing Loss = 1.163027048110962\n",
      "[INFO: 2022-02-17 07:05:26,856] Iteration 62940 (DataTime/BatchTime: 0.00181/0.479) losses = 1.4943, lr = [1.761549089202559e-05, 0.00017615490892025585]\n",
      "[INFO: 2022-02-17 07:05:26,856]   LabelSmoothing Loss = 1.810971975326538\n",
      "[INFO: 2022-02-17 07:05:36,398] Iteration 62960 (DataTime/BatchTime: 0.00126/0.477) losses = 1.4876, lr = [1.7612692872583245e-05, 0.00017612692872583243]\n",
      "[INFO: 2022-02-17 07:05:36,399]   LabelSmoothing Loss = 1.657823085784912\n",
      "[INFO: 2022-02-17 07:05:46,035] Iteration 62980 (DataTime/BatchTime: 0.00122/0.482) losses = 1.6417, lr = [1.7609896186017737e-05, 0.00017609896186017736]\n",
      "[INFO: 2022-02-17 07:05:46,035]   LabelSmoothing Loss = 0.772837221622467\n",
      "[INFO: 2022-02-17 07:05:55,579] Iteration 63000 (DataTime/BatchTime: 0.00126/0.477) losses = 1.3051, lr = [1.7607100831271168e-05, 0.00017607100831271166]\n",
      "[INFO: 2022-02-17 07:05:55,579]   LabelSmoothing Loss = 1.0490599870681763\n",
      "[INFO: 2022-02-17 07:06:05,136] Iteration 63020 (DataTime/BatchTime: 0.00133/0.478) losses = 1.6418, lr = [1.7604306807286827e-05, 0.00017604306807286825]\n",
      "[INFO: 2022-02-17 07:06:05,137]   LabelSmoothing Loss = 1.1290032863616943\n",
      "[INFO: 2022-02-17 07:09:37,198] ######## Epoch (VAL)66 ########\n",
      "[INFO: 2022-02-17 07:09:37,199] {'Bleu_1': 0.34025513065478974, 'Bleu_2': 0.2051692244710195, 'Bleu_3': 0.13527412019165772, 'Bleu_4': 0.09380106979306803, 'METEOR': 0.18205692707711804, 'ROUGE_L': 0.2812960161076626, 'CIDEr': 0.3077212186723136}\n",
      "[INFO: 2022-02-17 07:13:11,036] ######## Epoch (TEST)66 ########\n",
      "[INFO: 2022-02-17 07:13:11,036] {'Bleu_1': 0.30600034394172365, 'Bleu_2': 0.17270988936198525, 'Bleu_3': 0.10305530072591924, 'Bleu_4': 0.061740071518495074, 'METEOR': 0.16807671324537743, 'ROUGE_L': 0.2606515658296781, 'CIDEr': 0.1697845583258956}\n",
      "[INFO: 2022-02-17 07:13:17,398] Iteration 63040 (DataTime/BatchTime: 0.0915/0.578) losses = 1.5703, lr = [1.7601514113009173e-05, 0.0001760151411300917]\n",
      "[INFO: 2022-02-17 07:13:17,398]   LabelSmoothing Loss = 1.2776577472686768\n",
      "[INFO: 2022-02-17 07:13:26,950] Iteration 63060 (DataTime/BatchTime: 0.0021/0.478) losses = 1.3685, lr = [1.7598722747383836e-05, 0.00017598722747383833]\n",
      "[INFO: 2022-02-17 07:13:26,950]   LabelSmoothing Loss = 0.9997043013572693\n",
      "[INFO: 2022-02-17 07:13:36,583] Iteration 63080 (DataTime/BatchTime: 0.00278/0.482) losses = 1.4203, lr = [1.7595932709357618e-05, 0.00017595932709357616]\n",
      "[INFO: 2022-02-17 07:13:36,583]   LabelSmoothing Loss = 1.03192937374115\n",
      "[INFO: 2022-02-17 07:13:46,245] Iteration 63100 (DataTime/BatchTime: 0.00436/0.483) losses = 1.3233, lr = [1.759314399787849e-05, 0.00017593143997878487]\n",
      "[INFO: 2022-02-17 07:13:46,245]   LabelSmoothing Loss = 2.5846667289733887\n",
      "[INFO: 2022-02-17 07:13:55,829] Iteration 63120 (DataTime/BatchTime: 0.002/0.479) losses = 1.2345, lr = [1.7590356611895584e-05, 0.00017590356611895582]\n",
      "[INFO: 2022-02-17 07:13:55,830]   LabelSmoothing Loss = 1.329105019569397\n",
      "[INFO: 2022-02-17 07:14:05,387] Iteration 63140 (DataTime/BatchTime: 0.00219/0.478) losses = 1.2855, lr = [1.758757055035921e-05, 0.00017587570550359208]\n",
      "[INFO: 2022-02-17 07:14:05,387]   LabelSmoothing Loss = 0.6033499836921692\n",
      "[INFO: 2022-02-17 07:14:15,019] Iteration 63160 (DataTime/BatchTime: 0.00218/0.482) losses = 1.6506, lr = [1.7584785812220825e-05, 0.00017584785812220822]\n",
      "[INFO: 2022-02-17 07:14:15,019]   LabelSmoothing Loss = 2.151602268218994\n",
      "[INFO: 2022-02-17 07:14:24,623] Iteration 63180 (DataTime/BatchTime: 0.00139/0.48) losses = 1.4375, lr = [1.7582002396433057e-05, 0.00017582002396433055]\n",
      "[INFO: 2022-02-17 07:14:24,623]   LabelSmoothing Loss = 1.391180157661438\n",
      "[INFO: 2022-02-17 07:14:34,161] Iteration 63200 (DataTime/BatchTime: 0.00137/0.477) losses = 1.4167, lr = [1.7579220301949696e-05, 0.00017579220301949694]\n",
      "[INFO: 2022-02-17 07:14:34,161]   LabelSmoothing Loss = 0.7485384345054626\n",
      "[INFO: 2022-02-17 07:14:43,734] Iteration 63220 (DataTime/BatchTime: 0.00136/0.479) losses = 1.4348, lr = [1.7576439527725684e-05, 0.00017576439527725683]\n",
      "[INFO: 2022-02-17 07:14:43,735]   LabelSmoothing Loss = 1.4036740064620972\n",
      "[INFO: 2022-02-17 07:14:53,293] Iteration 63240 (DataTime/BatchTime: 0.00133/0.478) losses = 1.4149, lr = [1.7573660072717126e-05, 0.00017573660072717123]\n",
      "[INFO: 2022-02-17 07:14:53,294]   LabelSmoothing Loss = 0.9265927672386169\n",
      "[INFO: 2022-02-17 07:15:02,805] Iteration 63260 (DataTime/BatchTime: 0.00126/0.476) losses = 1.2994, lr = [1.7570881935881282e-05, 0.0001757088193588128]\n",
      "[INFO: 2022-02-17 07:15:02,805]   LabelSmoothing Loss = 1.3542792797088623\n",
      "[INFO: 2022-02-17 07:15:12,381] Iteration 63280 (DataTime/BatchTime: 0.00129/0.479) losses = 1.6644, lr = [1.7568105116176555e-05, 0.00017568105116176554]\n",
      "[INFO: 2022-02-17 07:15:12,382]   LabelSmoothing Loss = 1.4049557447433472\n",
      "[INFO: 2022-02-17 07:15:22,020] Iteration 63300 (DataTime/BatchTime: 0.00325/0.482) losses = 1.5079, lr = [1.756532961256251e-05, 0.00017565329612562509]\n",
      "[INFO: 2022-02-17 07:15:22,020]   LabelSmoothing Loss = 1.0983829498291016\n",
      "[INFO: 2022-02-17 07:15:31,688] Iteration 63320 (DataTime/BatchTime: 0.00142/0.483) losses = 1.6098, lr = [1.7562555423999862e-05, 0.0001756255542399986]\n",
      "[INFO: 2022-02-17 07:15:31,688]   LabelSmoothing Loss = 1.1502801179885864\n",
      "[INFO: 2022-02-17 07:15:41,346] Iteration 63340 (DataTime/BatchTime: 0.00208/0.482) losses = 1.3849, lr = [1.7559782549450474e-05, 0.00017559782549450475]\n",
      "[INFO: 2022-02-17 07:15:41,346]   LabelSmoothing Loss = 1.9879324436187744\n",
      "[INFO: 2022-02-17 07:15:50,973] Iteration 63360 (DataTime/BatchTime: 0.00301/0.482) losses = 1.5954, lr = [1.7557010987877354e-05, 0.0001755701098787735]\n",
      "[INFO: 2022-02-17 07:15:50,974]   LabelSmoothing Loss = 1.1598789691925049\n",
      "[INFO: 2022-02-17 07:16:00,554] Iteration 63380 (DataTime/BatchTime: 0.00131/0.479) losses = 1.6117, lr = [1.7554240738244655e-05, 0.00017554240738244654]\n",
      "[INFO: 2022-02-17 07:16:00,554]   LabelSmoothing Loss = 0.7733781337738037\n",
      "[INFO: 2022-02-17 07:16:10,199] Iteration 63400 (DataTime/BatchTime: 0.00257/0.482) losses = 1.3582, lr = [1.7551471799517676e-05, 0.00017551471799517673]\n",
      "[INFO: 2022-02-17 07:16:10,199]   LabelSmoothing Loss = 1.164191484451294\n",
      "[INFO: 2022-02-17 07:16:19,810] Iteration 63420 (DataTime/BatchTime: 0.00133/0.481) losses = 1.4832, lr = [1.7548704170662852e-05, 0.0001754870417066285]\n",
      "[INFO: 2022-02-17 07:16:19,811]   LabelSmoothing Loss = 1.1791499853134155\n",
      "[INFO: 2022-02-17 07:16:29,438] Iteration 63440 (DataTime/BatchTime: 0.00129/0.481) losses = 1.4893, lr = [1.7545937850647767e-05, 0.00017545937850647764]\n",
      "[INFO: 2022-02-17 07:16:29,438]   LabelSmoothing Loss = 2.2278363704681396\n",
      "[INFO: 2022-02-17 07:16:39,062] Iteration 63460 (DataTime/BatchTime: 0.00134/0.481) losses = 1.3885, lr = [1.754317283844114e-05, 0.0001754317283844114]\n",
      "[INFO: 2022-02-17 07:16:39,062]   LabelSmoothing Loss = 0.6729506254196167\n",
      "[INFO: 2022-02-17 07:16:48,633] Iteration 63480 (DataTime/BatchTime: 0.0012/0.479) losses = 1.32, lr = [1.7540409133012826e-05, 0.00017540409133012824]\n",
      "[INFO: 2022-02-17 07:16:48,633]   LabelSmoothing Loss = 1.2230767011642456\n",
      "[INFO: 2022-02-17 07:16:58,186] Iteration 63500 (DataTime/BatchTime: 0.00129/0.478) losses = 1.4679, lr = [1.7537646733333823e-05, 0.0001753764673333382]\n",
      "[INFO: 2022-02-17 07:16:58,186]   LabelSmoothing Loss = 1.7869335412979126\n",
      "[INFO: 2022-02-17 07:17:07,798] Iteration 63520 (DataTime/BatchTime: 0.00207/0.481) losses = 1.5183, lr = [1.753488563837625e-05, 0.0001753488563837625]\n",
      "[INFO: 2022-02-17 07:17:07,798]   LabelSmoothing Loss = 1.1555349826812744\n",
      "[INFO: 2022-02-17 07:17:17,409] Iteration 63540 (DataTime/BatchTime: 0.00126/0.481) losses = 1.4203, lr = [1.7532125847113367e-05, 0.00017532125847113364]\n",
      "[INFO: 2022-02-17 07:17:17,410]   LabelSmoothing Loss = 0.7145909070968628\n",
      "[INFO: 2022-02-17 07:17:27,011] Iteration 63560 (DataTime/BatchTime: 0.00131/0.48) losses = 1.6168, lr = [1.7529367358519565e-05, 0.00017529367358519563]\n",
      "[INFO: 2022-02-17 07:17:27,011]   LabelSmoothing Loss = 1.8694010972976685\n",
      "[INFO: 2022-02-17 07:17:36,639] Iteration 63580 (DataTime/BatchTime: 0.00426/0.481) losses = 1.5891, lr = [1.7526610171570362e-05, 0.0001752661017157036]\n",
      "[INFO: 2022-02-17 07:17:36,639]   LabelSmoothing Loss = 1.9737787246704102\n",
      "[INFO: 2022-02-17 07:17:46,295] Iteration 63600 (DataTime/BatchTime: 0.00138/0.483) losses = 1.491, lr = [1.7523854285242405e-05, 0.00017523854285242404]\n",
      "[INFO: 2022-02-17 07:17:46,296]   LabelSmoothing Loss = 1.9760631322860718\n",
      "[INFO: 2022-02-17 07:17:55,958] Iteration 63620 (DataTime/BatchTime: 0.00231/0.483) losses = 1.3782, lr = [1.7521099698513463e-05, 0.0001752109969851346]\n",
      "[INFO: 2022-02-17 07:17:55,959]   LabelSmoothing Loss = 1.8761727809906006\n",
      "[INFO: 2022-02-17 07:18:05,553] Iteration 63640 (DataTime/BatchTime: 0.00227/0.48) losses = 1.6033, lr = [1.751834641036244e-05, 0.00017518346410362438]\n",
      "[INFO: 2022-02-17 07:18:05,553]   LabelSmoothing Loss = 2.0357136726379395\n",
      "[INFO: 2022-02-17 07:18:15,297] Iteration 63660 (DataTime/BatchTime: 0.00148/0.487) losses = 1.5661, lr = [1.7515594419769345e-05, 0.00017515594419769342]\n",
      "[INFO: 2022-02-17 07:18:15,297]   LabelSmoothing Loss = 2.1567373275756836\n",
      "[INFO: 2022-02-17 07:18:24,982] Iteration 63680 (DataTime/BatchTime: 0.00229/0.484) losses = 1.4693, lr = [1.7512843725715326e-05, 0.00017512843725715324]\n",
      "[INFO: 2022-02-17 07:18:24,982]   LabelSmoothing Loss = 2.037309408187866\n",
      "[INFO: 2022-02-17 07:18:34,628] Iteration 63700 (DataTime/BatchTime: 0.00325/0.482) losses = 1.4738, lr = [1.7510094327182645e-05, 0.00017510094327182643]\n",
      "[INFO: 2022-02-17 07:18:34,628]   LabelSmoothing Loss = 1.8597983121871948\n",
      "[INFO: 2022-02-17 07:18:44,215] Iteration 63720 (DataTime/BatchTime: 0.00214/0.479) losses = 1.6296, lr = [1.7507346223154672e-05, 0.00017507346223154672]\n",
      "[INFO: 2022-02-17 07:18:44,215]   LabelSmoothing Loss = 0.9362518787384033\n",
      "[INFO: 2022-02-17 07:18:53,724] Iteration 63740 (DataTime/BatchTime: 0.00135/0.475) losses = 1.4168, lr = [1.7504599412615914e-05, 0.0001750459941261591]\n",
      "[INFO: 2022-02-17 07:18:53,724]   LabelSmoothing Loss = 2.058875560760498\n",
      "[INFO: 2022-02-17 07:19:03,330] Iteration 63760 (DataTime/BatchTime: 0.00138/0.48) losses = 1.4956, lr = [1.7501853894551967e-05, 0.00017501853894551965]\n",
      "[INFO: 2022-02-17 07:19:03,330]   LabelSmoothing Loss = 1.094681978225708\n",
      "[INFO: 2022-02-17 07:19:12,906] Iteration 63780 (DataTime/BatchTime: 0.00218/0.479) losses = 1.5327, lr = [1.7499109667949567e-05, 0.00017499109667949565]\n",
      "[INFO: 2022-02-17 07:19:12,906]   LabelSmoothing Loss = 1.5277361869812012\n",
      "[INFO: 2022-02-17 07:19:22,540] Iteration 63800 (DataTime/BatchTime: 0.00136/0.482) losses = 1.502, lr = [1.7496366731796545e-05, 0.00017496366731796544]\n",
      "[INFO: 2022-02-17 07:19:22,540]   LabelSmoothing Loss = 2.2211272716522217\n",
      "[INFO: 2022-02-17 07:19:32,165] Iteration 63820 (DataTime/BatchTime: 0.00143/0.481) losses = 1.5844, lr = [1.7493625085081847e-05, 0.00017493625085081844]\n",
      "[INFO: 2022-02-17 07:19:32,165]   LabelSmoothing Loss = 1.2044767141342163\n",
      "[INFO: 2022-02-17 07:19:41,798] Iteration 63840 (DataTime/BatchTime: 0.00221/0.482) losses = 1.3961, lr = [1.7490884726795518e-05, 0.00017490884726795516]\n",
      "[INFO: 2022-02-17 07:19:41,799]   LabelSmoothing Loss = 1.8356268405914307\n",
      "[INFO: 2022-02-17 07:19:51,351] Iteration 63860 (DataTime/BatchTime: 0.00136/0.478) losses = 1.5262, lr = [1.7488145655928734e-05, 0.00017488145655928733]\n",
      "[INFO: 2022-02-17 07:19:51,351]   LabelSmoothing Loss = 0.9292902946472168\n",
      "[INFO: 2022-02-17 07:20:00,936] Iteration 63880 (DataTime/BatchTime: 0.00219/0.479) losses = 1.4592, lr = [1.748540787147375e-05, 0.00017485407871473748]\n",
      "[INFO: 2022-02-17 07:20:00,936]   LabelSmoothing Loss = 2.066298484802246\n",
      "[INFO: 2022-02-17 07:20:10,466] Iteration 63900 (DataTime/BatchTime: 0.00135/0.477) losses = 1.4286, lr = [1.7482671372423946e-05, 0.00017482671372423943]\n",
      "[INFO: 2022-02-17 07:20:10,466]   LabelSmoothing Loss = 0.5554019212722778\n",
      "[INFO: 2022-02-17 07:20:19,993] Iteration 63920 (DataTime/BatchTime: 0.00136/0.476) losses = 1.4096, lr = [1.7479936157773788e-05, 0.00017479936157773783]\n",
      "[INFO: 2022-02-17 07:20:19,993]   LabelSmoothing Loss = 1.2912906408309937\n",
      "[INFO: 2022-02-17 07:20:29,628] Iteration 63940 (DataTime/BatchTime: 0.00141/0.482) losses = 1.4903, lr = [1.747720222651885e-05, 0.0001747720222651885]\n",
      "[INFO: 2022-02-17 07:20:29,628]   LabelSmoothing Loss = 0.9373876452445984\n",
      "[INFO: 2022-02-17 07:20:39,263] Iteration 63960 (DataTime/BatchTime: 0.00137/0.482) losses = 1.5796, lr = [1.747446957765581e-05, 0.0001747446957765581]\n",
      "[INFO: 2022-02-17 07:20:39,264]   LabelSmoothing Loss = 2.2985892295837402\n",
      "[INFO: 2022-02-17 07:20:48,744] Iteration 63980 (DataTime/BatchTime: 0.00207/0.474) losses = 1.6375, lr = [1.747173821018244e-05, 0.00017471738210182437]\n",
      "[INFO: 2022-02-17 07:20:48,744]   LabelSmoothing Loss = 1.4598503112792969\n",
      "[INFO: 2022-02-17 07:24:21,049] ######## Epoch (VAL)67 ########\n",
      "[INFO: 2022-02-17 07:24:21,050] {'Bleu_1': 0.3258888275447358, 'Bleu_2': 0.1894776391532511, 'Bleu_3': 0.11994227886141771, 'Bleu_4': 0.07918465209828178, 'METEOR': 0.1733758469984291, 'ROUGE_L': 0.28307740967716877, 'CIDEr': 0.3033395364450179}\n",
      "[INFO: 2022-02-17 07:27:58,909] ######## Epoch (TEST)67 ########\n",
      "[INFO: 2022-02-17 07:27:58,909] {'Bleu_1': 0.3164462027939931, 'Bleu_2': 0.18350080076483935, 'Bleu_3': 0.1155587063797959, 'Bleu_4': 0.07589360058716355, 'METEOR': 0.17072235128907423, 'ROUGE_L': 0.2745124041545201, 'CIDEr': 0.26120877086955785}\n",
      "[INFO: 2022-02-17 07:28:07,648] Iteration 64000 (DataTime/BatchTime: 0.0658/0.546) losses = 1.3958, lr = [1.74690081230976e-05, 0.000174690081230976]\n",
      "[INFO: 2022-02-17 07:28:07,649]   LabelSmoothing Loss = 1.7688618898391724\n",
      "[INFO: 2022-02-17 07:28:17,181] Iteration 64020 (DataTime/BatchTime: 0.00145/0.477) losses = 1.4132, lr = [1.7466279315401258e-05, 0.00017466279315401256]\n",
      "[INFO: 2022-02-17 07:28:17,181]   LabelSmoothing Loss = 1.0157036781311035\n",
      "[INFO: 2022-02-17 07:28:26,840] Iteration 64040 (DataTime/BatchTime: 0.00122/0.483) losses = 1.5294, lr = [1.746355178609447e-05, 0.0001746355178609447]\n",
      "[INFO: 2022-02-17 07:28:26,840]   LabelSmoothing Loss = 1.4256967306137085\n",
      "[INFO: 2022-02-17 07:28:36,400] Iteration 64060 (DataTime/BatchTime: 0.00312/0.478) losses = 1.4396, lr = [1.7460825534179376e-05, 0.00017460825534179375]\n",
      "[INFO: 2022-02-17 07:28:36,400]   LabelSmoothing Loss = 1.2757526636123657\n",
      "[INFO: 2022-02-17 07:28:45,968] Iteration 64080 (DataTime/BatchTime: 0.00211/0.478) losses = 1.4692, lr = [1.745810055865922e-05, 0.00017458100558659218]\n",
      "[INFO: 2022-02-17 07:28:45,969]   LabelSmoothing Loss = 1.5092027187347412\n",
      "[INFO: 2022-02-17 07:28:55,588] Iteration 64100 (DataTime/BatchTime: 0.00208/0.481) losses = 1.57, lr = [1.7455376858538324e-05, 0.00017455376858538322]\n",
      "[INFO: 2022-02-17 07:28:55,588]   LabelSmoothing Loss = 0.8825356960296631\n",
      "[INFO: 2022-02-17 07:29:05,164] Iteration 64120 (DataTime/BatchTime: 0.0023/0.479) losses = 1.5007, lr = [1.7452654432822104e-05, 0.000174526544328221]\n",
      "[INFO: 2022-02-17 07:29:05,165]   LabelSmoothing Loss = 1.6744515895843506\n",
      "[INFO: 2022-02-17 07:29:14,690] Iteration 64140 (DataTime/BatchTime: 0.00304/0.476) losses = 1.4904, lr = [1.7449933280517052e-05, 0.00017449933280517052]\n",
      "[INFO: 2022-02-17 07:29:14,690]   LabelSmoothing Loss = 1.6003451347351074\n",
      "[INFO: 2022-02-17 07:29:24,271] Iteration 64160 (DataTime/BatchTime: 0.00216/0.479) losses = 1.391, lr = [1.7447213400630758e-05, 0.00017447213400630758]\n",
      "[INFO: 2022-02-17 07:29:24,271]   LabelSmoothing Loss = 1.5802600383758545\n",
      "[INFO: 2022-02-17 07:29:33,793] Iteration 64180 (DataTime/BatchTime: 0.00129/0.476) losses = 1.3202, lr = [1.744449479217188e-05, 0.00017444494792171877]\n",
      "[INFO: 2022-02-17 07:29:33,793]   LabelSmoothing Loss = 1.452564001083374\n",
      "[INFO: 2022-02-17 07:29:43,335] Iteration 64200 (DataTime/BatchTime: 0.00128/0.477) losses = 1.5385, lr = [1.744177745415017e-05, 0.00017441777454150166]\n",
      "[INFO: 2022-02-17 07:29:43,335]   LabelSmoothing Loss = 1.8775739669799805\n",
      "[INFO: 2022-02-17 07:29:52,919] Iteration 64220 (DataTime/BatchTime: 0.0013/0.479) losses = 1.3642, lr = [1.7439061385576442e-05, 0.00017439061385576439]\n",
      "[INFO: 2022-02-17 07:29:52,919]   LabelSmoothing Loss = 1.0692628622055054\n",
      "[INFO: 2022-02-17 07:30:02,465] Iteration 64240 (DataTime/BatchTime: 0.00128/0.477) losses = 1.4828, lr = [1.7436346585462607e-05, 0.00017436346585462606]\n",
      "[INFO: 2022-02-17 07:30:02,465]   LabelSmoothing Loss = 0.9761072397232056\n",
      "[INFO: 2022-02-17 07:30:11,956] Iteration 64260 (DataTime/BatchTime: 0.00127/0.475) losses = 1.5113, lr = [1.743363305282164e-05, 0.0001743363305282164]\n",
      "[INFO: 2022-02-17 07:30:11,956]   LabelSmoothing Loss = 1.4526089429855347\n",
      "[INFO: 2022-02-17 07:30:21,480] Iteration 64280 (DataTime/BatchTime: 0.00127/0.476) losses = 1.4427, lr = [1.7430920786667603e-05, 0.000174309207866676]\n",
      "[INFO: 2022-02-17 07:30:21,480]   LabelSmoothing Loss = 0.7864289879798889\n",
      "[INFO: 2022-02-17 07:30:30,943] Iteration 64300 (DataTime/BatchTime: 0.00127/0.473) losses = 1.3788, lr = [1.7428209786015612e-05, 0.00017428209786015612]\n",
      "[INFO: 2022-02-17 07:30:30,944]   LabelSmoothing Loss = 1.3608421087265015\n",
      "[INFO: 2022-02-17 07:30:40,620] Iteration 64320 (DataTime/BatchTime: 0.00209/0.484) losses = 1.5717, lr = [1.7425500049881876e-05, 0.00017425500049881874]\n",
      "[INFO: 2022-02-17 07:30:40,620]   LabelSmoothing Loss = 1.2280809879302979\n",
      "[INFO: 2022-02-17 07:30:50,179] Iteration 64340 (DataTime/BatchTime: 0.00127/0.478) losses = 1.5138, lr = [1.742279157728366e-05, 0.0001742279157728366]\n",
      "[INFO: 2022-02-17 07:30:50,179]   LabelSmoothing Loss = 0.8891792893409729\n",
      "[INFO: 2022-02-17 07:30:59,675] Iteration 64360 (DataTime/BatchTime: 0.00129/0.475) losses = 1.5759, lr = [1.7420084367239305e-05, 0.00017420084367239302]\n",
      "[INFO: 2022-02-17 07:30:59,676]   LabelSmoothing Loss = 2.210580587387085\n",
      "[INFO: 2022-02-17 07:31:09,213] Iteration 64380 (DataTime/BatchTime: 0.00127/0.477) losses = 1.4702, lr = [1.7417378418768217e-05, 0.00017417378418768217]\n",
      "[INFO: 2022-02-17 07:31:09,213]   LabelSmoothing Loss = 0.6123878955841064\n",
      "[INFO: 2022-02-17 07:31:18,683] Iteration 64400 (DataTime/BatchTime: 0.00128/0.473) losses = 1.361, lr = [1.7414673730890867e-05, 0.00017414673730890867]\n",
      "[INFO: 2022-02-17 07:31:18,683]   LabelSmoothing Loss = 1.1689132452011108\n",
      "[INFO: 2022-02-17 07:31:28,214] Iteration 64420 (DataTime/BatchTime: 0.00127/0.477) losses = 1.4986, lr = [1.741197030262879e-05, 0.00017411970302628788]\n",
      "[INFO: 2022-02-17 07:31:28,214]   LabelSmoothing Loss = 1.5629873275756836\n",
      "[INFO: 2022-02-17 07:31:37,721] Iteration 64440 (DataTime/BatchTime: 0.00127/0.475) losses = 1.5375, lr = [1.7409268133004588e-05, 0.00017409268133004583]\n",
      "[INFO: 2022-02-17 07:31:37,721]   LabelSmoothing Loss = 1.0245260000228882\n",
      "[INFO: 2022-02-17 07:31:47,285] Iteration 64460 (DataTime/BatchTime: 0.00128/0.478) losses = 1.3705, lr = [1.7406567221041918e-05, 0.00017406567221041916]\n",
      "[INFO: 2022-02-17 07:31:47,286]   LabelSmoothing Loss = 1.6437644958496094\n",
      "[INFO: 2022-02-17 07:31:56,800] Iteration 64480 (DataTime/BatchTime: 0.0013/0.476) losses = 1.5367, lr = [1.7403867565765507e-05, 0.00017403867565765507]\n",
      "[INFO: 2022-02-17 07:31:56,800]   LabelSmoothing Loss = 0.525002658367157\n",
      "[INFO: 2022-02-17 07:32:06,284] Iteration 64500 (DataTime/BatchTime: 0.00128/0.474) losses = 1.457, lr = [1.740116916620113e-05, 0.0001740116916620113]\n",
      "[INFO: 2022-02-17 07:32:06,284]   LabelSmoothing Loss = 1.094282627105713\n",
      "[INFO: 2022-02-17 07:32:15,792] Iteration 64520 (DataTime/BatchTime: 0.00293/0.475) losses = 1.2901, lr = [1.7398472021375625e-05, 0.00017398472021375622]\n",
      "[INFO: 2022-02-17 07:32:15,792]   LabelSmoothing Loss = 2.232543706893921\n",
      "[INFO: 2022-02-17 07:32:25,277] Iteration 64540 (DataTime/BatchTime: 0.00128/0.474) losses = 1.3316, lr = [1.739577613031688e-05, 0.00017395776130316878]\n",
      "[INFO: 2022-02-17 07:32:25,278]   LabelSmoothing Loss = 0.8657046556472778\n",
      "[INFO: 2022-02-17 07:32:34,860] Iteration 64560 (DataTime/BatchTime: 0.00128/0.479) losses = 1.6266, lr = [1.7393081492053846e-05, 0.00017393081492053842]\n",
      "[INFO: 2022-02-17 07:32:34,860]   LabelSmoothing Loss = 1.3697667121887207\n",
      "[INFO: 2022-02-17 07:32:44,423] Iteration 64580 (DataTime/BatchTime: 0.00127/0.478) losses = 1.5008, lr = [1.7390388105616514e-05, 0.00017390388105616514]\n",
      "[INFO: 2022-02-17 07:32:44,423]   LabelSmoothing Loss = 0.721481204032898\n",
      "[INFO: 2022-02-17 07:32:53,950] Iteration 64600 (DataTime/BatchTime: 0.00127/0.476) losses = 1.5146, lr = [1.7387695970035944e-05, 0.00017387695970035944]\n",
      "[INFO: 2022-02-17 07:32:53,950]   LabelSmoothing Loss = 0.9000189900398254\n",
      "[INFO: 2022-02-17 07:33:03,520] Iteration 64620 (DataTime/BatchTime: 0.00126/0.479) losses = 1.379, lr = [1.738500508434423e-05, 0.0001738500508434423]\n",
      "[INFO: 2022-02-17 07:33:03,520]   LabelSmoothing Loss = 1.138278841972351\n",
      "[INFO: 2022-02-17 07:33:12,994] Iteration 64640 (DataTime/BatchTime: 0.00128/0.474) losses = 1.4933, lr = [1.738231544757452e-05, 0.00017382315447574516]\n",
      "[INFO: 2022-02-17 07:33:12,994]   LabelSmoothing Loss = 1.1074317693710327\n",
      "[INFO: 2022-02-17 07:33:22,483] Iteration 64660 (DataTime/BatchTime: 0.00127/0.474) losses = 1.403, lr = [1.737962705876101e-05, 0.00017379627058761006]\n",
      "[INFO: 2022-02-17 07:33:22,484]   LabelSmoothing Loss = 1.2173306941986084\n",
      "[INFO: 2022-02-17 07:33:31,981] Iteration 64680 (DataTime/BatchTime: 0.00128/0.475) losses = 1.3863, lr = [1.7376939916938932e-05, 0.0001737693991693893]\n",
      "[INFO: 2022-02-17 07:33:31,981]   LabelSmoothing Loss = 0.9825583100318909\n",
      "[INFO: 2022-02-17 07:33:41,517] Iteration 64700 (DataTime/BatchTime: 0.00128/0.477) losses = 1.3644, lr = [1.7374254021144576e-05, 0.00017374254021144573]\n",
      "[INFO: 2022-02-17 07:33:41,517]   LabelSmoothing Loss = 1.426862359046936\n",
      "[INFO: 2022-02-17 07:33:50,994] Iteration 64720 (DataTime/BatchTime: 0.00128/0.474) losses = 1.4733, lr = [1.7371569370415267e-05, 0.00017371569370415265]\n",
      "[INFO: 2022-02-17 07:33:50,994]   LabelSmoothing Loss = 2.6175377368927\n",
      "[INFO: 2022-02-17 07:34:00,543] Iteration 64740 (DataTime/BatchTime: 0.00128/0.477) losses = 1.5175, lr = [1.7368885963789373e-05, 0.00017368885963789371]\n",
      "[INFO: 2022-02-17 07:34:00,543]   LabelSmoothing Loss = 1.2616931200027466\n",
      "[INFO: 2022-02-17 07:34:10,065] Iteration 64760 (DataTime/BatchTime: 0.00138/0.476) losses = 1.3805, lr = [1.73662038003063e-05, 0.000173662038003063]\n",
      "[INFO: 2022-02-17 07:34:10,065]   LabelSmoothing Loss = 0.6556220650672913\n",
      "[INFO: 2022-02-17 07:34:19,573] Iteration 64780 (DataTime/BatchTime: 0.00127/0.475) losses = 1.5937, lr = [1.736352287900649e-05, 0.00017363522879006488]\n",
      "[INFO: 2022-02-17 07:34:19,573]   LabelSmoothing Loss = 1.3836510181427002\n",
      "[INFO: 2022-02-17 07:34:29,126] Iteration 64800 (DataTime/BatchTime: 0.00128/0.478) losses = 1.6497, lr = [1.7360843198931426e-05, 0.00017360843198931426]\n",
      "[INFO: 2022-02-17 07:34:29,127]   LabelSmoothing Loss = 2.7043557167053223\n",
      "[INFO: 2022-02-17 07:34:38,649] Iteration 64820 (DataTime/BatchTime: 0.00126/0.476) losses = 1.5855, lr = [1.735816475912362e-05, 0.0001735816475912362]\n",
      "[INFO: 2022-02-17 07:34:38,649]   LabelSmoothing Loss = 2.3024215698242188\n",
      "[INFO: 2022-02-17 07:34:48,178] Iteration 64840 (DataTime/BatchTime: 0.00127/0.476) losses = 1.4364, lr = [1.735548755862663e-05, 0.00017355487558626625]\n",
      "[INFO: 2022-02-17 07:34:48,178]   LabelSmoothing Loss = 0.8716947436332703\n",
      "[INFO: 2022-02-17 07:34:57,698] Iteration 64860 (DataTime/BatchTime: 0.00127/0.476) losses = 1.4486, lr = [1.7352811596485024e-05, 0.00017352811596485024]\n",
      "[INFO: 2022-02-17 07:34:57,698]   LabelSmoothing Loss = 1.2317990064620972\n",
      "[INFO: 2022-02-17 07:35:07,210] Iteration 64880 (DataTime/BatchTime: 0.00128/0.476) losses = 1.4908, lr = [1.735013687174443e-05, 0.00017350136871744428]\n",
      "[INFO: 2022-02-17 07:35:07,211]   LabelSmoothing Loss = 0.7189734578132629\n",
      "[INFO: 2022-02-17 07:35:16,670] Iteration 64900 (DataTime/BatchTime: 0.00127/0.473) losses = 1.5408, lr = [1.734746338345148e-05, 0.0001734746338345148]\n",
      "[INFO: 2022-02-17 07:35:16,671]   LabelSmoothing Loss = 2.1600120067596436\n",
      "[INFO: 2022-02-17 07:35:26,165] Iteration 64920 (DataTime/BatchTime: 0.00127/0.475) losses = 1.7003, lr = [1.7344791130653852e-05, 0.0001734479113065385]\n",
      "[INFO: 2022-02-17 07:35:26,166]   LabelSmoothing Loss = 1.8713891506195068\n",
      "[INFO: 2022-02-17 07:39:07,197] ######## Epoch (VAL)68 ########\n",
      "[INFO: 2022-02-17 07:39:07,197] {'Bleu_1': 0.36687525624824724, 'Bleu_2': 0.22153431448381714, 'Bleu_3': 0.1459764385248912, 'Bleu_4': 0.1008285959371842, 'METEOR': 0.18493665692962907, 'ROUGE_L': 0.29838865746858645, 'CIDEr': 0.2766855633605585}\n",
      "[INFO: 2022-02-17 07:42:42,704] ######## Epoch (TEST)68 ########\n",
      "[INFO: 2022-02-17 07:42:42,704] {'Bleu_1': 0.3230233213135299, 'Bleu_2': 0.18341978261461755, 'Bleu_3': 0.11229383929843208, 'Bleu_4': 0.06885192442759192, 'METEOR': 0.16579864773069025, 'ROUGE_L': 0.2685059569605114, 'CIDEr': 0.1712217991223846}\n",
      "[INFO: 2022-02-17 07:42:44,309] Iteration 64940 (DataTime/BatchTime: 1.01/1.6) losses = 0.76725, lr = [1.7342120112400238e-05, 0.00017342120112400237]\n",
      "[INFO: 2022-02-17 07:42:44,309]   LabelSmoothing Loss = 0.7672455906867981\n",
      "[INFO: 2022-02-17 07:42:53,863] Iteration 64960 (DataTime/BatchTime: 0.00135/0.478) losses = 1.3072, lr = [1.7339450327740363e-05, 0.0001733945032774036]\n",
      "[INFO: 2022-02-17 07:42:53,863]   LabelSmoothing Loss = 1.9308568239212036\n",
      "[INFO: 2022-02-17 07:43:03,384] Iteration 64980 (DataTime/BatchTime: 0.00212/0.476) losses = 1.3454, lr = [1.733678177572497e-05, 0.00017336781775724967]\n",
      "[INFO: 2022-02-17 07:43:03,384]   LabelSmoothing Loss = 0.8776928782463074\n",
      "[INFO: 2022-02-17 07:43:12,933] Iteration 65000 (DataTime/BatchTime: 0.0013/0.477) losses = 1.4717, lr = [1.7334114455405826e-05, 0.00017334114455405826]\n",
      "[INFO: 2022-02-17 07:43:12,933]   LabelSmoothing Loss = 0.9088010191917419\n",
      "[INFO: 2022-02-17 07:43:22,469] Iteration 65020 (DataTime/BatchTime: 0.00374/0.477) losses = 1.5085, lr = [1.7331448365835725e-05, 0.00017331448365835722]\n",
      "[INFO: 2022-02-17 07:43:22,469]   LabelSmoothing Loss = 1.7455788850784302\n",
      "[INFO: 2022-02-17 07:43:31,944] Iteration 65040 (DataTime/BatchTime: 0.00128/0.474) losses = 1.354, lr = [1.7328783506068473e-05, 0.0001732878350606847]\n",
      "[INFO: 2022-02-17 07:43:31,944]   LabelSmoothing Loss = 1.5210814476013184\n",
      "[INFO: 2022-02-17 07:43:41,516] Iteration 65060 (DataTime/BatchTime: 0.00369/0.479) losses = 1.5698, lr = [1.7326119875158895e-05, 0.00017326119875158894]\n",
      "[INFO: 2022-02-17 07:43:41,516]   LabelSmoothing Loss = 1.012883186340332\n",
      "[INFO: 2022-02-17 07:43:51,001] Iteration 65080 (DataTime/BatchTime: 0.00128/0.474) losses = 1.3889, lr = [1.7323457472162836e-05, 0.00017323457472162834]\n",
      "[INFO: 2022-02-17 07:43:51,001]   LabelSmoothing Loss = 1.1444463729858398\n",
      "[INFO: 2022-02-17 07:44:00,496] Iteration 65100 (DataTime/BatchTime: 0.00128/0.475) losses = 1.352, lr = [1.732079629613716e-05, 0.00017320796296137157]\n",
      "[INFO: 2022-02-17 07:44:00,496]   LabelSmoothing Loss = 1.2275034189224243\n",
      "[INFO: 2022-02-17 07:44:09,995] Iteration 65120 (DataTime/BatchTime: 0.00129/0.475) losses = 1.431, lr = [1.731813634613973e-05, 0.00017318136346139727]\n",
      "[INFO: 2022-02-17 07:44:09,995]   LabelSmoothing Loss = 1.801897644996643\n",
      "[INFO: 2022-02-17 07:44:19,492] Iteration 65140 (DataTime/BatchTime: 0.00128/0.475) losses = 1.3993, lr = [1.731547762122943e-05, 0.0001731547762122943]\n",
      "[INFO: 2022-02-17 07:44:19,492]   LabelSmoothing Loss = 1.8630651235580444\n",
      "[INFO: 2022-02-17 07:44:28,979] Iteration 65160 (DataTime/BatchTime: 0.00128/0.474) losses = 1.4778, lr = [1.7312820120466167e-05, 0.00017312820120466164]\n",
      "[INFO: 2022-02-17 07:44:28,979]   LabelSmoothing Loss = 1.1079739332199097\n",
      "[INFO: 2022-02-17 07:44:38,479] Iteration 65180 (DataTime/BatchTime: 0.00128/0.475) losses = 1.5266, lr = [1.7310163842910842e-05, 0.0001731016384291084]\n",
      "[INFO: 2022-02-17 07:44:38,479]   LabelSmoothing Loss = 0.8175977468490601\n",
      "[INFO: 2022-02-17 07:44:47,987] Iteration 65200 (DataTime/BatchTime: 0.00129/0.475) losses = 1.4518, lr = [1.7307508787625365e-05, 0.00017307508787625363]\n",
      "[INFO: 2022-02-17 07:44:47,987]   LabelSmoothing Loss = 2.029431104660034\n",
      "[INFO: 2022-02-17 07:44:57,511] Iteration 65220 (DataTime/BatchTime: 0.00127/0.476) losses = 1.5076, lr = [1.7304854953672656e-05, 0.00017304854953672654]\n",
      "[INFO: 2022-02-17 07:44:57,511]   LabelSmoothing Loss = 1.4575353860855103\n",
      "[INFO: 2022-02-17 07:45:07,058] Iteration 65240 (DataTime/BatchTime: 0.00208/0.477) losses = 1.4015, lr = [1.7302202340116648e-05, 0.00017302202340116645]\n",
      "[INFO: 2022-02-17 07:45:07,058]   LabelSmoothing Loss = 1.0987402200698853\n",
      "[INFO: 2022-02-17 07:45:16,590] Iteration 65260 (DataTime/BatchTime: 0.00125/0.477) losses = 1.4655, lr = [1.729955094602227e-05, 0.00017299550946022266]\n",
      "[INFO: 2022-02-17 07:45:16,590]   LabelSmoothing Loss = 1.337172031402588\n",
      "[INFO: 2022-02-17 07:45:26,066] Iteration 65280 (DataTime/BatchTime: 0.00125/0.474) losses = 1.3354, lr = [1.7296900770455447e-05, 0.00017296900770455445]\n",
      "[INFO: 2022-02-17 07:45:26,066]   LabelSmoothing Loss = 1.456761360168457\n",
      "[INFO: 2022-02-17 07:45:35,577] Iteration 65300 (DataTime/BatchTime: 0.00207/0.476) losses = 1.3418, lr = [1.7294251812483125e-05, 0.00017294251812483122]\n",
      "[INFO: 2022-02-17 07:45:35,577]   LabelSmoothing Loss = 1.3018972873687744\n",
      "[INFO: 2022-02-17 07:45:45,108] Iteration 65320 (DataTime/BatchTime: 0.00123/0.477) losses = 1.52, lr = [1.729160407117323e-05, 0.00017291604071173228]\n",
      "[INFO: 2022-02-17 07:45:45,108]   LabelSmoothing Loss = 1.239850640296936\n",
      "[INFO: 2022-02-17 07:45:54,650] Iteration 65340 (DataTime/BatchTime: 0.00124/0.477) losses = 1.5216, lr = [1.72889575455947e-05, 0.00017288957545594696]\n",
      "[INFO: 2022-02-17 07:45:54,650]   LabelSmoothing Loss = 1.5820690393447876\n",
      "[INFO: 2022-02-17 07:46:04,150] Iteration 65360 (DataTime/BatchTime: 0.00126/0.475) losses = 1.4365, lr = [1.7286312234817462e-05, 0.0001728631223481746]\n",
      "[INFO: 2022-02-17 07:46:04,151]   LabelSmoothing Loss = 1.9243980646133423\n",
      "[INFO: 2022-02-17 07:46:13,618] Iteration 65380 (DataTime/BatchTime: 0.00126/0.473) losses = 1.4888, lr = [1.7283668137912445e-05, 0.00017283668137912443]\n",
      "[INFO: 2022-02-17 07:46:13,619]   LabelSmoothing Loss = 2.6712121963500977\n",
      "[INFO: 2022-02-17 07:46:23,108] Iteration 65400 (DataTime/BatchTime: 0.00124/0.474) losses = 1.4756, lr = [1.7281025253951565e-05, 0.00017281025253951563]\n",
      "[INFO: 2022-02-17 07:46:23,108]   LabelSmoothing Loss = 1.0412653684616089\n",
      "[INFO: 2022-02-17 07:46:32,605] Iteration 65420 (DataTime/BatchTime: 0.00124/0.475) losses = 1.573, lr = [1.7278383582007743e-05, 0.0001727838358200774]\n",
      "[INFO: 2022-02-17 07:46:32,605]   LabelSmoothing Loss = 1.2856359481811523\n",
      "[INFO: 2022-02-17 07:46:42,074] Iteration 65440 (DataTime/BatchTime: 0.00125/0.473) losses = 1.5543, lr = [1.727574312115488e-05, 0.00017275743121154875]\n",
      "[INFO: 2022-02-17 07:46:42,074]   LabelSmoothing Loss = 1.613611102104187\n",
      "[INFO: 2022-02-17 07:46:51,597] Iteration 65460 (DataTime/BatchTime: 0.00125/0.476) losses = 1.4464, lr = [1.7273103870467866e-05, 0.00017273103870467865]\n",
      "[INFO: 2022-02-17 07:46:51,597]   LabelSmoothing Loss = 1.883978009223938\n",
      "[INFO: 2022-02-17 07:47:01,137] Iteration 65480 (DataTime/BatchTime: 0.00144/0.477) losses = 1.4261, lr = [1.7270465829022595e-05, 0.00017270465829022594]\n",
      "[INFO: 2022-02-17 07:47:01,137]   LabelSmoothing Loss = 0.8504711389541626\n",
      "[INFO: 2022-02-17 07:47:10,666] Iteration 65500 (DataTime/BatchTime: 0.00125/0.476) losses = 1.5125, lr = [1.7267828995895936e-05, 0.00017267828995895935]\n",
      "[INFO: 2022-02-17 07:47:10,666]   LabelSmoothing Loss = 1.6975288391113281\n",
      "[INFO: 2022-02-17 07:47:20,155] Iteration 65520 (DataTime/BatchTime: 0.00124/0.474) losses = 1.6509, lr = [1.726519337016575e-05, 0.00017265193370165748]\n",
      "[INFO: 2022-02-17 07:47:20,155]   LabelSmoothing Loss = 1.1281883716583252\n",
      "[INFO: 2022-02-17 07:47:29,627] Iteration 65540 (DataTime/BatchTime: 0.00125/0.474) losses = 1.3636, lr = [1.7262558950910874e-05, 0.00017262558950910872]\n",
      "[INFO: 2022-02-17 07:47:29,627]   LabelSmoothing Loss = 1.3475511074066162\n",
      "[INFO: 2022-02-17 07:47:39,125] Iteration 65560 (DataTime/BatchTime: 0.00125/0.475) losses = 1.4202, lr = [1.7259925737211143e-05, 0.00017259925737211142]\n",
      "[INFO: 2022-02-17 07:47:39,126]   LabelSmoothing Loss = 1.2238025665283203\n",
      "[INFO: 2022-02-17 07:47:48,704] Iteration 65580 (DataTime/BatchTime: 0.00228/0.479) losses = 1.3957, lr = [1.725729372814736e-05, 0.00017257293728147359]\n",
      "[INFO: 2022-02-17 07:47:48,704]   LabelSmoothing Loss = 1.1472604274749756\n",
      "[INFO: 2022-02-17 07:47:58,306] Iteration 65600 (DataTime/BatchTime: 0.00129/0.48) losses = 1.4834, lr = [1.725466292280132e-05, 0.00017254662922801318]\n",
      "[INFO: 2022-02-17 07:47:58,307]   LabelSmoothing Loss = 1.9404839277267456\n",
      "[INFO: 2022-02-17 07:48:07,912] Iteration 65620 (DataTime/BatchTime: 0.00126/0.48) losses = 1.5968, lr = [1.7252033320255792e-05, 0.00017252033320255792]\n",
      "[INFO: 2022-02-17 07:48:07,912]   LabelSmoothing Loss = 2.5072808265686035\n",
      "[INFO: 2022-02-17 07:48:17,533] Iteration 65640 (DataTime/BatchTime: 0.0014/0.481) losses = 1.434, lr = [1.724940491959452e-05, 0.0001724940491959452]\n",
      "[INFO: 2022-02-17 07:48:17,533]   LabelSmoothing Loss = 1.2698767185211182\n",
      "[INFO: 2022-02-17 07:48:27,113] Iteration 65660 (DataTime/BatchTime: 0.00127/0.479) losses = 1.474, lr = [1.724677771990224e-05, 0.00017246777719902236]\n",
      "[INFO: 2022-02-17 07:48:27,113]   LabelSmoothing Loss = 1.9618430137634277\n",
      "[INFO: 2022-02-17 07:48:36,821] Iteration 65680 (DataTime/BatchTime: 0.00127/0.485) losses = 1.57, lr = [1.7244151720264637e-05, 0.00017244151720264636]\n",
      "[INFO: 2022-02-17 07:48:36,821]   LabelSmoothing Loss = 3.385622262954712\n",
      "[INFO: 2022-02-17 07:48:46,429] Iteration 65700 (DataTime/BatchTime: 0.00258/0.48) losses = 1.3801, lr = [1.7241526919768397e-05, 0.00017241526919768393]\n",
      "[INFO: 2022-02-17 07:48:46,429]   LabelSmoothing Loss = 1.0201640129089355\n",
      "[INFO: 2022-02-17 07:48:55,978] Iteration 65720 (DataTime/BatchTime: 0.00129/0.477) losses = 1.6367, lr = [1.7238903317501163e-05, 0.0001723890331750116]\n",
      "[INFO: 2022-02-17 07:48:55,978]   LabelSmoothing Loss = 1.7346282005310059\n",
      "[INFO: 2022-02-17 07:49:05,721] Iteration 65740 (DataTime/BatchTime: 0.00126/0.487) losses = 1.5533, lr = [1.7236280912551554e-05, 0.00017236280912551552]\n",
      "[INFO: 2022-02-17 07:49:05,721]   LabelSmoothing Loss = 3.425149917602539\n",
      "[INFO: 2022-02-17 07:49:15,244] Iteration 65760 (DataTime/BatchTime: 0.00124/0.476) losses = 1.4958, lr = [1.723365970400916e-05, 0.00017233659704009159]\n",
      "[INFO: 2022-02-17 07:49:15,244]   LabelSmoothing Loss = 1.357401728630066\n",
      "[INFO: 2022-02-17 07:49:24,773] Iteration 65780 (DataTime/BatchTime: 0.00125/0.476) losses = 1.4359, lr = [1.723103969096454e-05, 0.00017231039690964538]\n",
      "[INFO: 2022-02-17 07:49:24,773]   LabelSmoothing Loss = 2.3208096027374268\n",
      "[INFO: 2022-02-17 07:49:34,308] Iteration 65800 (DataTime/BatchTime: 0.00126/0.477) losses = 1.3801, lr = [1.722842087250922e-05, 0.00017228420872509217]\n",
      "[INFO: 2022-02-17 07:49:34,308]   LabelSmoothing Loss = 1.400854229927063\n",
      "[INFO: 2022-02-17 07:49:43,912] Iteration 65820 (DataTime/BatchTime: 0.00124/0.48) losses = 1.6032, lr = [1.722580324773569e-05, 0.00017225803247735688]\n",
      "[INFO: 2022-02-17 07:49:43,912]   LabelSmoothing Loss = 1.8797192573547363\n",
      "[INFO: 2022-02-17 07:49:53,529] Iteration 65840 (DataTime/BatchTime: 0.00141/0.481) losses = 1.7007, lr = [1.7223186815737407e-05, 0.00017223186815737405]\n",
      "[INFO: 2022-02-17 07:49:53,530]   LabelSmoothing Loss = 1.9770311117172241\n",
      "[INFO: 2022-02-17 07:50:03,198] Iteration 65860 (DataTime/BatchTime: 0.00262/0.483) losses = 1.5304, lr = [1.722057157560879e-05, 0.0001722057157560879]\n",
      "[INFO: 2022-02-17 07:50:03,198]   LabelSmoothing Loss = 1.5632785558700562\n",
      "[INFO: 2022-02-17 07:50:12,879] Iteration 65880 (DataTime/BatchTime: 0.0015/0.484) losses = 1.4394, lr = [1.7217957526445226e-05, 0.00017217957526445224]\n",
      "[INFO: 2022-02-17 07:50:12,880]   LabelSmoothing Loss = 1.6266900300979614\n",
      "[INFO: 2022-02-17 07:53:49,491] ######## Epoch (VAL)69 ########\n",
      "[INFO: 2022-02-17 07:53:49,492] {'Bleu_1': 0.3617745790755095, 'Bleu_2': 0.21489810949792823, 'Bleu_3': 0.14037786898079002, 'Bleu_4': 0.09683217738793744, 'METEOR': 0.18251675424914482, 'ROUGE_L': 0.2888218413023368, 'CIDEr': 0.3019661571641483}\n",
      "[INFO: 2022-02-17 07:57:23,623] ######## Epoch (TEST)69 ########\n",
      "[INFO: 2022-02-17 07:57:23,624] {'Bleu_1': 0.33863572307043827, 'Bleu_2': 0.1938500608815155, 'Bleu_3': 0.11986744863193795, 'Bleu_4': 0.07413973645591145, 'METEOR': 0.1759556986066786, 'ROUGE_L': 0.2782960967842089, 'CIDEr': 0.18515986549240807}\n",
      "[INFO: 2022-02-17 07:57:27,561] Iteration 65900 (DataTime/BatchTime: 0.169/0.656) losses = 1.0425, lr = [1.7215344667343054e-05, 0.00017215344667343053]\n",
      "[INFO: 2022-02-17 07:57:27,561]   LabelSmoothing Loss = 1.039265513420105\n",
      "[INFO: 2022-02-17 07:57:37,056] Iteration 65920 (DataTime/BatchTime: 0.00218/0.475) losses = 1.4047, lr = [1.721273299739958e-05, 0.00017212732997399577]\n",
      "[INFO: 2022-02-17 07:57:37,057]   LabelSmoothing Loss = 1.540386438369751\n",
      "[INFO: 2022-02-17 07:57:46,583] Iteration 65940 (DataTime/BatchTime: 0.00121/0.476) losses = 1.2629, lr = [1.7210122515713062e-05, 0.00017210122515713062]\n",
      "[INFO: 2022-02-17 07:57:46,583]   LabelSmoothing Loss = 0.9258984923362732\n",
      "[INFO: 2022-02-17 07:57:56,153] Iteration 65960 (DataTime/BatchTime: 0.00206/0.478) losses = 1.6038, lr = [1.7207513221382723e-05, 0.0001720751322138272]\n",
      "[INFO: 2022-02-17 07:57:56,153]   LabelSmoothing Loss = 0.994878351688385\n",
      "[INFO: 2022-02-17 07:58:05,621] Iteration 65980 (DataTime/BatchTime: 0.00228/0.473) losses = 1.3921, lr = [1.7204905113508736e-05, 0.0001720490511350873]\n",
      "[INFO: 2022-02-17 07:58:05,621]   LabelSmoothing Loss = 1.7640624046325684\n",
      "[INFO: 2022-02-17 07:58:15,108] Iteration 66000 (DataTime/BatchTime: 0.00112/0.474) losses = 1.3579, lr = [1.7202298191192223e-05, 0.00017202298191192221]\n",
      "[INFO: 2022-02-17 07:58:15,108]   LabelSmoothing Loss = 1.598698377609253\n",
      "[INFO: 2022-02-17 07:58:24,608] Iteration 66020 (DataTime/BatchTime: 0.00119/0.475) losses = 1.3772, lr = [1.7199692453535276e-05, 0.00017199692453535273]\n",
      "[INFO: 2022-02-17 07:58:24,608]   LabelSmoothing Loss = 0.7880987524986267\n",
      "[INFO: 2022-02-17 07:58:34,064] Iteration 66040 (DataTime/BatchTime: 0.00207/0.473) losses = 1.3705, lr = [1.7197087899640923e-05, 0.0001719708789964092]\n",
      "[INFO: 2022-02-17 07:58:34,065]   LabelSmoothing Loss = 1.2009494304656982\n",
      "[INFO: 2022-02-17 07:58:43,531] Iteration 66060 (DataTime/BatchTime: 0.0013/0.473) losses = 1.4734, lr = [1.7194484528613146e-05, 0.00017194484528613145]\n",
      "[INFO: 2022-02-17 07:58:43,531]   LabelSmoothing Loss = 1.6475319862365723\n",
      "[INFO: 2022-02-17 07:58:52,965] Iteration 66080 (DataTime/BatchTime: 0.00203/0.472) losses = 1.2807, lr = [1.7191882339556885e-05, 0.0001719188233955688]\n",
      "[INFO: 2022-02-17 07:58:52,965]   LabelSmoothing Loss = 1.216515064239502\n",
      "[INFO: 2022-02-17 07:59:02,470] Iteration 66100 (DataTime/BatchTime: 0.00118/0.475) losses = 1.3778, lr = [1.7189281331578013e-05, 0.0001718928133157801]\n",
      "[INFO: 2022-02-17 07:59:02,470]   LabelSmoothing Loss = 1.2084689140319824\n",
      "[INFO: 2022-02-17 07:59:12,007] Iteration 66120 (DataTime/BatchTime: 0.00312/0.477) losses = 1.6737, lr = [1.7186681503783363e-05, 0.0001718668150378336]\n",
      "[INFO: 2022-02-17 07:59:12,007]   LabelSmoothing Loss = 0.8675354719161987\n",
      "[INFO: 2022-02-17 07:59:21,645] Iteration 66140 (DataTime/BatchTime: 0.00234/0.482) losses = 1.4625, lr = [1.7184082855280705e-05, 0.00017184082855280702]\n",
      "[INFO: 2022-02-17 07:59:21,646]   LabelSmoothing Loss = 2.6380062103271484\n",
      "[INFO: 2022-02-17 07:59:31,178] Iteration 66160 (DataTime/BatchTime: 0.00394/0.476) losses = 1.381, lr = [1.718148538517876e-05, 0.00017181485385178757]\n",
      "[INFO: 2022-02-17 07:59:31,178]   LabelSmoothing Loss = 1.21182119846344\n",
      "[INFO: 2022-02-17 07:59:40,771] Iteration 66180 (DataTime/BatchTime: 0.00198/0.48) losses = 1.5192, lr = [1.7178889092587185e-05, 0.00017178889092587182]\n",
      "[INFO: 2022-02-17 07:59:40,771]   LabelSmoothing Loss = 1.1576321125030518\n",
      "[INFO: 2022-02-17 07:59:50,295] Iteration 66200 (DataTime/BatchTime: 0.00215/0.476) losses = 1.507, lr = [1.7176293976616582e-05, 0.0001717629397661658]\n",
      "[INFO: 2022-02-17 07:59:50,295]   LabelSmoothing Loss = 1.6799108982086182\n",
      "[INFO: 2022-02-17 07:59:59,822] Iteration 66220 (DataTime/BatchTime: 0.00212/0.476) losses = 1.399, lr = [1.717370003637849e-05, 0.0001717370003637849]\n",
      "[INFO: 2022-02-17 07:59:59,822]   LabelSmoothing Loss = 1.1474976539611816\n",
      "[INFO: 2022-02-17 08:00:09,442] Iteration 66240 (DataTime/BatchTime: 0.00122/0.48) losses = 1.5967, lr = [1.7171107270985398e-05, 0.00017171107270985396]\n",
      "[INFO: 2022-02-17 08:00:09,442]   LabelSmoothing Loss = 1.8783372640609741\n",
      "[INFO: 2022-02-17 08:00:19,073] Iteration 66260 (DataTime/BatchTime: 0.00267/0.482) losses = 1.6254, lr = [1.7168515679550713e-05, 0.0001716851567955071]\n",
      "[INFO: 2022-02-17 08:00:19,073]   LabelSmoothing Loss = 1.3580580949783325\n",
      "[INFO: 2022-02-17 08:00:28,561] Iteration 66280 (DataTime/BatchTime: 0.00116/0.474) losses = 1.4239, lr = [1.71659252611888e-05, 0.00017165925261188795]\n",
      "[INFO: 2022-02-17 08:00:28,562]   LabelSmoothing Loss = 1.1673213243484497\n",
      "[INFO: 2022-02-17 08:00:38,103] Iteration 66300 (DataTime/BatchTime: 0.00213/0.477) losses = 1.3707, lr = [1.7163336015014937e-05, 0.00017163336015014937]\n",
      "[INFO: 2022-02-17 08:00:38,104]   LabelSmoothing Loss = 1.8863723278045654\n",
      "[INFO: 2022-02-17 08:00:47,890] Iteration 66320 (DataTime/BatchTime: 0.00205/0.489) losses = 1.6417, lr = [1.716074794014536e-05, 0.00017160747940145356]\n",
      "[INFO: 2022-02-17 08:00:47,890]   LabelSmoothing Loss = 0.7901198863983154\n",
      "[INFO: 2022-02-17 08:00:57,448] Iteration 66340 (DataTime/BatchTime: 0.00114/0.478) losses = 1.6637, lr = [1.7158161035697215e-05, 0.00017158161035697215]\n",
      "[INFO: 2022-02-17 08:00:57,448]   LabelSmoothing Loss = 2.3410446643829346\n",
      "[INFO: 2022-02-17 08:01:06,961] Iteration 66360 (DataTime/BatchTime: 0.002/0.476) losses = 1.3999, lr = [1.7155575300788596e-05, 0.00017155575300788596]\n",
      "[INFO: 2022-02-17 08:01:06,961]   LabelSmoothing Loss = 1.1687761545181274\n",
      "[INFO: 2022-02-17 08:01:16,477] Iteration 66380 (DataTime/BatchTime: 0.00118/0.476) losses = 1.3224, lr = [1.715299073453852e-05, 0.0001715299073453852]\n",
      "[INFO: 2022-02-17 08:01:16,477]   LabelSmoothing Loss = 1.7826632261276245\n",
      "[INFO: 2022-02-17 08:01:25,994] Iteration 66400 (DataTime/BatchTime: 0.00201/0.476) losses = 1.5118, lr = [1.715040733606693e-05, 0.0001715040733606693]\n",
      "[INFO: 2022-02-17 08:01:25,994]   LabelSmoothing Loss = 1.0747900009155273\n",
      "[INFO: 2022-02-17 08:01:35,550] Iteration 66420 (DataTime/BatchTime: 0.00573/0.478) losses = 1.367, lr = [1.71478251044947e-05, 0.00017147825104494698]\n",
      "[INFO: 2022-02-17 08:01:35,550]   LabelSmoothing Loss = 1.0331978797912598\n",
      "[INFO: 2022-02-17 08:01:45,148] Iteration 66440 (DataTime/BatchTime: 0.0013/0.48) losses = 1.5204, lr = [1.7145244038943634e-05, 0.00017145244038943634]\n",
      "[INFO: 2022-02-17 08:01:45,149]   LabelSmoothing Loss = 1.5420528650283813\n",
      "[INFO: 2022-02-17 08:01:54,735] Iteration 66460 (DataTime/BatchTime: 0.00127/0.479) losses = 1.4525, lr = [1.7142664138536453e-05, 0.00017142664138536452]\n",
      "[INFO: 2022-02-17 08:01:54,735]   LabelSmoothing Loss = 1.461086392402649\n",
      "[INFO: 2022-02-17 08:02:04,279] Iteration 66480 (DataTime/BatchTime: 0.00138/0.477) losses = 1.358, lr = [1.7140085402396806e-05, 0.00017140085402396805]\n",
      "[INFO: 2022-02-17 08:02:04,280]   LabelSmoothing Loss = 1.5002083778381348\n",
      "[INFO: 2022-02-17 08:02:13,843] Iteration 66500 (DataTime/BatchTime: 0.00118/0.478) losses = 1.4019, lr = [1.713750782964927e-05, 0.00017137507829649267]\n",
      "[INFO: 2022-02-17 08:02:13,843]   LabelSmoothing Loss = 1.6192818880081177\n",
      "[INFO: 2022-02-17 08:02:23,379] Iteration 66520 (DataTime/BatchTime: 0.00127/0.477) losses = 1.4817, lr = [1.713493141941933e-05, 0.00017134931419419326]\n",
      "[INFO: 2022-02-17 08:02:23,379]   LabelSmoothing Loss = 0.8196935653686523\n",
      "[INFO: 2022-02-17 08:02:33,062] Iteration 66540 (DataTime/BatchTime: 0.00136/0.484) losses = 1.3718, lr = [1.71323561708334e-05, 0.000171323561708334]\n",
      "[INFO: 2022-02-17 08:02:33,063]   LabelSmoothing Loss = 1.0286810398101807\n",
      "[INFO: 2022-02-17 08:02:42,606] Iteration 66560 (DataTime/BatchTime: 0.00205/0.477) losses = 1.5304, lr = [1.7129782083018818e-05, 0.00017129782083018816]\n",
      "[INFO: 2022-02-17 08:02:42,606]   LabelSmoothing Loss = 1.7638596296310425\n",
      "[INFO: 2022-02-17 08:02:52,312] Iteration 66580 (DataTime/BatchTime: 0.0021/0.485) losses = 1.5644, lr = [1.7127209155103824e-05, 0.00017127209155103822]\n",
      "[INFO: 2022-02-17 08:02:52,313]   LabelSmoothing Loss = 2.127215623855591\n",
      "[INFO: 2022-02-17 08:03:01,842] Iteration 66600 (DataTime/BatchTime: 0.00124/0.476) losses = 1.3833, lr = [1.712463738621759e-05, 0.0001712463738621759]\n",
      "[INFO: 2022-02-17 08:03:01,842]   LabelSmoothing Loss = 0.9814543128013611\n",
      "[INFO: 2022-02-17 08:03:11,471] Iteration 66620 (DataTime/BatchTime: 0.00126/0.481) losses = 1.5496, lr = [1.7122066775490197e-05, 0.00017122066775490194]\n",
      "[INFO: 2022-02-17 08:03:11,471]   LabelSmoothing Loss = 2.189746379852295\n",
      "[INFO: 2022-02-17 08:03:21,089] Iteration 66640 (DataTime/BatchTime: 0.0013/0.481) losses = 1.4919, lr = [1.7119497322052632e-05, 0.0001711949732205263]\n",
      "[INFO: 2022-02-17 08:03:21,089]   LabelSmoothing Loss = 1.2946152687072754\n",
      "[INFO: 2022-02-17 08:03:30,648] Iteration 66660 (DataTime/BatchTime: 0.00132/0.478) losses = 1.405, lr = [1.7116929025036805e-05, 0.00017116929025036803]\n",
      "[INFO: 2022-02-17 08:03:30,649]   LabelSmoothing Loss = 1.626868486404419\n",
      "[INFO: 2022-02-17 08:03:40,233] Iteration 66680 (DataTime/BatchTime: 0.00284/0.479) losses = 1.6747, lr = [1.7114361883575538e-05, 0.00017114361883575536]\n",
      "[INFO: 2022-02-17 08:03:40,233]   LabelSmoothing Loss = 0.49852991104125977\n",
      "[INFO: 2022-02-17 08:03:49,827] Iteration 66700 (DataTime/BatchTime: 0.00134/0.48) losses = 1.4149, lr = [1.7111795896802558e-05, 0.00017111795896802555]\n",
      "[INFO: 2022-02-17 08:03:49,828]   LabelSmoothing Loss = 1.100945234298706\n",
      "[INFO: 2022-02-17 08:03:59,434] Iteration 66720 (DataTime/BatchTime: 0.00139/0.48) losses = 1.5043, lr = [1.7109231063852495e-05, 0.00017109231063852493]\n",
      "[INFO: 2022-02-17 08:03:59,434]   LabelSmoothing Loss = 1.9616954326629639\n",
      "[INFO: 2022-02-17 08:04:09,076] Iteration 66740 (DataTime/BatchTime: 0.00145/0.482) losses = 1.6648, lr = [1.71066673838609e-05, 0.000171066673838609]\n",
      "[INFO: 2022-02-17 08:04:09,076]   LabelSmoothing Loss = 1.9358056783676147\n",
      "[INFO: 2022-02-17 08:04:18,752] Iteration 66760 (DataTime/BatchTime: 0.00132/0.484) losses = 1.5858, lr = [1.7104104855964227e-05, 0.00017104104855964226]\n",
      "[INFO: 2022-02-17 08:04:18,752]   LabelSmoothing Loss = 0.9982736706733704\n",
      "[INFO: 2022-02-17 08:04:28,342] Iteration 66780 (DataTime/BatchTime: 0.00138/0.479) losses = 1.4003, lr = [1.7101543479299827e-05, 0.00017101543479299824]\n",
      "[INFO: 2022-02-17 08:04:28,342]   LabelSmoothing Loss = 0.8337618708610535\n",
      "[INFO: 2022-02-17 08:04:37,940] Iteration 66800 (DataTime/BatchTime: 0.00225/0.48) losses = 1.4303, lr = [1.7098983253005963e-05, 0.0001709898325300596]\n",
      "[INFO: 2022-02-17 08:04:37,940]   LabelSmoothing Loss = 1.1627240180969238\n",
      "[INFO: 2022-02-17 08:04:47,486] Iteration 66820 (DataTime/BatchTime: 0.00223/0.477) losses = 1.3472, lr = [1.7096424176221796e-05, 0.00017096424176221795]\n",
      "[INFO: 2022-02-17 08:04:47,505]   LabelSmoothing Loss = 0.9512357115745544\n",
      "[INFO: 2022-02-17 08:04:57,051] Iteration 66840 (DataTime/BatchTime: 0.00229/0.478) losses = 1.2746, lr = [1.709386624808739e-05, 0.0001709386624808739]\n",
      "[INFO: 2022-02-17 08:04:57,051]   LabelSmoothing Loss = 1.465288758277893\n",
      "[INFO: 2022-02-17 08:08:34,331] ######## Epoch (VAL)70 ########\n",
      "[INFO: 2022-02-17 08:08:34,331] {'Bleu_1': 0.37672588753057784, 'Bleu_2': 0.2270724440279915, 'Bleu_3': 0.14920420871165613, 'Bleu_4': 0.10258696847869851, 'METEOR': 0.18928217124033442, 'ROUGE_L': 0.30186309084035795, 'CIDEr': 0.3165328852380084}\n",
      "[INFO: 2022-02-17 08:12:12,964] ######## Epoch (TEST)70 ########\n",
      "[INFO: 2022-02-17 08:12:12,964] {'Bleu_1': 0.3428231272916385, 'Bleu_2': 0.19879655496569526, 'Bleu_3': 0.1228836234641455, 'Bleu_4': 0.07767312063927716, 'METEOR': 0.17734727747928344, 'ROUGE_L': 0.27645012286920567, 'CIDEr': 0.23742474817704218}\n",
      "[INFO: 2022-02-17 08:12:19,395] Iteration 66860 (DataTime/BatchTime: 0.0979/0.585) losses = 1.5639, lr = [1.7091309467743718e-05, 0.00017091309467743716]\n",
      "[INFO: 2022-02-17 08:12:19,395]   LabelSmoothing Loss = 1.1464442014694214\n",
      "[INFO: 2022-02-17 08:12:28,877] Iteration 66880 (DataTime/BatchTime: 0.00116/0.474) losses = 1.4242, lr = [1.7088753834332636e-05, 0.00017088753834332637]\n",
      "[INFO: 2022-02-17 08:12:28,878]   LabelSmoothing Loss = 2.00785231590271\n",
      "[INFO: 2022-02-17 08:12:38,452] Iteration 66900 (DataTime/BatchTime: 0.00195/0.479) losses = 1.4714, lr = [1.7086199346996913e-05, 0.0001708619934699691]\n",
      "[INFO: 2022-02-17 08:12:38,452]   LabelSmoothing Loss = 0.3981085419654846\n",
      "[INFO: 2022-02-17 08:12:48,055] Iteration 66920 (DataTime/BatchTime: 0.00293/0.48) losses = 1.4716, lr = [1.70836460048802e-05, 0.000170836460048802]\n",
      "[INFO: 2022-02-17 08:12:48,056]   LabelSmoothing Loss = 1.228941798210144\n",
      "[INFO: 2022-02-17 08:12:57,573] Iteration 66940 (DataTime/BatchTime: 0.0035/0.476) losses = 1.3678, lr = [1.708109380712706e-05, 0.0001708109380712706]\n",
      "[INFO: 2022-02-17 08:12:57,573]   LabelSmoothing Loss = 1.5249122381210327\n",
      "[INFO: 2022-02-17 08:13:07,126] Iteration 66960 (DataTime/BatchTime: 0.00417/0.478) losses = 1.4715, lr = [1.7078542752882935e-05, 0.00017078542752882933]\n",
      "[INFO: 2022-02-17 08:13:07,126]   LabelSmoothing Loss = 1.604663610458374\n",
      "[INFO: 2022-02-17 08:13:16,833] Iteration 66980 (DataTime/BatchTime: 0.00396/0.485) losses = 1.339, lr = [1.7075992841294172e-05, 0.0001707599284129417]\n",
      "[INFO: 2022-02-17 08:13:16,833]   LabelSmoothing Loss = 0.7187471389770508\n",
      "[INFO: 2022-02-17 08:13:26,644] Iteration 67000 (DataTime/BatchTime: 0.00134/0.491) losses = 1.3962, lr = [1.7073444071508e-05, 0.00017073444071507999]\n",
      "[INFO: 2022-02-17 08:13:26,644]   LabelSmoothing Loss = 1.5516198873519897\n",
      "[INFO: 2022-02-17 08:13:36,193] Iteration 67020 (DataTime/BatchTime: 0.0013/0.477) losses = 1.2758, lr = [1.7070896442672546e-05, 0.00017070896442672543]\n",
      "[INFO: 2022-02-17 08:13:36,193]   LabelSmoothing Loss = 1.145027756690979\n",
      "[INFO: 2022-02-17 08:13:45,802] Iteration 67040 (DataTime/BatchTime: 0.00127/0.48) losses = 1.5711, lr = [1.7068349953936828e-05, 0.00017068349953936826]\n",
      "[INFO: 2022-02-17 08:13:45,802]   LabelSmoothing Loss = 0.6481226682662964\n",
      "[INFO: 2022-02-17 08:13:55,504] Iteration 67060 (DataTime/BatchTime: 0.00442/0.485) losses = 1.4527, lr = [1.7065804604450744e-05, 0.00017065804604450742]\n",
      "[INFO: 2022-02-17 08:13:55,505]   LabelSmoothing Loss = 2.73378324508667\n",
      "[INFO: 2022-02-17 08:14:05,225] Iteration 67080 (DataTime/BatchTime: 0.00312/0.486) losses = 1.6008, lr = [1.7063260393365083e-05, 0.0001706326039336508]\n",
      "[INFO: 2022-02-17 08:14:05,225]   LabelSmoothing Loss = 1.8586218357086182\n",
      "[INFO: 2022-02-17 08:14:14,982] Iteration 67100 (DataTime/BatchTime: 0.00225/0.488) losses = 1.3531, lr = [1.7060717319831524e-05, 0.0001706071731983152]\n",
      "[INFO: 2022-02-17 08:14:14,982]   LabelSmoothing Loss = 1.6075201034545898\n",
      "[INFO: 2022-02-17 08:14:24,568] Iteration 67120 (DataTime/BatchTime: 0.00237/0.479) losses = 1.4982, lr = [1.7058175383002624e-05, 0.00017058175383002623]\n",
      "[INFO: 2022-02-17 08:14:24,569]   LabelSmoothing Loss = 1.3772902488708496\n",
      "[INFO: 2022-02-17 08:14:34,241] Iteration 67140 (DataTime/BatchTime: 0.00312/0.483) losses = 1.5586, lr = [1.7055634582031828e-05, 0.00017055634582031828]\n",
      "[INFO: 2022-02-17 08:14:34,241]   LabelSmoothing Loss = 1.852765679359436\n",
      "[INFO: 2022-02-17 08:14:43,856] Iteration 67160 (DataTime/BatchTime: 0.00317/0.482) losses = 1.6172, lr = [1.7053094916073466e-05, 0.00017053094916073464]\n",
      "[INFO: 2022-02-17 08:14:43,856]   LabelSmoothing Loss = 1.5046850442886353\n",
      "[INFO: 2022-02-17 08:14:53,452] Iteration 67180 (DataTime/BatchTime: 0.00232/0.48) losses = 1.5452, lr = [1.705055638428274e-05, 0.0001705055638428274]\n",
      "[INFO: 2022-02-17 08:14:53,452]   LabelSmoothing Loss = 0.8158642649650574\n",
      "[INFO: 2022-02-17 08:15:02,988] Iteration 67200 (DataTime/BatchTime: 0.00121/0.477) losses = 1.4478, lr = [1.7048018985815744e-05, 0.00017048018985815741]\n",
      "[INFO: 2022-02-17 08:15:02,989]   LabelSmoothing Loss = 2.375089406967163\n",
      "[INFO: 2022-02-17 08:15:12,552] Iteration 67220 (DataTime/BatchTime: 0.00119/0.478) losses = 1.5315, lr = [1.7045482719829438e-05, 0.00017045482719829435]\n",
      "[INFO: 2022-02-17 08:15:12,552]   LabelSmoothing Loss = 0.87090003490448\n",
      "[INFO: 2022-02-17 08:15:22,142] Iteration 67240 (DataTime/BatchTime: 0.00312/0.479) losses = 1.4196, lr = [1.7042947585481666e-05, 0.00017042947585481664]\n",
      "[INFO: 2022-02-17 08:15:22,142]   LabelSmoothing Loss = 0.8992417454719543\n",
      "[INFO: 2022-02-17 08:15:31,817] Iteration 67260 (DataTime/BatchTime: 0.00367/0.484) losses = 1.7213, lr = [1.7040413581931156e-05, 0.00017040413581931153]\n",
      "[INFO: 2022-02-17 08:15:31,818]   LabelSmoothing Loss = 2.444082498550415\n",
      "[INFO: 2022-02-17 08:15:41,343] Iteration 67280 (DataTime/BatchTime: 0.00126/0.476) losses = 1.4261, lr = [1.7037880708337496e-05, 0.00017037880708337493]\n",
      "[INFO: 2022-02-17 08:15:41,343]   LabelSmoothing Loss = 0.8242063522338867\n",
      "[INFO: 2022-02-17 08:15:50,875] Iteration 67300 (DataTime/BatchTime: 0.00235/0.477) losses = 1.3871, lr = [1.703534896386116e-05, 0.00017035348963861157]\n",
      "[INFO: 2022-02-17 08:15:50,875]   LabelSmoothing Loss = 1.5416539907455444\n",
      "[INFO: 2022-02-17 08:16:00,430] Iteration 67320 (DataTime/BatchTime: 0.00129/0.478) losses = 1.3509, lr = [1.703281834766349e-05, 0.0001703281834766349]\n",
      "[INFO: 2022-02-17 08:16:00,431]   LabelSmoothing Loss = 0.5766870379447937\n",
      "[INFO: 2022-02-17 08:16:09,955] Iteration 67340 (DataTime/BatchTime: 0.00227/0.476) losses = 1.4989, lr = [1.70302888589067e-05, 0.00017030288858906702]\n",
      "[INFO: 2022-02-17 08:16:09,955]   LabelSmoothing Loss = 1.0298514366149902\n",
      "[INFO: 2022-02-17 08:16:19,652] Iteration 67360 (DataTime/BatchTime: 0.00137/0.485) losses = 1.3699, lr = [1.7027760496753884e-05, 0.0001702776049675388]\n",
      "[INFO: 2022-02-17 08:16:19,653]   LabelSmoothing Loss = 1.2183830738067627\n",
      "[INFO: 2022-02-17 08:16:29,369] Iteration 67380 (DataTime/BatchTime: 0.00372/0.486) losses = 1.6446, lr = [1.7025233260368985e-05, 0.0001702523326036898]\n",
      "[INFO: 2022-02-17 08:16:29,369]   LabelSmoothing Loss = 0.8459581136703491\n",
      "[INFO: 2022-02-17 08:16:39,005] Iteration 67400 (DataTime/BatchTime: 0.00146/0.482) losses = 1.441, lr = [1.702270714891683e-05, 0.0001702270714891683]\n",
      "[INFO: 2022-02-17 08:16:39,005]   LabelSmoothing Loss = 0.8335170149803162\n",
      "[INFO: 2022-02-17 08:16:48,662] Iteration 67420 (DataTime/BatchTime: 0.00131/0.483) losses = 1.445, lr = [1.7020182161563113e-05, 0.0001702018216156311]\n",
      "[INFO: 2022-02-17 08:16:48,662]   LabelSmoothing Loss = 2.2422327995300293\n",
      "[INFO: 2022-02-17 08:16:58,276] Iteration 67440 (DataTime/BatchTime: 0.00143/0.481) losses = 1.3952, lr = [1.7017658297474386e-05, 0.00017017658297474386]\n",
      "[INFO: 2022-02-17 08:16:58,276]   LabelSmoothing Loss = 1.235987663269043\n",
      "[INFO: 2022-02-17 08:17:07,847] Iteration 67460 (DataTime/BatchTime: 0.00225/0.479) losses = 1.446, lr = [1.7015135555818075e-05, 0.00017015135555818075]\n",
      "[INFO: 2022-02-17 08:17:07,847]   LabelSmoothing Loss = 1.1580599546432495\n",
      "[INFO: 2022-02-17 08:17:17,422] Iteration 67480 (DataTime/BatchTime: 0.00224/0.479) losses = 1.4025, lr = [1.7012613935762467e-05, 0.00017012613935762463]\n",
      "[INFO: 2022-02-17 08:17:17,423]   LabelSmoothing Loss = 1.5520888566970825\n",
      "[INFO: 2022-02-17 08:17:26,992] Iteration 67500 (DataTime/BatchTime: 0.00214/0.478) losses = 1.2747, lr = [1.70100934364767e-05, 0.00017010093436476697]\n",
      "[INFO: 2022-02-17 08:17:26,992]   LabelSmoothing Loss = 1.1024909019470215\n",
      "[INFO: 2022-02-17 08:17:36,637] Iteration 67520 (DataTime/BatchTime: 0.00249/0.482) losses = 1.7784, lr = [1.7007574057130792e-05, 0.0001700757405713079]\n",
      "[INFO: 2022-02-17 08:17:36,637]   LabelSmoothing Loss = 1.7096482515335083\n",
      "[INFO: 2022-02-17 08:17:46,194] Iteration 67540 (DataTime/BatchTime: 0.00133/0.478) losses = 1.3126, lr = [1.700505579689561e-05, 0.00017005055796895607]\n",
      "[INFO: 2022-02-17 08:17:46,194]   LabelSmoothing Loss = 1.510180950164795\n",
      "[INFO: 2022-02-17 08:17:55,924] Iteration 67560 (DataTime/BatchTime: 0.00242/0.487) losses = 1.4435, lr = [1.7002538654942882e-05, 0.00017002538654942878]\n",
      "[INFO: 2022-02-17 08:17:55,924]   LabelSmoothing Loss = 1.0888372659683228\n",
      "[INFO: 2022-02-17 08:18:05,517] Iteration 67580 (DataTime/BatchTime: 0.00246/0.48) losses = 1.494, lr = [1.7000022630445193e-05, 0.00017000022630445192]\n",
      "[INFO: 2022-02-17 08:18:05,517]   LabelSmoothing Loss = 2.142698049545288\n",
      "[INFO: 2022-02-17 08:18:15,004] Iteration 67600 (DataTime/BatchTime: 0.00211/0.474) losses = 1.4959, lr = [1.6997507722575988e-05, 0.00016997507722575986]\n",
      "[INFO: 2022-02-17 08:18:15,004]   LabelSmoothing Loss = 1.0217159986495972\n",
      "[INFO: 2022-02-17 08:18:24,535] Iteration 67620 (DataTime/BatchTime: 0.0013/0.477) losses = 1.3083, lr = [1.6994993930509565e-05, 0.00016994993930509564]\n",
      "[INFO: 2022-02-17 08:18:24,535]   LabelSmoothing Loss = 0.8838492631912231\n",
      "[INFO: 2022-02-17 08:18:34,084] Iteration 67640 (DataTime/BatchTime: 0.00139/0.477) losses = 1.4693, lr = [1.699248125342108e-05, 0.00016992481253421077]\n",
      "[INFO: 2022-02-17 08:18:34,085]   LabelSmoothing Loss = 1.6037663221359253\n",
      "[INFO: 2022-02-17 08:18:43,717] Iteration 67660 (DataTime/BatchTime: 0.00136/0.482) losses = 1.4809, lr = [1.6989969690486537e-05, 0.00016989969690486535]\n",
      "[INFO: 2022-02-17 08:18:43,717]   LabelSmoothing Loss = 1.5473756790161133\n",
      "[INFO: 2022-02-17 08:18:53,256] Iteration 67680 (DataTime/BatchTime: 0.00225/0.477) losses = 1.3546, lr = [1.6987459240882798e-05, 0.00016987459240882795]\n",
      "[INFO: 2022-02-17 08:18:53,256]   LabelSmoothing Loss = 1.5297353267669678\n",
      "[INFO: 2022-02-17 08:19:02,839] Iteration 67700 (DataTime/BatchTime: 0.0022/0.479) losses = 1.3387, lr = [1.698494990378757e-05, 0.00016984949903787569]\n",
      "[INFO: 2022-02-17 08:19:02,839]   LabelSmoothing Loss = 1.5646405220031738\n",
      "[INFO: 2022-02-17 08:19:12,414] Iteration 67720 (DataTime/BatchTime: 0.00234/0.479) losses = 1.3607, lr = [1.6982441678379418e-05, 0.00016982441678379414]\n",
      "[INFO: 2022-02-17 08:19:12,415]   LabelSmoothing Loss = 0.9795269966125488\n",
      "[INFO: 2022-02-17 08:19:21,963] Iteration 67740 (DataTime/BatchTime: 0.00315/0.477) losses = 1.4572, lr = [1.6979934563837747e-05, 0.00016979934563837745]\n",
      "[INFO: 2022-02-17 08:19:21,963]   LabelSmoothing Loss = 1.4901665449142456\n",
      "[INFO: 2022-02-17 08:19:31,497] Iteration 67760 (DataTime/BatchTime: 0.0014/0.477) losses = 1.262, lr = [1.6977428559342816e-05, 0.00016977428559342814]\n",
      "[INFO: 2022-02-17 08:19:31,497]   LabelSmoothing Loss = 0.6291700005531311\n",
      "[INFO: 2022-02-17 08:19:41,079] Iteration 67780 (DataTime/BatchTime: 0.00412/0.479) losses = 1.3784, lr = [1.6974923664075727e-05, 0.00016974923664075725]\n",
      "[INFO: 2022-02-17 08:19:41,079]   LabelSmoothing Loss = 0.9107745289802551\n",
      "[INFO: 2022-02-17 08:19:50,606] Iteration 67800 (DataTime/BatchTime: 0.00127/0.476) losses = 1.5988, lr = [1.697241987721843e-05, 0.0001697241987721843]\n",
      "[INFO: 2022-02-17 08:19:50,606]   LabelSmoothing Loss = 1.9117012023925781\n",
      "[INFO: 2022-02-17 08:23:24,745] ######## Epoch (VAL)71 ########\n",
      "[INFO: 2022-02-17 08:23:24,746] {'Bleu_1': 0.3599432814205901, 'Bleu_2': 0.21828488047266445, 'Bleu_3': 0.1445094029125027, 'Bleu_4': 0.10177947559947335, 'METEOR': 0.18751102420734256, 'ROUGE_L': 0.2962476804529241, 'CIDEr': 0.3700239849995696}\n",
      "[INFO: 2022-02-17 08:27:03,200] ######## Epoch (TEST)71 ########\n",
      "[INFO: 2022-02-17 08:27:03,200] {'Bleu_1': 0.33983171044074956, 'Bleu_2': 0.19625835236076, 'Bleu_3': 0.12213233857903609, 'Bleu_4': 0.0793925642134049, 'METEOR': 0.17623855770794425, 'ROUGE_L': 0.2779815520496007, 'CIDEr': 0.24476288492198806}\n",
      "[INFO: 2022-02-17 08:27:12,037] Iteration 67820 (DataTime/BatchTime: 0.069/0.552) losses = 1.714, lr = [1.696991719795372e-05, 0.00016969917197953718]\n",
      "[INFO: 2022-02-17 08:27:12,037]   LabelSmoothing Loss = 1.2972617149353027\n",
      "[INFO: 2022-02-17 08:27:21,500] Iteration 67840 (DataTime/BatchTime: 0.00308/0.473) losses = 1.302, lr = [1.6967415625465233e-05, 0.0001696741562546523]\n",
      "[INFO: 2022-02-17 08:27:21,500]   LabelSmoothing Loss = 1.3136810064315796\n",
      "[INFO: 2022-02-17 08:27:31,075] Iteration 67860 (DataTime/BatchTime: 0.00129/0.479) losses = 1.4424, lr = [1.6964915158937447e-05, 0.00016964915158937445]\n",
      "[INFO: 2022-02-17 08:27:31,075]   LabelSmoothing Loss = 1.2938556671142578\n",
      "[INFO: 2022-02-17 08:27:40,574] Iteration 67880 (DataTime/BatchTime: 0.00403/0.475) losses = 1.4317, lr = [1.6962415797555682e-05, 0.0001696241579755568]\n",
      "[INFO: 2022-02-17 08:27:40,574]   LabelSmoothing Loss = 1.132999062538147\n",
      "[INFO: 2022-02-17 08:27:50,119] Iteration 67900 (DataTime/BatchTime: 0.00225/0.477) losses = 1.2936, lr = [1.69599175405061e-05, 0.000169599175405061]\n",
      "[INFO: 2022-02-17 08:27:50,120]   LabelSmoothing Loss = 1.487270712852478\n",
      "[INFO: 2022-02-17 08:27:59,674] Iteration 67920 (DataTime/BatchTime: 0.00249/0.478) losses = 1.4844, lr = [1.69574203869757e-05, 0.00016957420386975696]\n",
      "[INFO: 2022-02-17 08:27:59,674]   LabelSmoothing Loss = 1.627968192100525\n",
      "[INFO: 2022-02-17 08:28:09,281] Iteration 67940 (DataTime/BatchTime: 0.00143/0.48) losses = 1.4758, lr = [1.6954924336152315e-05, 0.0001695492433615231]\n",
      "[INFO: 2022-02-17 08:28:09,281]   LabelSmoothing Loss = 2.185133934020996\n",
      "[INFO: 2022-02-17 08:28:18,860] Iteration 67960 (DataTime/BatchTime: 0.00137/0.479) losses = 1.3919, lr = [1.695242938722462e-05, 0.00016952429387224617]\n",
      "[INFO: 2022-02-17 08:28:18,860]   LabelSmoothing Loss = 1.726712942123413\n",
      "[INFO: 2022-02-17 08:28:28,417] Iteration 67980 (DataTime/BatchTime: 0.00311/0.478) losses = 1.3669, lr = [1.6949935539382118e-05, 0.00016949935539382118]\n",
      "[INFO: 2022-02-17 08:28:28,417]   LabelSmoothing Loss = 1.3897441625595093\n",
      "[INFO: 2022-02-17 08:28:37,997] Iteration 68000 (DataTime/BatchTime: 0.00133/0.479) losses = 1.4947, lr = [1.6947442791815162e-05, 0.0001694744279181516]\n",
      "[INFO: 2022-02-17 08:28:37,997]   LabelSmoothing Loss = 2.525777816772461\n",
      "[INFO: 2022-02-17 08:28:47,717] Iteration 68020 (DataTime/BatchTime: 0.00343/0.486) losses = 1.5584, lr = [1.6944951143714922e-05, 0.0001694495114371492]\n",
      "[INFO: 2022-02-17 08:28:47,717]   LabelSmoothing Loss = 1.8768678903579712\n",
      "[INFO: 2022-02-17 08:28:57,280] Iteration 68040 (DataTime/BatchTime: 0.00133/0.478) losses = 1.3913, lr = [1.6942460594273406e-05, 0.00016942460594273405]\n",
      "[INFO: 2022-02-17 08:28:57,280]   LabelSmoothing Loss = 2.2424046993255615\n",
      "[INFO: 2022-02-17 08:29:06,849] Iteration 68060 (DataTime/BatchTime: 0.00225/0.478) losses = 1.4472, lr = [1.6939971142683457e-05, 0.00016939971142683455]\n",
      "[INFO: 2022-02-17 08:29:06,849]   LabelSmoothing Loss = 1.5820354223251343\n",
      "[INFO: 2022-02-17 08:29:16,644] Iteration 68080 (DataTime/BatchTime: 0.00237/0.49) losses = 1.3312, lr = [1.693748278813874e-05, 0.00016937482788138735]\n",
      "[INFO: 2022-02-17 08:29:16,644]   LabelSmoothing Loss = 1.2781410217285156\n",
      "[INFO: 2022-02-17 08:29:26,161] Iteration 68100 (DataTime/BatchTime: 0.00135/0.476) losses = 1.2274, lr = [1.693499552983375e-05, 0.0001693499552983375]\n",
      "[INFO: 2022-02-17 08:29:26,161]   LabelSmoothing Loss = 0.7799806594848633\n",
      "[INFO: 2022-02-17 08:29:35,774] Iteration 68120 (DataTime/BatchTime: 0.00237/0.481) losses = 1.4064, lr = [1.6932509366963826e-05, 0.00016932509366963824]\n",
      "[INFO: 2022-02-17 08:29:35,775]   LabelSmoothing Loss = 1.942564845085144\n",
      "[INFO: 2022-02-17 08:29:45,412] Iteration 68140 (DataTime/BatchTime: 0.00136/0.482) losses = 1.5693, lr = [1.693002429872511e-05, 0.00016930024298725108]\n",
      "[INFO: 2022-02-17 08:29:45,412]   LabelSmoothing Loss = 2.3699147701263428\n",
      "[INFO: 2022-02-17 08:29:54,944] Iteration 68160 (DataTime/BatchTime: 0.00135/0.477) losses = 1.3189, lr = [1.692754032431458e-05, 0.00016927540324314578]\n",
      "[INFO: 2022-02-17 08:29:54,945]   LabelSmoothing Loss = 1.2252016067504883\n",
      "[INFO: 2022-02-17 08:30:04,487] Iteration 68180 (DataTime/BatchTime: 0.00132/0.477) losses = 1.4833, lr = [1.692505744293004e-05, 0.0001692505744293004]\n",
      "[INFO: 2022-02-17 08:30:04,487]   LabelSmoothing Loss = 1.2855089902877808\n",
      "[INFO: 2022-02-17 08:30:14,121] Iteration 68200 (DataTime/BatchTime: 0.00144/0.482) losses = 1.3331, lr = [1.692257565377012e-05, 0.00016922575653770117]\n",
      "[INFO: 2022-02-17 08:30:14,122]   LabelSmoothing Loss = 1.926103949546814\n",
      "[INFO: 2022-02-17 08:30:23,659] Iteration 68220 (DataTime/BatchTime: 0.00223/0.477) losses = 1.4147, lr = [1.6920094956034264e-05, 0.00016920094956034262]\n",
      "[INFO: 2022-02-17 08:30:23,660]   LabelSmoothing Loss = 1.5634844303131104\n",
      "[INFO: 2022-02-17 08:30:33,243] Iteration 68240 (DataTime/BatchTime: 0.00296/0.479) losses = 1.6139, lr = [1.691761534892274e-05, 0.0001691761534892274]\n",
      "[INFO: 2022-02-17 08:30:33,243]   LabelSmoothing Loss = 1.1617926359176636\n",
      "[INFO: 2022-02-17 08:30:42,877] Iteration 68260 (DataTime/BatchTime: 0.00225/0.482) losses = 1.4071, lr = [1.6915136831636645e-05, 0.00016915136831636645]\n",
      "[INFO: 2022-02-17 08:30:42,878]   LabelSmoothing Loss = 1.4524401426315308\n",
      "[INFO: 2022-02-17 08:30:52,470] Iteration 68280 (DataTime/BatchTime: 0.00214/0.48) losses = 1.3786, lr = [1.6912659403377885e-05, 0.0001691265940337788]\n",
      "[INFO: 2022-02-17 08:30:52,470]   LabelSmoothing Loss = 2.4215281009674072\n",
      "[INFO: 2022-02-17 08:31:02,048] Iteration 68300 (DataTime/BatchTime: 0.00137/0.479) losses = 1.5295, lr = [1.691018306334918e-05, 0.0001691018306334918]\n",
      "[INFO: 2022-02-17 08:31:02,048]   LabelSmoothing Loss = 2.755741834640503\n",
      "[INFO: 2022-02-17 08:31:11,618] Iteration 68320 (DataTime/BatchTime: 0.00216/0.479) losses = 1.3654, lr = [1.6907707810754082e-05, 0.00016907707810754082]\n",
      "[INFO: 2022-02-17 08:31:11,619]   LabelSmoothing Loss = 1.5687888860702515\n",
      "[INFO: 2022-02-17 08:31:21,184] Iteration 68340 (DataTime/BatchTime: 0.00319/0.478) losses = 1.2609, lr = [1.6905233644796945e-05, 0.00016905233644796944]\n",
      "[INFO: 2022-02-17 08:31:21,184]   LabelSmoothing Loss = 1.3851114511489868\n",
      "[INFO: 2022-02-17 08:31:30,813] Iteration 68360 (DataTime/BatchTime: 0.00381/0.481) losses = 1.6485, lr = [1.690276056468295e-05, 0.0001690276056468295]\n",
      "[INFO: 2022-02-17 08:31:30,813]   LabelSmoothing Loss = 1.7069380283355713\n",
      "[INFO: 2022-02-17 08:31:40,384] Iteration 68380 (DataTime/BatchTime: 0.00239/0.479) losses = 1.3735, lr = [1.690028856961808e-05, 0.00016900288569618078]\n",
      "[INFO: 2022-02-17 08:31:40,384]   LabelSmoothing Loss = 1.3078200817108154\n",
      "[INFO: 2022-02-17 08:31:49,947] Iteration 68400 (DataTime/BatchTime: 0.00132/0.478) losses = 1.5039, lr = [1.6897817658809134e-05, 0.0001689781765880913]\n",
      "[INFO: 2022-02-17 08:31:49,948]   LabelSmoothing Loss = 1.2172296047210693\n",
      "[INFO: 2022-02-17 08:31:59,544] Iteration 68420 (DataTime/BatchTime: 0.00135/0.48) losses = 1.4703, lr = [1.689534783146373e-05, 0.00016895347831463725]\n",
      "[INFO: 2022-02-17 08:31:59,544]   LabelSmoothing Loss = 2.177178382873535\n",
      "[INFO: 2022-02-17 08:32:09,201] Iteration 68440 (DataTime/BatchTime: 0.00144/0.483) losses = 1.5138, lr = [1.6892879086790284e-05, 0.00016892879086790282]\n",
      "[INFO: 2022-02-17 08:32:09,201]   LabelSmoothing Loss = 1.3684312105178833\n",
      "[INFO: 2022-02-17 08:32:18,780] Iteration 68460 (DataTime/BatchTime: 0.00135/0.479) losses = 1.4011, lr = [1.6890411423998032e-05, 0.0001689041142399803]\n",
      "[INFO: 2022-02-17 08:32:18,780]   LabelSmoothing Loss = 0.4163145124912262\n",
      "[INFO: 2022-02-17 08:32:28,329] Iteration 68480 (DataTime/BatchTime: 0.00136/0.477) losses = 1.6813, lr = [1.6887944842297015e-05, 0.00016887944842297012]\n",
      "[INFO: 2022-02-17 08:32:28,329]   LabelSmoothing Loss = 1.272891640663147\n",
      "[INFO: 2022-02-17 08:32:37,962] Iteration 68500 (DataTime/BatchTime: 0.00422/0.482) losses = 1.6603, lr = [1.6885479340898078e-05, 0.00016885479340898076]\n",
      "[INFO: 2022-02-17 08:32:37,962]   LabelSmoothing Loss = 1.354332685470581\n",
      "[INFO: 2022-02-17 08:32:47,628] Iteration 68520 (DataTime/BatchTime: 0.00137/0.483) losses = 1.4488, lr = [1.6883014919012878e-05, 0.00016883014919012878]\n",
      "[INFO: 2022-02-17 08:32:47,628]   LabelSmoothing Loss = 0.9093425273895264\n",
      "[INFO: 2022-02-17 08:32:57,272] Iteration 68540 (DataTime/BatchTime: 0.00309/0.482) losses = 1.3631, lr = [1.6880551575853874e-05, 0.00016880551575853872]\n",
      "[INFO: 2022-02-17 08:32:57,272]   LabelSmoothing Loss = 1.5890716314315796\n",
      "[INFO: 2022-02-17 08:33:06,911] Iteration 68560 (DataTime/BatchTime: 0.00139/0.482) losses = 1.6132, lr = [1.6878089310634328e-05, 0.00016878089310634324]\n",
      "[INFO: 2022-02-17 08:33:06,911]   LabelSmoothing Loss = 1.4730561971664429\n",
      "[INFO: 2022-02-17 08:33:16,487] Iteration 68580 (DataTime/BatchTime: 0.00137/0.479) losses = 1.5172, lr = [1.6875628122568305e-05, 0.00016875628122568304]\n",
      "[INFO: 2022-02-17 08:33:16,488]   LabelSmoothing Loss = 1.4493980407714844\n",
      "[INFO: 2022-02-17 08:33:26,081] Iteration 68600 (DataTime/BatchTime: 0.00137/0.48) losses = 1.4051, lr = [1.6873168010870674e-05, 0.00016873168010870672]\n",
      "[INFO: 2022-02-17 08:33:26,081]   LabelSmoothing Loss = 1.700955867767334\n",
      "[INFO: 2022-02-17 08:33:35,664] Iteration 68620 (DataTime/BatchTime: 0.00152/0.479) losses = 1.4156, lr = [1.6870708974757106e-05, 0.00016870708974757104]\n",
      "[INFO: 2022-02-17 08:33:35,664]   LabelSmoothing Loss = 0.854088544845581\n",
      "[INFO: 2022-02-17 08:33:45,233] Iteration 68640 (DataTime/BatchTime: 0.00134/0.478) losses = 1.4189, lr = [1.6868251013444068e-05, 0.00016868251013444068]\n",
      "[INFO: 2022-02-17 08:33:45,233]   LabelSmoothing Loss = 0.6530598402023315\n",
      "[INFO: 2022-02-17 08:33:54,743] Iteration 68660 (DataTime/BatchTime: 0.00129/0.476) losses = 1.3168, lr = [1.686579412614883e-05, 0.0001686579412614883]\n",
      "[INFO: 2022-02-17 08:33:54,744]   LabelSmoothing Loss = 2.0536746978759766\n",
      "[INFO: 2022-02-17 08:34:04,442] Iteration 68680 (DataTime/BatchTime: 0.00137/0.485) losses = 1.4943, lr = [1.6863338312089458e-05, 0.00016863338312089456]\n",
      "[INFO: 2022-02-17 08:34:04,442]   LabelSmoothing Loss = 1.0698262453079224\n",
      "[INFO: 2022-02-17 08:34:14,076] Iteration 68700 (DataTime/BatchTime: 0.00311/0.482) losses = 1.3314, lr = [1.6860883570484815e-05, 0.00016860883570484812]\n",
      "[INFO: 2022-02-17 08:34:14,076]   LabelSmoothing Loss = 1.073363184928894\n",
      "[INFO: 2022-02-17 08:34:23,690] Iteration 68720 (DataTime/BatchTime: 0.00306/0.481) losses = 1.2526, lr = [1.6858429900554554e-05, 0.00016858429900554553]\n",
      "[INFO: 2022-02-17 08:34:23,690]   LabelSmoothing Loss = 0.6309218406677246\n",
      "[INFO: 2022-02-17 08:34:33,348] Iteration 68740 (DataTime/BatchTime: 0.00159/0.483) losses = 1.4154, lr = [1.6855977301519134e-05, 0.00016855977301519134]\n",
      "[INFO: 2022-02-17 08:34:33,348]   LabelSmoothing Loss = 1.2656117677688599\n",
      "[INFO: 2022-02-17 08:38:13,973] ######## Epoch (VAL)72 ########\n",
      "[INFO: 2022-02-17 08:38:13,973] {'Bleu_1': 0.359534415544128, 'Bleu_2': 0.22074135270186898, 'Bleu_3': 0.14743159377917106, 'Bleu_4': 0.10264123136176345, 'METEOR': 0.18688803203241908, 'ROUGE_L': 0.2968746243837464, 'CIDEr': 0.32001531296434665}\n",
      "[INFO: 2022-02-17 08:41:48,057] ######## Epoch (TEST)72 ########\n",
      "[INFO: 2022-02-17 08:41:48,057] {'Bleu_1': 0.32321930028491447, 'Bleu_2': 0.18158032437972776, 'Bleu_3': 0.10816448643671449, 'Bleu_4': 0.0634143730248223, 'METEOR': 0.17232455853389358, 'ROUGE_L': 0.2774395975200992, 'CIDEr': 0.19714528380437096}\n",
      "[INFO: 2022-02-17 08:41:49,580] Iteration 68760 (DataTime/BatchTime: 0.936/1.52) losses = 2.0437, lr = [1.68535257725998e-05, 0.000168535257725998]\n",
      "[INFO: 2022-02-17 08:41:49,581]   LabelSmoothing Loss = 2.0437119007110596\n",
      "[INFO: 2022-02-17 08:41:59,041] Iteration 68780 (DataTime/BatchTime: 0.00341/0.473) losses = 1.4323, lr = [1.6851075313018593e-05, 0.0001685107531301859]\n",
      "[INFO: 2022-02-17 08:41:59,041]   LabelSmoothing Loss = 2.2812347412109375\n",
      "[INFO: 2022-02-17 08:42:08,436] Iteration 68800 (DataTime/BatchTime: 0.00134/0.47) losses = 1.4246, lr = [1.684862592199834e-05, 0.0001684862592199834]\n",
      "[INFO: 2022-02-17 08:42:08,436]   LabelSmoothing Loss = 1.5352400541305542\n",
      "[INFO: 2022-02-17 08:42:17,913] Iteration 68820 (DataTime/BatchTime: 0.00217/0.474) losses = 1.3888, lr = [1.6846177598762666e-05, 0.00016846177598762663]\n",
      "[INFO: 2022-02-17 08:42:17,913]   LabelSmoothing Loss = 0.6364743113517761\n",
      "[INFO: 2022-02-17 08:42:27,413] Iteration 68840 (DataTime/BatchTime: 0.00132/0.475) losses = 1.5037, lr = [1.6843730342535978e-05, 0.00016843730342535975]\n",
      "[INFO: 2022-02-17 08:42:27,413]   LabelSmoothing Loss = 2.3657779693603516\n",
      "[INFO: 2022-02-17 08:42:36,903] Iteration 68860 (DataTime/BatchTime: 0.00213/0.474) losses = 1.4125, lr = [1.684128415254348e-05, 0.00016841284152543476]\n",
      "[INFO: 2022-02-17 08:42:36,903]   LabelSmoothing Loss = 2.180943250656128\n",
      "[INFO: 2022-02-17 08:42:46,421] Iteration 68880 (DataTime/BatchTime: 0.0029/0.476) losses = 1.4981, lr = [1.683883902801115e-05, 0.0001683883902801115]\n",
      "[INFO: 2022-02-17 08:42:46,422]   LabelSmoothing Loss = 0.771415114402771\n",
      "[INFO: 2022-02-17 08:42:55,954] Iteration 68900 (DataTime/BatchTime: 0.0013/0.477) losses = 1.5129, lr = [1.6836394968165774e-05, 0.0001683639496816577]\n",
      "[INFO: 2022-02-17 08:42:55,954]   LabelSmoothing Loss = 0.9489779472351074\n",
      "[INFO: 2022-02-17 08:43:05,506] Iteration 68920 (DataTime/BatchTime: 0.00128/0.478) losses = 1.4628, lr = [1.68339519722349e-05, 0.000168339519722349]\n",
      "[INFO: 2022-02-17 08:43:05,506]   LabelSmoothing Loss = 1.6398659944534302\n",
      "[INFO: 2022-02-17 08:43:14,995] Iteration 68940 (DataTime/BatchTime: 0.00128/0.474) losses = 1.272, lr = [1.6831510039446877e-05, 0.00016831510039446877]\n",
      "[INFO: 2022-02-17 08:43:14,996]   LabelSmoothing Loss = 1.2493870258331299\n",
      "[INFO: 2022-02-17 08:43:24,524] Iteration 68960 (DataTime/BatchTime: 0.00127/0.476) losses = 1.4967, lr = [1.682906916903083e-05, 0.00016829069169030828]\n",
      "[INFO: 2022-02-17 08:43:24,524]   LabelSmoothing Loss = 1.814742922782898\n",
      "[INFO: 2022-02-17 08:43:33,977] Iteration 68980 (DataTime/BatchTime: 0.00126/0.473) losses = 1.2644, lr = [1.6826629360216663e-05, 0.00016826629360216662]\n",
      "[INFO: 2022-02-17 08:43:33,977]   LabelSmoothing Loss = 1.2809083461761475\n",
      "[INFO: 2022-02-17 08:43:43,472] Iteration 69000 (DataTime/BatchTime: 0.00126/0.475) losses = 1.3531, lr = [1.6824190612235072e-05, 0.0001682419061223507]\n",
      "[INFO: 2022-02-17 08:43:43,472]   LabelSmoothing Loss = 2.337775707244873\n",
      "[INFO: 2022-02-17 08:43:52,991] Iteration 69020 (DataTime/BatchTime: 0.00129/0.476) losses = 1.5454, lr = [1.6821752924317525e-05, 0.00016821752924317524]\n",
      "[INFO: 2022-02-17 08:43:52,992]   LabelSmoothing Loss = 2.1771292686462402\n",
      "[INFO: 2022-02-17 08:44:02,514] Iteration 69040 (DataTime/BatchTime: 0.00211/0.476) losses = 1.4218, lr = [1.6819316295696268e-05, 0.00016819316295696267]\n",
      "[INFO: 2022-02-17 08:44:02,514]   LabelSmoothing Loss = 0.9954740405082703\n",
      "[INFO: 2022-02-17 08:44:11,977] Iteration 69060 (DataTime/BatchTime: 0.00208/0.473) losses = 1.4065, lr = [1.6816880725604334e-05, 0.00016816880725604332]\n",
      "[INFO: 2022-02-17 08:44:11,977]   LabelSmoothing Loss = 2.0018317699432373\n",
      "[INFO: 2022-02-17 08:44:21,457] Iteration 69080 (DataTime/BatchTime: 0.00127/0.474) losses = 1.3487, lr = [1.6814446213275526e-05, 0.00016814446213275522]\n",
      "[INFO: 2022-02-17 08:44:21,458]   LabelSmoothing Loss = 1.6183216571807861\n",
      "[INFO: 2022-02-17 08:44:30,957] Iteration 69100 (DataTime/BatchTime: 0.00128/0.475) losses = 1.2753, lr = [1.681201275794442e-05, 0.0001681201275794442]\n",
      "[INFO: 2022-02-17 08:44:30,957]   LabelSmoothing Loss = 1.7904846668243408\n",
      "[INFO: 2022-02-17 08:44:40,592] Iteration 69120 (DataTime/BatchTime: 0.00206/0.482) losses = 1.5089, lr = [1.680958035884638e-05, 0.00016809580358846378]\n",
      "[INFO: 2022-02-17 08:44:40,592]   LabelSmoothing Loss = 1.4915902614593506\n",
      "[INFO: 2022-02-17 08:44:50,207] Iteration 69140 (DataTime/BatchTime: 0.00126/0.481) losses = 1.4059, lr = [1.680714901521753e-05, 0.00016807149015217527]\n",
      "[INFO: 2022-02-17 08:44:50,208]   LabelSmoothing Loss = 2.031008243560791\n",
      "[INFO: 2022-02-17 08:44:59,729] Iteration 69160 (DataTime/BatchTime: 0.00127/0.476) losses = 1.5532, lr = [1.6804718726294778e-05, 0.00016804718726294777]\n",
      "[INFO: 2022-02-17 08:44:59,729]   LabelSmoothing Loss = 1.805609107017517\n",
      "[INFO: 2022-02-17 08:45:09,270] Iteration 69180 (DataTime/BatchTime: 0.00127/0.476) losses = 1.3541, lr = [1.68022894913158e-05, 0.00016802289491315797]\n",
      "[INFO: 2022-02-17 08:45:09,271]   LabelSmoothing Loss = 2.1140003204345703\n",
      "[INFO: 2022-02-17 08:45:18,767] Iteration 69200 (DataTime/BatchTime: 0.00209/0.476) losses = 1.3633, lr = [1.6799861309519037e-05, 0.00016799861309519035]\n",
      "[INFO: 2022-02-17 08:45:18,767]   LabelSmoothing Loss = 2.3278071880340576\n",
      "[INFO: 2022-02-17 08:45:28,367] Iteration 69220 (DataTime/BatchTime: 0.00127/0.48) losses = 1.5384, lr = [1.679743418014371e-05, 0.0001679743418014371]\n",
      "[INFO: 2022-02-17 08:45:28,367]   LabelSmoothing Loss = 1.0011012554168701\n",
      "[INFO: 2022-02-17 08:45:37,926] Iteration 69240 (DataTime/BatchTime: 0.00125/0.478) losses = 1.6472, lr = [1.679500810242981e-05, 0.00016795008102429807]\n",
      "[INFO: 2022-02-17 08:45:37,926]   LabelSmoothing Loss = 2.1293551921844482\n",
      "[INFO: 2022-02-17 08:45:47,572] Iteration 69260 (DataTime/BatchTime: 0.00236/0.482) losses = 1.3954, lr = [1.6792583075618083e-05, 0.0001679258307561808]\n",
      "[INFO: 2022-02-17 08:45:47,572]   LabelSmoothing Loss = 1.9770275354385376\n",
      "[INFO: 2022-02-17 08:45:57,170] Iteration 69280 (DataTime/BatchTime: 0.00132/0.48) losses = 1.3855, lr = [1.6790159098950055e-05, 0.0001679015909895005]\n",
      "[INFO: 2022-02-17 08:45:57,170]   LabelSmoothing Loss = 1.6578567028045654\n",
      "[INFO: 2022-02-17 08:46:06,780] Iteration 69300 (DataTime/BatchTime: 0.00212/0.48) losses = 1.3262, lr = [1.6787736171668012e-05, 0.0001678773617166801]\n",
      "[INFO: 2022-02-17 08:46:06,781]   LabelSmoothing Loss = 1.3753411769866943\n",
      "[INFO: 2022-02-17 08:46:16,331] Iteration 69320 (DataTime/BatchTime: 0.00303/0.478) losses = 1.3627, lr = [1.6785314293015007e-05, 0.00016785314293015006]\n",
      "[INFO: 2022-02-17 08:46:16,331]   LabelSmoothing Loss = 0.9902083277702332\n",
      "[INFO: 2022-02-17 08:46:25,957] Iteration 69340 (DataTime/BatchTime: 0.00143/0.481) losses = 1.5471, lr = [1.6782893462234864e-05, 0.0001678289346223486]\n",
      "[INFO: 2022-02-17 08:46:25,957]   LabelSmoothing Loss = 0.9503421187400818\n",
      "[INFO: 2022-02-17 08:46:35,580] Iteration 69360 (DataTime/BatchTime: 0.0015/0.481) losses = 1.5381, lr = [1.678047367857215e-05, 0.00016780473678572149]\n",
      "[INFO: 2022-02-17 08:46:35,580]   LabelSmoothing Loss = 1.6613895893096924\n",
      "[INFO: 2022-02-17 08:46:45,183] Iteration 69380 (DataTime/BatchTime: 0.0029/0.48) losses = 1.5444, lr = [1.677805494127222e-05, 0.00016778054941272218]\n",
      "[INFO: 2022-02-17 08:46:45,183]   LabelSmoothing Loss = 2.644411087036133\n",
      "[INFO: 2022-02-17 08:46:54,719] Iteration 69400 (DataTime/BatchTime: 0.00207/0.477) losses = 1.4286, lr = [1.677563724958117e-05, 0.00016775637249581167]\n",
      "[INFO: 2022-02-17 08:46:54,719]   LabelSmoothing Loss = 1.3073837757110596\n",
      "[INFO: 2022-02-17 08:47:04,299] Iteration 69420 (DataTime/BatchTime: 0.00129/0.479) losses = 1.3574, lr = [1.6773220602745866e-05, 0.00016773220602745866]\n",
      "[INFO: 2022-02-17 08:47:04,299]   LabelSmoothing Loss = 1.658892035484314\n",
      "[INFO: 2022-02-17 08:47:13,874] Iteration 69440 (DataTime/BatchTime: 0.00291/0.479) losses = 1.3939, lr = [1.6770805000013934e-05, 0.00016770805000013934]\n",
      "[INFO: 2022-02-17 08:47:13,875]   LabelSmoothing Loss = 0.8385348916053772\n",
      "[INFO: 2022-02-17 08:47:23,476] Iteration 69460 (DataTime/BatchTime: 0.00148/0.48) losses = 1.6657, lr = [1.6768390440633752e-05, 0.00016768390440633751]\n",
      "[INFO: 2022-02-17 08:47:23,477]   LabelSmoothing Loss = 1.0537086725234985\n",
      "[INFO: 2022-02-17 08:47:33,154] Iteration 69480 (DataTime/BatchTime: 0.00126/0.484) losses = 1.4677, lr = [1.676597692385446e-05, 0.00016765976923854457]\n",
      "[INFO: 2022-02-17 08:47:33,155]   LabelSmoothing Loss = 0.8937987089157104\n",
      "[INFO: 2022-02-17 08:47:42,762] Iteration 69500 (DataTime/BatchTime: 0.00257/0.48) losses = 1.3748, lr = [1.6763564448925952e-05, 0.0001676356444892595]\n",
      "[INFO: 2022-02-17 08:47:42,762]   LabelSmoothing Loss = 1.408552885055542\n",
      "[INFO: 2022-02-17 08:47:52,321] Iteration 69520 (DataTime/BatchTime: 0.00128/0.478) losses = 1.3088, lr = [1.6761153015098884e-05, 0.0001676115301509888]\n",
      "[INFO: 2022-02-17 08:47:52,321]   LabelSmoothing Loss = 1.2172561883926392\n",
      "[INFO: 2022-02-17 08:48:01,930] Iteration 69540 (DataTime/BatchTime: 0.00235/0.48) losses = 1.3456, lr = [1.675874262162465e-05, 0.00016758742621624648]\n",
      "[INFO: 2022-02-17 08:48:01,930]   LabelSmoothing Loss = 1.0089181661605835\n",
      "[INFO: 2022-02-17 08:48:11,500] Iteration 69560 (DataTime/BatchTime: 0.0022/0.478) losses = 1.3623, lr = [1.6756333267755417e-05, 0.00016756333267755415]\n",
      "[INFO: 2022-02-17 08:48:11,500]   LabelSmoothing Loss = 0.9110369086265564\n",
      "[INFO: 2022-02-17 08:48:21,234] Iteration 69580 (DataTime/BatchTime: 0.00151/0.487) losses = 1.4095, lr = [1.6753924952744094e-05, 0.00016753924952744092]\n",
      "[INFO: 2022-02-17 08:48:21,235]   LabelSmoothing Loss = 2.101391553878784\n",
      "[INFO: 2022-02-17 08:48:30,784] Iteration 69600 (DataTime/BatchTime: 0.00136/0.477) losses = 1.4103, lr = [1.6751517675844336e-05, 0.00016751517675844336]\n",
      "[INFO: 2022-02-17 08:48:30,784]   LabelSmoothing Loss = 1.7094367742538452\n",
      "[INFO: 2022-02-17 08:48:40,342] Iteration 69620 (DataTime/BatchTime: 0.00217/0.478) losses = 1.5073, lr = [1.6749111436310566e-05, 0.00016749111436310563]\n",
      "[INFO: 2022-02-17 08:48:40,342]   LabelSmoothing Loss = 1.8669440746307373\n",
      "[INFO: 2022-02-17 08:48:49,957] Iteration 69640 (DataTime/BatchTime: 0.00131/0.481) losses = 1.4427, lr = [1.674670623339794e-05, 0.00016746706233397937]\n",
      "[INFO: 2022-02-17 08:48:49,958]   LabelSmoothing Loss = 1.2988495826721191\n",
      "[INFO: 2022-02-17 08:48:59,518] Iteration 69660 (DataTime/BatchTime: 0.00131/0.478) losses = 1.4072, lr = [1.6744302066362365e-05, 0.00016744302066362365]\n",
      "[INFO: 2022-02-17 08:48:59,518]   LabelSmoothing Loss = 1.933929681777954\n",
      "[INFO: 2022-02-17 08:49:09,089] Iteration 69680 (DataTime/BatchTime: 0.00211/0.479) losses = 1.5083, lr = [1.6741898934460504e-05, 0.00016741898934460504]\n",
      "[INFO: 2022-02-17 08:49:09,089]   LabelSmoothing Loss = 1.774415135383606\n",
      "[INFO: 2022-02-17 08:49:18,756] Iteration 69700 (DataTime/BatchTime: 0.00136/0.483) losses = 1.4591, lr = [1.6739496836949762e-05, 0.0001673949683694976]\n",
      "[INFO: 2022-02-17 08:49:18,756]   LabelSmoothing Loss = 1.2089018821716309\n",
      "[INFO: 2022-02-17 08:52:59,364] ######## Epoch (VAL)73 ########\n",
      "[INFO: 2022-02-17 08:52:59,364] {'Bleu_1': 0.37824556563004746, 'Bleu_2': 0.2312388257405095, 'Bleu_3': 0.1552234107123029, 'Bleu_4': 0.11110276889471793, 'METEOR': 0.1930368315819105, 'ROUGE_L': 0.30021273964043177, 'CIDEr': 0.35553575125498804}\n",
      "[INFO: 2022-02-17 08:56:38,726] ######## Epoch (TEST)73 ########\n",
      "[INFO: 2022-02-17 08:56:38,727] {'Bleu_1': 0.3354909960412283, 'Bleu_2': 0.18988603162046214, 'Bleu_3': 0.11503098795200885, 'Bleu_4': 0.06901193133577042, 'METEOR': 0.17325506285302764, 'ROUGE_L': 0.2700127417270001, 'CIDEr': 0.1927868498981204}\n",
      "[INFO: 2022-02-17 08:56:42,780] Iteration 69720 (DataTime/BatchTime: 0.191/0.675) losses = 1.2681, lr = [1.6737095773088285e-05, 0.00016737095773088285]\n",
      "[INFO: 2022-02-17 08:56:42,781]   LabelSmoothing Loss = 1.3977988958358765\n",
      "[INFO: 2022-02-17 08:56:52,385] Iteration 69740 (DataTime/BatchTime: 0.00235/0.48) losses = 1.2651, lr = [1.6734695742134968e-05, 0.00016734695742134966]\n",
      "[INFO: 2022-02-17 08:56:52,385]   LabelSmoothing Loss = 1.371269702911377\n",
      "[INFO: 2022-02-17 08:57:01,876] Iteration 69760 (DataTime/BatchTime: 0.00118/0.475) losses = 1.289, lr = [1.6732296743349455e-05, 0.00016732296743349453]\n",
      "[INFO: 2022-02-17 08:57:01,876]   LabelSmoothing Loss = 2.0061261653900146\n",
      "[INFO: 2022-02-17 08:57:11,402] Iteration 69780 (DataTime/BatchTime: 0.00119/0.476) losses = 1.4971, lr = [1.672989877599212e-05, 0.0001672989877599212]\n",
      "[INFO: 2022-02-17 08:57:11,402]   LabelSmoothing Loss = 2.5366668701171875\n",
      "[INFO: 2022-02-17 08:57:20,905] Iteration 69800 (DataTime/BatchTime: 0.00324/0.475) losses = 1.1796, lr = [1.6727501839324088e-05, 0.00016727501839324088]\n",
      "[INFO: 2022-02-17 08:57:20,905]   LabelSmoothing Loss = 1.2211850881576538\n",
      "[INFO: 2022-02-17 08:57:30,545] Iteration 69820 (DataTime/BatchTime: 0.00336/0.482) losses = 1.581, lr = [1.6725105932607226e-05, 0.00016725105932607225]\n",
      "[INFO: 2022-02-17 08:57:30,546]   LabelSmoothing Loss = 1.5357310771942139\n",
      "[INFO: 2022-02-17 08:57:40,017] Iteration 69840 (DataTime/BatchTime: 0.00099/0.474) losses = 1.2909, lr = [1.6722711055104133e-05, 0.00016722711055104132]\n",
      "[INFO: 2022-02-17 08:57:40,017]   LabelSmoothing Loss = 0.3264235854148865\n",
      "[INFO: 2022-02-17 08:57:49,599] Iteration 69860 (DataTime/BatchTime: 0.00277/0.479) losses = 1.6098, lr = [1.6720317206078155e-05, 0.00016720317206078152]\n",
      "[INFO: 2022-02-17 08:57:49,599]   LabelSmoothing Loss = 1.0033197402954102\n",
      "[INFO: 2022-02-17 08:57:59,101] Iteration 69880 (DataTime/BatchTime: 0.00108/0.475) losses = 1.3689, lr = [1.671792438479337e-05, 0.0001671792438479337]\n",
      "[INFO: 2022-02-17 08:57:59,101]   LabelSmoothing Loss = 2.5191681385040283\n",
      "[INFO: 2022-02-17 08:58:08,650] Iteration 69900 (DataTime/BatchTime: 0.000989/0.477) losses = 1.3557, lr = [1.6715532590514596e-05, 0.00016715532590514596]\n",
      "[INFO: 2022-02-17 08:58:08,650]   LabelSmoothing Loss = 2.1370773315429688\n",
      "[INFO: 2022-02-17 08:58:18,143] Iteration 69920 (DataTime/BatchTime: 0.00199/0.475) losses = 1.4271, lr = [1.671314182250739e-05, 0.00016713141822507387]\n",
      "[INFO: 2022-02-17 08:58:18,144]   LabelSmoothing Loss = 1.5204585790634155\n",
      "[INFO: 2022-02-17 08:58:27,668] Iteration 69940 (DataTime/BatchTime: 0.00155/0.476) losses = 1.2658, lr = [1.6710752080038032e-05, 0.0001671075208003803]\n",
      "[INFO: 2022-02-17 08:58:27,668]   LabelSmoothing Loss = 1.1729027032852173\n",
      "[INFO: 2022-02-17 08:58:37,241] Iteration 69960 (DataTime/BatchTime: 0.00114/0.479) losses = 1.5069, lr = [1.670836336237355e-05, 0.00016708363362373548]\n",
      "[INFO: 2022-02-17 08:58:37,241]   LabelSmoothing Loss = 1.536889672279358\n",
      "[INFO: 2022-02-17 08:58:46,784] Iteration 69980 (DataTime/BatchTime: 0.00234/0.477) losses = 1.4429, lr = [1.67059756687817e-05, 0.00016705975668781698]\n",
      "[INFO: 2022-02-17 08:58:46,784]   LabelSmoothing Loss = 1.7454893589019775\n",
      "[INFO: 2022-02-17 08:58:56,296] Iteration 70000 (DataTime/BatchTime: 0.000958/0.476) losses = 1.4352, lr = [1.670358899853097e-05, 0.00016703588998530968]\n",
      "[INFO: 2022-02-17 08:58:56,297]   LabelSmoothing Loss = 1.1553654670715332\n",
      "[INFO: 2022-02-17 08:59:05,840] Iteration 70020 (DataTime/BatchTime: 0.00188/0.477) losses = 1.2835, lr = [1.670120335089058e-05, 0.0001670120335089058]\n",
      "[INFO: 2022-02-17 08:59:05,840]   LabelSmoothing Loss = 1.7433940172195435\n",
      "[INFO: 2022-02-17 08:59:15,384] Iteration 70040 (DataTime/BatchTime: 0.00104/0.477) losses = 1.2432, lr = [1.6698818725130482e-05, 0.0001669881872513048]\n",
      "[INFO: 2022-02-17 08:59:15,384]   LabelSmoothing Loss = 1.4229300022125244\n",
      "[INFO: 2022-02-17 08:59:24,966] Iteration 70060 (DataTime/BatchTime: 0.00195/0.479) losses = 1.456, lr = [1.6696435120521347e-05, 0.00016696435120521345]\n",
      "[INFO: 2022-02-17 08:59:24,966]   LabelSmoothing Loss = 2.047795295715332\n",
      "[INFO: 2022-02-17 08:59:34,632] Iteration 70080 (DataTime/BatchTime: 0.00259/0.483) losses = 1.4301, lr = [1.6694052536334593e-05, 0.00016694052536334592]\n",
      "[INFO: 2022-02-17 08:59:34,632]   LabelSmoothing Loss = 1.0365979671478271\n",
      "[INFO: 2022-02-17 08:59:44,304] Iteration 70100 (DataTime/BatchTime: 0.00229/0.484) losses = 1.6557, lr = [1.669167097184235e-05, 0.0001669167097184235]\n",
      "[INFO: 2022-02-17 08:59:44,304]   LabelSmoothing Loss = 3.049355983734131\n",
      "[INFO: 2022-02-17 08:59:53,932] Iteration 70120 (DataTime/BatchTime: 0.00221/0.481) losses = 1.5763, lr = [1.6689290426317482e-05, 0.00016689290426317478]\n",
      "[INFO: 2022-02-17 08:59:53,932]   LabelSmoothing Loss = 0.7531537413597107\n",
      "[INFO: 2022-02-17 09:00:03,473] Iteration 70140 (DataTime/BatchTime: 0.00213/0.477) losses = 1.5053, lr = [1.6686910899033576e-05, 0.0001668691089903357]\n",
      "[INFO: 2022-02-17 09:00:03,473]   LabelSmoothing Loss = 0.8197822570800781\n",
      "[INFO: 2022-02-17 09:00:13,036] Iteration 70160 (DataTime/BatchTime: 0.00102/0.477) losses = 1.4373, lr = [1.668453238926494e-05, 0.0001668453238926494]\n",
      "[INFO: 2022-02-17 09:00:13,036]   LabelSmoothing Loss = 1.254319190979004\n",
      "[INFO: 2022-02-17 09:00:22,588] Iteration 70180 (DataTime/BatchTime: 0.00369/0.478) losses = 1.5402, lr = [1.668215489628662e-05, 0.00016682154896286618]\n",
      "[INFO: 2022-02-17 09:00:22,588]   LabelSmoothing Loss = 0.8883882761001587\n",
      "[INFO: 2022-02-17 09:00:32,250] Iteration 70200 (DataTime/BatchTime: 0.00125/0.483) losses = 1.3314, lr = [1.667977841937437e-05, 0.00016679778419374366]\n",
      "[INFO: 2022-02-17 09:00:32,250]   LabelSmoothing Loss = 1.3027245998382568\n",
      "[INFO: 2022-02-17 09:00:41,885] Iteration 70220 (DataTime/BatchTime: 0.00299/0.482) losses = 1.3353, lr = [1.667740295780467e-05, 0.00016677402957804668]\n",
      "[INFO: 2022-02-17 09:00:41,885]   LabelSmoothing Loss = 1.6113512516021729\n",
      "[INFO: 2022-02-17 09:00:51,476] Iteration 70240 (DataTime/BatchTime: 0.00205/0.479) losses = 1.4302, lr = [1.6675028510854724e-05, 0.00016675028510854722]\n",
      "[INFO: 2022-02-17 09:00:51,476]   LabelSmoothing Loss = 1.620509147644043\n",
      "[INFO: 2022-02-17 09:01:01,044] Iteration 70260 (DataTime/BatchTime: 0.00204/0.479) losses = 1.2281, lr = [1.6672655077802457e-05, 0.00016672655077802455]\n",
      "[INFO: 2022-02-17 09:01:01,044]   LabelSmoothing Loss = 1.2044317722320557\n",
      "[INFO: 2022-02-17 09:01:10,629] Iteration 70280 (DataTime/BatchTime: 0.00205/0.479) losses = 1.5079, lr = [1.667028265792651e-05, 0.00016670282657926507]\n",
      "[INFO: 2022-02-17 09:01:10,629]   LabelSmoothing Loss = 1.1766307353973389\n",
      "[INFO: 2022-02-17 09:01:20,134] Iteration 70300 (DataTime/BatchTime: 0.00112/0.475) losses = 1.2963, lr = [1.666791125050624e-05, 0.00016667911250506238]\n",
      "[INFO: 2022-02-17 09:01:20,134]   LabelSmoothing Loss = 1.1090108156204224\n",
      "[INFO: 2022-02-17 09:01:29,734] Iteration 70320 (DataTime/BatchTime: 0.0011/0.48) losses = 1.6414, lr = [1.6665540854821725e-05, 0.00016665540854821724]\n",
      "[INFO: 2022-02-17 09:01:29,734]   LabelSmoothing Loss = 2.539752721786499\n",
      "[INFO: 2022-02-17 09:01:39,249] Iteration 70340 (DataTime/BatchTime: 0.00112/0.476) losses = 1.3123, lr = [1.6663171470153766e-05, 0.00016663171470153763]\n",
      "[INFO: 2022-02-17 09:01:39,249]   LabelSmoothing Loss = 2.5231964588165283\n",
      "[INFO: 2022-02-17 09:01:48,816] Iteration 70360 (DataTime/BatchTime: 0.002/0.478) losses = 1.3687, lr = [1.6660803095783864e-05, 0.00016660803095783862]\n",
      "[INFO: 2022-02-17 09:01:48,817]   LabelSmoothing Loss = 1.8979214429855347\n",
      "[INFO: 2022-02-17 09:01:58,540] Iteration 70380 (DataTime/BatchTime: 0.00232/0.486) losses = 1.4299, lr = [1.6658435730994247e-05, 0.00016658435730994246]\n",
      "[INFO: 2022-02-17 09:01:58,540]   LabelSmoothing Loss = 1.5383111238479614\n",
      "[INFO: 2022-02-17 09:02:08,156] Iteration 70400 (DataTime/BatchTime: 0.00135/0.48) losses = 1.5029, lr = [1.6656069375067852e-05, 0.00016656069375067852]\n",
      "[INFO: 2022-02-17 09:02:08,157]   LabelSmoothing Loss = 1.4915988445281982\n",
      "[INFO: 2022-02-17 09:02:17,929] Iteration 70420 (DataTime/BatchTime: 0.00327/0.49) losses = 1.5807, lr = [1.6653704027288332e-05, 0.0001665370402728833]\n",
      "[INFO: 2022-02-17 09:02:17,929]   LabelSmoothing Loss = 0.9714905023574829\n",
      "[INFO: 2022-02-17 09:02:27,452] Iteration 70440 (DataTime/BatchTime: 0.00228/0.476) losses = 1.3122, lr = [1.665133968694005e-05, 0.00016651339686940046]\n",
      "[INFO: 2022-02-17 09:02:27,453]   LabelSmoothing Loss = 0.6814723014831543\n",
      "[INFO: 2022-02-17 09:02:37,058] Iteration 70460 (DataTime/BatchTime: 0.00319/0.48) losses = 1.4162, lr = [1.664897635330807e-05, 0.0001664897635330807]\n",
      "[INFO: 2022-02-17 09:02:37,058]   LabelSmoothing Loss = 2.2189204692840576\n",
      "[INFO: 2022-02-17 09:02:46,569] Iteration 70480 (DataTime/BatchTime: 0.00306/0.476) losses = 1.445, lr = [1.664661402567819e-05, 0.0001664661402567819]\n",
      "[INFO: 2022-02-17 09:02:46,570]   LabelSmoothing Loss = 1.4799648523330688\n",
      "[INFO: 2022-02-17 09:02:56,291] Iteration 70500 (DataTime/BatchTime: 0.00137/0.486) losses = 1.4302, lr = [1.6644252703336896e-05, 0.00016644252703336895]\n",
      "[INFO: 2022-02-17 09:02:56,291]   LabelSmoothing Loss = 0.6310123205184937\n",
      "[INFO: 2022-02-17 09:03:05,816] Iteration 70520 (DataTime/BatchTime: 0.00304/0.476) losses = 1.4143, lr = [1.6641892385571392e-05, 0.0001664189238557139]\n",
      "[INFO: 2022-02-17 09:03:05,816]   LabelSmoothing Loss = 1.2932766675949097\n",
      "[INFO: 2022-02-17 09:03:15,515] Iteration 70540 (DataTime/BatchTime: 0.00136/0.485) losses = 1.5688, lr = [1.663953307166958e-05, 0.0001663953307166958]\n",
      "[INFO: 2022-02-17 09:03:15,515]   LabelSmoothing Loss = 1.5000134706497192\n",
      "[INFO: 2022-02-17 09:03:25,175] Iteration 70560 (DataTime/BatchTime: 0.00231/0.483) losses = 1.3207, lr = [1.6637174760920084e-05, 0.0001663717476092008]\n",
      "[INFO: 2022-02-17 09:03:25,176]   LabelSmoothing Loss = 1.4850302934646606\n",
      "[INFO: 2022-02-17 09:03:34,960] Iteration 70580 (DataTime/BatchTime: 0.00142/0.489) losses = 1.5699, lr = [1.6634817452612217e-05, 0.00016634817452612215]\n",
      "[INFO: 2022-02-17 09:03:34,960]   LabelSmoothing Loss = 0.9503729343414307\n",
      "[INFO: 2022-02-17 09:03:44,687] Iteration 70600 (DataTime/BatchTime: 0.00305/0.486) losses = 1.4953, lr = [1.663246114603601e-05, 0.00016632461146036005]\n",
      "[INFO: 2022-02-17 09:03:44,687]   LabelSmoothing Loss = 1.8413485288619995\n",
      "[INFO: 2022-02-17 09:03:54,247] Iteration 70620 (DataTime/BatchTime: 0.00307/0.478) losses = 1.4104, lr = [1.6630105840482186e-05, 0.00016630105840482182]\n",
      "[INFO: 2022-02-17 09:03:54,247]   LabelSmoothing Loss = 0.9411063194274902\n",
      "[INFO: 2022-02-17 09:04:03,955] Iteration 70640 (DataTime/BatchTime: 0.0022/0.485) losses = 1.4597, lr = [1.6627751535242182e-05, 0.0001662775153524218]\n",
      "[INFO: 2022-02-17 09:04:03,955]   LabelSmoothing Loss = 1.4717172384262085\n",
      "[INFO: 2022-02-17 09:04:13,534] Iteration 70660 (DataTime/BatchTime: 0.00315/0.479) losses = 1.4224, lr = [1.662539822960813e-05, 0.00016625398229608128]\n",
      "[INFO: 2022-02-17 09:04:13,534]   LabelSmoothing Loss = 1.1994919776916504\n",
      "[INFO: 2022-02-17 09:07:51,468] ######## Epoch (VAL)74 ########\n",
      "[INFO: 2022-02-17 09:07:51,468] {'Bleu_1': 0.352917440764452, 'Bleu_2': 0.210462005903711, 'Bleu_3': 0.13817653095493165, 'Bleu_4': 0.09538199614687908, 'METEOR': 0.18229344279401385, 'ROUGE_L': 0.2909882206515146, 'CIDEr': 0.2993359454499715}\n",
      "[INFO: 2022-02-17 09:11:29,445] ######## Epoch (TEST)74 ########\n",
      "[INFO: 2022-02-17 09:11:29,446] {'Bleu_1': 0.3264801380959263, 'Bleu_2': 0.1864381643163203, 'Bleu_3': 0.11540114168010984, 'Bleu_4': 0.07312513683029068, 'METEOR': 0.17263034573223968, 'ROUGE_L': 0.2748597182282894, 'CIDEr': 0.2216621081112141}\n",
      "[INFO: 2022-02-17 09:11:35,799] Iteration 70680 (DataTime/BatchTime: 0.0968/0.578) losses = 1.5185, lr = [1.662304592287287e-05, 0.00016623045922872865]\n",
      "[INFO: 2022-02-17 09:11:35,799]   LabelSmoothing Loss = 1.7758326530456543\n",
      "[INFO: 2022-02-17 09:11:45,377] Iteration 70700 (DataTime/BatchTime: 0.00123/0.479) losses = 1.3491, lr = [1.662069461432993e-05, 0.00016620694614329927]\n",
      "[INFO: 2022-02-17 09:11:45,377]   LabelSmoothing Loss = 0.6131410002708435\n",
      "[INFO: 2022-02-17 09:11:54,849] Iteration 70720 (DataTime/BatchTime: 0.00122/0.474) losses = 1.3382, lr = [1.6618344303273547e-05, 0.00016618344303273542]\n",
      "[INFO: 2022-02-17 09:11:54,849]   LabelSmoothing Loss = 0.7631159424781799\n",
      "[INFO: 2022-02-17 09:12:04,579] Iteration 70740 (DataTime/BatchTime: 0.00337/0.487) losses = 1.5341, lr = [1.6615994988998653e-05, 0.0001661599498899865]\n",
      "[INFO: 2022-02-17 09:12:04,579]   LabelSmoothing Loss = 1.3084450960159302\n",
      "[INFO: 2022-02-17 09:12:14,107] Iteration 70760 (DataTime/BatchTime: 0.0022/0.476) losses = 1.4411, lr = [1.661364667080088e-05, 0.00016613646670800877]\n",
      "[INFO: 2022-02-17 09:12:14,107]   LabelSmoothing Loss = 1.465173602104187\n",
      "[INFO: 2022-02-17 09:12:23,729] Iteration 70780 (DataTime/BatchTime: 0.0013/0.481) losses = 1.2737, lr = [1.6611299347976556e-05, 0.00016611299347976555]\n",
      "[INFO: 2022-02-17 09:12:23,729]   LabelSmoothing Loss = 1.3894978761672974\n",
      "[INFO: 2022-02-17 09:12:33,288] Iteration 70800 (DataTime/BatchTime: 0.00134/0.478) losses = 1.54, lr = [1.6608953019822703e-05, 0.000166089530198227]\n",
      "[INFO: 2022-02-17 09:12:33,288]   LabelSmoothing Loss = 1.4933494329452515\n",
      "[INFO: 2022-02-17 09:12:42,824] Iteration 70820 (DataTime/BatchTime: 0.00236/0.477) losses = 1.2933, lr = [1.6606607685637037e-05, 0.00016606607685637034]\n",
      "[INFO: 2022-02-17 09:12:42,824]   LabelSmoothing Loss = 0.9865980744361877\n",
      "[INFO: 2022-02-17 09:12:52,519] Iteration 70840 (DataTime/BatchTime: 0.00127/0.485) losses = 1.6398, lr = [1.6604263344717973e-05, 0.0001660426334471797]\n",
      "[INFO: 2022-02-17 09:12:52,520]   LabelSmoothing Loss = 1.7908707857131958\n",
      "[INFO: 2022-02-17 09:13:02,058] Iteration 70860 (DataTime/BatchTime: 0.00127/0.477) losses = 1.3381, lr = [1.660191999636461e-05, 0.00016601919996364612]\n",
      "[INFO: 2022-02-17 09:13:02,058]   LabelSmoothing Loss = 0.6221561431884766\n",
      "[INFO: 2022-02-17 09:13:11,640] Iteration 70880 (DataTime/BatchTime: 0.0013/0.479) losses = 1.4133, lr = [1.6599577639876755e-05, 0.00016599577639876754]\n",
      "[INFO: 2022-02-17 09:13:11,640]   LabelSmoothing Loss = 1.9358445405960083\n",
      "[INFO: 2022-02-17 09:13:21,229] Iteration 70900 (DataTime/BatchTime: 0.00218/0.479) losses = 1.319, lr = [1.6597236274554887e-05, 0.00016597236274554884]\n",
      "[INFO: 2022-02-17 09:13:21,229]   LabelSmoothing Loss = 1.0500282049179077\n",
      "[INFO: 2022-02-17 09:13:30,782] Iteration 70920 (DataTime/BatchTime: 0.00134/0.478) losses = 1.3778, lr = [1.6594895899700188e-05, 0.00016594895899700186]\n",
      "[INFO: 2022-02-17 09:13:30,782]   LabelSmoothing Loss = 2.010728597640991\n",
      "[INFO: 2022-02-17 09:13:40,342] Iteration 70940 (DataTime/BatchTime: 0.00132/0.478) losses = 1.4627, lr = [1.659255651461453e-05, 0.00016592556514614528]\n",
      "[INFO: 2022-02-17 09:13:40,343]   LabelSmoothing Loss = 1.6974496841430664\n",
      "[INFO: 2022-02-17 09:13:50,001] Iteration 70960 (DataTime/BatchTime: 0.00133/0.483) losses = 1.5176, lr = [1.659021811860046e-05, 0.0001659021811860046]\n",
      "[INFO: 2022-02-17 09:13:50,001]   LabelSmoothing Loss = 0.7654833197593689\n",
      "[INFO: 2022-02-17 09:13:59,528] Iteration 70980 (DataTime/BatchTime: 0.0013/0.476) losses = 1.4113, lr = [1.6587880710961237e-05, 0.00016587880710961233]\n",
      "[INFO: 2022-02-17 09:13:59,528]   LabelSmoothing Loss = 0.8229856491088867\n",
      "[INFO: 2022-02-17 09:14:09,068] Iteration 71000 (DataTime/BatchTime: 0.0013/0.477) losses = 1.507, lr = [1.658554429100078e-05, 0.00016585544291000779]\n",
      "[INFO: 2022-02-17 09:14:09,068]   LabelSmoothing Loss = 2.4331090450286865\n",
      "[INFO: 2022-02-17 09:14:18,628] Iteration 71020 (DataTime/BatchTime: 0.00212/0.478) losses = 1.2955, lr = [1.6583208858023717e-05, 0.00016583208858023715]\n",
      "[INFO: 2022-02-17 09:14:18,628]   LabelSmoothing Loss = 1.7073982954025269\n",
      "[INFO: 2022-02-17 09:14:28,205] Iteration 71040 (DataTime/BatchTime: 0.0013/0.479) losses = 1.4447, lr = [1.6580874411335345e-05, 0.00016580874411335344]\n",
      "[INFO: 2022-02-17 09:14:28,205]   LabelSmoothing Loss = 1.3524417877197266\n",
      "[INFO: 2022-02-17 09:14:37,707] Iteration 71060 (DataTime/BatchTime: 0.00211/0.475) losses = 1.5207, lr = [1.6578540950241655e-05, 0.0001657854095024165]\n",
      "[INFO: 2022-02-17 09:14:37,707]   LabelSmoothing Loss = 1.0795950889587402\n",
      "[INFO: 2022-02-17 09:14:47,247] Iteration 71080 (DataTime/BatchTime: 0.00129/0.477) losses = 1.4873, lr = [1.6576208474049315e-05, 0.00016576208474049312]\n",
      "[INFO: 2022-02-17 09:14:47,247]   LabelSmoothing Loss = 0.8741629719734192\n",
      "[INFO: 2022-02-17 09:14:56,765] Iteration 71100 (DataTime/BatchTime: 0.00126/0.476) losses = 1.4614, lr = [1.657387698206568e-05, 0.0001657387698206568]\n",
      "[INFO: 2022-02-17 09:14:56,765]   LabelSmoothing Loss = 2.406068801879883\n",
      "[INFO: 2022-02-17 09:15:06,320] Iteration 71120 (DataTime/BatchTime: 0.00124/0.478) losses = 1.4448, lr = [1.657154647359879e-05, 0.00016571546473598787]\n",
      "[INFO: 2022-02-17 09:15:06,320]   LabelSmoothing Loss = 1.4746683835983276\n",
      "[INFO: 2022-02-17 09:15:15,836] Iteration 71140 (DataTime/BatchTime: 0.00128/0.476) losses = 1.4082, lr = [1.6569216947957354e-05, 0.00016569216947957352]\n",
      "[INFO: 2022-02-17 09:15:15,836]   LabelSmoothing Loss = 1.2881453037261963\n",
      "[INFO: 2022-02-17 09:15:25,446] Iteration 71160 (DataTime/BatchTime: 0.00132/0.481) losses = 1.2969, lr = [1.6566888404450774e-05, 0.00016566888404450774]\n",
      "[INFO: 2022-02-17 09:15:25,446]   LabelSmoothing Loss = 1.4165226221084595\n",
      "[INFO: 2022-02-17 09:15:35,033] Iteration 71180 (DataTime/BatchTime: 0.00213/0.479) losses = 1.4115, lr = [1.6564560842389124e-05, 0.00016564560842389123]\n",
      "[INFO: 2022-02-17 09:15:35,033]   LabelSmoothing Loss = 0.6785160303115845\n",
      "[INFO: 2022-02-17 09:15:44,680] Iteration 71200 (DataTime/BatchTime: 0.00139/0.482) losses = 1.4932, lr = [1.656223426108316e-05, 0.00016562234261083156]\n",
      "[INFO: 2022-02-17 09:15:44,680]   LabelSmoothing Loss = 0.8731629252433777\n",
      "[INFO: 2022-02-17 09:15:54,167] Iteration 71220 (DataTime/BatchTime: 0.00127/0.474) losses = 1.415, lr = [1.6559908659844306e-05, 0.00016559908659844304]\n",
      "[INFO: 2022-02-17 09:15:54,167]   LabelSmoothing Loss = 1.2916678190231323\n",
      "[INFO: 2022-02-17 09:16:03,687] Iteration 71240 (DataTime/BatchTime: 0.00213/0.476) losses = 1.4452, lr = [1.655758403798468e-05, 0.00016557584037984677]\n",
      "[INFO: 2022-02-17 09:16:03,688]   LabelSmoothing Loss = 1.511542558670044\n",
      "[INFO: 2022-02-17 09:16:13,234] Iteration 71260 (DataTime/BatchTime: 0.00131/0.477) losses = 1.4075, lr = [1.6555260394817057e-05, 0.00016555260394817054]\n",
      "[INFO: 2022-02-17 09:16:13,234]   LabelSmoothing Loss = 1.1776317358016968\n",
      "[INFO: 2022-02-17 09:16:22,877] Iteration 71280 (DataTime/BatchTime: 0.0013/0.482) losses = 1.5284, lr = [1.6552937729654902e-05, 0.00016552937729654902]\n",
      "[INFO: 2022-02-17 09:16:22,877]   LabelSmoothing Loss = 2.1291186809539795\n",
      "[INFO: 2022-02-17 09:16:32,412] Iteration 71300 (DataTime/BatchTime: 0.00128/0.477) losses = 1.5211, lr = [1.6550616041812346e-05, 0.00016550616041812344]\n",
      "[INFO: 2022-02-17 09:16:32,412]   LabelSmoothing Loss = 0.9015353322029114\n",
      "[INFO: 2022-02-17 09:16:42,079] Iteration 71320 (DataTime/BatchTime: 0.00136/0.483) losses = 1.4113, lr = [1.6548295330604198e-05, 0.00016548295330604193]\n",
      "[INFO: 2022-02-17 09:16:42,079]   LabelSmoothing Loss = 1.2726261615753174\n",
      "[INFO: 2022-02-17 09:16:51,642] Iteration 71340 (DataTime/BatchTime: 0.00128/0.478) losses = 1.5229, lr = [1.654597559534593e-05, 0.00016545975595345927]\n",
      "[INFO: 2022-02-17 09:16:51,643]   LabelSmoothing Loss = 1.0278440713882446\n",
      "[INFO: 2022-02-17 09:17:01,211] Iteration 71360 (DataTime/BatchTime: 0.0012/0.478) losses = 1.5096, lr = [1.6543656835353693e-05, 0.00016543656835353693]\n",
      "[INFO: 2022-02-17 09:17:01,211]   LabelSmoothing Loss = 0.49644559621810913\n",
      "[INFO: 2022-02-17 09:17:10,737] Iteration 71380 (DataTime/BatchTime: 0.00138/0.476) losses = 1.437, lr = [1.6541339049944312e-05, 0.0001654133904994431]\n",
      "[INFO: 2022-02-17 09:17:10,738]   LabelSmoothing Loss = 1.4045130014419556\n",
      "[INFO: 2022-02-17 09:17:20,328] Iteration 71400 (DataTime/BatchTime: 0.00128/0.48) losses = 1.6245, lr = [1.6539022238435274e-05, 0.00016539022238435273]\n",
      "[INFO: 2022-02-17 09:17:20,328]   LabelSmoothing Loss = 2.2927727699279785\n",
      "[INFO: 2022-02-17 09:17:29,824] Iteration 71420 (DataTime/BatchTime: 0.00128/0.475) losses = 1.3928, lr = [1.653670640014474e-05, 0.0001653670640014474]\n",
      "[INFO: 2022-02-17 09:17:29,824]   LabelSmoothing Loss = 1.4008961915969849\n",
      "[INFO: 2022-02-17 09:17:39,384] Iteration 71440 (DataTime/BatchTime: 0.0013/0.478) losses = 1.2722, lr = [1.653439153439154e-05, 0.00016534391534391536]\n",
      "[INFO: 2022-02-17 09:17:39,385]   LabelSmoothing Loss = 1.6750763654708862\n",
      "[INFO: 2022-02-17 09:17:48,898] Iteration 71460 (DataTime/BatchTime: 0.00121/0.476) losses = 1.4724, lr = [1.653207764049516e-05, 0.00016532077640495158]\n",
      "[INFO: 2022-02-17 09:17:48,898]   LabelSmoothing Loss = 1.166725993156433\n",
      "[INFO: 2022-02-17 09:17:58,458] Iteration 71480 (DataTime/BatchTime: 0.0013/0.478) losses = 1.5415, lr = [1.6529764717775767e-05, 0.00016529764717775766]\n",
      "[INFO: 2022-02-17 09:17:58,459]   LabelSmoothing Loss = 1.7022404670715332\n",
      "[INFO: 2022-02-17 09:18:07,945] Iteration 71500 (DataTime/BatchTime: 0.00128/0.474) losses = 1.2539, lr = [1.6527452765554188e-05, 0.00016527452765554188]\n",
      "[INFO: 2022-02-17 09:18:07,945]   LabelSmoothing Loss = 1.5457756519317627\n",
      "[INFO: 2022-02-17 09:18:17,460] Iteration 71520 (DataTime/BatchTime: 0.00212/0.476) losses = 1.3661, lr = [1.6525141783151915e-05, 0.0001652514178315191]\n",
      "[INFO: 2022-02-17 09:18:17,460]   LabelSmoothing Loss = 0.4741310179233551\n",
      "[INFO: 2022-02-17 09:18:26,961] Iteration 71540 (DataTime/BatchTime: 0.0013/0.475) losses = 1.2721, lr = [1.65228317698911e-05, 0.00016522831769891097]\n",
      "[INFO: 2022-02-17 09:18:26,961]   LabelSmoothing Loss = 1.7404086589813232\n",
      "[INFO: 2022-02-17 09:18:36,483] Iteration 71560 (DataTime/BatchTime: 0.00128/0.476) losses = 1.4054, lr = [1.6520522725094564e-05, 0.00016520522725094563]\n",
      "[INFO: 2022-02-17 09:18:36,483]   LabelSmoothing Loss = 1.5643552541732788\n",
      "[INFO: 2022-02-17 09:18:46,019] Iteration 71580 (DataTime/BatchTime: 0.00132/0.477) losses = 1.2444, lr = [1.6518214648085788e-05, 0.00016518214648085787]\n",
      "[INFO: 2022-02-17 09:18:46,036]   LabelSmoothing Loss = 1.7308474779129028\n",
      "[INFO: 2022-02-17 09:18:55,546] Iteration 71600 (DataTime/BatchTime: 0.00291/0.476) losses = 1.2974, lr = [1.6515907538188913e-05, 0.00016515907538188913]\n",
      "[INFO: 2022-02-17 09:18:55,546]   LabelSmoothing Loss = 0.8834691643714905\n",
      "[INFO: 2022-02-17 09:19:05,042] Iteration 71620 (DataTime/BatchTime: 0.00117/0.475) losses = 1.3976, lr = [1.6513601394728744e-05, 0.00016513601394728742]\n",
      "[INFO: 2022-02-17 09:19:05,042]   LabelSmoothing Loss = 1.4549977779388428\n",
      "[INFO: 2022-02-17 09:22:36,928] ######## Epoch (VAL)75 ########\n",
      "[INFO: 2022-02-17 09:22:36,929] {'Bleu_1': 0.35164905658685824, 'Bleu_2': 0.20931032762498294, 'Bleu_3': 0.13595621829801552, 'Bleu_4': 0.09284804631618906, 'METEOR': 0.18481803676005926, 'ROUGE_L': 0.2904558152345283, 'CIDEr': 0.31393940523688973}\n",
      "[INFO: 2022-02-17 09:26:17,805] ######## Epoch (TEST)75 ########\n",
      "[INFO: 2022-02-17 09:26:17,805] {'Bleu_1': 0.32557233134587005, 'Bleu_2': 0.18501182065503757, 'Bleu_3': 0.11240195762071427, 'Bleu_4': 0.06723897727143258, 'METEOR': 0.17151360013231226, 'ROUGE_L': 0.2719387812692227, 'CIDEr': 0.17886343738852836}\n",
      "[INFO: 2022-02-17 09:26:26,556] Iteration 71640 (DataTime/BatchTime: 0.0688/0.547) losses = 1.4296, lr = [1.6511296217030744e-05, 0.0001651129621703074]\n",
      "[INFO: 2022-02-17 09:26:26,556]   LabelSmoothing Loss = 1.8502391576766968\n",
      "[INFO: 2022-02-17 09:26:36,219] Iteration 71660 (DataTime/BatchTime: 0.00268/0.483) losses = 1.3796, lr = [1.650899200442103e-05, 0.00016508992004421027]\n",
      "[INFO: 2022-02-17 09:26:36,219]   LabelSmoothing Loss = 1.6449713706970215\n",
      "[INFO: 2022-02-17 09:26:45,824] Iteration 71680 (DataTime/BatchTime: 0.00331/0.48) losses = 1.1891, lr = [1.6506688756226383e-05, 0.00016506688756226382]\n",
      "[INFO: 2022-02-17 09:26:45,824]   LabelSmoothing Loss = 0.9645699262619019\n",
      "[INFO: 2022-02-17 09:26:55,516] Iteration 71700 (DataTime/BatchTime: 0.00236/0.485) losses = 1.4177, lr = [1.6504386471774244e-05, 0.0001650438647177424]\n",
      "[INFO: 2022-02-17 09:26:55,516]   LabelSmoothing Loss = 0.9603850841522217\n",
      "[INFO: 2022-02-17 09:27:05,197] Iteration 71720 (DataTime/BatchTime: 0.00154/0.484) losses = 1.5226, lr = [1.65020851503927e-05, 0.00016502085150392698]\n",
      "[INFO: 2022-02-17 09:27:05,198]   LabelSmoothing Loss = 2.030716896057129\n",
      "[INFO: 2022-02-17 09:27:14,833] Iteration 71740 (DataTime/BatchTime: 0.00323/0.482) losses = 1.4166, lr = [1.6499784791410506e-05, 0.00016499784791410506]\n",
      "[INFO: 2022-02-17 09:27:14,833]   LabelSmoothing Loss = 1.5310815572738647\n",
      "[INFO: 2022-02-17 09:27:24,420] Iteration 71760 (DataTime/BatchTime: 0.00237/0.479) losses = 1.4958, lr = [1.6497485394157063e-05, 0.00016497485394157064]\n",
      "[INFO: 2022-02-17 09:27:24,421]   LabelSmoothing Loss = 1.29916512966156\n",
      "[INFO: 2022-02-17 09:27:33,989] Iteration 71780 (DataTime/BatchTime: 0.00146/0.478) losses = 1.5437, lr = [1.649518695796243e-05, 0.0001649518695796243]\n",
      "[INFO: 2022-02-17 09:27:33,989]   LabelSmoothing Loss = 1.4920161962509155\n",
      "[INFO: 2022-02-17 09:27:43,620] Iteration 71800 (DataTime/BatchTime: 0.0023/0.482) losses = 1.4005, lr = [1.649288948215732e-05, 0.00016492889482157315]\n",
      "[INFO: 2022-02-17 09:27:43,620]   LabelSmoothing Loss = 1.093196153640747\n",
      "[INFO: 2022-02-17 09:27:53,222] Iteration 71820 (DataTime/BatchTime: 0.00144/0.48) losses = 1.5046, lr = [1.649059296607309e-05, 0.00016490592966073088]\n",
      "[INFO: 2022-02-17 09:27:53,222]   LabelSmoothing Loss = 1.3079403638839722\n",
      "[INFO: 2022-02-17 09:28:02,848] Iteration 71840 (DataTime/BatchTime: 0.0014/0.481) losses = 1.4919, lr = [1.648829740904176e-05, 0.00016488297409041758]\n",
      "[INFO: 2022-02-17 09:28:02,848]   LabelSmoothing Loss = 0.7221688628196716\n",
      "[INFO: 2022-02-17 09:28:12,456] Iteration 71860 (DataTime/BatchTime: 0.00143/0.48) losses = 1.6511, lr = [1.6486002810395994e-05, 0.00016486002810395993]\n",
      "[INFO: 2022-02-17 09:28:12,456]   LabelSmoothing Loss = 1.9808244705200195\n",
      "[INFO: 2022-02-17 09:28:22,095] Iteration 71880 (DataTime/BatchTime: 0.00355/0.482) losses = 1.4579, lr = [1.6483709169469108e-05, 0.00016483709169469107]\n",
      "[INFO: 2022-02-17 09:28:22,096]   LabelSmoothing Loss = 1.3227533102035522\n",
      "[INFO: 2022-02-17 09:28:31,685] Iteration 71900 (DataTime/BatchTime: 0.00235/0.479) losses = 1.3584, lr = [1.6481416485595066e-05, 0.00016481416485595064]\n",
      "[INFO: 2022-02-17 09:28:31,685]   LabelSmoothing Loss = 0.9091572165489197\n",
      "[INFO: 2022-02-17 09:28:41,299] Iteration 71920 (DataTime/BatchTime: 0.0024/0.481) losses = 1.412, lr = [1.6479124758108483e-05, 0.0001647912475810848]\n",
      "[INFO: 2022-02-17 09:28:41,299]   LabelSmoothing Loss = 1.3485203981399536\n",
      "[INFO: 2022-02-17 09:28:51,004] Iteration 71940 (DataTime/BatchTime: 0.00409/0.485) losses = 1.3943, lr = [1.6476833986344617e-05, 0.00016476833986344615]\n",
      "[INFO: 2022-02-17 09:28:51,004]   LabelSmoothing Loss = 1.7768441438674927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "royal-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "['Epoch (VAL)1', 'Epoch (TEST)1', 'Epoch (VAL)2', 'Epoch (TEST)2', 'Epoch (VAL)3', 'Epoch (TEST)3', 'Epoch (VAL)4', 'Epoch (TEST)4', 'Epoch (VAL)5', 'Epoch (TEST)5']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "epoch_pat = \"Epoch \\([A-Z]+\\)\\d+\"\n",
    "epoch_p = re.compile(epoch_pat)\n",
    "epoch_result = epoch_p.findall(log)\n",
    "print(len(epoch_result))\n",
    "print(epoch_result[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "found-algeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "[\"'Bleu_1': 0.03599053214421497, 'Bleu_2': 0.019354143062080532, 'Bleu_3': 0.010051681717282978, 'Bleu_4': 0.0036336721862897207, 'METEOR': 0.04151045728956936, 'ROUGE_L': 0.06993456866924995, 'CIDEr': 1.6714689863366942e-05\", \"'Bleu_1': 0.03555573824399796, 'Bleu_2': 0.019086384192299723, 'Bleu_3': 0.009943746207586784, 'Bleu_4': 0.003461828631336404, 'METEOR': 0.04030218369551406, 'ROUGE_L': 0.06823833168042216, 'CIDEr': 0.0010043294589451082\", \"'Bleu_1': 0.05049945786328811, 'Bleu_2': 0.03183225735496136, 'Bleu_3': 0.021074412779134837, 'Bleu_4': 0.01353795280698437, 'METEOR': 0.06785705005333549, 'ROUGE_L': 0.1048292641439479, 'CIDEr': 0.014917171196877597\", \"'Bleu_1': 0.05337919770348058, 'Bleu_2': 0.03203141999697107, 'Bleu_3': 0.021071301991496007, 'Bleu_4': 0.013527393311483924, 'METEOR': 0.0665785402547023, 'ROUGE_L': 0.11352427032340508, 'CIDEr': 0.012927409531943337\", \"'Bleu_1': 0.06919185584681489, 'Bleu_2': 0.043670778182192026, 'Bleu_3': 0.02770311364207306, 'Bleu_4': 0.017266426226323187, 'METEOR': 0.09615467068994439, 'ROUGE_L': 0.11983800695220521, 'CIDEr': 9.181789393904066e-64\", \"'Bleu_1': 0.06778353132297558, 'Bleu_2': 0.042079351689884185, 'Bleu_3': 0.02663017912475834, 'Bleu_4': 0.016447966372810843, 'METEOR': 0.09051799957358553, 'ROUGE_L': 0.11610490507136882, 'CIDEr': 3.8640275246475766e-33\", \"'Bleu_1': 0.3457203437116007, 'Bleu_2': 0.23088231800161152, 'Bleu_3': 0.15901441350856216, 'Bleu_4': 0.10496710196918183, 'METEOR': 0.18527603919703475, 'ROUGE_L': 0.29995064570617586, 'CIDEr': 0.15816083158463248\", \"'Bleu_1': 0.34085432639645774, 'Bleu_2': 0.22460455820080721, 'Bleu_3': 0.1536284550218421, 'Bleu_4': 0.10193740516303954, 'METEOR': 0.17433906068098615, 'ROUGE_L': 0.2909439311019202, 'CIDEr': 0.17697559798446535\", \"'Bleu_1': 0.39030345826915486, 'Bleu_2': 0.2591248172813358, 'Bleu_3': 0.17566854044793923, 'Bleu_4': 0.11637108499867088, 'METEOR': 0.19144645288716286, 'ROUGE_L': 0.33135292836041086, 'CIDEr': 0.23135928710403342\", \"'Bleu_1': 0.3680644483094619, 'Bleu_2': 0.24385228584364407, 'Bleu_3': 0.16664479717593889, 'Bleu_4': 0.11132765886952835, 'METEOR': 0.18039774971743303, 'ROUGE_L': 0.32054140667665165, 'CIDEr': 0.2537625409708473\", \"'Bleu_1': 0.32051874928487445, 'Bleu_2': 0.21748120436163404, 'Bleu_3': 0.14781147366682343, 'Bleu_4': 0.0978908966596941, 'METEOR': 0.17524307109288323, 'ROUGE_L': 0.340375952055344, 'CIDEr': 0.21755164201905738\", \"'Bleu_1': 0.29655632610832455, 'Bleu_2': 0.19887097543157928, 'Bleu_3': 0.13462901965082344, 'Bleu_4': 0.09071897479752747, 'METEOR': 0.16572124898504756, 'ROUGE_L': 0.31730771317758366, 'CIDEr': 0.23765886592249547\", \"'Bleu_1': 0.368059865831697, 'Bleu_2': 0.2340078090547708, 'Bleu_3': 0.15032728185303904, 'Bleu_4': 0.09872867871888813, 'METEOR': 0.18914375836815325, 'ROUGE_L': 0.35201489092411614, 'CIDEr': 0.2738442586461069\", \"'Bleu_1': 0.34101944799483624, 'Bleu_2': 0.21931750571713557, 'Bleu_3': 0.1447035292143456, 'Bleu_4': 0.09655396518769772, 'METEOR': 0.17907455313043216, 'ROUGE_L': 0.33623002472891755, 'CIDEr': 0.3226128142862051\", \"'Bleu_1': 0.4026710308045643, 'Bleu_2': 0.2687196545073892, 'Bleu_3': 0.18395829452764553, 'Bleu_4': 0.12317318445337318, 'METEOR': 0.19615253354693182, 'ROUGE_L': 0.34878870893407976, 'CIDEr': 0.29508307263825007\", \"'Bleu_1': 0.38176894088747104, 'Bleu_2': 0.24962313897637917, 'Bleu_3': 0.16700279252562814, 'Bleu_4': 0.11000113830496684, 'METEOR': 0.18517935718605116, 'ROUGE_L': 0.33013967217209184, 'CIDEr': 0.3460842781828871\", \"'Bleu_1': 0.34877288622891744, 'Bleu_2': 0.2201564626503559, 'Bleu_3': 0.14940499850039626, 'Bleu_4': 0.10361994210539348, 'METEOR': 0.19050392909971398, 'ROUGE_L': 0.3501853468387843, 'CIDEr': 0.28180210923916055\", \"'Bleu_1': 0.3246772574500357, 'Bleu_2': 0.2019694261365944, 'Bleu_3': 0.13673893869956544, 'Bleu_4': 0.0940873795119763, 'METEOR': 0.17990967947346997, 'ROUGE_L': 0.33151342611771967, 'CIDEr': 0.31321985772720995\", \"'Bleu_1': 0.29650475147210525, 'Bleu_2': 0.19364070052688123, 'Bleu_3': 0.1366099210530055, 'Bleu_4': 0.09585553009791765, 'METEOR': 0.1757550886202129, 'ROUGE_L': 0.3486559561408683, 'CIDEr': 0.26137310241530803\", \"'Bleu_1': 0.2757722237434221, 'Bleu_2': 0.1755455296965636, 'Bleu_3': 0.12182955797185967, 'Bleu_4': 0.0847959782866886, 'METEOR': 0.16724224038146993, 'ROUGE_L': 0.33064972996395403, 'CIDEr': 0.23922764456815257\", \"'Bleu_1': 0.31156636062254633, 'Bleu_2': 0.19067079334339762, 'Bleu_3': 0.12790615478509734, 'Bleu_4': 0.09048089881467675, 'METEOR': 0.17410910851952466, 'ROUGE_L': 0.33212122116946136, 'CIDEr': 0.34671497668134876\", \"'Bleu_1': 0.28551832626906126, 'Bleu_2': 0.16508137779635412, 'Bleu_3': 0.10551119432317832, 'Bleu_4': 0.06944513454036848, 'METEOR': 0.1619008871617653, 'ROUGE_L': 0.3019118559677144, 'CIDEr': 0.21220425854303585\", \"'Bleu_1': 0.33851598510566655, 'Bleu_2': 0.20905704518873774, 'Bleu_3': 0.1395018538239687, 'Bleu_4': 0.0964650685752548, 'METEOR': 0.17657972815094491, 'ROUGE_L': 0.3330921085420392, 'CIDEr': 0.3192607719616489\", \"'Bleu_1': 0.31296679562229063, 'Bleu_2': 0.18628622439752723, 'Bleu_3': 0.11975080588338692, 'Bleu_4': 0.08056440746778099, 'METEOR': 0.16482532652466525, 'ROUGE_L': 0.3094169022873763, 'CIDEr': 0.27078650505213414\", \"'Bleu_1': 0.32760169480705803, 'Bleu_2': 0.20970915348932903, 'Bleu_3': 0.14178929122537873, 'Bleu_4': 0.09559279909683363, 'METEOR': 0.18063868717989262, 'ROUGE_L': 0.3283817984876917, 'CIDEr': 0.22503895852843148\", \"'Bleu_1': 0.30322014429268873, 'Bleu_2': 0.19556017108204338, 'Bleu_3': 0.13496219959951408, 'Bleu_4': 0.09395243652411793, 'METEOR': 0.17150646552999427, 'ROUGE_L': 0.3173908866944552, 'CIDEr': 0.28433413055983797\", \"'Bleu_1': 0.32860671584673945, 'Bleu_2': 0.20961021572804275, 'Bleu_3': 0.14532447696361792, 'Bleu_4': 0.10318615378739704, 'METEOR': 0.17886944444657424, 'ROUGE_L': 0.33384675829722976, 'CIDEr': 0.21483070599718163\", \"'Bleu_1': 0.3163141009925444, 'Bleu_2': 0.1925237553130506, 'Bleu_3': 0.1280970227193625, 'Bleu_4': 0.08736648439886895, 'METEOR': 0.17231738657584686, 'ROUGE_L': 0.31507772613697166, 'CIDEr': 0.2446624029735795\", \"'Bleu_1': 0.3684988506779151, 'Bleu_2': 0.22665556132258446, 'Bleu_3': 0.15029522867378334, 'Bleu_4': 0.10208961437929659, 'METEOR': 0.18531006155709495, 'ROUGE_L': 0.33357720414186687, 'CIDEr': 0.3156354736735075\", \"'Bleu_1': 0.3420254940562698, 'Bleu_2': 0.2049566508264836, 'Bleu_3': 0.1328029533539528, 'Bleu_4': 0.08960638874807035, 'METEOR': 0.17415731244266688, 'ROUGE_L': 0.3082530447653692, 'CIDEr': 0.3113433973118467\", \"'Bleu_1': 0.4001582114418587, 'Bleu_2': 0.24955807316557005, 'Bleu_3': 0.1681754502097059, 'Bleu_4': 0.11481700944614888, 'METEOR': 0.20062113594255288, 'ROUGE_L': 0.32101775711644454, 'CIDEr': 0.28290377425074564\", \"'Bleu_1': 0.37991029580744, 'Bleu_2': 0.23207960469152178, 'Bleu_3': 0.1536430110786039, 'Bleu_4': 0.10335688964443332, 'METEOR': 0.19231743253816663, 'ROUGE_L': 0.3095690514432706, 'CIDEr': 0.31083708412799577\", \"'Bleu_1': 0.4154249451910944, 'Bleu_2': 0.2698694455765327, 'Bleu_3': 0.18568100883066874, 'Bleu_4': 0.12758405351940771, 'METEOR': 0.2057821049217111, 'ROUGE_L': 0.32203287271764, 'CIDEr': 0.29954418981399517\", \"'Bleu_1': 0.3893778207269174, 'Bleu_2': 0.24080397147920735, 'Bleu_3': 0.15998458178584835, 'Bleu_4': 0.10636726205039133, 'METEOR': 0.19284346483272913, 'ROUGE_L': 0.3046960543756504, 'CIDEr': 0.3171912415850091\", \"'Bleu_1': 0.3515433062027791, 'Bleu_2': 0.22374017144510008, 'Bleu_3': 0.1538022036655399, 'Bleu_4': 0.10739484169937422, 'METEOR': 0.18591926047768673, 'ROUGE_L': 0.3176537809820055, 'CIDEr': 0.25187931888214204\", \"'Bleu_1': 0.331490634931352, 'Bleu_2': 0.20417526687356533, 'Bleu_3': 0.1373753180529791, 'Bleu_4': 0.09359324645026054, 'METEOR': 0.17838528598123835, 'ROUGE_L': 0.3025729554123366, 'CIDEr': 0.28809633855446115\", \"'Bleu_1': 0.3846037108465745, 'Bleu_2': 0.23865879158643022, 'Bleu_3': 0.16101800325444746, 'Bleu_4': 0.11215367555726673, 'METEOR': 0.19184418082675855, 'ROUGE_L': 0.31907214922059396, 'CIDEr': 0.31608659297697833\", \"'Bleu_1': 0.3613994878991019, 'Bleu_2': 0.21420124656042674, 'Bleu_3': 0.13760617077161627, 'Bleu_4': 0.0905411161847295, 'METEOR': 0.18092464204975447, 'ROUGE_L': 0.30240276166545016, 'CIDEr': 0.2715624652670599\", \"'Bleu_1': 0.3358513762441915, 'Bleu_2': 0.20895686803551303, 'Bleu_3': 0.14045736526670075, 'Bleu_4': 0.09858120183032462, 'METEOR': 0.18145521491607708, 'ROUGE_L': 0.3111206640885505, 'CIDEr': 0.20777535048638374\", \"'Bleu_1': 0.3053890297907663, 'Bleu_2': 0.17919791225516404, 'Bleu_3': 0.11109355048427134, 'Bleu_4': 0.0695851304928692, 'METEOR': 0.1679153908072285, 'ROUGE_L': 0.28171750309366145, 'CIDEr': 0.19980866546476717\", \"'Bleu_1': 0.3117483730449823, 'Bleu_2': 0.19244981399541639, 'Bleu_3': 0.12968541155651037, 'Bleu_4': 0.09251345165528846, 'METEOR': 0.1721414336063794, 'ROUGE_L': 0.3119978702166016, 'CIDEr': 0.41030528530742727\", \"'Bleu_1': 0.2892343527793005, 'Bleu_2': 0.1652033642901737, 'Bleu_3': 0.1043777687806194, 'Bleu_4': 0.06976158373618223, 'METEOR': 0.15983690141900606, 'ROUGE_L': 0.28841342211893567, 'CIDEr': 0.2722761211617019\", \"'Bleu_1': 0.36413081520983426, 'Bleu_2': 0.22705175291569565, 'Bleu_3': 0.15423528320281296, 'Bleu_4': 0.10895524271364006, 'METEOR': 0.18533213840955112, 'ROUGE_L': 0.32415187723537187, 'CIDEr': 0.3738893510492875\", \"'Bleu_1': 0.3351549471607736, 'Bleu_2': 0.1972837748302385, 'Bleu_3': 0.1269553453512406, 'Bleu_4': 0.08442866682235847, 'METEOR': 0.17028630657343577, 'ROUGE_L': 0.3002532284123427, 'CIDEr': 0.2692300797413971\", \"'Bleu_1': 0.3401055748733046, 'Bleu_2': 0.209522544926381, 'Bleu_3': 0.14005669511715846, 'Bleu_4': 0.1006127690633987, 'METEOR': 0.1818398392132281, 'ROUGE_L': 0.2979636405423304, 'CIDEr': 0.29832837366774667\", \"'Bleu_1': 0.3180054821422586, 'Bleu_2': 0.18571284982428493, 'Bleu_3': 0.11905885368596168, 'Bleu_4': 0.08012151140981293, 'METEOR': 0.17208351285861337, 'ROUGE_L': 0.2862316930044561, 'CIDEr': 0.25154321199615803\", \"'Bleu_1': 0.35033160371241284, 'Bleu_2': 0.2211508141344426, 'Bleu_3': 0.15123130819443323, 'Bleu_4': 0.11029790478343925, 'METEOR': 0.18591084754851242, 'ROUGE_L': 0.3040473551896012, 'CIDEr': 0.38541683344351396\", \"'Bleu_1': 0.3117647094933931, 'Bleu_2': 0.18152898839770548, 'Bleu_3': 0.11442855830043065, 'Bleu_4': 0.07568299621488735, 'METEOR': 0.172142951210309, 'ROUGE_L': 0.28299511292368396, 'CIDEr': 0.24957202783366525\", \"'Bleu_1': 0.36459180742815317, 'Bleu_2': 0.2229760945710489, 'Bleu_3': 0.14969494461642244, 'Bleu_4': 0.10734426052881416, 'METEOR': 0.18543573829932075, 'ROUGE_L': 0.30529182228012874, 'CIDEr': 0.40753154250622464\", \"'Bleu_1': 0.35323959681344147, 'Bleu_2': 0.20640012309189404, 'Bleu_3': 0.13227625641435797, 'Bleu_4': 0.08969833265356564, 'METEOR': 0.17634089962973606, 'ROUGE_L': 0.2900089989457082, 'CIDEr': 0.29189062559616863\", \"'Bleu_1': 0.34761341563315423, 'Bleu_2': 0.21205167468935543, 'Bleu_3': 0.1398128538256833, 'Bleu_4': 0.09741425328613136, 'METEOR': 0.18040631077702277, 'ROUGE_L': 0.28685409720965094, 'CIDEr': 0.29986238679651583\", \"'Bleu_1': 0.3390584521367953, 'Bleu_2': 0.20275781537393966, 'Bleu_3': 0.13194101074087608, 'Bleu_4': 0.09074735329086343, 'METEOR': 0.1764594505271811, 'ROUGE_L': 0.28194397666230014, 'CIDEr': 0.3126499186478492\", \"'Bleu_1': 0.3634075335316537, 'Bleu_2': 0.22537566294133507, 'Bleu_3': 0.15211282542839344, 'Bleu_4': 0.10917496707059075, 'METEOR': 0.18763312215844566, 'ROUGE_L': 0.29987578399349474, 'CIDEr': 0.3700995765491178\", \"'Bleu_1': 0.34213022995507836, 'Bleu_2': 0.20410773840092072, 'Bleu_3': 0.13287192051480884, 'Bleu_4': 0.0915365032576931, 'METEOR': 0.178108692155097, 'ROUGE_L': 0.28701306667285814, 'CIDEr': 0.31904411213502265\", \"'Bleu_1': 0.3224672078423686, 'Bleu_2': 0.1984292773855937, 'Bleu_3': 0.131232265164419, 'Bleu_4': 0.09171324259556049, 'METEOR': 0.17274085903661368, 'ROUGE_L': 0.30080229058702185, 'CIDEr': 0.4058176518864926\", \"'Bleu_1': 0.28585093353599206, 'Bleu_2': 0.16483115671303772, 'Bleu_3': 0.1048374001104095, 'Bleu_4': 0.07041419980998552, 'METEOR': 0.16071448011499082, 'ROUGE_L': 0.27571361896403995, 'CIDEr': 0.24378575678020267\", \"'Bleu_1': 0.32071762396732567, 'Bleu_2': 0.18800481440220693, 'Bleu_3': 0.117728802148925, 'Bleu_4': 0.07612144667980997, 'METEOR': 0.170170454096901, 'ROUGE_L': 0.27919539068255755, 'CIDEr': 0.259418538449254\", \"'Bleu_1': 0.3197883960644868, 'Bleu_2': 0.1920305159760713, 'Bleu_3': 0.12749016895807927, 'Bleu_4': 0.0902073656257901, 'METEOR': 0.16887514442549234, 'ROUGE_L': 0.2919532441609997, 'CIDEr': 0.34602951738951904\", \"'Bleu_1': 0.3371015034058704, 'Bleu_2': 0.2099240436643337, 'Bleu_3': 0.14099975070769757, 'Bleu_4': 0.09969289518528984, 'METEOR': 0.1795907395162519, 'ROUGE_L': 0.2979496035087552, 'CIDEr': 0.36591019475268366\", \"'Bleu_1': 0.31145884223253917, 'Bleu_2': 0.18289035829474146, 'Bleu_3': 0.1186147858861324, 'Bleu_4': 0.08109739809928158, 'METEOR': 0.16653825306175973, 'ROUGE_L': 0.2823665748918977, 'CIDEr': 0.30292310656558924\", \"'Bleu_1': 0.35147212471516753, 'Bleu_2': 0.21667634150452936, 'Bleu_3': 0.14499175459610394, 'Bleu_4': 0.10366444834451652, 'METEOR': 0.1861330596866481, 'ROUGE_L': 0.2945335341052424, 'CIDEr': 0.34061654725952056\", \"'Bleu_1': 0.3368317028264611, 'Bleu_2': 0.19971396293611973, 'Bleu_3': 0.12972886476560852, 'Bleu_4': 0.08953675897969833, 'METEOR': 0.17534064640612887, 'ROUGE_L': 0.2873052113425134, 'CIDEr': 0.3004206708867578\", \"'Bleu_1': 0.3603521138745733, 'Bleu_2': 0.22029250548636725, 'Bleu_3': 0.14712427715759957, 'Bleu_4': 0.10362755373312989, 'METEOR': 0.18447386992759363, 'ROUGE_L': 0.3033673529737577, 'CIDEr': 0.3321593691251627\", \"'Bleu_1': 0.3511328343575936, 'Bleu_2': 0.21085050551901213, 'Bleu_3': 0.13883854323210815, 'Bleu_4': 0.09628043636295074, 'METEOR': 0.1777352506279958, 'ROUGE_L': 0.298149429779643, 'CIDEr': 0.3199604514987689\", \"'Bleu_1': 0.32407337905949274, 'Bleu_2': 0.19196299605686568, 'Bleu_3': 0.12173031605103878, 'Bleu_4': 0.08041140317604857, 'METEOR': 0.1702845919114169, 'ROUGE_L': 0.2876862565109423, 'CIDEr': 0.33616412716923766\", \"'Bleu_1': 0.29917338186352443, 'Bleu_2': 0.1676351759637163, 'Bleu_3': 0.10235385850668723, 'Bleu_4': 0.06507350417751276, 'METEOR': 0.15976680055497194, 'ROUGE_L': 0.2690807149391147, 'CIDEr': 0.24077417205127943\", \"'Bleu_1': 0.3533046658931689, 'Bleu_2': 0.21614410494666006, 'Bleu_3': 0.14257177896937917, 'Bleu_4': 0.09953245215051396, 'METEOR': 0.1812740487030281, 'ROUGE_L': 0.2954585861673202, 'CIDEr': 0.313575026138529\", \"'Bleu_1': 0.3429567166446224, 'Bleu_2': 0.20412367395584977, 'Bleu_3': 0.1326137365611655, 'Bleu_4': 0.091402864624463, 'METEOR': 0.17519177570946867, 'ROUGE_L': 0.2911019572337083, 'CIDEr': 0.3005798090851597\", \"'Bleu_1': 0.31938686984366316, 'Bleu_2': 0.19528782207109743, 'Bleu_3': 0.1287357312412064, 'Bleu_4': 0.08901848217567561, 'METEOR': 0.17679593816225234, 'ROUGE_L': 0.28271784770630404, 'CIDEr': 0.2884026184762444\", \"'Bleu_1': 0.3017298637805405, 'Bleu_2': 0.17785704586762122, 'Bleu_3': 0.11389846672824769, 'Bleu_4': 0.07707503155492933, 'METEOR': 0.16984957555924143, 'ROUGE_L': 0.27531394007039095, 'CIDEr': 0.264443690971005\", \"'Bleu_1': 0.2947909009047015, 'Bleu_2': 0.17417593050554997, 'Bleu_3': 0.1120140271588627, 'Bleu_4': 0.07627098846608318, 'METEOR': 0.16404224871958006, 'ROUGE_L': 0.2923432069738031, 'CIDEr': 0.3508837225081082\", \"'Bleu_1': 0.27748677316224873, 'Bleu_2': 0.1525153403091945, 'Bleu_3': 0.0899136440159304, 'Bleu_4': 0.05415668011975442, 'METEOR': 0.15787469609922003, 'ROUGE_L': 0.2703359951760686, 'CIDEr': 0.15691455587953704\", \"'Bleu_1': 0.33234700088833063, 'Bleu_2': 0.20050399166163896, 'Bleu_3': 0.13056102194873825, 'Bleu_4': 0.08855181767439972, 'METEOR': 0.17387331242595475, 'ROUGE_L': 0.28917680304073534, 'CIDEr': 0.33044460699050304\", \"'Bleu_1': 0.3198710665385794, 'Bleu_2': 0.18782759060805213, 'Bleu_3': 0.12004264740773063, 'Bleu_4': 0.08117515410934592, 'METEOR': 0.17049475295858824, 'ROUGE_L': 0.28162886296108364, 'CIDEr': 0.3250754196710809\", \"'Bleu_1': 0.34833929424462423, 'Bleu_2': 0.2081978054680515, 'Bleu_3': 0.13190186037972854, 'Bleu_4': 0.08520990925684453, 'METEOR': 0.18034210037615142, 'ROUGE_L': 0.2885323913231158, 'CIDEr': 0.2422446241481393\", \"'Bleu_1': 0.3177531783392353, 'Bleu_2': 0.181212128443851, 'Bleu_3': 0.11171819547453447, 'Bleu_4': 0.07033121169596934, 'METEOR': 0.16787090650852413, 'ROUGE_L': 0.27469028748925584, 'CIDEr': 0.1739777392866414\", \"'Bleu_1': 0.3667351949485423, 'Bleu_2': 0.22276241598592275, 'Bleu_3': 0.14720273285556346, 'Bleu_4': 0.10195318577562709, 'METEOR': 0.18751899100812067, 'ROUGE_L': 0.2984068170395035, 'CIDEr': 0.30713537165097027\", \"'Bleu_1': 0.34582513644871393, 'Bleu_2': 0.2033898274098132, 'Bleu_3': 0.13144874554912603, 'Bleu_4': 0.0893891652400853, 'METEOR': 0.17815603709222674, 'ROUGE_L': 0.2860034497288279, 'CIDEr': 0.3036630862246032\", \"'Bleu_1': 0.3551910787257583, 'Bleu_2': 0.2152821221708602, 'Bleu_3': 0.14341616530544699, 'Bleu_4': 0.09913815396705616, 'METEOR': 0.18482659865184536, 'ROUGE_L': 0.30119122837272017, 'CIDEr': 0.30051564602711256\", \"'Bleu_1': 0.3421890576386531, 'Bleu_2': 0.200450653036498, 'Bleu_3': 0.12840894907697037, 'Bleu_4': 0.08470009406334543, 'METEOR': 0.17930862687417498, 'ROUGE_L': 0.28505061713725716, 'CIDEr': 0.1924346555276385\", \"'Bleu_1': 0.3571672424559901, 'Bleu_2': 0.21250928829366517, 'Bleu_3': 0.13732762483198283, 'Bleu_4': 0.09198674898589602, 'METEOR': 0.18593226699457044, 'ROUGE_L': 0.29417555671534623, 'CIDEr': 0.2851290295396153\", \"'Bleu_1': 0.3293411451122174, 'Bleu_2': 0.18221896476900903, 'Bleu_3': 0.10694489514896992, 'Bleu_4': 0.06057979906500187, 'METEOR': 0.1724126400769239, 'ROUGE_L': 0.2724458981444916, 'CIDEr': 0.16304427916166703\", \"'Bleu_1': 0.37124615748399487, 'Bleu_2': 0.23075545552003734, 'Bleu_3': 0.15590026582138464, 'Bleu_4': 0.11007130598709036, 'METEOR': 0.1835129658878216, 'ROUGE_L': 0.29784728783328046, 'CIDEr': 0.3484075118352242\", \"'Bleu_1': 0.3396123097141233, 'Bleu_2': 0.2014655601435779, 'Bleu_3': 0.12993261196052663, 'Bleu_4': 0.08736686154741449, 'METEOR': 0.1743624735102722, 'ROUGE_L': 0.2825591482146947, 'CIDEr': 0.2699024162621854\", \"'Bleu_1': 0.35967154634719367, 'Bleu_2': 0.22065964674014668, 'Bleu_3': 0.1469294002971982, 'Bleu_4': 0.10324504233012723, 'METEOR': 0.18246840748145438, 'ROUGE_L': 0.2951631722564896, 'CIDEr': 0.3350360886981546\", \"'Bleu_1': 0.3339741411264295, 'Bleu_2': 0.19688905595659614, 'Bleu_3': 0.12698928027863116, 'Bleu_4': 0.0866198022214147, 'METEOR': 0.17202470972678166, 'ROUGE_L': 0.28120014858052994, 'CIDEr': 0.27067365818737693\", \"'Bleu_1': 0.3615578066006017, 'Bleu_2': 0.22033492171721544, 'Bleu_3': 0.14773883777098792, 'Bleu_4': 0.10450138315075229, 'METEOR': 0.18264053219445534, 'ROUGE_L': 0.2977009138130065, 'CIDEr': 0.32456244388246785\", \"'Bleu_1': 0.33793919097127767, 'Bleu_2': 0.19865462342007276, 'Bleu_3': 0.12716885703040162, 'Bleu_4': 0.08575007434814674, 'METEOR': 0.17385072444224658, 'ROUGE_L': 0.2835433481718149, 'CIDEr': 0.28417394904080123\", \"'Bleu_1': 0.33596509688256965, 'Bleu_2': 0.20310591201921505, 'Bleu_3': 0.13390580139097352, 'Bleu_4': 0.09313723174744638, 'METEOR': 0.18176533447495075, 'ROUGE_L': 0.28689514543428324, 'CIDEr': 0.31647339893690385\", \"'Bleu_1': 0.3163532525635414, 'Bleu_2': 0.18063323607280088, 'Bleu_3': 0.1103011368578707, 'Bleu_4': 0.06888474998329205, 'METEOR': 0.17459647813080806, 'ROUGE_L': 0.27399665507825494, 'CIDEr': 0.20359594844679096\", \"'Bleu_1': 0.3387602798619112, 'Bleu_2': 0.1981409814936867, 'Bleu_3': 0.12136010988895102, 'Bleu_4': 0.07652177602032344, 'METEOR': 0.1761720623408269, 'ROUGE_L': 0.2873234786662836, 'CIDEr': 0.23139291004755036\", \"'Bleu_1': 0.3125613427934851, 'Bleu_2': 0.1797611677329993, 'Bleu_3': 0.11281915601828775, 'Bleu_4': 0.07408641951011971, 'METEOR': 0.17094725218413806, 'ROUGE_L': 0.27090404699129184, 'CIDEr': 0.22180292548722821\", \"'Bleu_1': 0.36093647611123175, 'Bleu_2': 0.21711334423268955, 'Bleu_3': 0.14081736567160202, 'Bleu_4': 0.09575823884304287, 'METEOR': 0.1854488617860113, 'ROUGE_L': 0.28866922179577126, 'CIDEr': 0.2865920624295629\", \"'Bleu_1': 0.3292948729000925, 'Bleu_2': 0.1867112000545451, 'Bleu_3': 0.11315983314122903, 'Bleu_4': 0.06963304343702048, 'METEOR': 0.17265388379021954, 'ROUGE_L': 0.27368082506752645, 'CIDEr': 0.2049890681389889\", \"'Bleu_1': 0.35440566488649633, 'Bleu_2': 0.21414014729178252, 'Bleu_3': 0.14101417117237014, 'Bleu_4': 0.09792104672777584, 'METEOR': 0.1844054529747023, 'ROUGE_L': 0.2916891649075532, 'CIDEr': 0.3191652492458008\", \"'Bleu_1': 0.32155181209352973, 'Bleu_2': 0.18259664359123565, 'Bleu_3': 0.1125131968385585, 'Bleu_4': 0.07172070984973476, 'METEOR': 0.17354315222376296, 'ROUGE_L': 0.2750086646760212, 'CIDEr': 0.22507607344122255\", \"'Bleu_1': 0.36351979173931387, 'Bleu_2': 0.21947363246398843, 'Bleu_3': 0.14382606341199294, 'Bleu_4': 0.09922056900659366, 'METEOR': 0.18411588206262886, 'ROUGE_L': 0.29125067273867505, 'CIDEr': 0.29170205812627253\", \"'Bleu_1': 0.33753996017007754, 'Bleu_2': 0.19376552615535453, 'Bleu_3': 0.11999071940398151, 'Bleu_4': 0.07790442283052498, 'METEOR': 0.1695798156300039, 'ROUGE_L': 0.2743650591327987, 'CIDEr': 0.2342758568740625\", \"'Bleu_1': 0.3866997854803673, 'Bleu_2': 0.23917380767582852, 'Bleu_3': 0.16244150808333385, 'Bleu_4': 0.11658788663149097, 'METEOR': 0.1929936326123175, 'ROUGE_L': 0.3074158216000527, 'CIDEr': 0.34517694896797535\", \"'Bleu_1': 0.3518026161862861, 'Bleu_2': 0.2056567045032227, 'Bleu_3': 0.13148184324026002, 'Bleu_4': 0.08754505437128618, 'METEOR': 0.17807927691221068, 'ROUGE_L': 0.28824400614632156, 'CIDEr': 0.2896254214628751\", \"'Bleu_1': 0.32343656246454255, 'Bleu_2': 0.19023326527886628, 'Bleu_3': 0.12294751815690962, 'Bleu_4': 0.08364459243977833, 'METEOR': 0.172549857883499, 'ROUGE_L': 0.28284286862446056, 'CIDEr': 0.2672526129558856\", \"'Bleu_1': 0.2988526347652721, 'Bleu_2': 0.16873432499992497, 'Bleu_3': 0.10393295740720171, 'Bleu_4': 0.06629447059555126, 'METEOR': 0.16368312776705124, 'ROUGE_L': 0.2725776106585315, 'CIDEr': 0.22319848203194154\", \"'Bleu_1': 0.348551228238872, 'Bleu_2': 0.2097491496266475, 'Bleu_3': 0.13797733137907664, 'Bleu_4': 0.09608279309625391, 'METEOR': 0.17928666157572923, 'ROUGE_L': 0.2890588509847598, 'CIDEr': 0.3356213541862266\", \"'Bleu_1': 0.3227732575442557, 'Bleu_2': 0.1785686130780816, 'Bleu_3': 0.10526074266785712, 'Bleu_4': 0.0611300686823987, 'METEOR': 0.16983698138886563, 'ROUGE_L': 0.2685525156010363, 'CIDEr': 0.15771209904481207\", \"'Bleu_1': 0.30669033290384945, 'Bleu_2': 0.17505985130173657, 'Bleu_3': 0.10849400204596256, 'Bleu_4': 0.06895437014712785, 'METEOR': 0.16835649735462688, 'ROUGE_L': 0.27642741332290155, 'CIDEr': 0.24959092953102763\", \"'Bleu_1': 0.28897698265102467, 'Bleu_2': 0.15833891358142876, 'Bleu_3': 0.09171120105153513, 'Bleu_4': 0.05060085442998065, 'METEOR': 0.16146786135997584, 'ROUGE_L': 0.26343329898761336, 'CIDEr': 0.14863137807179325\", \"'Bleu_1': 0.3519471800591605, 'Bleu_2': 0.2097601417027563, 'Bleu_3': 0.13898769918625187, 'Bleu_4': 0.09848435832586563, 'METEOR': 0.1828242911151315, 'ROUGE_L': 0.2876390609989104, 'CIDEr': 0.32907910594666123\", \"'Bleu_1': 0.32979360822433273, 'Bleu_2': 0.18148373605873808, 'Bleu_3': 0.10798306096658125, 'Bleu_4': 0.0629598893041053, 'METEOR': 0.1721373544482412, 'ROUGE_L': 0.26650623077201213, 'CIDEr': 0.16378137596058967\", \"'Bleu_1': 0.3471212988400757, 'Bleu_2': 0.21058493844147697, 'Bleu_3': 0.1400319345316031, 'Bleu_4': 0.09798603075394732, 'METEOR': 0.1839294293681203, 'ROUGE_L': 0.29270809934519915, 'CIDEr': 0.3615169214900403\", \"'Bleu_1': 0.3204883297593066, 'Bleu_2': 0.1764290925968712, 'Bleu_3': 0.1036418177878664, 'Bleu_4': 0.06057769517195858, 'METEOR': 0.16842377979888004, 'ROUGE_L': 0.26485205112850363, 'CIDEr': 0.16051943614632533\", \"'Bleu_1': 0.359527320868207, 'Bleu_2': 0.21826557944828945, 'Bleu_3': 0.1440930251549521, 'Bleu_4': 0.10013551449995738, 'METEOR': 0.18686046406038442, 'ROUGE_L': 0.2920249051331039, 'CIDEr': 0.3152602099111442\", \"'Bleu_1': 0.3305044241793925, 'Bleu_2': 0.1907217169959578, 'Bleu_3': 0.11804943332569993, 'Bleu_4': 0.0751420367889762, 'METEOR': 0.17215866311581343, 'ROUGE_L': 0.2727073478048211, 'CIDEr': 0.1970861328560445\", \"'Bleu_1': 0.3082331622914141, 'Bleu_2': 0.18380859756631332, 'Bleu_3': 0.1204792561031338, 'Bleu_4': 0.08322645567104153, 'METEOR': 0.1689806818025887, 'ROUGE_L': 0.30126386748231365, 'CIDEr': 0.3455123770232683\", \"'Bleu_1': 0.294978025472759, 'Bleu_2': 0.16854393428283573, 'Bleu_3': 0.1052211739276604, 'Bleu_4': 0.06864553880558494, 'METEOR': 0.1606797489683947, 'ROUGE_L': 0.2785843365573748, 'CIDEr': 0.2482065255225251\", \"'Bleu_1': 0.3351737340666462, 'Bleu_2': 0.20035935726749407, 'Bleu_3': 0.13014564958853295, 'Bleu_4': 0.090714331182446, 'METEOR': 0.18247472811198165, 'ROUGE_L': 0.28653191763573843, 'CIDEr': 0.29878771125175285\", \"'Bleu_1': 0.3059826027934482, 'Bleu_2': 0.1743190762368705, 'Bleu_3': 0.10562012305893385, 'Bleu_4': 0.06578155741707753, 'METEOR': 0.17165160360011225, 'ROUGE_L': 0.26832881237152406, 'CIDEr': 0.18577664278819572\", \"'Bleu_1': 0.37581394249142774, 'Bleu_2': 0.2299444239293509, 'Bleu_3': 0.15496202922745966, 'Bleu_4': 0.11007659463298526, 'METEOR': 0.190547883384764, 'ROUGE_L': 0.30331436872750783, 'CIDEr': 0.3573950336235383\", \"'Bleu_1': 0.35162768462230154, 'Bleu_2': 0.2043081905115046, 'Bleu_3': 0.13060195018674414, 'Bleu_4': 0.08786270373940724, 'METEOR': 0.18001322519552035, 'ROUGE_L': 0.2881004962162176, 'CIDEr': 0.31046197870017767\", \"'Bleu_1': 0.3612609454256348, 'Bleu_2': 0.22013542627545432, 'Bleu_3': 0.14626533004327236, 'Bleu_4': 0.10298350017945743, 'METEOR': 0.18774328553987105, 'ROUGE_L': 0.29471555196157856, 'CIDEr': 0.33142318787362296\", \"'Bleu_1': 0.32868827752007934, 'Bleu_2': 0.18066975782303052, 'Bleu_3': 0.10649210930527282, 'Bleu_4': 0.0627157882875887, 'METEOR': 0.17182110486668742, 'ROUGE_L': 0.2686883913501368, 'CIDEr': 0.15961573454026964\", \"'Bleu_1': 0.3522315379913373, 'Bleu_2': 0.20981991929836422, 'Bleu_3': 0.13371644764956725, 'Bleu_4': 0.09027015200797454, 'METEOR': 0.1845388414656559, 'ROUGE_L': 0.2848968423985958, 'CIDEr': 0.275993223950085\", \"'Bleu_1': 0.313673925889567, 'Bleu_2': 0.17598075409339184, 'Bleu_3': 0.10355550912254234, 'Bleu_4': 0.06053347942363859, 'METEOR': 0.16909097769424464, 'ROUGE_L': 0.2626453256409488, 'CIDEr': 0.1601368512088879\", \"'Bleu_1': 0.3503807540694962, 'Bleu_2': 0.21750076397004692, 'Bleu_3': 0.1485244363604553, 'Bleu_4': 0.10623305038876892, 'METEOR': 0.18314833826544136, 'ROUGE_L': 0.30327343424677444, 'CIDEr': 0.40513695037537445\", \"'Bleu_1': 0.31495325009978836, 'Bleu_2': 0.17844989560745633, 'Bleu_3': 0.10893081565024912, 'Bleu_4': 0.06882558287814124, 'METEOR': 0.16813800145590127, 'ROUGE_L': 0.27728128121286894, 'CIDEr': 0.18656565515626175\", \"'Bleu_1': 0.3267448737626938, 'Bleu_2': 0.18831534325798924, 'Bleu_3': 0.11607140301996507, 'Bleu_4': 0.07319673896709653, 'METEOR': 0.17529997651241752, 'ROUGE_L': 0.2780863942251655, 'CIDEr': 0.22732136072067718\", \"'Bleu_1': 0.296792526973291, 'Bleu_2': 0.16275794476094116, 'Bleu_3': 0.09593258717990348, 'Bleu_4': 0.05637416329399166, 'METEOR': 0.16451866098842144, 'ROUGE_L': 0.2601929165594764, 'CIDEr': 0.18545374610963844\", \"'Bleu_1': 0.36440628444596074, 'Bleu_2': 0.21951374444766553, 'Bleu_3': 0.1473643082160101, 'Bleu_4': 0.10426350299081173, 'METEOR': 0.1825033863914506, 'ROUGE_L': 0.2949717555668533, 'CIDEr': 0.3455283391323563\", \"'Bleu_1': 0.327653570653318, 'Bleu_2': 0.18639132645987172, 'Bleu_3': 0.11530960653226464, 'Bleu_4': 0.07252467921522392, 'METEOR': 0.16723202727312855, 'ROUGE_L': 0.2711895513540959, 'CIDEr': 0.18111161605942291\", \"'Bleu_1': 0.329321162788924, 'Bleu_2': 0.19160834211982478, 'Bleu_3': 0.12009571440698896, 'Bleu_4': 0.07839425785534188, 'METEOR': 0.17768832954911834, 'ROUGE_L': 0.27015410723782957, 'CIDEr': 0.23427604982307354\", \"'Bleu_1': 0.3069051166865657, 'Bleu_2': 0.16769100183322, 'Bleu_3': 0.09478393878471854, 'Bleu_4': 0.04967038072117183, 'METEOR': 0.16571465364488777, 'ROUGE_L': 0.254030476640455, 'CIDEr': 0.14301138812986885\", \"'Bleu_1': 0.34025513065478974, 'Bleu_2': 0.2051692244710195, 'Bleu_3': 0.13527412019165772, 'Bleu_4': 0.09380106979306803, 'METEOR': 0.18205692707711804, 'ROUGE_L': 0.2812960161076626, 'CIDEr': 0.3077212186723136\", \"'Bleu_1': 0.30600034394172365, 'Bleu_2': 0.17270988936198525, 'Bleu_3': 0.10305530072591924, 'Bleu_4': 0.061740071518495074, 'METEOR': 0.16807671324537743, 'ROUGE_L': 0.2606515658296781, 'CIDEr': 0.1697845583258956\", \"'Bleu_1': 0.3258888275447358, 'Bleu_2': 0.1894776391532511, 'Bleu_3': 0.11994227886141771, 'Bleu_4': 0.07918465209828178, 'METEOR': 0.1733758469984291, 'ROUGE_L': 0.28307740967716877, 'CIDEr': 0.3033395364450179\", \"'Bleu_1': 0.3164462027939931, 'Bleu_2': 0.18350080076483935, 'Bleu_3': 0.1155587063797959, 'Bleu_4': 0.07589360058716355, 'METEOR': 0.17072235128907423, 'ROUGE_L': 0.2745124041545201, 'CIDEr': 0.26120877086955785\", \"'Bleu_1': 0.36687525624824724, 'Bleu_2': 0.22153431448381714, 'Bleu_3': 0.1459764385248912, 'Bleu_4': 0.1008285959371842, 'METEOR': 0.18493665692962907, 'ROUGE_L': 0.29838865746858645, 'CIDEr': 0.2766855633605585\", \"'Bleu_1': 0.3230233213135299, 'Bleu_2': 0.18341978261461755, 'Bleu_3': 0.11229383929843208, 'Bleu_4': 0.06885192442759192, 'METEOR': 0.16579864773069025, 'ROUGE_L': 0.2685059569605114, 'CIDEr': 0.1712217991223846\", \"'Bleu_1': 0.3617745790755095, 'Bleu_2': 0.21489810949792823, 'Bleu_3': 0.14037786898079002, 'Bleu_4': 0.09683217738793744, 'METEOR': 0.18251675424914482, 'ROUGE_L': 0.2888218413023368, 'CIDEr': 0.3019661571641483\", \"'Bleu_1': 0.33863572307043827, 'Bleu_2': 0.1938500608815155, 'Bleu_3': 0.11986744863193795, 'Bleu_4': 0.07413973645591145, 'METEOR': 0.1759556986066786, 'ROUGE_L': 0.2782960967842089, 'CIDEr': 0.18515986549240807\", \"'Bleu_1': 0.37672588753057784, 'Bleu_2': 0.2270724440279915, 'Bleu_3': 0.14920420871165613, 'Bleu_4': 0.10258696847869851, 'METEOR': 0.18928217124033442, 'ROUGE_L': 0.30186309084035795, 'CIDEr': 0.3165328852380084\", \"'Bleu_1': 0.3428231272916385, 'Bleu_2': 0.19879655496569526, 'Bleu_3': 0.1228836234641455, 'Bleu_4': 0.07767312063927716, 'METEOR': 0.17734727747928344, 'ROUGE_L': 0.27645012286920567, 'CIDEr': 0.23742474817704218\", \"'Bleu_1': 0.3599432814205901, 'Bleu_2': 0.21828488047266445, 'Bleu_3': 0.1445094029125027, 'Bleu_4': 0.10177947559947335, 'METEOR': 0.18751102420734256, 'ROUGE_L': 0.2962476804529241, 'CIDEr': 0.3700239849995696\", \"'Bleu_1': 0.33983171044074956, 'Bleu_2': 0.19625835236076, 'Bleu_3': 0.12213233857903609, 'Bleu_4': 0.0793925642134049, 'METEOR': 0.17623855770794425, 'ROUGE_L': 0.2779815520496007, 'CIDEr': 0.24476288492198806\", \"'Bleu_1': 0.359534415544128, 'Bleu_2': 0.22074135270186898, 'Bleu_3': 0.14743159377917106, 'Bleu_4': 0.10264123136176345, 'METEOR': 0.18688803203241908, 'ROUGE_L': 0.2968746243837464, 'CIDEr': 0.32001531296434665\", \"'Bleu_1': 0.32321930028491447, 'Bleu_2': 0.18158032437972776, 'Bleu_3': 0.10816448643671449, 'Bleu_4': 0.0634143730248223, 'METEOR': 0.17232455853389358, 'ROUGE_L': 0.2774395975200992, 'CIDEr': 0.19714528380437096\", \"'Bleu_1': 0.37824556563004746, 'Bleu_2': 0.2312388257405095, 'Bleu_3': 0.1552234107123029, 'Bleu_4': 0.11110276889471793, 'METEOR': 0.1930368315819105, 'ROUGE_L': 0.30021273964043177, 'CIDEr': 0.35553575125498804\", \"'Bleu_1': 0.3354909960412283, 'Bleu_2': 0.18988603162046214, 'Bleu_3': 0.11503098795200885, 'Bleu_4': 0.06901193133577042, 'METEOR': 0.17325506285302764, 'ROUGE_L': 0.2700127417270001, 'CIDEr': 0.1927868498981204\", \"'Bleu_1': 0.352917440764452, 'Bleu_2': 0.210462005903711, 'Bleu_3': 0.13817653095493165, 'Bleu_4': 0.09538199614687908, 'METEOR': 0.18229344279401385, 'ROUGE_L': 0.2909882206515146, 'CIDEr': 0.2993359454499715\", \"'Bleu_1': 0.3264801380959263, 'Bleu_2': 0.1864381643163203, 'Bleu_3': 0.11540114168010984, 'Bleu_4': 0.07312513683029068, 'METEOR': 0.17263034573223968, 'ROUGE_L': 0.2748597182282894, 'CIDEr': 0.2216621081112141\", \"'Bleu_1': 0.35164905658685824, 'Bleu_2': 0.20931032762498294, 'Bleu_3': 0.13595621829801552, 'Bleu_4': 0.09284804631618906, 'METEOR': 0.18481803676005926, 'ROUGE_L': 0.2904558152345283, 'CIDEr': 0.31393940523688973\", \"'Bleu_1': 0.32557233134587005, 'Bleu_2': 0.18501182065503757, 'Bleu_3': 0.11240195762071427, 'Bleu_4': 0.06723897727143258, 'METEOR': 0.17151360013231226, 'ROUGE_L': 0.2719387812692227, 'CIDEr': 0.17886343738852836\"]\n"
     ]
    }
   ],
   "source": [
    "score_pat = \"'Bleu_1': \\d+.\\d+e*-*\\d*, 'Bleu_2': \\d+.\\d+e*-*\\d*, 'Bleu_3': \\d+.\\d+e*-*\\d*, 'Bleu_4': \\d+.\\d+e*-*\\d*, 'METEOR': \\d+.\\d+e*-*\\d*, 'ROUGE_L': \\d+.\\d+e*-*\\d*, 'CIDEr': \\d+.\\d+e*-*\\d*\"\n",
    "score_p = re.compile(score_pat)\n",
    "score_result = score_p.findall(log)\n",
    "print(len(score_result))\n",
    "print(score_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chronic-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rows = []\n",
    "score_rows_val = []\n",
    "for i, score in enumerate(score_result):\n",
    "    row = []\n",
    "    row_val = []\n",
    "    if '(TEST)' in epoch_result[i]:\n",
    "        p = re.compile('\\d+')\n",
    "        epoch = p.findall(epoch_result[i])[0]\n",
    "        row.append(epoch)\n",
    "        scores = []\n",
    "        p = re.compile('\\d+.\\d+e*-*\\d*')\n",
    "        row.extend(p.findall(score))\n",
    "        score_rows.append(row)\n",
    "    elif '(VAL)' in epoch_result[i]:\n",
    "        p = re.compile('\\d+')\n",
    "        epoch = p.findall(epoch_result[i])[0]\n",
    "        row_val.append(epoch)\n",
    "        scores = []\n",
    "        p = re.compile('\\d+.\\d+e*-*\\d*')\n",
    "        row_val.extend(p.findall(score))\n",
    "        score_rows_val.append(row_val)\n",
    "    #print(\"score_rows:\", score_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quiet-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"./experiments/\"+experiment+\".csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Epoch','Bleu_1','Bleu_2','Bleu_3','Bleu_4','METEOR','ROUGE_L','CIDEr'])\n",
    "    for score in score_rows:\n",
    "        writer.writerow(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aging-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./experiments/\"+experiment+\"_val.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Epoch','Bleu_1','Bleu_2','Bleu_3','Bleu_4','METEOR','ROUGE_L','CIDEr'])\n",
    "    for score in score_rows_val:\n",
    "        writer.writerow(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-henry",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stock-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3606\n",
      "['LabelSmoothing Loss = 6.919795989990234', 'LabelSmoothing Loss = 6.951554298400879', 'LabelSmoothing Loss = 6.945693016052246', 'LabelSmoothing Loss = 6.908546447753906', 'LabelSmoothing Loss = 6.938315391540527', 'LabelSmoothing Loss = 6.90019416809082', 'LabelSmoothing Loss = 6.918609142303467', 'LabelSmoothing Loss = 6.754445552825928', 'LabelSmoothing Loss = 6.977380275726318', 'LabelSmoothing Loss = 6.889980316162109']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "loss_pat = \"LabelSmoothing Loss = \\d+.\\d+\"  # \"CrossEntropy Loss = \\d+.\\d+\"\n",
    "loss_p = re.compile(loss_pat)\n",
    "loss_result = loss_p.findall(log)\n",
    "print(len(loss_result))\n",
    "print(loss_result[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "damaged-consultancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3606\n",
      "['6.919795989990234', '6.951554298400879', '6.945693016052246', '6.908546447753906', '6.938315391540527', '6.90019416809082', '6.918609142303467', '6.754445552825928', '6.977380275726318', '6.889980316162109']\n"
     ]
    }
   ],
   "source": [
    "loss_pat = \"\\d+.\\d+\"\n",
    "loss_p = re.compile(loss_pat)\n",
    "loss = loss_p.findall(\" \".join(loss_result))\n",
    "print(len(loss))\n",
    "print(loss[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "earlier-gambling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.919795989990234, 6.951554298400879, 6.945693016052246, 6.908546447753906, 6.938315391540527, 6.90019416809082, 6.918609142303467, 6.754445552825928, 6.977380275726318, 6.889980316162109]\n",
      "0.2945133149623871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2910"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_float = []\n",
    "for l in loss:\n",
    "    loss_float.append(float(l))\n",
    "print(loss_float[:10])\n",
    "print(min(loss_float))\n",
    "loss_float.index(min(loss_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "missing-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3606\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "for i in range(0, len(loss)):\n",
    "    idx.append(i)\n",
    "print(len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "provincial-hobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(idx, loss_float, 'r--' )\n",
    "plt.title('Label smoothing loss')\n",
    "plt.xlabel('Iterations', fontsize=10)\n",
    "#plt.ylabel('Loss', fontsize=10)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axes.yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d1a33",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a946ee",
   "metadata": {},
   "source": [
    "## 1. X_Transformer(mimic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/xtransformer'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_52a3b_row0_col1, #T_52a3b_row0_col2, #T_52a3b_row1_col1, #T_52a3b_row1_col2, #T_52a3b_row2_col3, #T_52a3b_row2_col4, #T_52a3b_row3_col3, #T_52a3b_row3_col4, #T_52a3b_row4_col0, #T_52a3b_row4_col5, #T_52a3b_row5_col6, #T_52a3b_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_52a3b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_52a3b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_52a3b_row0_col0\" class=\"data row0 col0\" >175</td>\n",
       "      <td id=\"T_52a3b_row0_col1\" class=\"data row0 col1\" >0.387451</td>\n",
       "      <td id=\"T_52a3b_row0_col2\" class=\"data row0 col2\" >0.257668</td>\n",
       "      <td id=\"T_52a3b_row0_col3\" class=\"data row0 col3\" >0.179389</td>\n",
       "      <td id=\"T_52a3b_row0_col4\" class=\"data row0 col4\" >0.130434</td>\n",
       "      <td id=\"T_52a3b_row0_col5\" class=\"data row0 col5\" >0.232736</td>\n",
       "      <td id=\"T_52a3b_row0_col6\" class=\"data row0 col6\" >0.332429</td>\n",
       "      <td id=\"T_52a3b_row0_col7\" class=\"data row0 col7\" >0.285342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52a3b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_52a3b_row1_col0\" class=\"data row1 col0\" >175</td>\n",
       "      <td id=\"T_52a3b_row1_col1\" class=\"data row1 col1\" >0.387451</td>\n",
       "      <td id=\"T_52a3b_row1_col2\" class=\"data row1 col2\" >0.257668</td>\n",
       "      <td id=\"T_52a3b_row1_col3\" class=\"data row1 col3\" >0.179389</td>\n",
       "      <td id=\"T_52a3b_row1_col4\" class=\"data row1 col4\" >0.130434</td>\n",
       "      <td id=\"T_52a3b_row1_col5\" class=\"data row1 col5\" >0.232736</td>\n",
       "      <td id=\"T_52a3b_row1_col6\" class=\"data row1 col6\" >0.332429</td>\n",
       "      <td id=\"T_52a3b_row1_col7\" class=\"data row1 col7\" >0.285342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52a3b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_52a3b_row2_col0\" class=\"data row2 col0\" >125</td>\n",
       "      <td id=\"T_52a3b_row2_col1\" class=\"data row2 col1\" >0.380585</td>\n",
       "      <td id=\"T_52a3b_row2_col2\" class=\"data row2 col2\" >0.256397</td>\n",
       "      <td id=\"T_52a3b_row2_col3\" class=\"data row2 col3\" >0.181555</td>\n",
       "      <td id=\"T_52a3b_row2_col4\" class=\"data row2 col4\" >0.134096</td>\n",
       "      <td id=\"T_52a3b_row2_col5\" class=\"data row2 col5\" >0.229927</td>\n",
       "      <td id=\"T_52a3b_row2_col6\" class=\"data row2 col6\" >0.338627</td>\n",
       "      <td id=\"T_52a3b_row2_col7\" class=\"data row2 col7\" >0.291803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52a3b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_52a3b_row3_col0\" class=\"data row3 col0\" >125</td>\n",
       "      <td id=\"T_52a3b_row3_col1\" class=\"data row3 col1\" >0.380585</td>\n",
       "      <td id=\"T_52a3b_row3_col2\" class=\"data row3 col2\" >0.256397</td>\n",
       "      <td id=\"T_52a3b_row3_col3\" class=\"data row3 col3\" >0.181555</td>\n",
       "      <td id=\"T_52a3b_row3_col4\" class=\"data row3 col4\" >0.134096</td>\n",
       "      <td id=\"T_52a3b_row3_col5\" class=\"data row3 col5\" >0.229927</td>\n",
       "      <td id=\"T_52a3b_row3_col6\" class=\"data row3 col6\" >0.338627</td>\n",
       "      <td id=\"T_52a3b_row3_col7\" class=\"data row3 col7\" >0.291803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52a3b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_52a3b_row4_col0\" class=\"data row4 col0\" >233</td>\n",
       "      <td id=\"T_52a3b_row4_col1\" class=\"data row4 col1\" >0.377428</td>\n",
       "      <td id=\"T_52a3b_row4_col2\" class=\"data row4 col2\" >0.255548</td>\n",
       "      <td id=\"T_52a3b_row4_col3\" class=\"data row4 col3\" >0.180973</td>\n",
       "      <td id=\"T_52a3b_row4_col4\" class=\"data row4 col4\" >0.134017</td>\n",
       "      <td id=\"T_52a3b_row4_col5\" class=\"data row4 col5\" >0.233230</td>\n",
       "      <td id=\"T_52a3b_row4_col6\" class=\"data row4 col6\" >0.342638</td>\n",
       "      <td id=\"T_52a3b_row4_col7\" class=\"data row4 col7\" >0.309591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52a3b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_52a3b_row5_col0\" class=\"data row5 col0\" >70</td>\n",
       "      <td id=\"T_52a3b_row5_col1\" class=\"data row5 col1\" >0.306219</td>\n",
       "      <td id=\"T_52a3b_row5_col2\" class=\"data row5 col2\" >0.220519</td>\n",
       "      <td id=\"T_52a3b_row5_col3\" class=\"data row5 col3\" >0.164565</td>\n",
       "      <td id=\"T_52a3b_row5_col4\" class=\"data row5 col4\" >0.126747</td>\n",
       "      <td id=\"T_52a3b_row5_col5\" class=\"data row5 col5\" >0.218107</td>\n",
       "      <td id=\"T_52a3b_row5_col6\" class=\"data row5 col6\" >0.352799</td>\n",
       "      <td id=\"T_52a3b_row5_col7\" class=\"data row5 col7\" >0.358382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52a3b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_52a3b_row6_col0\" class=\"data row6 col0\" >37</td>\n",
       "      <td id=\"T_52a3b_row6_col1\" class=\"data row6 col1\" >0.259697</td>\n",
       "      <td id=\"T_52a3b_row6_col2\" class=\"data row6 col2\" >0.184385</td>\n",
       "      <td id=\"T_52a3b_row6_col3\" class=\"data row6 col3\" >0.136768</td>\n",
       "      <td id=\"T_52a3b_row6_col4\" class=\"data row6 col4\" >0.105231</td>\n",
       "      <td id=\"T_52a3b_row6_col5\" class=\"data row6 col5\" >0.192482</td>\n",
       "      <td id=\"T_52a3b_row6_col6\" class=\"data row6 col6\" >0.344987</td>\n",
       "      <td id=\"T_52a3b_row6_col7\" class=\"data row6 col7\" >0.414077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f88602897d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c39026c",
   "metadata": {},
   "source": [
    "# XTransformer(End-to-End)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db1267",
   "metadata": {},
   "source": [
    "## One-Resnet(Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/xtransformer_pair'\n",
    "log_val_path=os.path.join(root, 'log_val.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5585_row0_col1, #T_f5585_row0_col2, #T_f5585_row0_col3, #T_f5585_row0_col4, #T_f5585_row1_col1, #T_f5585_row1_col2, #T_f5585_row1_col3, #T_f5585_row1_col4, #T_f5585_row2_col1, #T_f5585_row2_col2, #T_f5585_row2_col3, #T_f5585_row2_col4, #T_f5585_row3_col1, #T_f5585_row3_col2, #T_f5585_row3_col3, #T_f5585_row3_col4, #T_f5585_row4_col0, #T_f5585_row4_col5, #T_f5585_row5_col6, #T_f5585_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5585_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5585_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5585_row0_col0\" class=\"data row0 col0\" >22</td>\n",
       "      <td id=\"T_f5585_row0_col1\" class=\"data row0 col1\" >0.305479</td>\n",
       "      <td id=\"T_f5585_row0_col2\" class=\"data row0 col2\" >0.215439</td>\n",
       "      <td id=\"T_f5585_row0_col3\" class=\"data row0 col3\" >0.160601</td>\n",
       "      <td id=\"T_f5585_row0_col4\" class=\"data row0 col4\" >0.124498</td>\n",
       "      <td id=\"T_f5585_row0_col5\" class=\"data row0 col5\" >0.207296</td>\n",
       "      <td id=\"T_f5585_row0_col6\" class=\"data row0 col6\" >0.330040</td>\n",
       "      <td id=\"T_f5585_row0_col7\" class=\"data row0 col7\" >0.429666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5585_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5585_row1_col0\" class=\"data row1 col0\" >22</td>\n",
       "      <td id=\"T_f5585_row1_col1\" class=\"data row1 col1\" >0.305479</td>\n",
       "      <td id=\"T_f5585_row1_col2\" class=\"data row1 col2\" >0.215439</td>\n",
       "      <td id=\"T_f5585_row1_col3\" class=\"data row1 col3\" >0.160601</td>\n",
       "      <td id=\"T_f5585_row1_col4\" class=\"data row1 col4\" >0.124498</td>\n",
       "      <td id=\"T_f5585_row1_col5\" class=\"data row1 col5\" >0.207296</td>\n",
       "      <td id=\"T_f5585_row1_col6\" class=\"data row1 col6\" >0.330040</td>\n",
       "      <td id=\"T_f5585_row1_col7\" class=\"data row1 col7\" >0.429666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5585_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5585_row2_col0\" class=\"data row2 col0\" >22</td>\n",
       "      <td id=\"T_f5585_row2_col1\" class=\"data row2 col1\" >0.305479</td>\n",
       "      <td id=\"T_f5585_row2_col2\" class=\"data row2 col2\" >0.215439</td>\n",
       "      <td id=\"T_f5585_row2_col3\" class=\"data row2 col3\" >0.160601</td>\n",
       "      <td id=\"T_f5585_row2_col4\" class=\"data row2 col4\" >0.124498</td>\n",
       "      <td id=\"T_f5585_row2_col5\" class=\"data row2 col5\" >0.207296</td>\n",
       "      <td id=\"T_f5585_row2_col6\" class=\"data row2 col6\" >0.330040</td>\n",
       "      <td id=\"T_f5585_row2_col7\" class=\"data row2 col7\" >0.429666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5585_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5585_row3_col0\" class=\"data row3 col0\" >22</td>\n",
       "      <td id=\"T_f5585_row3_col1\" class=\"data row3 col1\" >0.305479</td>\n",
       "      <td id=\"T_f5585_row3_col2\" class=\"data row3 col2\" >0.215439</td>\n",
       "      <td id=\"T_f5585_row3_col3\" class=\"data row3 col3\" >0.160601</td>\n",
       "      <td id=\"T_f5585_row3_col4\" class=\"data row3 col4\" >0.124498</td>\n",
       "      <td id=\"T_f5585_row3_col5\" class=\"data row3 col5\" >0.207296</td>\n",
       "      <td id=\"T_f5585_row3_col6\" class=\"data row3 col6\" >0.330040</td>\n",
       "      <td id=\"T_f5585_row3_col7\" class=\"data row3 col7\" >0.429666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5585_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f5585_row4_col0\" class=\"data row4 col0\" >32</td>\n",
       "      <td id=\"T_f5585_row4_col1\" class=\"data row4 col1\" >0.305421</td>\n",
       "      <td id=\"T_f5585_row4_col2\" class=\"data row4 col2\" >0.214475</td>\n",
       "      <td id=\"T_f5585_row4_col3\" class=\"data row4 col3\" >0.159297</td>\n",
       "      <td id=\"T_f5585_row4_col4\" class=\"data row4 col4\" >0.122980</td>\n",
       "      <td id=\"T_f5585_row4_col5\" class=\"data row4 col5\" >0.207539</td>\n",
       "      <td id=\"T_f5585_row4_col6\" class=\"data row4 col6\" >0.330397</td>\n",
       "      <td id=\"T_f5585_row4_col7\" class=\"data row4 col7\" >0.430449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5585_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f5585_row5_col0\" class=\"data row5 col0\" >17</td>\n",
       "      <td id=\"T_f5585_row5_col1\" class=\"data row5 col1\" >0.219380</td>\n",
       "      <td id=\"T_f5585_row5_col2\" class=\"data row5 col2\" >0.161252</td>\n",
       "      <td id=\"T_f5585_row5_col3\" class=\"data row5 col3\" >0.124058</td>\n",
       "      <td id=\"T_f5585_row5_col4\" class=\"data row5 col4\" >0.097925</td>\n",
       "      <td id=\"T_f5585_row5_col5\" class=\"data row5 col5\" >0.187272</td>\n",
       "      <td id=\"T_f5585_row5_col6\" class=\"data row5 col6\" >0.346611</td>\n",
       "      <td id=\"T_f5585_row5_col7\" class=\"data row5 col7\" >0.363119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5585_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f5585_row6_col0\" class=\"data row6 col0\" >23</td>\n",
       "      <td id=\"T_f5585_row6_col1\" class=\"data row6 col1\" >0.299751</td>\n",
       "      <td id=\"T_f5585_row6_col2\" class=\"data row6 col2\" >0.210692</td>\n",
       "      <td id=\"T_f5585_row6_col3\" class=\"data row6 col3\" >0.156487</td>\n",
       "      <td id=\"T_f5585_row6_col4\" class=\"data row6 col4\" >0.120768</td>\n",
       "      <td id=\"T_f5585_row6_col5\" class=\"data row6 col5\" >0.207023</td>\n",
       "      <td id=\"T_f5585_row6_col6\" class=\"data row6 col6\" >0.331106</td>\n",
       "      <td id=\"T_f5585_row6_col7\" class=\"data row6 col7\" >0.474111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f87c7ad5590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd8c4b",
   "metadata": {},
   "source": [
    "## One-Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/xtransformer_one_dense'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7a8a8_row0_col1, #T_7a8a8_row1_col2, #T_7a8a8_row1_col3, #T_7a8a8_row1_col5, #T_7a8a8_row2_col2, #T_7a8a8_row2_col3, #T_7a8a8_row2_col5, #T_7a8a8_row3_col4, #T_7a8a8_row4_col2, #T_7a8a8_row4_col3, #T_7a8a8_row4_col5, #T_7a8a8_row5_col0, #T_7a8a8_row5_col6, #T_7a8a8_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7a8a8_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7a8a8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7a8a8_row0_col0\" class=\"data row0 col0\" >79</td>\n",
       "      <td id=\"T_7a8a8_row0_col1\" class=\"data row0 col1\" >0.320604</td>\n",
       "      <td id=\"T_7a8a8_row0_col2\" class=\"data row0 col2\" >0.222350</td>\n",
       "      <td id=\"T_7a8a8_row0_col3\" class=\"data row0 col3\" >0.158737</td>\n",
       "      <td id=\"T_7a8a8_row0_col4\" class=\"data row0 col4\" >0.115587</td>\n",
       "      <td id=\"T_7a8a8_row0_col5\" class=\"data row0 col5\" >0.212959</td>\n",
       "      <td id=\"T_7a8a8_row0_col6\" class=\"data row0 col6\" >0.337769</td>\n",
       "      <td id=\"T_7a8a8_row0_col7\" class=\"data row0 col7\" >0.208471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a8a8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7a8a8_row1_col0\" class=\"data row1 col0\" >81</td>\n",
       "      <td id=\"T_7a8a8_row1_col1\" class=\"data row1 col1\" >0.320542</td>\n",
       "      <td id=\"T_7a8a8_row1_col2\" class=\"data row1 col2\" >0.222876</td>\n",
       "      <td id=\"T_7a8a8_row1_col3\" class=\"data row1 col3\" >0.159496</td>\n",
       "      <td id=\"T_7a8a8_row1_col4\" class=\"data row1 col4\" >0.116727</td>\n",
       "      <td id=\"T_7a8a8_row1_col5\" class=\"data row1 col5\" >0.214547</td>\n",
       "      <td id=\"T_7a8a8_row1_col6\" class=\"data row1 col6\" >0.337975</td>\n",
       "      <td id=\"T_7a8a8_row1_col7\" class=\"data row1 col7\" >0.221249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a8a8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7a8a8_row2_col0\" class=\"data row2 col0\" >81</td>\n",
       "      <td id=\"T_7a8a8_row2_col1\" class=\"data row2 col1\" >0.320542</td>\n",
       "      <td id=\"T_7a8a8_row2_col2\" class=\"data row2 col2\" >0.222876</td>\n",
       "      <td id=\"T_7a8a8_row2_col3\" class=\"data row2 col3\" >0.159496</td>\n",
       "      <td id=\"T_7a8a8_row2_col4\" class=\"data row2 col4\" >0.116727</td>\n",
       "      <td id=\"T_7a8a8_row2_col5\" class=\"data row2 col5\" >0.214547</td>\n",
       "      <td id=\"T_7a8a8_row2_col6\" class=\"data row2 col6\" >0.337975</td>\n",
       "      <td id=\"T_7a8a8_row2_col7\" class=\"data row2 col7\" >0.221249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a8a8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7a8a8_row3_col0\" class=\"data row3 col0\" >98</td>\n",
       "      <td id=\"T_7a8a8_row3_col1\" class=\"data row3 col1\" >0.312375</td>\n",
       "      <td id=\"T_7a8a8_row3_col2\" class=\"data row3 col2\" >0.219953</td>\n",
       "      <td id=\"T_7a8a8_row3_col3\" class=\"data row3 col3\" >0.159151</td>\n",
       "      <td id=\"T_7a8a8_row3_col4\" class=\"data row3 col4\" >0.117988</td>\n",
       "      <td id=\"T_7a8a8_row3_col5\" class=\"data row3 col5\" >0.211073</td>\n",
       "      <td id=\"T_7a8a8_row3_col6\" class=\"data row3 col6\" >0.341805</td>\n",
       "      <td id=\"T_7a8a8_row3_col7\" class=\"data row3 col7\" >0.235747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a8a8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7a8a8_row4_col0\" class=\"data row4 col0\" >81</td>\n",
       "      <td id=\"T_7a8a8_row4_col1\" class=\"data row4 col1\" >0.320542</td>\n",
       "      <td id=\"T_7a8a8_row4_col2\" class=\"data row4 col2\" >0.222876</td>\n",
       "      <td id=\"T_7a8a8_row4_col3\" class=\"data row4 col3\" >0.159496</td>\n",
       "      <td id=\"T_7a8a8_row4_col4\" class=\"data row4 col4\" >0.116727</td>\n",
       "      <td id=\"T_7a8a8_row4_col5\" class=\"data row4 col5\" >0.214547</td>\n",
       "      <td id=\"T_7a8a8_row4_col6\" class=\"data row4 col6\" >0.337975</td>\n",
       "      <td id=\"T_7a8a8_row4_col7\" class=\"data row4 col7\" >0.221249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a8a8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7a8a8_row5_col0\" class=\"data row5 col0\" >327</td>\n",
       "      <td id=\"T_7a8a8_row5_col1\" class=\"data row5 col1\" >0.297130</td>\n",
       "      <td id=\"T_7a8a8_row5_col2\" class=\"data row5 col2\" >0.210579</td>\n",
       "      <td id=\"T_7a8a8_row5_col3\" class=\"data row5 col3\" >0.153614</td>\n",
       "      <td id=\"T_7a8a8_row5_col4\" class=\"data row5 col4\" >0.115365</td>\n",
       "      <td id=\"T_7a8a8_row5_col5\" class=\"data row5 col5\" >0.206356</td>\n",
       "      <td id=\"T_7a8a8_row5_col6\" class=\"data row5 col6\" >0.345371</td>\n",
       "      <td id=\"T_7a8a8_row5_col7\" class=\"data row5 col7\" >0.304757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a8a8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7a8a8_row6_col0\" class=\"data row6 col0\" >277</td>\n",
       "      <td id=\"T_7a8a8_row6_col1\" class=\"data row6 col1\" >0.289783</td>\n",
       "      <td id=\"T_7a8a8_row6_col2\" class=\"data row6 col2\" >0.205692</td>\n",
       "      <td id=\"T_7a8a8_row6_col3\" class=\"data row6 col3\" >0.150379</td>\n",
       "      <td id=\"T_7a8a8_row6_col4\" class=\"data row6 col4\" >0.113322</td>\n",
       "      <td id=\"T_7a8a8_row6_col5\" class=\"data row6 col5\" >0.202769</td>\n",
       "      <td id=\"T_7a8a8_row6_col6\" class=\"data row6 col6\" >0.345033</td>\n",
       "      <td id=\"T_7a8a8_row6_col7\" class=\"data row6 col7\" >0.341677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f87c7465fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## No-Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/xtransformer_no_dense'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7373e_row0_col1, #T_7373e_row0_col2, #T_7373e_row0_col3, #T_7373e_row0_col4, #T_7373e_row0_col5, #T_7373e_row1_col1, #T_7373e_row1_col2, #T_7373e_row1_col3, #T_7373e_row1_col4, #T_7373e_row1_col5, #T_7373e_row2_col1, #T_7373e_row2_col2, #T_7373e_row2_col3, #T_7373e_row2_col4, #T_7373e_row2_col5, #T_7373e_row3_col1, #T_7373e_row3_col2, #T_7373e_row3_col3, #T_7373e_row3_col4, #T_7373e_row3_col5, #T_7373e_row4_col1, #T_7373e_row4_col2, #T_7373e_row4_col3, #T_7373e_row4_col4, #T_7373e_row4_col5, #T_7373e_row5_col0, #T_7373e_row5_col6, #T_7373e_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7373e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7373e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7373e_row0_col0\" class=\"data row0 col0\" >39</td>\n",
       "      <td id=\"T_7373e_row0_col1\" class=\"data row0 col1\" >0.315976</td>\n",
       "      <td id=\"T_7373e_row0_col2\" class=\"data row0 col2\" >0.219718</td>\n",
       "      <td id=\"T_7373e_row0_col3\" class=\"data row0 col3\" >0.156637</td>\n",
       "      <td id=\"T_7373e_row0_col4\" class=\"data row0 col4\" >0.114772</td>\n",
       "      <td id=\"T_7373e_row0_col5\" class=\"data row0 col5\" >0.209438</td>\n",
       "      <td id=\"T_7373e_row0_col6\" class=\"data row0 col6\" >0.333612</td>\n",
       "      <td id=\"T_7373e_row0_col7\" class=\"data row0 col7\" >0.239103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7373e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7373e_row1_col0\" class=\"data row1 col0\" >39</td>\n",
       "      <td id=\"T_7373e_row1_col1\" class=\"data row1 col1\" >0.315976</td>\n",
       "      <td id=\"T_7373e_row1_col2\" class=\"data row1 col2\" >0.219718</td>\n",
       "      <td id=\"T_7373e_row1_col3\" class=\"data row1 col3\" >0.156637</td>\n",
       "      <td id=\"T_7373e_row1_col4\" class=\"data row1 col4\" >0.114772</td>\n",
       "      <td id=\"T_7373e_row1_col5\" class=\"data row1 col5\" >0.209438</td>\n",
       "      <td id=\"T_7373e_row1_col6\" class=\"data row1 col6\" >0.333612</td>\n",
       "      <td id=\"T_7373e_row1_col7\" class=\"data row1 col7\" >0.239103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7373e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7373e_row2_col0\" class=\"data row2 col0\" >39</td>\n",
       "      <td id=\"T_7373e_row2_col1\" class=\"data row2 col1\" >0.315976</td>\n",
       "      <td id=\"T_7373e_row2_col2\" class=\"data row2 col2\" >0.219718</td>\n",
       "      <td id=\"T_7373e_row2_col3\" class=\"data row2 col3\" >0.156637</td>\n",
       "      <td id=\"T_7373e_row2_col4\" class=\"data row2 col4\" >0.114772</td>\n",
       "      <td id=\"T_7373e_row2_col5\" class=\"data row2 col5\" >0.209438</td>\n",
       "      <td id=\"T_7373e_row2_col6\" class=\"data row2 col6\" >0.333612</td>\n",
       "      <td id=\"T_7373e_row2_col7\" class=\"data row2 col7\" >0.239103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7373e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7373e_row3_col0\" class=\"data row3 col0\" >39</td>\n",
       "      <td id=\"T_7373e_row3_col1\" class=\"data row3 col1\" >0.315976</td>\n",
       "      <td id=\"T_7373e_row3_col2\" class=\"data row3 col2\" >0.219718</td>\n",
       "      <td id=\"T_7373e_row3_col3\" class=\"data row3 col3\" >0.156637</td>\n",
       "      <td id=\"T_7373e_row3_col4\" class=\"data row3 col4\" >0.114772</td>\n",
       "      <td id=\"T_7373e_row3_col5\" class=\"data row3 col5\" >0.209438</td>\n",
       "      <td id=\"T_7373e_row3_col6\" class=\"data row3 col6\" >0.333612</td>\n",
       "      <td id=\"T_7373e_row3_col7\" class=\"data row3 col7\" >0.239103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7373e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7373e_row4_col0\" class=\"data row4 col0\" >39</td>\n",
       "      <td id=\"T_7373e_row4_col1\" class=\"data row4 col1\" >0.315976</td>\n",
       "      <td id=\"T_7373e_row4_col2\" class=\"data row4 col2\" >0.219718</td>\n",
       "      <td id=\"T_7373e_row4_col3\" class=\"data row4 col3\" >0.156637</td>\n",
       "      <td id=\"T_7373e_row4_col4\" class=\"data row4 col4\" >0.114772</td>\n",
       "      <td id=\"T_7373e_row4_col5\" class=\"data row4 col5\" >0.209438</td>\n",
       "      <td id=\"T_7373e_row4_col6\" class=\"data row4 col6\" >0.333612</td>\n",
       "      <td id=\"T_7373e_row4_col7\" class=\"data row4 col7\" >0.239103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7373e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7373e_row5_col0\" class=\"data row5 col0\" >186</td>\n",
       "      <td id=\"T_7373e_row5_col1\" class=\"data row5 col1\" >0.273296</td>\n",
       "      <td id=\"T_7373e_row5_col2\" class=\"data row5 col2\" >0.195535</td>\n",
       "      <td id=\"T_7373e_row5_col3\" class=\"data row5 col3\" >0.144807</td>\n",
       "      <td id=\"T_7373e_row5_col4\" class=\"data row5 col4\" >0.110978</td>\n",
       "      <td id=\"T_7373e_row5_col5\" class=\"data row5 col5\" >0.197604</td>\n",
       "      <td id=\"T_7373e_row5_col6\" class=\"data row5 col6\" >0.348650</td>\n",
       "      <td id=\"T_7373e_row5_col7\" class=\"data row5 col7\" >0.321220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7373e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7373e_row6_col0\" class=\"data row6 col0\" >169</td>\n",
       "      <td id=\"T_7373e_row6_col1\" class=\"data row6 col1\" >0.274715</td>\n",
       "      <td id=\"T_7373e_row6_col2\" class=\"data row6 col2\" >0.195587</td>\n",
       "      <td id=\"T_7373e_row6_col3\" class=\"data row6 col3\" >0.144465</td>\n",
       "      <td id=\"T_7373e_row6_col4\" class=\"data row6 col4\" >0.110323</td>\n",
       "      <td id=\"T_7373e_row6_col5\" class=\"data row6 col5\" >0.197260</td>\n",
       "      <td id=\"T_7373e_row6_col6\" class=\"data row6 col6\" >0.347943</td>\n",
       "      <td id=\"T_7373e_row6_col7\" class=\"data row6 col7\" >0.321523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f87c718ecd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560153d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## One_Dense_x4_ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/xtransformer_one_dense_x4'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_88d4f_row0_col0, #T_88d4f_row0_col1, #T_88d4f_row0_col2, #T_88d4f_row0_col3, #T_88d4f_row0_col4, #T_88d4f_row0_col5, #T_88d4f_row0_col6, #T_88d4f_row0_col7, #T_88d4f_row1_col0, #T_88d4f_row1_col1, #T_88d4f_row1_col2, #T_88d4f_row1_col3, #T_88d4f_row1_col4, #T_88d4f_row1_col5, #T_88d4f_row1_col6, #T_88d4f_row1_col7, #T_88d4f_row2_col0, #T_88d4f_row2_col1, #T_88d4f_row2_col2, #T_88d4f_row2_col3, #T_88d4f_row2_col4, #T_88d4f_row2_col5, #T_88d4f_row2_col6, #T_88d4f_row2_col7, #T_88d4f_row3_col0, #T_88d4f_row3_col1, #T_88d4f_row3_col2, #T_88d4f_row3_col3, #T_88d4f_row3_col4, #T_88d4f_row3_col5, #T_88d4f_row3_col6, #T_88d4f_row3_col7, #T_88d4f_row4_col0, #T_88d4f_row4_col1, #T_88d4f_row4_col2, #T_88d4f_row4_col3, #T_88d4f_row4_col4, #T_88d4f_row4_col5, #T_88d4f_row4_col6, #T_88d4f_row4_col7, #T_88d4f_row5_col0, #T_88d4f_row5_col1, #T_88d4f_row5_col2, #T_88d4f_row5_col3, #T_88d4f_row5_col4, #T_88d4f_row5_col5, #T_88d4f_row5_col6, #T_88d4f_row5_col7, #T_88d4f_row6_col0, #T_88d4f_row6_col1, #T_88d4f_row6_col2, #T_88d4f_row6_col3, #T_88d4f_row6_col4, #T_88d4f_row6_col5, #T_88d4f_row6_col6, #T_88d4f_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_88d4f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88d4f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_88d4f_row0_col0\" class=\"data row0 col0\" >35</td>\n",
       "      <td id=\"T_88d4f_row0_col1\" class=\"data row0 col1\" >0.191808</td>\n",
       "      <td id=\"T_88d4f_row0_col2\" class=\"data row0 col2\" >0.142973</td>\n",
       "      <td id=\"T_88d4f_row0_col3\" class=\"data row0 col3\" >0.108382</td>\n",
       "      <td id=\"T_88d4f_row0_col4\" class=\"data row0 col4\" >0.082824</td>\n",
       "      <td id=\"T_88d4f_row0_col5\" class=\"data row0 col5\" >0.172801</td>\n",
       "      <td id=\"T_88d4f_row0_col6\" class=\"data row0 col6\" >0.340363</td>\n",
       "      <td id=\"T_88d4f_row0_col7\" class=\"data row0 col7\" >0.273473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d4f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_88d4f_row1_col0\" class=\"data row1 col0\" >35</td>\n",
       "      <td id=\"T_88d4f_row1_col1\" class=\"data row1 col1\" >0.191808</td>\n",
       "      <td id=\"T_88d4f_row1_col2\" class=\"data row1 col2\" >0.142973</td>\n",
       "      <td id=\"T_88d4f_row1_col3\" class=\"data row1 col3\" >0.108382</td>\n",
       "      <td id=\"T_88d4f_row1_col4\" class=\"data row1 col4\" >0.082824</td>\n",
       "      <td id=\"T_88d4f_row1_col5\" class=\"data row1 col5\" >0.172801</td>\n",
       "      <td id=\"T_88d4f_row1_col6\" class=\"data row1 col6\" >0.340363</td>\n",
       "      <td id=\"T_88d4f_row1_col7\" class=\"data row1 col7\" >0.273473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d4f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_88d4f_row2_col0\" class=\"data row2 col0\" >35</td>\n",
       "      <td id=\"T_88d4f_row2_col1\" class=\"data row2 col1\" >0.191808</td>\n",
       "      <td id=\"T_88d4f_row2_col2\" class=\"data row2 col2\" >0.142973</td>\n",
       "      <td id=\"T_88d4f_row2_col3\" class=\"data row2 col3\" >0.108382</td>\n",
       "      <td id=\"T_88d4f_row2_col4\" class=\"data row2 col4\" >0.082824</td>\n",
       "      <td id=\"T_88d4f_row2_col5\" class=\"data row2 col5\" >0.172801</td>\n",
       "      <td id=\"T_88d4f_row2_col6\" class=\"data row2 col6\" >0.340363</td>\n",
       "      <td id=\"T_88d4f_row2_col7\" class=\"data row2 col7\" >0.273473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d4f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_88d4f_row3_col0\" class=\"data row3 col0\" >35</td>\n",
       "      <td id=\"T_88d4f_row3_col1\" class=\"data row3 col1\" >0.191808</td>\n",
       "      <td id=\"T_88d4f_row3_col2\" class=\"data row3 col2\" >0.142973</td>\n",
       "      <td id=\"T_88d4f_row3_col3\" class=\"data row3 col3\" >0.108382</td>\n",
       "      <td id=\"T_88d4f_row3_col4\" class=\"data row3 col4\" >0.082824</td>\n",
       "      <td id=\"T_88d4f_row3_col5\" class=\"data row3 col5\" >0.172801</td>\n",
       "      <td id=\"T_88d4f_row3_col6\" class=\"data row3 col6\" >0.340363</td>\n",
       "      <td id=\"T_88d4f_row3_col7\" class=\"data row3 col7\" >0.273473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d4f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_88d4f_row4_col0\" class=\"data row4 col0\" >35</td>\n",
       "      <td id=\"T_88d4f_row4_col1\" class=\"data row4 col1\" >0.191808</td>\n",
       "      <td id=\"T_88d4f_row4_col2\" class=\"data row4 col2\" >0.142973</td>\n",
       "      <td id=\"T_88d4f_row4_col3\" class=\"data row4 col3\" >0.108382</td>\n",
       "      <td id=\"T_88d4f_row4_col4\" class=\"data row4 col4\" >0.082824</td>\n",
       "      <td id=\"T_88d4f_row4_col5\" class=\"data row4 col5\" >0.172801</td>\n",
       "      <td id=\"T_88d4f_row4_col6\" class=\"data row4 col6\" >0.340363</td>\n",
       "      <td id=\"T_88d4f_row4_col7\" class=\"data row4 col7\" >0.273473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d4f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_88d4f_row5_col0\" class=\"data row5 col0\" >35</td>\n",
       "      <td id=\"T_88d4f_row5_col1\" class=\"data row5 col1\" >0.191808</td>\n",
       "      <td id=\"T_88d4f_row5_col2\" class=\"data row5 col2\" >0.142973</td>\n",
       "      <td id=\"T_88d4f_row5_col3\" class=\"data row5 col3\" >0.108382</td>\n",
       "      <td id=\"T_88d4f_row5_col4\" class=\"data row5 col4\" >0.082824</td>\n",
       "      <td id=\"T_88d4f_row5_col5\" class=\"data row5 col5\" >0.172801</td>\n",
       "      <td id=\"T_88d4f_row5_col6\" class=\"data row5 col6\" >0.340363</td>\n",
       "      <td id=\"T_88d4f_row5_col7\" class=\"data row5 col7\" >0.273473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d4f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_88d4f_row6_col0\" class=\"data row6 col0\" >35</td>\n",
       "      <td id=\"T_88d4f_row6_col1\" class=\"data row6 col1\" >0.191808</td>\n",
       "      <td id=\"T_88d4f_row6_col2\" class=\"data row6 col2\" >0.142973</td>\n",
       "      <td id=\"T_88d4f_row6_col3\" class=\"data row6 col3\" >0.108382</td>\n",
       "      <td id=\"T_88d4f_row6_col4\" class=\"data row6 col4\" >0.082824</td>\n",
       "      <td id=\"T_88d4f_row6_col5\" class=\"data row6 col5\" >0.172801</td>\n",
       "      <td id=\"T_88d4f_row6_col6\" class=\"data row6 col6\" >0.340363</td>\n",
       "      <td id=\"T_88d4f_row6_col7\" class=\"data row6 col7\" >0.273473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fda97727190>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## One_Dense_x4_ChexPERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer_one_dense_x4_CheXpert'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ac060_row0_col1, #T_ac060_row0_col2, #T_ac060_row0_col3, #T_ac060_row0_col5, #T_ac060_row1_col1, #T_ac060_row1_col2, #T_ac060_row1_col3, #T_ac060_row1_col5, #T_ac060_row2_col1, #T_ac060_row2_col2, #T_ac060_row2_col3, #T_ac060_row2_col5, #T_ac060_row3_col4, #T_ac060_row3_col7, #T_ac060_row4_col1, #T_ac060_row4_col2, #T_ac060_row4_col3, #T_ac060_row4_col5, #T_ac060_row5_col0, #T_ac060_row5_col6, #T_ac060_row6_col4, #T_ac060_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ac060_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ac060_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ac060_row0_col0\" class=\"data row0 col0\" >17</td>\n",
       "      <td id=\"T_ac060_row0_col1\" class=\"data row0 col1\" >0.331528</td>\n",
       "      <td id=\"T_ac060_row0_col2\" class=\"data row0 col2\" >0.229141</td>\n",
       "      <td id=\"T_ac060_row0_col3\" class=\"data row0 col3\" >0.163418</td>\n",
       "      <td id=\"T_ac060_row0_col4\" class=\"data row0 col4\" >0.119533</td>\n",
       "      <td id=\"T_ac060_row0_col5\" class=\"data row0 col5\" >0.215178</td>\n",
       "      <td id=\"T_ac060_row0_col6\" class=\"data row0 col6\" >0.336627</td>\n",
       "      <td id=\"T_ac060_row0_col7\" class=\"data row0 col7\" >0.235689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac060_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ac060_row1_col0\" class=\"data row1 col0\" >17</td>\n",
       "      <td id=\"T_ac060_row1_col1\" class=\"data row1 col1\" >0.331528</td>\n",
       "      <td id=\"T_ac060_row1_col2\" class=\"data row1 col2\" >0.229141</td>\n",
       "      <td id=\"T_ac060_row1_col3\" class=\"data row1 col3\" >0.163418</td>\n",
       "      <td id=\"T_ac060_row1_col4\" class=\"data row1 col4\" >0.119533</td>\n",
       "      <td id=\"T_ac060_row1_col5\" class=\"data row1 col5\" >0.215178</td>\n",
       "      <td id=\"T_ac060_row1_col6\" class=\"data row1 col6\" >0.336627</td>\n",
       "      <td id=\"T_ac060_row1_col7\" class=\"data row1 col7\" >0.235689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac060_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ac060_row2_col0\" class=\"data row2 col0\" >17</td>\n",
       "      <td id=\"T_ac060_row2_col1\" class=\"data row2 col1\" >0.331528</td>\n",
       "      <td id=\"T_ac060_row2_col2\" class=\"data row2 col2\" >0.229141</td>\n",
       "      <td id=\"T_ac060_row2_col3\" class=\"data row2 col3\" >0.163418</td>\n",
       "      <td id=\"T_ac060_row2_col4\" class=\"data row2 col4\" >0.119533</td>\n",
       "      <td id=\"T_ac060_row2_col5\" class=\"data row2 col5\" >0.215178</td>\n",
       "      <td id=\"T_ac060_row2_col6\" class=\"data row2 col6\" >0.336627</td>\n",
       "      <td id=\"T_ac060_row2_col7\" class=\"data row2 col7\" >0.235689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac060_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ac060_row3_col0\" class=\"data row3 col0\" >25</td>\n",
       "      <td id=\"T_ac060_row3_col1\" class=\"data row3 col1\" >0.297378</td>\n",
       "      <td id=\"T_ac060_row3_col2\" class=\"data row3 col2\" >0.213104</td>\n",
       "      <td id=\"T_ac060_row3_col3\" class=\"data row3 col3\" >0.157771</td>\n",
       "      <td id=\"T_ac060_row3_col4\" class=\"data row3 col4\" >0.120700</td>\n",
       "      <td id=\"T_ac060_row3_col5\" class=\"data row3 col5\" >0.206212</td>\n",
       "      <td id=\"T_ac060_row3_col6\" class=\"data row3 col6\" >0.349054</td>\n",
       "      <td id=\"T_ac060_row3_col7\" class=\"data row3 col7\" >0.355076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac060_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ac060_row4_col0\" class=\"data row4 col0\" >17</td>\n",
       "      <td id=\"T_ac060_row4_col1\" class=\"data row4 col1\" >0.331528</td>\n",
       "      <td id=\"T_ac060_row4_col2\" class=\"data row4 col2\" >0.229141</td>\n",
       "      <td id=\"T_ac060_row4_col3\" class=\"data row4 col3\" >0.163418</td>\n",
       "      <td id=\"T_ac060_row4_col4\" class=\"data row4 col4\" >0.119533</td>\n",
       "      <td id=\"T_ac060_row4_col5\" class=\"data row4 col5\" >0.215178</td>\n",
       "      <td id=\"T_ac060_row4_col6\" class=\"data row4 col6\" >0.336627</td>\n",
       "      <td id=\"T_ac060_row4_col7\" class=\"data row4 col7\" >0.235689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac060_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ac060_row5_col0\" class=\"data row5 col0\" >63</td>\n",
       "      <td id=\"T_ac060_row5_col1\" class=\"data row5 col1\" >0.272937</td>\n",
       "      <td id=\"T_ac060_row5_col2\" class=\"data row5 col2\" >0.193980</td>\n",
       "      <td id=\"T_ac060_row5_col3\" class=\"data row5 col3\" >0.143585</td>\n",
       "      <td id=\"T_ac060_row5_col4\" class=\"data row5 col4\" >0.109924</td>\n",
       "      <td id=\"T_ac060_row5_col5\" class=\"data row5 col5\" >0.198882</td>\n",
       "      <td id=\"T_ac060_row5_col6\" class=\"data row5 col6\" >0.351452</td>\n",
       "      <td id=\"T_ac060_row5_col7\" class=\"data row5 col7\" >0.312963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac060_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ac060_row6_col0\" class=\"data row6 col0\" >25</td>\n",
       "      <td id=\"T_ac060_row6_col1\" class=\"data row6 col1\" >0.297378</td>\n",
       "      <td id=\"T_ac060_row6_col2\" class=\"data row6 col2\" >0.213104</td>\n",
       "      <td id=\"T_ac060_row6_col3\" class=\"data row6 col3\" >0.157771</td>\n",
       "      <td id=\"T_ac060_row6_col4\" class=\"data row6 col4\" >0.120700</td>\n",
       "      <td id=\"T_ac060_row6_col5\" class=\"data row6 col5\" >0.206212</td>\n",
       "      <td id=\"T_ac060_row6_col6\" class=\"data row6 col6\" >0.349054</td>\n",
       "      <td id=\"T_ac060_row6_col7\" class=\"data row6 col7\" >0.355076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fda97580fd0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812d1fb",
   "metadata": {},
   "source": [
    "(2차학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## Pair_Dense_x2_ChexPERT_Detach-Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer_pair_dense_x2_CheXpert_fc'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de31d_row0_col0, #T_de31d_row0_col1, #T_de31d_row0_col5, #T_de31d_row1_col2, #T_de31d_row1_col3, #T_de31d_row1_col4, #T_de31d_row2_col2, #T_de31d_row2_col3, #T_de31d_row2_col4, #T_de31d_row3_col2, #T_de31d_row3_col3, #T_de31d_row3_col4, #T_de31d_row4_col0, #T_de31d_row4_col1, #T_de31d_row4_col5, #T_de31d_row5_col6, #T_de31d_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de31d_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de31d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_de31d_row0_col0\" class=\"data row0 col0\" >200</td>\n",
       "      <td id=\"T_de31d_row0_col1\" class=\"data row0 col1\" >0.324600</td>\n",
       "      <td id=\"T_de31d_row0_col2\" class=\"data row0 col2\" >0.223651</td>\n",
       "      <td id=\"T_de31d_row0_col3\" class=\"data row0 col3\" >0.160046</td>\n",
       "      <td id=\"T_de31d_row0_col4\" class=\"data row0 col4\" >0.118637</td>\n",
       "      <td id=\"T_de31d_row0_col5\" class=\"data row0 col5\" >0.216100</td>\n",
       "      <td id=\"T_de31d_row0_col6\" class=\"data row0 col6\" >0.348056</td>\n",
       "      <td id=\"T_de31d_row0_col7\" class=\"data row0 col7\" >0.312396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de31d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_de31d_row1_col0\" class=\"data row1 col0\" >61</td>\n",
       "      <td id=\"T_de31d_row1_col1\" class=\"data row1 col1\" >0.320386</td>\n",
       "      <td id=\"T_de31d_row1_col2\" class=\"data row1 col2\" >0.226957</td>\n",
       "      <td id=\"T_de31d_row1_col3\" class=\"data row1 col3\" >0.164734</td>\n",
       "      <td id=\"T_de31d_row1_col4\" class=\"data row1 col4\" >0.123809</td>\n",
       "      <td id=\"T_de31d_row1_col5\" class=\"data row1 col5\" >0.214949</td>\n",
       "      <td id=\"T_de31d_row1_col6\" class=\"data row1 col6\" >0.347416</td>\n",
       "      <td id=\"T_de31d_row1_col7\" class=\"data row1 col7\" >0.301699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de31d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_de31d_row2_col0\" class=\"data row2 col0\" >61</td>\n",
       "      <td id=\"T_de31d_row2_col1\" class=\"data row2 col1\" >0.320386</td>\n",
       "      <td id=\"T_de31d_row2_col2\" class=\"data row2 col2\" >0.226957</td>\n",
       "      <td id=\"T_de31d_row2_col3\" class=\"data row2 col3\" >0.164734</td>\n",
       "      <td id=\"T_de31d_row2_col4\" class=\"data row2 col4\" >0.123809</td>\n",
       "      <td id=\"T_de31d_row2_col5\" class=\"data row2 col5\" >0.214949</td>\n",
       "      <td id=\"T_de31d_row2_col6\" class=\"data row2 col6\" >0.347416</td>\n",
       "      <td id=\"T_de31d_row2_col7\" class=\"data row2 col7\" >0.301699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de31d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_de31d_row3_col0\" class=\"data row3 col0\" >61</td>\n",
       "      <td id=\"T_de31d_row3_col1\" class=\"data row3 col1\" >0.320386</td>\n",
       "      <td id=\"T_de31d_row3_col2\" class=\"data row3 col2\" >0.226957</td>\n",
       "      <td id=\"T_de31d_row3_col3\" class=\"data row3 col3\" >0.164734</td>\n",
       "      <td id=\"T_de31d_row3_col4\" class=\"data row3 col4\" >0.123809</td>\n",
       "      <td id=\"T_de31d_row3_col5\" class=\"data row3 col5\" >0.214949</td>\n",
       "      <td id=\"T_de31d_row3_col6\" class=\"data row3 col6\" >0.347416</td>\n",
       "      <td id=\"T_de31d_row3_col7\" class=\"data row3 col7\" >0.301699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de31d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_de31d_row4_col0\" class=\"data row4 col0\" >200</td>\n",
       "      <td id=\"T_de31d_row4_col1\" class=\"data row4 col1\" >0.324600</td>\n",
       "      <td id=\"T_de31d_row4_col2\" class=\"data row4 col2\" >0.223651</td>\n",
       "      <td id=\"T_de31d_row4_col3\" class=\"data row4 col3\" >0.160046</td>\n",
       "      <td id=\"T_de31d_row4_col4\" class=\"data row4 col4\" >0.118637</td>\n",
       "      <td id=\"T_de31d_row4_col5\" class=\"data row4 col5\" >0.216100</td>\n",
       "      <td id=\"T_de31d_row4_col6\" class=\"data row4 col6\" >0.348056</td>\n",
       "      <td id=\"T_de31d_row4_col7\" class=\"data row4 col7\" >0.312396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de31d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_de31d_row5_col0\" class=\"data row5 col0\" >174</td>\n",
       "      <td id=\"T_de31d_row5_col1\" class=\"data row5 col1\" >0.307176</td>\n",
       "      <td id=\"T_de31d_row5_col2\" class=\"data row5 col2\" >0.214309</td>\n",
       "      <td id=\"T_de31d_row5_col3\" class=\"data row5 col3\" >0.156726</td>\n",
       "      <td id=\"T_de31d_row5_col4\" class=\"data row5 col4\" >0.118969</td>\n",
       "      <td id=\"T_de31d_row5_col5\" class=\"data row5 col5\" >0.212167</td>\n",
       "      <td id=\"T_de31d_row5_col6\" class=\"data row5 col6\" >0.354644</td>\n",
       "      <td id=\"T_de31d_row5_col7\" class=\"data row5 col7\" >0.335476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de31d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_de31d_row6_col0\" class=\"data row6 col0\" >141</td>\n",
       "      <td id=\"T_de31d_row6_col1\" class=\"data row6 col1\" >0.303408</td>\n",
       "      <td id=\"T_de31d_row6_col2\" class=\"data row6 col2\" >0.214122</td>\n",
       "      <td id=\"T_de31d_row6_col3\" class=\"data row6 col3\" >0.157629</td>\n",
       "      <td id=\"T_de31d_row6_col4\" class=\"data row6 col4\" >0.120723</td>\n",
       "      <td id=\"T_de31d_row6_col5\" class=\"data row6 col5\" >0.210367</td>\n",
       "      <td id=\"T_de31d_row6_col6\" class=\"data row6 col6\" >0.353160</td>\n",
       "      <td id=\"T_de31d_row6_col7\" class=\"data row6 col7\" >0.343146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fda976ef510>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3bd12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## Pair_Dense_x2_ChexPERT_fc+en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917f6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer_pair_dense_x2_CheXpert_fc_en'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9edafb",
   "metadata": {},
   "source": [
    "# 512-Verision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## Pair_Dense_x2_ChexPERT_fc+en ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_pair_dense_x2_CheXpert_no'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a378a_row0_col1, #T_a378a_row0_col5, #T_a378a_row1_col2, #T_a378a_row1_col3, #T_a378a_row1_col4, #T_a378a_row2_col2, #T_a378a_row2_col3, #T_a378a_row2_col4, #T_a378a_row3_col2, #T_a378a_row3_col3, #T_a378a_row3_col4, #T_a378a_row4_col1, #T_a378a_row4_col5, #T_a378a_row5_col6, #T_a378a_row6_col0, #T_a378a_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a378a_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a378a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a378a_row0_col0\" class=\"data row0 col0\" >69</td>\n",
       "      <td id=\"T_a378a_row0_col1\" class=\"data row0 col1\" >0.359409</td>\n",
       "      <td id=\"T_a378a_row0_col2\" class=\"data row0 col2\" >0.242989</td>\n",
       "      <td id=\"T_a378a_row0_col3\" class=\"data row0 col3\" >0.170001</td>\n",
       "      <td id=\"T_a378a_row0_col4\" class=\"data row0 col4\" >0.122624</td>\n",
       "      <td id=\"T_a378a_row0_col5\" class=\"data row0 col5\" >0.227001</td>\n",
       "      <td id=\"T_a378a_row0_col6\" class=\"data row0 col6\" >0.335866</td>\n",
       "      <td id=\"T_a378a_row0_col7\" class=\"data row0 col7\" >0.183835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a378a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a378a_row1_col0\" class=\"data row1 col0\" >117</td>\n",
       "      <td id=\"T_a378a_row1_col1\" class=\"data row1 col1\" >0.357664</td>\n",
       "      <td id=\"T_a378a_row1_col2\" class=\"data row1 col2\" >0.245415</td>\n",
       "      <td id=\"T_a378a_row1_col3\" class=\"data row1 col3\" >0.176054</td>\n",
       "      <td id=\"T_a378a_row1_col4\" class=\"data row1 col4\" >0.131798</td>\n",
       "      <td id=\"T_a378a_row1_col5\" class=\"data row1 col5\" >0.222965</td>\n",
       "      <td id=\"T_a378a_row1_col6\" class=\"data row1 col6\" >0.346946</td>\n",
       "      <td id=\"T_a378a_row1_col7\" class=\"data row1 col7\" >0.357867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a378a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a378a_row2_col0\" class=\"data row2 col0\" >117</td>\n",
       "      <td id=\"T_a378a_row2_col1\" class=\"data row2 col1\" >0.357664</td>\n",
       "      <td id=\"T_a378a_row2_col2\" class=\"data row2 col2\" >0.245415</td>\n",
       "      <td id=\"T_a378a_row2_col3\" class=\"data row2 col3\" >0.176054</td>\n",
       "      <td id=\"T_a378a_row2_col4\" class=\"data row2 col4\" >0.131798</td>\n",
       "      <td id=\"T_a378a_row2_col5\" class=\"data row2 col5\" >0.222965</td>\n",
       "      <td id=\"T_a378a_row2_col6\" class=\"data row2 col6\" >0.346946</td>\n",
       "      <td id=\"T_a378a_row2_col7\" class=\"data row2 col7\" >0.357867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a378a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a378a_row3_col0\" class=\"data row3 col0\" >117</td>\n",
       "      <td id=\"T_a378a_row3_col1\" class=\"data row3 col1\" >0.357664</td>\n",
       "      <td id=\"T_a378a_row3_col2\" class=\"data row3 col2\" >0.245415</td>\n",
       "      <td id=\"T_a378a_row3_col3\" class=\"data row3 col3\" >0.176054</td>\n",
       "      <td id=\"T_a378a_row3_col4\" class=\"data row3 col4\" >0.131798</td>\n",
       "      <td id=\"T_a378a_row3_col5\" class=\"data row3 col5\" >0.222965</td>\n",
       "      <td id=\"T_a378a_row3_col6\" class=\"data row3 col6\" >0.346946</td>\n",
       "      <td id=\"T_a378a_row3_col7\" class=\"data row3 col7\" >0.357867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a378a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a378a_row4_col0\" class=\"data row4 col0\" >69</td>\n",
       "      <td id=\"T_a378a_row4_col1\" class=\"data row4 col1\" >0.359409</td>\n",
       "      <td id=\"T_a378a_row4_col2\" class=\"data row4 col2\" >0.242989</td>\n",
       "      <td id=\"T_a378a_row4_col3\" class=\"data row4 col3\" >0.170001</td>\n",
       "      <td id=\"T_a378a_row4_col4\" class=\"data row4 col4\" >0.122624</td>\n",
       "      <td id=\"T_a378a_row4_col5\" class=\"data row4 col5\" >0.227001</td>\n",
       "      <td id=\"T_a378a_row4_col6\" class=\"data row4 col6\" >0.335866</td>\n",
       "      <td id=\"T_a378a_row4_col7\" class=\"data row4 col7\" >0.183835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a378a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a378a_row5_col0\" class=\"data row5 col0\" >16</td>\n",
       "      <td id=\"T_a378a_row5_col1\" class=\"data row5 col1\" >0.267485</td>\n",
       "      <td id=\"T_a378a_row5_col2\" class=\"data row5 col2\" >0.197016</td>\n",
       "      <td id=\"T_a378a_row5_col3\" class=\"data row5 col3\" >0.149277</td>\n",
       "      <td id=\"T_a378a_row5_col4\" class=\"data row5 col4\" >0.115357</td>\n",
       "      <td id=\"T_a378a_row5_col5\" class=\"data row5 col5\" >0.202126</td>\n",
       "      <td id=\"T_a378a_row5_col6\" class=\"data row5 col6\" >0.356521</td>\n",
       "      <td id=\"T_a378a_row5_col7\" class=\"data row5 col7\" >0.338189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a378a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a378a_row6_col0\" class=\"data row6 col0\" >360</td>\n",
       "      <td id=\"T_a378a_row6_col1\" class=\"data row6 col1\" >0.332045</td>\n",
       "      <td id=\"T_a378a_row6_col2\" class=\"data row6 col2\" >0.229208</td>\n",
       "      <td id=\"T_a378a_row6_col3\" class=\"data row6 col3\" >0.166999</td>\n",
       "      <td id=\"T_a378a_row6_col4\" class=\"data row6 col4\" >0.126630</td>\n",
       "      <td id=\"T_a378a_row6_col5\" class=\"data row6 col5\" >0.212787</td>\n",
       "      <td id=\"T_a378a_row6_col6\" class=\"data row6 col6\" >0.343812</td>\n",
       "      <td id=\"T_a378a_row6_col7\" class=\"data row6 col7\" >0.395780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1fd96ee050>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## Pair_Dense_x2_ChexPERT_fc+en ++ (2stage, not SCSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_pair_dense_x2_CheXpert_no_2stage'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_43f1c_row0_col0, #T_43f1c_row0_col1, #T_43f1c_row0_col2, #T_43f1c_row0_col3, #T_43f1c_row0_col4, #T_43f1c_row0_col5, #T_43f1c_row1_col0, #T_43f1c_row1_col1, #T_43f1c_row1_col2, #T_43f1c_row1_col3, #T_43f1c_row1_col4, #T_43f1c_row1_col5, #T_43f1c_row2_col0, #T_43f1c_row2_col1, #T_43f1c_row2_col2, #T_43f1c_row2_col3, #T_43f1c_row2_col4, #T_43f1c_row2_col5, #T_43f1c_row3_col0, #T_43f1c_row3_col1, #T_43f1c_row3_col2, #T_43f1c_row3_col3, #T_43f1c_row3_col4, #T_43f1c_row3_col5, #T_43f1c_row4_col0, #T_43f1c_row4_col1, #T_43f1c_row4_col2, #T_43f1c_row4_col3, #T_43f1c_row4_col4, #T_43f1c_row4_col5, #T_43f1c_row5_col6, #T_43f1c_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_43f1c_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_43f1c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_43f1c_row0_col0\" class=\"data row0 col0\" >136</td>\n",
       "      <td id=\"T_43f1c_row0_col1\" class=\"data row0 col1\" >0.372686</td>\n",
       "      <td id=\"T_43f1c_row0_col2\" class=\"data row0 col2\" >0.253315</td>\n",
       "      <td id=\"T_43f1c_row0_col3\" class=\"data row0 col3\" >0.179351</td>\n",
       "      <td id=\"T_43f1c_row0_col4\" class=\"data row0 col4\" >0.131907</td>\n",
       "      <td id=\"T_43f1c_row0_col5\" class=\"data row0 col5\" >0.229081</td>\n",
       "      <td id=\"T_43f1c_row0_col6\" class=\"data row0 col6\" >0.340140</td>\n",
       "      <td id=\"T_43f1c_row0_col7\" class=\"data row0 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43f1c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_43f1c_row1_col0\" class=\"data row1 col0\" >136</td>\n",
       "      <td id=\"T_43f1c_row1_col1\" class=\"data row1 col1\" >0.372686</td>\n",
       "      <td id=\"T_43f1c_row1_col2\" class=\"data row1 col2\" >0.253315</td>\n",
       "      <td id=\"T_43f1c_row1_col3\" class=\"data row1 col3\" >0.179351</td>\n",
       "      <td id=\"T_43f1c_row1_col4\" class=\"data row1 col4\" >0.131907</td>\n",
       "      <td id=\"T_43f1c_row1_col5\" class=\"data row1 col5\" >0.229081</td>\n",
       "      <td id=\"T_43f1c_row1_col6\" class=\"data row1 col6\" >0.340140</td>\n",
       "      <td id=\"T_43f1c_row1_col7\" class=\"data row1 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43f1c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_43f1c_row2_col0\" class=\"data row2 col0\" >136</td>\n",
       "      <td id=\"T_43f1c_row2_col1\" class=\"data row2 col1\" >0.372686</td>\n",
       "      <td id=\"T_43f1c_row2_col2\" class=\"data row2 col2\" >0.253315</td>\n",
       "      <td id=\"T_43f1c_row2_col3\" class=\"data row2 col3\" >0.179351</td>\n",
       "      <td id=\"T_43f1c_row2_col4\" class=\"data row2 col4\" >0.131907</td>\n",
       "      <td id=\"T_43f1c_row2_col5\" class=\"data row2 col5\" >0.229081</td>\n",
       "      <td id=\"T_43f1c_row2_col6\" class=\"data row2 col6\" >0.340140</td>\n",
       "      <td id=\"T_43f1c_row2_col7\" class=\"data row2 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43f1c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_43f1c_row3_col0\" class=\"data row3 col0\" >136</td>\n",
       "      <td id=\"T_43f1c_row3_col1\" class=\"data row3 col1\" >0.372686</td>\n",
       "      <td id=\"T_43f1c_row3_col2\" class=\"data row3 col2\" >0.253315</td>\n",
       "      <td id=\"T_43f1c_row3_col3\" class=\"data row3 col3\" >0.179351</td>\n",
       "      <td id=\"T_43f1c_row3_col4\" class=\"data row3 col4\" >0.131907</td>\n",
       "      <td id=\"T_43f1c_row3_col5\" class=\"data row3 col5\" >0.229081</td>\n",
       "      <td id=\"T_43f1c_row3_col6\" class=\"data row3 col6\" >0.340140</td>\n",
       "      <td id=\"T_43f1c_row3_col7\" class=\"data row3 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43f1c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_43f1c_row4_col0\" class=\"data row4 col0\" >136</td>\n",
       "      <td id=\"T_43f1c_row4_col1\" class=\"data row4 col1\" >0.372686</td>\n",
       "      <td id=\"T_43f1c_row4_col2\" class=\"data row4 col2\" >0.253315</td>\n",
       "      <td id=\"T_43f1c_row4_col3\" class=\"data row4 col3\" >0.179351</td>\n",
       "      <td id=\"T_43f1c_row4_col4\" class=\"data row4 col4\" >0.131907</td>\n",
       "      <td id=\"T_43f1c_row4_col5\" class=\"data row4 col5\" >0.229081</td>\n",
       "      <td id=\"T_43f1c_row4_col6\" class=\"data row4 col6\" >0.340140</td>\n",
       "      <td id=\"T_43f1c_row4_col7\" class=\"data row4 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43f1c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_43f1c_row5_col0\" class=\"data row5 col0\" >3</td>\n",
       "      <td id=\"T_43f1c_row5_col1\" class=\"data row5 col1\" >0.328741</td>\n",
       "      <td id=\"T_43f1c_row5_col2\" class=\"data row5 col2\" >0.229285</td>\n",
       "      <td id=\"T_43f1c_row5_col3\" class=\"data row5 col3\" >0.166524</td>\n",
       "      <td id=\"T_43f1c_row5_col4\" class=\"data row5 col4\" >0.126304</td>\n",
       "      <td id=\"T_43f1c_row5_col5\" class=\"data row5 col5\" >0.213787</td>\n",
       "      <td id=\"T_43f1c_row5_col6\" class=\"data row5 col6\" >0.352006</td>\n",
       "      <td id=\"T_43f1c_row5_col7\" class=\"data row5 col7\" >0.349572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_43f1c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_43f1c_row6_col0\" class=\"data row6 col0\" >52</td>\n",
       "      <td id=\"T_43f1c_row6_col1\" class=\"data row6 col1\" >0.318453</td>\n",
       "      <td id=\"T_43f1c_row6_col2\" class=\"data row6 col2\" >0.218960</td>\n",
       "      <td id=\"T_43f1c_row6_col3\" class=\"data row6 col3\" >0.158938</td>\n",
       "      <td id=\"T_43f1c_row6_col4\" class=\"data row6 col4\" >0.120539</td>\n",
       "      <td id=\"T_43f1c_row6_col5\" class=\"data row6 col5\" >0.209633</td>\n",
       "      <td id=\"T_43f1c_row6_col6\" class=\"data row6 col6\" >0.350044</td>\n",
       "      <td id=\"T_43f1c_row6_col7\" class=\"data row6 col7\" >0.362956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1fd2c25210>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## Pair_Dense_x2_ChexPERT_fc+en ++ (2stage, yes SCSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_pair_dense_x2_CheXpert_no_2stage'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bd267_row0_col0, #T_bd267_row0_col1, #T_bd267_row0_col2, #T_bd267_row0_col3, #T_bd267_row0_col4, #T_bd267_row0_col5, #T_bd267_row1_col0, #T_bd267_row1_col1, #T_bd267_row1_col2, #T_bd267_row1_col3, #T_bd267_row1_col4, #T_bd267_row1_col5, #T_bd267_row2_col0, #T_bd267_row2_col1, #T_bd267_row2_col2, #T_bd267_row2_col3, #T_bd267_row2_col4, #T_bd267_row2_col5, #T_bd267_row3_col0, #T_bd267_row3_col1, #T_bd267_row3_col2, #T_bd267_row3_col3, #T_bd267_row3_col4, #T_bd267_row3_col5, #T_bd267_row4_col0, #T_bd267_row4_col1, #T_bd267_row4_col2, #T_bd267_row4_col3, #T_bd267_row4_col4, #T_bd267_row4_col5, #T_bd267_row5_col6, #T_bd267_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bd267_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bd267_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bd267_row0_col0\" class=\"data row0 col0\" >136</td>\n",
       "      <td id=\"T_bd267_row0_col1\" class=\"data row0 col1\" >0.372686</td>\n",
       "      <td id=\"T_bd267_row0_col2\" class=\"data row0 col2\" >0.253315</td>\n",
       "      <td id=\"T_bd267_row0_col3\" class=\"data row0 col3\" >0.179351</td>\n",
       "      <td id=\"T_bd267_row0_col4\" class=\"data row0 col4\" >0.131907</td>\n",
       "      <td id=\"T_bd267_row0_col5\" class=\"data row0 col5\" >0.229081</td>\n",
       "      <td id=\"T_bd267_row0_col6\" class=\"data row0 col6\" >0.340140</td>\n",
       "      <td id=\"T_bd267_row0_col7\" class=\"data row0 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd267_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bd267_row1_col0\" class=\"data row1 col0\" >136</td>\n",
       "      <td id=\"T_bd267_row1_col1\" class=\"data row1 col1\" >0.372686</td>\n",
       "      <td id=\"T_bd267_row1_col2\" class=\"data row1 col2\" >0.253315</td>\n",
       "      <td id=\"T_bd267_row1_col3\" class=\"data row1 col3\" >0.179351</td>\n",
       "      <td id=\"T_bd267_row1_col4\" class=\"data row1 col4\" >0.131907</td>\n",
       "      <td id=\"T_bd267_row1_col5\" class=\"data row1 col5\" >0.229081</td>\n",
       "      <td id=\"T_bd267_row1_col6\" class=\"data row1 col6\" >0.340140</td>\n",
       "      <td id=\"T_bd267_row1_col7\" class=\"data row1 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd267_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bd267_row2_col0\" class=\"data row2 col0\" >136</td>\n",
       "      <td id=\"T_bd267_row2_col1\" class=\"data row2 col1\" >0.372686</td>\n",
       "      <td id=\"T_bd267_row2_col2\" class=\"data row2 col2\" >0.253315</td>\n",
       "      <td id=\"T_bd267_row2_col3\" class=\"data row2 col3\" >0.179351</td>\n",
       "      <td id=\"T_bd267_row2_col4\" class=\"data row2 col4\" >0.131907</td>\n",
       "      <td id=\"T_bd267_row2_col5\" class=\"data row2 col5\" >0.229081</td>\n",
       "      <td id=\"T_bd267_row2_col6\" class=\"data row2 col6\" >0.340140</td>\n",
       "      <td id=\"T_bd267_row2_col7\" class=\"data row2 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd267_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bd267_row3_col0\" class=\"data row3 col0\" >136</td>\n",
       "      <td id=\"T_bd267_row3_col1\" class=\"data row3 col1\" >0.372686</td>\n",
       "      <td id=\"T_bd267_row3_col2\" class=\"data row3 col2\" >0.253315</td>\n",
       "      <td id=\"T_bd267_row3_col3\" class=\"data row3 col3\" >0.179351</td>\n",
       "      <td id=\"T_bd267_row3_col4\" class=\"data row3 col4\" >0.131907</td>\n",
       "      <td id=\"T_bd267_row3_col5\" class=\"data row3 col5\" >0.229081</td>\n",
       "      <td id=\"T_bd267_row3_col6\" class=\"data row3 col6\" >0.340140</td>\n",
       "      <td id=\"T_bd267_row3_col7\" class=\"data row3 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd267_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bd267_row4_col0\" class=\"data row4 col0\" >136</td>\n",
       "      <td id=\"T_bd267_row4_col1\" class=\"data row4 col1\" >0.372686</td>\n",
       "      <td id=\"T_bd267_row4_col2\" class=\"data row4 col2\" >0.253315</td>\n",
       "      <td id=\"T_bd267_row4_col3\" class=\"data row4 col3\" >0.179351</td>\n",
       "      <td id=\"T_bd267_row4_col4\" class=\"data row4 col4\" >0.131907</td>\n",
       "      <td id=\"T_bd267_row4_col5\" class=\"data row4 col5\" >0.229081</td>\n",
       "      <td id=\"T_bd267_row4_col6\" class=\"data row4 col6\" >0.340140</td>\n",
       "      <td id=\"T_bd267_row4_col7\" class=\"data row4 col7\" >0.286912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd267_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_bd267_row5_col0\" class=\"data row5 col0\" >3</td>\n",
       "      <td id=\"T_bd267_row5_col1\" class=\"data row5 col1\" >0.328741</td>\n",
       "      <td id=\"T_bd267_row5_col2\" class=\"data row5 col2\" >0.229285</td>\n",
       "      <td id=\"T_bd267_row5_col3\" class=\"data row5 col3\" >0.166524</td>\n",
       "      <td id=\"T_bd267_row5_col4\" class=\"data row5 col4\" >0.126304</td>\n",
       "      <td id=\"T_bd267_row5_col5\" class=\"data row5 col5\" >0.213787</td>\n",
       "      <td id=\"T_bd267_row5_col6\" class=\"data row5 col6\" >0.352006</td>\n",
       "      <td id=\"T_bd267_row5_col7\" class=\"data row5 col7\" >0.349572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd267_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_bd267_row6_col0\" class=\"data row6 col0\" >52</td>\n",
       "      <td id=\"T_bd267_row6_col1\" class=\"data row6 col1\" >0.318453</td>\n",
       "      <td id=\"T_bd267_row6_col2\" class=\"data row6 col2\" >0.218960</td>\n",
       "      <td id=\"T_bd267_row6_col3\" class=\"data row6 col3\" >0.158938</td>\n",
       "      <td id=\"T_bd267_row6_col4\" class=\"data row6 col4\" >0.120539</td>\n",
       "      <td id=\"T_bd267_row6_col5\" class=\"data row6 col5\" >0.209633</td>\n",
       "      <td id=\"T_bd267_row6_col6\" class=\"data row6 col6\" >0.350044</td>\n",
       "      <td id=\"T_bd267_row6_col7\" class=\"data row6 col7\" >0.362956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1fd272d650>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## Random_Dense_x2_ChexPERT_fc+en ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_random_dense_x2_CheXpert_no'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c21b1_row0_col0, #T_c21b1_row0_col1, #T_c21b1_row1_col2, #T_c21b1_row1_col3, #T_c21b1_row1_col5, #T_c21b1_row2_col2, #T_c21b1_row2_col3, #T_c21b1_row2_col5, #T_c21b1_row3_col4, #T_c21b1_row4_col2, #T_c21b1_row4_col3, #T_c21b1_row4_col5, #T_c21b1_row5_col6, #T_c21b1_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c21b1_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c21b1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c21b1_row0_col0\" class=\"data row0 col0\" >286</td>\n",
       "      <td id=\"T_c21b1_row0_col1\" class=\"data row0 col1\" >0.376090</td>\n",
       "      <td id=\"T_c21b1_row0_col2\" class=\"data row0 col2\" >0.253783</td>\n",
       "      <td id=\"T_c21b1_row0_col3\" class=\"data row0 col3\" >0.180947</td>\n",
       "      <td id=\"T_c21b1_row0_col4\" class=\"data row0 col4\" >0.135200</td>\n",
       "      <td id=\"T_c21b1_row0_col5\" class=\"data row0 col5\" >0.225442</td>\n",
       "      <td id=\"T_c21b1_row0_col6\" class=\"data row0 col6\" >0.347635</td>\n",
       "      <td id=\"T_c21b1_row0_col7\" class=\"data row0 col7\" >0.394136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c21b1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c21b1_row1_col0\" class=\"data row1 col0\" >119</td>\n",
       "      <td id=\"T_c21b1_row1_col1\" class=\"data row1 col1\" >0.374865</td>\n",
       "      <td id=\"T_c21b1_row1_col2\" class=\"data row1 col2\" >0.257306</td>\n",
       "      <td id=\"T_c21b1_row1_col3\" class=\"data row1 col3\" >0.183774</td>\n",
       "      <td id=\"T_c21b1_row1_col4\" class=\"data row1 col4\" >0.135527</td>\n",
       "      <td id=\"T_c21b1_row1_col5\" class=\"data row1 col5\" >0.230028</td>\n",
       "      <td id=\"T_c21b1_row1_col6\" class=\"data row1 col6\" >0.342997</td>\n",
       "      <td id=\"T_c21b1_row1_col7\" class=\"data row1 col7\" >0.325087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c21b1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c21b1_row2_col0\" class=\"data row2 col0\" >119</td>\n",
       "      <td id=\"T_c21b1_row2_col1\" class=\"data row2 col1\" >0.374865</td>\n",
       "      <td id=\"T_c21b1_row2_col2\" class=\"data row2 col2\" >0.257306</td>\n",
       "      <td id=\"T_c21b1_row2_col3\" class=\"data row2 col3\" >0.183774</td>\n",
       "      <td id=\"T_c21b1_row2_col4\" class=\"data row2 col4\" >0.135527</td>\n",
       "      <td id=\"T_c21b1_row2_col5\" class=\"data row2 col5\" >0.230028</td>\n",
       "      <td id=\"T_c21b1_row2_col6\" class=\"data row2 col6\" >0.342997</td>\n",
       "      <td id=\"T_c21b1_row2_col7\" class=\"data row2 col7\" >0.325087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c21b1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c21b1_row3_col0\" class=\"data row3 col0\" >51</td>\n",
       "      <td id=\"T_c21b1_row3_col1\" class=\"data row3 col1\" >0.353187</td>\n",
       "      <td id=\"T_c21b1_row3_col2\" class=\"data row3 col2\" >0.247110</td>\n",
       "      <td id=\"T_c21b1_row3_col3\" class=\"data row3 col3\" >0.181482</td>\n",
       "      <td id=\"T_c21b1_row3_col4\" class=\"data row3 col4\" >0.138786</td>\n",
       "      <td id=\"T_c21b1_row3_col5\" class=\"data row3 col5\" >0.223846</td>\n",
       "      <td id=\"T_c21b1_row3_col6\" class=\"data row3 col6\" >0.354642</td>\n",
       "      <td id=\"T_c21b1_row3_col7\" class=\"data row3 col7\" >0.356401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c21b1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c21b1_row4_col0\" class=\"data row4 col0\" >119</td>\n",
       "      <td id=\"T_c21b1_row4_col1\" class=\"data row4 col1\" >0.374865</td>\n",
       "      <td id=\"T_c21b1_row4_col2\" class=\"data row4 col2\" >0.257306</td>\n",
       "      <td id=\"T_c21b1_row4_col3\" class=\"data row4 col3\" >0.183774</td>\n",
       "      <td id=\"T_c21b1_row4_col4\" class=\"data row4 col4\" >0.135527</td>\n",
       "      <td id=\"T_c21b1_row4_col5\" class=\"data row4 col5\" >0.230028</td>\n",
       "      <td id=\"T_c21b1_row4_col6\" class=\"data row4 col6\" >0.342997</td>\n",
       "      <td id=\"T_c21b1_row4_col7\" class=\"data row4 col7\" >0.325087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c21b1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c21b1_row5_col0\" class=\"data row5 col0\" >59</td>\n",
       "      <td id=\"T_c21b1_row5_col1\" class=\"data row5 col1\" >0.338299</td>\n",
       "      <td id=\"T_c21b1_row5_col2\" class=\"data row5 col2\" >0.236180</td>\n",
       "      <td id=\"T_c21b1_row5_col3\" class=\"data row5 col3\" >0.172575</td>\n",
       "      <td id=\"T_c21b1_row5_col4\" class=\"data row5 col4\" >0.131069</td>\n",
       "      <td id=\"T_c21b1_row5_col5\" class=\"data row5 col5\" >0.219699</td>\n",
       "      <td id=\"T_c21b1_row5_col6\" class=\"data row5 col6\" >0.360458</td>\n",
       "      <td id=\"T_c21b1_row5_col7\" class=\"data row5 col7\" >0.381152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c21b1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c21b1_row6_col0\" class=\"data row6 col0\" >186</td>\n",
       "      <td id=\"T_c21b1_row6_col1\" class=\"data row6 col1\" >0.344898</td>\n",
       "      <td id=\"T_c21b1_row6_col2\" class=\"data row6 col2\" >0.235199</td>\n",
       "      <td id=\"T_c21b1_row6_col3\" class=\"data row6 col3\" >0.170488</td>\n",
       "      <td id=\"T_c21b1_row6_col4\" class=\"data row6 col4\" >0.129580</td>\n",
       "      <td id=\"T_c21b1_row6_col5\" class=\"data row6 col5\" >0.218335</td>\n",
       "      <td id=\"T_c21b1_row6_col6\" class=\"data row6 col6\" >0.347356</td>\n",
       "      <td id=\"T_c21b1_row6_col7\" class=\"data row6 col7\" >0.411264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1fd2c25610>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best #119"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## No_Dense_x2_ChexPERT_fc+en ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_no_dense_x2_Chexpert'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ae889_row0_col0, #T_ae889_row0_col1, #T_ae889_row1_col2, #T_ae889_row1_col5, #T_ae889_row2_col3, #T_ae889_row3_col4, #T_ae889_row4_col2, #T_ae889_row4_col5, #T_ae889_row5_col6, #T_ae889_row5_col7, #T_ae889_row6_col6, #T_ae889_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ae889_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ae889_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ae889_row0_col0\" class=\"data row0 col0\" >399</td>\n",
       "      <td id=\"T_ae889_row0_col1\" class=\"data row0 col1\" >0.370591</td>\n",
       "      <td id=\"T_ae889_row0_col2\" class=\"data row0 col2\" >0.235473</td>\n",
       "      <td id=\"T_ae889_row0_col3\" class=\"data row0 col3\" >0.159197</td>\n",
       "      <td id=\"T_ae889_row0_col4\" class=\"data row0 col4\" >0.112898</td>\n",
       "      <td id=\"T_ae889_row0_col5\" class=\"data row0 col5\" >0.220751</td>\n",
       "      <td id=\"T_ae889_row0_col6\" class=\"data row0 col6\" >0.310487</td>\n",
       "      <td id=\"T_ae889_row0_col7\" class=\"data row0 col7\" >0.159908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae889_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ae889_row1_col0\" class=\"data row1 col0\" >88</td>\n",
       "      <td id=\"T_ae889_row1_col1\" class=\"data row1 col1\" >0.356252</td>\n",
       "      <td id=\"T_ae889_row1_col2\" class=\"data row1 col2\" >0.243313</td>\n",
       "      <td id=\"T_ae889_row1_col3\" class=\"data row1 col3\" >0.172691</td>\n",
       "      <td id=\"T_ae889_row1_col4\" class=\"data row1 col4\" >0.126458</td>\n",
       "      <td id=\"T_ae889_row1_col5\" class=\"data row1 col5\" >0.224358</td>\n",
       "      <td id=\"T_ae889_row1_col6\" class=\"data row1 col6\" >0.339022</td>\n",
       "      <td id=\"T_ae889_row1_col7\" class=\"data row1 col7\" >0.262737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae889_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ae889_row2_col0\" class=\"data row2 col0\" >65</td>\n",
       "      <td id=\"T_ae889_row2_col1\" class=\"data row2 col1\" >0.350816</td>\n",
       "      <td id=\"T_ae889_row2_col2\" class=\"data row2 col2\" >0.241980</td>\n",
       "      <td id=\"T_ae889_row2_col3\" class=\"data row2 col3\" >0.173056</td>\n",
       "      <td id=\"T_ae889_row2_col4\" class=\"data row2 col4\" >0.127232</td>\n",
       "      <td id=\"T_ae889_row2_col5\" class=\"data row2 col5\" >0.220753</td>\n",
       "      <td id=\"T_ae889_row2_col6\" class=\"data row2 col6\" >0.340465</td>\n",
       "      <td id=\"T_ae889_row2_col7\" class=\"data row2 col7\" >0.283285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae889_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ae889_row3_col0\" class=\"data row3 col0\" >81</td>\n",
       "      <td id=\"T_ae889_row3_col1\" class=\"data row3 col1\" >0.338432</td>\n",
       "      <td id=\"T_ae889_row3_col2\" class=\"data row3 col2\" >0.233178</td>\n",
       "      <td id=\"T_ae889_row3_col3\" class=\"data row3 col3\" >0.168740</td>\n",
       "      <td id=\"T_ae889_row3_col4\" class=\"data row3 col4\" >0.127268</td>\n",
       "      <td id=\"T_ae889_row3_col5\" class=\"data row3 col5\" >0.219293</td>\n",
       "      <td id=\"T_ae889_row3_col6\" class=\"data row3 col6\" >0.346632</td>\n",
       "      <td id=\"T_ae889_row3_col7\" class=\"data row3 col7\" >0.358616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae889_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ae889_row4_col0\" class=\"data row4 col0\" >88</td>\n",
       "      <td id=\"T_ae889_row4_col1\" class=\"data row4 col1\" >0.356252</td>\n",
       "      <td id=\"T_ae889_row4_col2\" class=\"data row4 col2\" >0.243313</td>\n",
       "      <td id=\"T_ae889_row4_col3\" class=\"data row4 col3\" >0.172691</td>\n",
       "      <td id=\"T_ae889_row4_col4\" class=\"data row4 col4\" >0.126458</td>\n",
       "      <td id=\"T_ae889_row4_col5\" class=\"data row4 col5\" >0.224358</td>\n",
       "      <td id=\"T_ae889_row4_col6\" class=\"data row4 col6\" >0.339022</td>\n",
       "      <td id=\"T_ae889_row4_col7\" class=\"data row4 col7\" >0.262737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae889_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ae889_row5_col0\" class=\"data row5 col0\" >52</td>\n",
       "      <td id=\"T_ae889_row5_col1\" class=\"data row5 col1\" >0.324476</td>\n",
       "      <td id=\"T_ae889_row5_col2\" class=\"data row5 col2\" >0.227995</td>\n",
       "      <td id=\"T_ae889_row5_col3\" class=\"data row5 col3\" >0.167191</td>\n",
       "      <td id=\"T_ae889_row5_col4\" class=\"data row5 col4\" >0.126706</td>\n",
       "      <td id=\"T_ae889_row5_col5\" class=\"data row5 col5\" >0.216311</td>\n",
       "      <td id=\"T_ae889_row5_col6\" class=\"data row5 col6\" >0.349634</td>\n",
       "      <td id=\"T_ae889_row5_col7\" class=\"data row5 col7\" >0.371363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae889_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ae889_row6_col0\" class=\"data row6 col0\" >52</td>\n",
       "      <td id=\"T_ae889_row6_col1\" class=\"data row6 col1\" >0.324476</td>\n",
       "      <td id=\"T_ae889_row6_col2\" class=\"data row6 col2\" >0.227995</td>\n",
       "      <td id=\"T_ae889_row6_col3\" class=\"data row6 col3\" >0.167191</td>\n",
       "      <td id=\"T_ae889_row6_col4\" class=\"data row6 col4\" >0.126706</td>\n",
       "      <td id=\"T_ae889_row6_col5\" class=\"data row6 col5\" >0.216311</td>\n",
       "      <td id=\"T_ae889_row6_col6\" class=\"data row6 col6\" >0.349634</td>\n",
       "      <td id=\"T_ae889_row6_col7\" class=\"data row6 col7\" >0.371363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1fd0bae210>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 88"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## Random_Dense_x2_ImageNet_fc+en ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_random_dense_x2_ImageNet_no'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_daa32_row0_col1, #T_daa32_row0_col2, #T_daa32_row1_col1, #T_daa32_row1_col2, #T_daa32_row2_col3, #T_daa32_row2_col4, #T_daa32_row3_col3, #T_daa32_row3_col4, #T_daa32_row4_col5, #T_daa32_row5_col6, #T_daa32_row6_col0, #T_daa32_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_daa32_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_daa32_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_daa32_row0_col0\" class=\"data row0 col0\" >218</td>\n",
       "      <td id=\"T_daa32_row0_col1\" class=\"data row0 col1\" >0.390012</td>\n",
       "      <td id=\"T_daa32_row0_col2\" class=\"data row0 col2\" >0.253700</td>\n",
       "      <td id=\"T_daa32_row0_col3\" class=\"data row0 col3\" >0.174012</td>\n",
       "      <td id=\"T_daa32_row0_col4\" class=\"data row0 col4\" >0.124374</td>\n",
       "      <td id=\"T_daa32_row0_col5\" class=\"data row0 col5\" >0.227515</td>\n",
       "      <td id=\"T_daa32_row0_col6\" class=\"data row0 col6\" >0.316377</td>\n",
       "      <td id=\"T_daa32_row0_col7\" class=\"data row0 col7\" >0.165638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daa32_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_daa32_row1_col0\" class=\"data row1 col0\" >218</td>\n",
       "      <td id=\"T_daa32_row1_col1\" class=\"data row1 col1\" >0.390012</td>\n",
       "      <td id=\"T_daa32_row1_col2\" class=\"data row1 col2\" >0.253700</td>\n",
       "      <td id=\"T_daa32_row1_col3\" class=\"data row1 col3\" >0.174012</td>\n",
       "      <td id=\"T_daa32_row1_col4\" class=\"data row1 col4\" >0.124374</td>\n",
       "      <td id=\"T_daa32_row1_col5\" class=\"data row1 col5\" >0.227515</td>\n",
       "      <td id=\"T_daa32_row1_col6\" class=\"data row1 col6\" >0.316377</td>\n",
       "      <td id=\"T_daa32_row1_col7\" class=\"data row1 col7\" >0.165638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daa32_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_daa32_row2_col0\" class=\"data row2 col0\" >234</td>\n",
       "      <td id=\"T_daa32_row2_col1\" class=\"data row2 col1\" >0.372018</td>\n",
       "      <td id=\"T_daa32_row2_col2\" class=\"data row2 col2\" >0.249205</td>\n",
       "      <td id=\"T_daa32_row2_col3\" class=\"data row2 col3\" >0.175830</td>\n",
       "      <td id=\"T_daa32_row2_col4\" class=\"data row2 col4\" >0.129558</td>\n",
       "      <td id=\"T_daa32_row2_col5\" class=\"data row2 col5\" >0.225142</td>\n",
       "      <td id=\"T_daa32_row2_col6\" class=\"data row2 col6\" >0.327915</td>\n",
       "      <td id=\"T_daa32_row2_col7\" class=\"data row2 col7\" >0.208479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daa32_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_daa32_row3_col0\" class=\"data row3 col0\" >234</td>\n",
       "      <td id=\"T_daa32_row3_col1\" class=\"data row3 col1\" >0.372018</td>\n",
       "      <td id=\"T_daa32_row3_col2\" class=\"data row3 col2\" >0.249205</td>\n",
       "      <td id=\"T_daa32_row3_col3\" class=\"data row3 col3\" >0.175830</td>\n",
       "      <td id=\"T_daa32_row3_col4\" class=\"data row3 col4\" >0.129558</td>\n",
       "      <td id=\"T_daa32_row3_col5\" class=\"data row3 col5\" >0.225142</td>\n",
       "      <td id=\"T_daa32_row3_col6\" class=\"data row3 col6\" >0.327915</td>\n",
       "      <td id=\"T_daa32_row3_col7\" class=\"data row3 col7\" >0.208479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daa32_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_daa32_row4_col0\" class=\"data row4 col0\" >254</td>\n",
       "      <td id=\"T_daa32_row4_col1\" class=\"data row4 col1\" >0.377074</td>\n",
       "      <td id=\"T_daa32_row4_col2\" class=\"data row4 col2\" >0.252837</td>\n",
       "      <td id=\"T_daa32_row4_col3\" class=\"data row4 col3\" >0.175815</td>\n",
       "      <td id=\"T_daa32_row4_col4\" class=\"data row4 col4\" >0.127158</td>\n",
       "      <td id=\"T_daa32_row4_col5\" class=\"data row4 col5\" >0.228151</td>\n",
       "      <td id=\"T_daa32_row4_col6\" class=\"data row4 col6\" >0.326920</td>\n",
       "      <td id=\"T_daa32_row4_col7\" class=\"data row4 col7\" >0.223946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daa32_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_daa32_row5_col0\" class=\"data row5 col0\" >303</td>\n",
       "      <td id=\"T_daa32_row5_col1\" class=\"data row5 col1\" >0.346218</td>\n",
       "      <td id=\"T_daa32_row5_col2\" class=\"data row5 col2\" >0.238053</td>\n",
       "      <td id=\"T_daa32_row5_col3\" class=\"data row5 col3\" >0.171316</td>\n",
       "      <td id=\"T_daa32_row5_col4\" class=\"data row5 col4\" >0.128457</td>\n",
       "      <td id=\"T_daa32_row5_col5\" class=\"data row5 col5\" >0.217269</td>\n",
       "      <td id=\"T_daa32_row5_col6\" class=\"data row5 col6\" >0.341395</td>\n",
       "      <td id=\"T_daa32_row5_col7\" class=\"data row5 col7\" >0.346330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daa32_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_daa32_row6_col0\" class=\"data row6 col0\" >331</td>\n",
       "      <td id=\"T_daa32_row6_col1\" class=\"data row6 col1\" >0.331932</td>\n",
       "      <td id=\"T_daa32_row6_col2\" class=\"data row6 col2\" >0.223138</td>\n",
       "      <td id=\"T_daa32_row6_col3\" class=\"data row6 col3\" >0.159098</td>\n",
       "      <td id=\"T_daa32_row6_col4\" class=\"data row6 col4\" >0.119082</td>\n",
       "      <td id=\"T_daa32_row6_col5\" class=\"data row6 col5\" >0.211295</td>\n",
       "      <td id=\"T_daa32_row6_col6\" class=\"data row6 col6\" >0.330647</td>\n",
       "      <td id=\"T_daa32_row6_col7\" class=\"data row6 col7\" >0.358116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8d4f7855d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## random_dense_x2_CheXpert_(no)detach ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_random_dense_x2_CheXpert_nodetach'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c7114_row0_col1, #T_c7114_row1_col2, #T_c7114_row2_col0, #T_c7114_row2_col3, #T_c7114_row3_col4, #T_c7114_row3_col7, #T_c7114_row4_col5, #T_c7114_row5_col6, #T_c7114_row6_col4, #T_c7114_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c7114_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c7114_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c7114_row0_col0\" class=\"data row0 col0\" >73</td>\n",
       "      <td id=\"T_c7114_row0_col1\" class=\"data row0 col1\" >0.365859</td>\n",
       "      <td id=\"T_c7114_row0_col2\" class=\"data row0 col2\" >0.244612</td>\n",
       "      <td id=\"T_c7114_row0_col3\" class=\"data row0 col3\" >0.170726</td>\n",
       "      <td id=\"T_c7114_row0_col4\" class=\"data row0 col4\" >0.123503</td>\n",
       "      <td id=\"T_c7114_row0_col5\" class=\"data row0 col5\" >0.226417</td>\n",
       "      <td id=\"T_c7114_row0_col6\" class=\"data row0 col6\" >0.337395</td>\n",
       "      <td id=\"T_c7114_row0_col7\" class=\"data row0 col7\" >0.253027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7114_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c7114_row1_col0\" class=\"data row1 col0\" >45</td>\n",
       "      <td id=\"T_c7114_row1_col1\" class=\"data row1 col1\" >0.361976</td>\n",
       "      <td id=\"T_c7114_row1_col2\" class=\"data row1 col2\" >0.245710</td>\n",
       "      <td id=\"T_c7114_row1_col3\" class=\"data row1 col3\" >0.175385</td>\n",
       "      <td id=\"T_c7114_row1_col4\" class=\"data row1 col4\" >0.131572</td>\n",
       "      <td id=\"T_c7114_row1_col5\" class=\"data row1 col5\" >0.223302</td>\n",
       "      <td id=\"T_c7114_row1_col6\" class=\"data row1 col6\" >0.344529</td>\n",
       "      <td id=\"T_c7114_row1_col7\" class=\"data row1 col7\" >0.380481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7114_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c7114_row2_col0\" class=\"data row2 col0\" >86</td>\n",
       "      <td id=\"T_c7114_row2_col1\" class=\"data row2 col1\" >0.359797</td>\n",
       "      <td id=\"T_c7114_row2_col2\" class=\"data row2 col2\" >0.245210</td>\n",
       "      <td id=\"T_c7114_row2_col3\" class=\"data row2 col3\" >0.176520</td>\n",
       "      <td id=\"T_c7114_row2_col4\" class=\"data row2 col4\" >0.132613</td>\n",
       "      <td id=\"T_c7114_row2_col5\" class=\"data row2 col5\" >0.225531</td>\n",
       "      <td id=\"T_c7114_row2_col6\" class=\"data row2 col6\" >0.345665</td>\n",
       "      <td id=\"T_c7114_row2_col7\" class=\"data row2 col7\" >0.390443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7114_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c7114_row3_col0\" class=\"data row3 col0\" >58</td>\n",
       "      <td id=\"T_c7114_row3_col1\" class=\"data row3 col1\" >0.354671</td>\n",
       "      <td id=\"T_c7114_row3_col2\" class=\"data row3 col2\" >0.243139</td>\n",
       "      <td id=\"T_c7114_row3_col3\" class=\"data row3 col3\" >0.175938</td>\n",
       "      <td id=\"T_c7114_row3_col4\" class=\"data row3 col4\" >0.133775</td>\n",
       "      <td id=\"T_c7114_row3_col5\" class=\"data row3 col5\" >0.222093</td>\n",
       "      <td id=\"T_c7114_row3_col6\" class=\"data row3 col6\" >0.352388</td>\n",
       "      <td id=\"T_c7114_row3_col7\" class=\"data row3 col7\" >0.404952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7114_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c7114_row4_col0\" class=\"data row4 col0\" >81</td>\n",
       "      <td id=\"T_c7114_row4_col1\" class=\"data row4 col1\" >0.365580</td>\n",
       "      <td id=\"T_c7114_row4_col2\" class=\"data row4 col2\" >0.244965</td>\n",
       "      <td id=\"T_c7114_row4_col3\" class=\"data row4 col3\" >0.171528</td>\n",
       "      <td id=\"T_c7114_row4_col4\" class=\"data row4 col4\" >0.123932</td>\n",
       "      <td id=\"T_c7114_row4_col5\" class=\"data row4 col5\" >0.227182</td>\n",
       "      <td id=\"T_c7114_row4_col6\" class=\"data row4 col6\" >0.334288</td>\n",
       "      <td id=\"T_c7114_row4_col7\" class=\"data row4 col7\" >0.254766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7114_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c7114_row5_col0\" class=\"data row5 col0\" >26</td>\n",
       "      <td id=\"T_c7114_row5_col1\" class=\"data row5 col1\" >0.319458</td>\n",
       "      <td id=\"T_c7114_row5_col2\" class=\"data row5 col2\" >0.223396</td>\n",
       "      <td id=\"T_c7114_row5_col3\" class=\"data row5 col3\" >0.164771</td>\n",
       "      <td id=\"T_c7114_row5_col4\" class=\"data row5 col4\" >0.125822</td>\n",
       "      <td id=\"T_c7114_row5_col5\" class=\"data row5 col5\" >0.214500</td>\n",
       "      <td id=\"T_c7114_row5_col6\" class=\"data row5 col6\" >0.353596</td>\n",
       "      <td id=\"T_c7114_row5_col7\" class=\"data row5 col7\" >0.382781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7114_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c7114_row6_col0\" class=\"data row6 col0\" >58</td>\n",
       "      <td id=\"T_c7114_row6_col1\" class=\"data row6 col1\" >0.354671</td>\n",
       "      <td id=\"T_c7114_row6_col2\" class=\"data row6 col2\" >0.243139</td>\n",
       "      <td id=\"T_c7114_row6_col3\" class=\"data row6 col3\" >0.175938</td>\n",
       "      <td id=\"T_c7114_row6_col4\" class=\"data row6 col4\" >0.133775</td>\n",
       "      <td id=\"T_c7114_row6_col5\" class=\"data row6 col5\" >0.222093</td>\n",
       "      <td id=\"T_c7114_row6_col6\" class=\"data row6 col6\" >0.352388</td>\n",
       "      <td id=\"T_c7114_row6_col7\" class=\"data row6 col7\" >0.404952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd2ae7ab6d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## CA10_dense_x2_CheXpert_no ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca_dense_x2_CheXpert_no'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_21552_row0_col0, #T_21552_row0_col1, #T_21552_row1_col2, #T_21552_row2_col3, #T_21552_row2_col4, #T_21552_row3_col3, #T_21552_row3_col4, #T_21552_row4_col5, #T_21552_row5_col6, #T_21552_row5_col7, #T_21552_row6_col6, #T_21552_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_21552_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_21552_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_21552_row0_col0\" class=\"data row0 col0\" >305</td>\n",
       "      <td id=\"T_21552_row0_col1\" class=\"data row0 col1\" >0.383706</td>\n",
       "      <td id=\"T_21552_row0_col2\" class=\"data row0 col2\" >0.241341</td>\n",
       "      <td id=\"T_21552_row0_col3\" class=\"data row0 col3\" >0.162806</td>\n",
       "      <td id=\"T_21552_row0_col4\" class=\"data row0 col4\" >0.115420</td>\n",
       "      <td id=\"T_21552_row0_col5\" class=\"data row0 col5\" >0.222212</td>\n",
       "      <td id=\"T_21552_row0_col6\" class=\"data row0 col6\" >0.314283</td>\n",
       "      <td id=\"T_21552_row0_col7\" class=\"data row0 col7\" >0.204477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21552_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_21552_row1_col0\" class=\"data row1 col0\" >53</td>\n",
       "      <td id=\"T_21552_row1_col1\" class=\"data row1 col1\" >0.363147</td>\n",
       "      <td id=\"T_21552_row1_col2\" class=\"data row1 col2\" >0.248755</td>\n",
       "      <td id=\"T_21552_row1_col3\" class=\"data row1 col3\" >0.177906</td>\n",
       "      <td id=\"T_21552_row1_col4\" class=\"data row1 col4\" >0.132371</td>\n",
       "      <td id=\"T_21552_row1_col5\" class=\"data row1 col5\" >0.224689</td>\n",
       "      <td id=\"T_21552_row1_col6\" class=\"data row1 col6\" >0.345253</td>\n",
       "      <td id=\"T_21552_row1_col7\" class=\"data row1 col7\" >0.268457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21552_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_21552_row2_col0\" class=\"data row2 col0\" >34</td>\n",
       "      <td id=\"T_21552_row2_col1\" class=\"data row2 col1\" >0.354621</td>\n",
       "      <td id=\"T_21552_row2_col2\" class=\"data row2 col2\" >0.248030</td>\n",
       "      <td id=\"T_21552_row2_col3\" class=\"data row2 col3\" >0.178939</td>\n",
       "      <td id=\"T_21552_row2_col4\" class=\"data row2 col4\" >0.133246</td>\n",
       "      <td id=\"T_21552_row2_col5\" class=\"data row2 col5\" >0.227910</td>\n",
       "      <td id=\"T_21552_row2_col6\" class=\"data row2 col6\" >0.347526</td>\n",
       "      <td id=\"T_21552_row2_col7\" class=\"data row2 col7\" >0.255577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21552_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_21552_row3_col0\" class=\"data row3 col0\" >34</td>\n",
       "      <td id=\"T_21552_row3_col1\" class=\"data row3 col1\" >0.354621</td>\n",
       "      <td id=\"T_21552_row3_col2\" class=\"data row3 col2\" >0.248030</td>\n",
       "      <td id=\"T_21552_row3_col3\" class=\"data row3 col3\" >0.178939</td>\n",
       "      <td id=\"T_21552_row3_col4\" class=\"data row3 col4\" >0.133246</td>\n",
       "      <td id=\"T_21552_row3_col5\" class=\"data row3 col5\" >0.227910</td>\n",
       "      <td id=\"T_21552_row3_col6\" class=\"data row3 col6\" >0.347526</td>\n",
       "      <td id=\"T_21552_row3_col7\" class=\"data row3 col7\" >0.255577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21552_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_21552_row4_col0\" class=\"data row4 col0\" >47</td>\n",
       "      <td id=\"T_21552_row4_col1\" class=\"data row4 col1\" >0.353337</td>\n",
       "      <td id=\"T_21552_row4_col2\" class=\"data row4 col2\" >0.241143</td>\n",
       "      <td id=\"T_21552_row4_col3\" class=\"data row4 col3\" >0.172239</td>\n",
       "      <td id=\"T_21552_row4_col4\" class=\"data row4 col4\" >0.127981</td>\n",
       "      <td id=\"T_21552_row4_col5\" class=\"data row4 col5\" >0.229392</td>\n",
       "      <td id=\"T_21552_row4_col6\" class=\"data row4 col6\" >0.348762</td>\n",
       "      <td id=\"T_21552_row4_col7\" class=\"data row4 col7\" >0.263717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21552_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_21552_row5_col0\" class=\"data row5 col0\" >22</td>\n",
       "      <td id=\"T_21552_row5_col1\" class=\"data row5 col1\" >0.312410</td>\n",
       "      <td id=\"T_21552_row5_col2\" class=\"data row5 col2\" >0.224150</td>\n",
       "      <td id=\"T_21552_row5_col3\" class=\"data row5 col3\" >0.167595</td>\n",
       "      <td id=\"T_21552_row5_col4\" class=\"data row5 col4\" >0.128011</td>\n",
       "      <td id=\"T_21552_row5_col5\" class=\"data row5 col5\" >0.215042</td>\n",
       "      <td id=\"T_21552_row5_col6\" class=\"data row5 col6\" >0.359851</td>\n",
       "      <td id=\"T_21552_row5_col7\" class=\"data row5 col7\" >0.346491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21552_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_21552_row6_col0\" class=\"data row6 col0\" >22</td>\n",
       "      <td id=\"T_21552_row6_col1\" class=\"data row6 col1\" >0.312410</td>\n",
       "      <td id=\"T_21552_row6_col2\" class=\"data row6 col2\" >0.224150</td>\n",
       "      <td id=\"T_21552_row6_col3\" class=\"data row6 col3\" >0.167595</td>\n",
       "      <td id=\"T_21552_row6_col4\" class=\"data row6 col4\" >0.128011</td>\n",
       "      <td id=\"T_21552_row6_col5\" class=\"data row6 col5\" >0.215042</td>\n",
       "      <td id=\"T_21552_row6_col6\" class=\"data row6 col6\" >0.359851</td>\n",
       "      <td id=\"T_21552_row6_col7\" class=\"data row6 col7\" >0.346491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd22cf6f1d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## CA10_dense_x4_CheXpert_no ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca10_dense_x4_CheXpert_no'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_28d49_row0_col1, #T_28d49_row1_col2, #T_28d49_row1_col3, #T_28d49_row1_col4, #T_28d49_row2_col2, #T_28d49_row2_col3, #T_28d49_row2_col4, #T_28d49_row3_col2, #T_28d49_row3_col3, #T_28d49_row3_col4, #T_28d49_row4_col5, #T_28d49_row5_col6, #T_28d49_row6_col0, #T_28d49_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_28d49_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_28d49_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_28d49_row0_col0\" class=\"data row0 col0\" >116</td>\n",
       "      <td id=\"T_28d49_row0_col1\" class=\"data row0 col1\" >0.371524</td>\n",
       "      <td id=\"T_28d49_row0_col2\" class=\"data row0 col2\" >0.247363</td>\n",
       "      <td id=\"T_28d49_row0_col3\" class=\"data row0 col3\" >0.172465</td>\n",
       "      <td id=\"T_28d49_row0_col4\" class=\"data row0 col4\" >0.125445</td>\n",
       "      <td id=\"T_28d49_row0_col5\" class=\"data row0 col5\" >0.226573</td>\n",
       "      <td id=\"T_28d49_row0_col6\" class=\"data row0 col6\" >0.332185</td>\n",
       "      <td id=\"T_28d49_row0_col7\" class=\"data row0 col7\" >0.216404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28d49_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_28d49_row1_col0\" class=\"data row1 col0\" >109</td>\n",
       "      <td id=\"T_28d49_row1_col1\" class=\"data row1 col1\" >0.367602</td>\n",
       "      <td id=\"T_28d49_row1_col2\" class=\"data row1 col2\" >0.250133</td>\n",
       "      <td id=\"T_28d49_row1_col3\" class=\"data row1 col3\" >0.179106</td>\n",
       "      <td id=\"T_28d49_row1_col4\" class=\"data row1 col4\" >0.134259</td>\n",
       "      <td id=\"T_28d49_row1_col5\" class=\"data row1 col5\" >0.224810</td>\n",
       "      <td id=\"T_28d49_row1_col6\" class=\"data row1 col6\" >0.343650</td>\n",
       "      <td id=\"T_28d49_row1_col7\" class=\"data row1 col7\" >0.287585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28d49_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_28d49_row2_col0\" class=\"data row2 col0\" >109</td>\n",
       "      <td id=\"T_28d49_row2_col1\" class=\"data row2 col1\" >0.367602</td>\n",
       "      <td id=\"T_28d49_row2_col2\" class=\"data row2 col2\" >0.250133</td>\n",
       "      <td id=\"T_28d49_row2_col3\" class=\"data row2 col3\" >0.179106</td>\n",
       "      <td id=\"T_28d49_row2_col4\" class=\"data row2 col4\" >0.134259</td>\n",
       "      <td id=\"T_28d49_row2_col5\" class=\"data row2 col5\" >0.224810</td>\n",
       "      <td id=\"T_28d49_row2_col6\" class=\"data row2 col6\" >0.343650</td>\n",
       "      <td id=\"T_28d49_row2_col7\" class=\"data row2 col7\" >0.287585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28d49_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_28d49_row3_col0\" class=\"data row3 col0\" >109</td>\n",
       "      <td id=\"T_28d49_row3_col1\" class=\"data row3 col1\" >0.367602</td>\n",
       "      <td id=\"T_28d49_row3_col2\" class=\"data row3 col2\" >0.250133</td>\n",
       "      <td id=\"T_28d49_row3_col3\" class=\"data row3 col3\" >0.179106</td>\n",
       "      <td id=\"T_28d49_row3_col4\" class=\"data row3 col4\" >0.134259</td>\n",
       "      <td id=\"T_28d49_row3_col5\" class=\"data row3 col5\" >0.224810</td>\n",
       "      <td id=\"T_28d49_row3_col6\" class=\"data row3 col6\" >0.343650</td>\n",
       "      <td id=\"T_28d49_row3_col7\" class=\"data row3 col7\" >0.287585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28d49_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_28d49_row4_col0\" class=\"data row4 col0\" >55</td>\n",
       "      <td id=\"T_28d49_row4_col1\" class=\"data row4 col1\" >0.348388</td>\n",
       "      <td id=\"T_28d49_row4_col2\" class=\"data row4 col2\" >0.238821</td>\n",
       "      <td id=\"T_28d49_row4_col3\" class=\"data row4 col3\" >0.168743</td>\n",
       "      <td id=\"T_28d49_row4_col4\" class=\"data row4 col4\" >0.122732</td>\n",
       "      <td id=\"T_28d49_row4_col5\" class=\"data row4 col5\" >0.226709</td>\n",
       "      <td id=\"T_28d49_row4_col6\" class=\"data row4 col6\" >0.337385</td>\n",
       "      <td id=\"T_28d49_row4_col7\" class=\"data row4 col7\" >0.248267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28d49_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_28d49_row5_col0\" class=\"data row5 col0\" >135</td>\n",
       "      <td id=\"T_28d49_row5_col1\" class=\"data row5 col1\" >0.330002</td>\n",
       "      <td id=\"T_28d49_row5_col2\" class=\"data row5 col2\" >0.229247</td>\n",
       "      <td id=\"T_28d49_row5_col3\" class=\"data row5 col3\" >0.167481</td>\n",
       "      <td id=\"T_28d49_row5_col4\" class=\"data row5 col4\" >0.127851</td>\n",
       "      <td id=\"T_28d49_row5_col5\" class=\"data row5 col5\" >0.214435</td>\n",
       "      <td id=\"T_28d49_row5_col6\" class=\"data row5 col6\" >0.354467</td>\n",
       "      <td id=\"T_28d49_row5_col7\" class=\"data row5 col7\" >0.396587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28d49_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_28d49_row6_col0\" class=\"data row6 col0\" >348</td>\n",
       "      <td id=\"T_28d49_row6_col1\" class=\"data row6 col1\" >0.300038</td>\n",
       "      <td id=\"T_28d49_row6_col2\" class=\"data row6 col2\" >0.202243</td>\n",
       "      <td id=\"T_28d49_row6_col3\" class=\"data row6 col3\" >0.147795</td>\n",
       "      <td id=\"T_28d49_row6_col4\" class=\"data row6 col4\" >0.113752</td>\n",
       "      <td id=\"T_28d49_row6_col5\" class=\"data row6 col5\" >0.202084</td>\n",
       "      <td id=\"T_28d49_row6_col6\" class=\"data row6 col6\" >0.325507</td>\n",
       "      <td id=\"T_28d49_row6_col7\" class=\"data row6 col7\" >0.410693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f06200e67d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## CA30_dense_x2_CheXpert_no ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca30_dense_x2_CheXpert_no'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d169b_row0_col1, #T_d169b_row0_col2, #T_d169b_row0_col5, #T_d169b_row1_col1, #T_d169b_row1_col2, #T_d169b_row1_col5, #T_d169b_row2_col3, #T_d169b_row3_col4, #T_d169b_row4_col1, #T_d169b_row4_col2, #T_d169b_row4_col5, #T_d169b_row5_col6, #T_d169b_row6_col0, #T_d169b_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d169b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d169b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d169b_row0_col0\" class=\"data row0 col0\" >47</td>\n",
       "      <td id=\"T_d169b_row0_col1\" class=\"data row0 col1\" >0.382924</td>\n",
       "      <td id=\"T_d169b_row0_col2\" class=\"data row0 col2\" >0.257954</td>\n",
       "      <td id=\"T_d169b_row0_col3\" class=\"data row0 col3\" >0.181299</td>\n",
       "      <td id=\"T_d169b_row0_col4\" class=\"data row0 col4\" >0.132113</td>\n",
       "      <td id=\"T_d169b_row0_col5\" class=\"data row0 col5\" >0.234652</td>\n",
       "      <td id=\"T_d169b_row0_col6\" class=\"data row0 col6\" >0.340306</td>\n",
       "      <td id=\"T_d169b_row0_col7\" class=\"data row0 col7\" >0.261855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d169b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d169b_row1_col0\" class=\"data row1 col0\" >47</td>\n",
       "      <td id=\"T_d169b_row1_col1\" class=\"data row1 col1\" >0.382924</td>\n",
       "      <td id=\"T_d169b_row1_col2\" class=\"data row1 col2\" >0.257954</td>\n",
       "      <td id=\"T_d169b_row1_col3\" class=\"data row1 col3\" >0.181299</td>\n",
       "      <td id=\"T_d169b_row1_col4\" class=\"data row1 col4\" >0.132113</td>\n",
       "      <td id=\"T_d169b_row1_col5\" class=\"data row1 col5\" >0.234652</td>\n",
       "      <td id=\"T_d169b_row1_col6\" class=\"data row1 col6\" >0.340306</td>\n",
       "      <td id=\"T_d169b_row1_col7\" class=\"data row1 col7\" >0.261855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d169b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d169b_row2_col0\" class=\"data row2 col0\" >94</td>\n",
       "      <td id=\"T_d169b_row2_col1\" class=\"data row2 col1\" >0.368318</td>\n",
       "      <td id=\"T_d169b_row2_col2\" class=\"data row2 col2\" >0.255517</td>\n",
       "      <td id=\"T_d169b_row2_col3\" class=\"data row2 col3\" >0.184282</td>\n",
       "      <td id=\"T_d169b_row2_col4\" class=\"data row2 col4\" >0.137501</td>\n",
       "      <td id=\"T_d169b_row2_col5\" class=\"data row2 col5\" >0.231405</td>\n",
       "      <td id=\"T_d169b_row2_col6\" class=\"data row2 col6\" >0.352337</td>\n",
       "      <td id=\"T_d169b_row2_col7\" class=\"data row2 col7\" >0.368945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d169b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d169b_row3_col0\" class=\"data row3 col0\" >99</td>\n",
       "      <td id=\"T_d169b_row3_col1\" class=\"data row3 col1\" >0.370934</td>\n",
       "      <td id=\"T_d169b_row3_col2\" class=\"data row3 col2\" >0.254703</td>\n",
       "      <td id=\"T_d169b_row3_col3\" class=\"data row3 col3\" >0.183628</td>\n",
       "      <td id=\"T_d169b_row3_col4\" class=\"data row3 col4\" >0.137801</td>\n",
       "      <td id=\"T_d169b_row3_col5\" class=\"data row3 col5\" >0.231497</td>\n",
       "      <td id=\"T_d169b_row3_col6\" class=\"data row3 col6\" >0.352262</td>\n",
       "      <td id=\"T_d169b_row3_col7\" class=\"data row3 col7\" >0.363529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d169b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d169b_row4_col0\" class=\"data row4 col0\" >47</td>\n",
       "      <td id=\"T_d169b_row4_col1\" class=\"data row4 col1\" >0.382924</td>\n",
       "      <td id=\"T_d169b_row4_col2\" class=\"data row4 col2\" >0.257954</td>\n",
       "      <td id=\"T_d169b_row4_col3\" class=\"data row4 col3\" >0.181299</td>\n",
       "      <td id=\"T_d169b_row4_col4\" class=\"data row4 col4\" >0.132113</td>\n",
       "      <td id=\"T_d169b_row4_col5\" class=\"data row4 col5\" >0.234652</td>\n",
       "      <td id=\"T_d169b_row4_col6\" class=\"data row4 col6\" >0.340306</td>\n",
       "      <td id=\"T_d169b_row4_col7\" class=\"data row4 col7\" >0.261855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d169b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d169b_row5_col0\" class=\"data row5 col0\" >35</td>\n",
       "      <td id=\"T_d169b_row5_col1\" class=\"data row5 col1\" >0.335786</td>\n",
       "      <td id=\"T_d169b_row5_col2\" class=\"data row5 col2\" >0.232653</td>\n",
       "      <td id=\"T_d169b_row5_col3\" class=\"data row5 col3\" >0.170069</td>\n",
       "      <td id=\"T_d169b_row5_col4\" class=\"data row5 col4\" >0.129806</td>\n",
       "      <td id=\"T_d169b_row5_col5\" class=\"data row5 col5\" >0.221176</td>\n",
       "      <td id=\"T_d169b_row5_col6\" class=\"data row5 col6\" >0.357582</td>\n",
       "      <td id=\"T_d169b_row5_col7\" class=\"data row5 col7\" >0.336038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d169b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d169b_row6_col0\" class=\"data row6 col0\" >155</td>\n",
       "      <td id=\"T_d169b_row6_col1\" class=\"data row6 col1\" >0.362555</td>\n",
       "      <td id=\"T_d169b_row6_col2\" class=\"data row6 col2\" >0.248336</td>\n",
       "      <td id=\"T_d169b_row6_col3\" class=\"data row6 col3\" >0.180371</td>\n",
       "      <td id=\"T_d169b_row6_col4\" class=\"data row6 col4\" >0.136987</td>\n",
       "      <td id=\"T_d169b_row6_col5\" class=\"data row6 col5\" >0.225081</td>\n",
       "      <td id=\"T_d169b_row6_col6\" class=\"data row6 col6\" >0.350388</td>\n",
       "      <td id=\"T_d169b_row6_col7\" class=\"data row6 col7\" >0.400146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f71002b6990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bold_best # 94i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c4017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87bbdec1",
   "metadata": {},
   "source": [
    "# 여기부터 pre-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## CA30_512_dense_x2_CheXpert_fc ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca30_512_dense_x2_CheXpert_fc'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0147_row0_col0, #T_f0147_row0_col1, #T_f0147_row0_col2, #T_f0147_row1_col0, #T_f0147_row1_col1, #T_f0147_row1_col2, #T_f0147_row2_col3, #T_f0147_row3_col4, #T_f0147_row4_col5, #T_f0147_row5_col6, #T_f0147_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0147_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f0147_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f0147_row0_col0\" class=\"data row0 col0\" >108</td>\n",
       "      <td id=\"T_f0147_row0_col1\" class=\"data row0 col1\" >0.376295</td>\n",
       "      <td id=\"T_f0147_row0_col2\" class=\"data row0 col2\" >0.250974</td>\n",
       "      <td id=\"T_f0147_row0_col3\" class=\"data row0 col3\" >0.175075</td>\n",
       "      <td id=\"T_f0147_row0_col4\" class=\"data row0 col4\" >0.127002</td>\n",
       "      <td id=\"T_f0147_row0_col5\" class=\"data row0 col5\" >0.225808</td>\n",
       "      <td id=\"T_f0147_row0_col6\" class=\"data row0 col6\" >0.341031</td>\n",
       "      <td id=\"T_f0147_row0_col7\" class=\"data row0 col7\" >0.256697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0147_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f0147_row1_col0\" class=\"data row1 col0\" >108</td>\n",
       "      <td id=\"T_f0147_row1_col1\" class=\"data row1 col1\" >0.376295</td>\n",
       "      <td id=\"T_f0147_row1_col2\" class=\"data row1 col2\" >0.250974</td>\n",
       "      <td id=\"T_f0147_row1_col3\" class=\"data row1 col3\" >0.175075</td>\n",
       "      <td id=\"T_f0147_row1_col4\" class=\"data row1 col4\" >0.127002</td>\n",
       "      <td id=\"T_f0147_row1_col5\" class=\"data row1 col5\" >0.225808</td>\n",
       "      <td id=\"T_f0147_row1_col6\" class=\"data row1 col6\" >0.341031</td>\n",
       "      <td id=\"T_f0147_row1_col7\" class=\"data row1 col7\" >0.256697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0147_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f0147_row2_col0\" class=\"data row2 col0\" >22</td>\n",
       "      <td id=\"T_f0147_row2_col1\" class=\"data row2 col1\" >0.354148</td>\n",
       "      <td id=\"T_f0147_row2_col2\" class=\"data row2 col2\" >0.247072</td>\n",
       "      <td id=\"T_f0147_row2_col3\" class=\"data row2 col3\" >0.180303</td>\n",
       "      <td id=\"T_f0147_row2_col4\" class=\"data row2 col4\" >0.135978</td>\n",
       "      <td id=\"T_f0147_row2_col5\" class=\"data row2 col5\" >0.226283</td>\n",
       "      <td id=\"T_f0147_row2_col6\" class=\"data row2 col6\" >0.349464</td>\n",
       "      <td id=\"T_f0147_row2_col7\" class=\"data row2 col7\" >0.281989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0147_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f0147_row3_col0\" class=\"data row3 col0\" >93</td>\n",
       "      <td id=\"T_f0147_row3_col1\" class=\"data row3 col1\" >0.353829</td>\n",
       "      <td id=\"T_f0147_row3_col2\" class=\"data row3 col2\" >0.244102</td>\n",
       "      <td id=\"T_f0147_row3_col3\" class=\"data row3 col3\" >0.178536</td>\n",
       "      <td id=\"T_f0147_row3_col4\" class=\"data row3 col4\" >0.136013</td>\n",
       "      <td id=\"T_f0147_row3_col5\" class=\"data row3 col5\" >0.221016</td>\n",
       "      <td id=\"T_f0147_row3_col6\" class=\"data row3 col6\" >0.352587</td>\n",
       "      <td id=\"T_f0147_row3_col7\" class=\"data row3 col7\" >0.316722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0147_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f0147_row4_col0\" class=\"data row4 col0\" >102</td>\n",
       "      <td id=\"T_f0147_row4_col1\" class=\"data row4 col1\" >0.363841</td>\n",
       "      <td id=\"T_f0147_row4_col2\" class=\"data row4 col2\" >0.242793</td>\n",
       "      <td id=\"T_f0147_row4_col3\" class=\"data row4 col3\" >0.170380</td>\n",
       "      <td id=\"T_f0147_row4_col4\" class=\"data row4 col4\" >0.124846</td>\n",
       "      <td id=\"T_f0147_row4_col5\" class=\"data row4 col5\" >0.226473</td>\n",
       "      <td id=\"T_f0147_row4_col6\" class=\"data row4 col6\" >0.341931</td>\n",
       "      <td id=\"T_f0147_row4_col7\" class=\"data row4 col7\" >0.257182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0147_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f0147_row5_col0\" class=\"data row5 col0\" >40</td>\n",
       "      <td id=\"T_f0147_row5_col1\" class=\"data row5 col1\" >0.315172</td>\n",
       "      <td id=\"T_f0147_row5_col2\" class=\"data row5 col2\" >0.222786</td>\n",
       "      <td id=\"T_f0147_row5_col3\" class=\"data row5 col3\" >0.165606</td>\n",
       "      <td id=\"T_f0147_row5_col4\" class=\"data row5 col4\" >0.127727</td>\n",
       "      <td id=\"T_f0147_row5_col5\" class=\"data row5 col5\" >0.214501</td>\n",
       "      <td id=\"T_f0147_row5_col6\" class=\"data row5 col6\" >0.356624</td>\n",
       "      <td id=\"T_f0147_row5_col7\" class=\"data row5 col7\" >0.357628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0147_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f0147_row6_col0\" class=\"data row6 col0\" >70</td>\n",
       "      <td id=\"T_f0147_row6_col1\" class=\"data row6 col1\" >0.353148</td>\n",
       "      <td id=\"T_f0147_row6_col2\" class=\"data row6 col2\" >0.241741</td>\n",
       "      <td id=\"T_f0147_row6_col3\" class=\"data row6 col3\" >0.177112</td>\n",
       "      <td id=\"T_f0147_row6_col4\" class=\"data row6 col4\" >0.135472</td>\n",
       "      <td id=\"T_f0147_row6_col5\" class=\"data row6 col5\" >0.218202</td>\n",
       "      <td id=\"T_f0147_row6_col6\" class=\"data row6 col6\" >0.353922</td>\n",
       "      <td id=\"T_f0147_row6_col7\" class=\"data row6 col7\" >0.403598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f64427938d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## CA30_512_dense_x2_CheXpert_fc_noconcat++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca30_512_dense_x2_CheXpert_fc_noconcat'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b81cc_row0_col1, #T_b81cc_row1_col2, #T_b81cc_row1_col3, #T_b81cc_row1_col4, #T_b81cc_row2_col2, #T_b81cc_row2_col3, #T_b81cc_row2_col4, #T_b81cc_row3_col2, #T_b81cc_row3_col3, #T_b81cc_row3_col4, #T_b81cc_row4_col5, #T_b81cc_row5_col6, #T_b81cc_row6_col0, #T_b81cc_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b81cc_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b81cc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b81cc_row0_col0\" class=\"data row0 col0\" >112</td>\n",
       "      <td id=\"T_b81cc_row0_col1\" class=\"data row0 col1\" >0.367562</td>\n",
       "      <td id=\"T_b81cc_row0_col2\" class=\"data row0 col2\" >0.249394</td>\n",
       "      <td id=\"T_b81cc_row0_col3\" class=\"data row0 col3\" >0.177260</td>\n",
       "      <td id=\"T_b81cc_row0_col4\" class=\"data row0 col4\" >0.131537</td>\n",
       "      <td id=\"T_b81cc_row0_col5\" class=\"data row0 col5\" >0.223243</td>\n",
       "      <td id=\"T_b81cc_row0_col6\" class=\"data row0 col6\" >0.342119</td>\n",
       "      <td id=\"T_b81cc_row0_col7\" class=\"data row0 col7\" >0.268885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b81cc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b81cc_row1_col0\" class=\"data row1 col0\" >109</td>\n",
       "      <td id=\"T_b81cc_row1_col1\" class=\"data row1 col1\" >0.363032</td>\n",
       "      <td id=\"T_b81cc_row1_col2\" class=\"data row1 col2\" >0.250444</td>\n",
       "      <td id=\"T_b81cc_row1_col3\" class=\"data row1 col3\" >0.181530</td>\n",
       "      <td id=\"T_b81cc_row1_col4\" class=\"data row1 col4\" >0.136285</td>\n",
       "      <td id=\"T_b81cc_row1_col5\" class=\"data row1 col5\" >0.221706</td>\n",
       "      <td id=\"T_b81cc_row1_col6\" class=\"data row1 col6\" >0.346920</td>\n",
       "      <td id=\"T_b81cc_row1_col7\" class=\"data row1 col7\" >0.343168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b81cc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b81cc_row2_col0\" class=\"data row2 col0\" >109</td>\n",
       "      <td id=\"T_b81cc_row2_col1\" class=\"data row2 col1\" >0.363032</td>\n",
       "      <td id=\"T_b81cc_row2_col2\" class=\"data row2 col2\" >0.250444</td>\n",
       "      <td id=\"T_b81cc_row2_col3\" class=\"data row2 col3\" >0.181530</td>\n",
       "      <td id=\"T_b81cc_row2_col4\" class=\"data row2 col4\" >0.136285</td>\n",
       "      <td id=\"T_b81cc_row2_col5\" class=\"data row2 col5\" >0.221706</td>\n",
       "      <td id=\"T_b81cc_row2_col6\" class=\"data row2 col6\" >0.346920</td>\n",
       "      <td id=\"T_b81cc_row2_col7\" class=\"data row2 col7\" >0.343168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b81cc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b81cc_row3_col0\" class=\"data row3 col0\" >109</td>\n",
       "      <td id=\"T_b81cc_row3_col1\" class=\"data row3 col1\" >0.363032</td>\n",
       "      <td id=\"T_b81cc_row3_col2\" class=\"data row3 col2\" >0.250444</td>\n",
       "      <td id=\"T_b81cc_row3_col3\" class=\"data row3 col3\" >0.181530</td>\n",
       "      <td id=\"T_b81cc_row3_col4\" class=\"data row3 col4\" >0.136285</td>\n",
       "      <td id=\"T_b81cc_row3_col5\" class=\"data row3 col5\" >0.221706</td>\n",
       "      <td id=\"T_b81cc_row3_col6\" class=\"data row3 col6\" >0.346920</td>\n",
       "      <td id=\"T_b81cc_row3_col7\" class=\"data row3 col7\" >0.343168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b81cc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b81cc_row4_col0\" class=\"data row4 col0\" >106</td>\n",
       "      <td id=\"T_b81cc_row4_col1\" class=\"data row4 col1\" >0.357598</td>\n",
       "      <td id=\"T_b81cc_row4_col2\" class=\"data row4 col2\" >0.245796</td>\n",
       "      <td id=\"T_b81cc_row4_col3\" class=\"data row4 col3\" >0.178253</td>\n",
       "      <td id=\"T_b81cc_row4_col4\" class=\"data row4 col4\" >0.133994</td>\n",
       "      <td id=\"T_b81cc_row4_col5\" class=\"data row4 col5\" >0.226456</td>\n",
       "      <td id=\"T_b81cc_row4_col6\" class=\"data row4 col6\" >0.347640</td>\n",
       "      <td id=\"T_b81cc_row4_col7\" class=\"data row4 col7\" >0.358066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b81cc_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b81cc_row5_col0\" class=\"data row5 col0\" >24</td>\n",
       "      <td id=\"T_b81cc_row5_col1\" class=\"data row5 col1\" >0.313936</td>\n",
       "      <td id=\"T_b81cc_row5_col2\" class=\"data row5 col2\" >0.228304</td>\n",
       "      <td id=\"T_b81cc_row5_col3\" class=\"data row5 col3\" >0.172073</td>\n",
       "      <td id=\"T_b81cc_row5_col4\" class=\"data row5 col4\" >0.132914</td>\n",
       "      <td id=\"T_b81cc_row5_col5\" class=\"data row5 col5\" >0.220390</td>\n",
       "      <td id=\"T_b81cc_row5_col6\" class=\"data row5 col6\" >0.357755</td>\n",
       "      <td id=\"T_b81cc_row5_col7\" class=\"data row5 col7\" >0.297641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b81cc_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b81cc_row6_col0\" class=\"data row6 col0\" >138</td>\n",
       "      <td id=\"T_b81cc_row6_col1\" class=\"data row6 col1\" >0.350222</td>\n",
       "      <td id=\"T_b81cc_row6_col2\" class=\"data row6 col2\" >0.239237</td>\n",
       "      <td id=\"T_b81cc_row6_col3\" class=\"data row6 col3\" >0.172101</td>\n",
       "      <td id=\"T_b81cc_row6_col4\" class=\"data row6 col4\" >0.128941</td>\n",
       "      <td id=\"T_b81cc_row6_col5\" class=\"data row6 col5\" >0.222392</td>\n",
       "      <td id=\"T_b81cc_row6_col6\" class=\"data row6 col6\" >0.345456</td>\n",
       "      <td id=\"T_b81cc_row6_col7\" class=\"data row6 col7\" >0.367672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f64b9776f90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## x_transformer+_ca30BiP_512_dense_x2_CheXpert_fc_dropout_schedule/+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca30BiP_512_dense_x2_CheXpert_fc_dropout_schedule/'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6c462_row0_col0, #T_6c462_row0_col1, #T_6c462_row0_col2, #T_6c462_row0_col5, #T_6c462_row1_col0, #T_6c462_row1_col1, #T_6c462_row1_col2, #T_6c462_row1_col5, #T_6c462_row2_col3, #T_6c462_row2_col4, #T_6c462_row3_col3, #T_6c462_row3_col4, #T_6c462_row4_col0, #T_6c462_row4_col1, #T_6c462_row4_col2, #T_6c462_row4_col5, #T_6c462_row5_col6, #T_6c462_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6c462_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6c462_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6c462_row0_col0\" class=\"data row0 col0\" >388</td>\n",
       "      <td id=\"T_6c462_row0_col1\" class=\"data row0 col1\" >0.380711</td>\n",
       "      <td id=\"T_6c462_row0_col2\" class=\"data row0 col2\" >0.241849</td>\n",
       "      <td id=\"T_6c462_row0_col3\" class=\"data row0 col3\" >0.164074</td>\n",
       "      <td id=\"T_6c462_row0_col4\" class=\"data row0 col4\" >0.114771</td>\n",
       "      <td id=\"T_6c462_row0_col5\" class=\"data row0 col5\" >0.225231</td>\n",
       "      <td id=\"T_6c462_row0_col6\" class=\"data row0 col6\" >0.307912</td>\n",
       "      <td id=\"T_6c462_row0_col7\" class=\"data row0 col7\" >0.147974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c462_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6c462_row1_col0\" class=\"data row1 col0\" >388</td>\n",
       "      <td id=\"T_6c462_row1_col1\" class=\"data row1 col1\" >0.380711</td>\n",
       "      <td id=\"T_6c462_row1_col2\" class=\"data row1 col2\" >0.241849</td>\n",
       "      <td id=\"T_6c462_row1_col3\" class=\"data row1 col3\" >0.164074</td>\n",
       "      <td id=\"T_6c462_row1_col4\" class=\"data row1 col4\" >0.114771</td>\n",
       "      <td id=\"T_6c462_row1_col5\" class=\"data row1 col5\" >0.225231</td>\n",
       "      <td id=\"T_6c462_row1_col6\" class=\"data row1 col6\" >0.307912</td>\n",
       "      <td id=\"T_6c462_row1_col7\" class=\"data row1 col7\" >0.147974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c462_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6c462_row2_col0\" class=\"data row2 col0\" >24</td>\n",
       "      <td id=\"T_6c462_row2_col1\" class=\"data row2 col1\" >0.330440</td>\n",
       "      <td id=\"T_6c462_row2_col2\" class=\"data row2 col2\" >0.234749</td>\n",
       "      <td id=\"T_6c462_row2_col3\" class=\"data row2 col3\" >0.175902</td>\n",
       "      <td id=\"T_6c462_row2_col4\" class=\"data row2 col4\" >0.135251</td>\n",
       "      <td id=\"T_6c462_row2_col5\" class=\"data row2 col5\" >0.218037</td>\n",
       "      <td id=\"T_6c462_row2_col6\" class=\"data row2 col6\" >0.351760</td>\n",
       "      <td id=\"T_6c462_row2_col7\" class=\"data row2 col7\" >0.330815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c462_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6c462_row3_col0\" class=\"data row3 col0\" >24</td>\n",
       "      <td id=\"T_6c462_row3_col1\" class=\"data row3 col1\" >0.330440</td>\n",
       "      <td id=\"T_6c462_row3_col2\" class=\"data row3 col2\" >0.234749</td>\n",
       "      <td id=\"T_6c462_row3_col3\" class=\"data row3 col3\" >0.175902</td>\n",
       "      <td id=\"T_6c462_row3_col4\" class=\"data row3 col4\" >0.135251</td>\n",
       "      <td id=\"T_6c462_row3_col5\" class=\"data row3 col5\" >0.218037</td>\n",
       "      <td id=\"T_6c462_row3_col6\" class=\"data row3 col6\" >0.351760</td>\n",
       "      <td id=\"T_6c462_row3_col7\" class=\"data row3 col7\" >0.330815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c462_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6c462_row4_col0\" class=\"data row4 col0\" >388</td>\n",
       "      <td id=\"T_6c462_row4_col1\" class=\"data row4 col1\" >0.380711</td>\n",
       "      <td id=\"T_6c462_row4_col2\" class=\"data row4 col2\" >0.241849</td>\n",
       "      <td id=\"T_6c462_row4_col3\" class=\"data row4 col3\" >0.164074</td>\n",
       "      <td id=\"T_6c462_row4_col4\" class=\"data row4 col4\" >0.114771</td>\n",
       "      <td id=\"T_6c462_row4_col5\" class=\"data row4 col5\" >0.225231</td>\n",
       "      <td id=\"T_6c462_row4_col6\" class=\"data row4 col6\" >0.307912</td>\n",
       "      <td id=\"T_6c462_row4_col7\" class=\"data row4 col7\" >0.147974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c462_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6c462_row5_col0\" class=\"data row5 col0\" >69</td>\n",
       "      <td id=\"T_6c462_row5_col1\" class=\"data row5 col1\" >0.318462</td>\n",
       "      <td id=\"T_6c462_row5_col2\" class=\"data row5 col2\" >0.223557</td>\n",
       "      <td id=\"T_6c462_row5_col3\" class=\"data row5 col3\" >0.164635</td>\n",
       "      <td id=\"T_6c462_row5_col4\" class=\"data row5 col4\" >0.125671</td>\n",
       "      <td id=\"T_6c462_row5_col5\" class=\"data row5 col5\" >0.214454</td>\n",
       "      <td id=\"T_6c462_row5_col6\" class=\"data row5 col6\" >0.352472</td>\n",
       "      <td id=\"T_6c462_row5_col7\" class=\"data row5 col7\" >0.342698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c462_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6c462_row6_col0\" class=\"data row6 col0\" >100</td>\n",
       "      <td id=\"T_6c462_row6_col1\" class=\"data row6 col1\" >0.343950</td>\n",
       "      <td id=\"T_6c462_row6_col2\" class=\"data row6 col2\" >0.229614</td>\n",
       "      <td id=\"T_6c462_row6_col3\" class=\"data row6 col3\" >0.161468</td>\n",
       "      <td id=\"T_6c462_row6_col4\" class=\"data row6 col4\" >0.118733</td>\n",
       "      <td id=\"T_6c462_row6_col5\" class=\"data row6 col5\" >0.217608</td>\n",
       "      <td id=\"T_6c462_row6_col6\" class=\"data row6 col6\" >0.340185</td>\n",
       "      <td id=\"T_6c462_row6_col7\" class=\"data row6 col7\" >0.342700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f822365fc10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## x_transformer+_ca30_512_dense_x2_CheXpert_fc_dropout_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca30_512_dense_x2_CheXpert_fc_dropout_schedule/'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_92a1a_row0_col0, #T_92a1a_row0_col1, #T_92a1a_row0_col2, #T_92a1a_row0_col3, #T_92a1a_row0_col5, #T_92a1a_row1_col0, #T_92a1a_row1_col1, #T_92a1a_row1_col2, #T_92a1a_row1_col3, #T_92a1a_row1_col5, #T_92a1a_row2_col0, #T_92a1a_row2_col1, #T_92a1a_row2_col2, #T_92a1a_row2_col3, #T_92a1a_row2_col5, #T_92a1a_row3_col4, #T_92a1a_row3_col7, #T_92a1a_row4_col0, #T_92a1a_row4_col1, #T_92a1a_row4_col2, #T_92a1a_row4_col3, #T_92a1a_row4_col5, #T_92a1a_row5_col6, #T_92a1a_row6_col4, #T_92a1a_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_92a1a_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_92a1a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_92a1a_row0_col0\" class=\"data row0 col0\" >169</td>\n",
       "      <td id=\"T_92a1a_row0_col1\" class=\"data row0 col1\" >0.379745</td>\n",
       "      <td id=\"T_92a1a_row0_col2\" class=\"data row0 col2\" >0.261974</td>\n",
       "      <td id=\"T_92a1a_row0_col3\" class=\"data row0 col3\" >0.190057</td>\n",
       "      <td id=\"T_92a1a_row0_col4\" class=\"data row0 col4\" >0.143036</td>\n",
       "      <td id=\"T_92a1a_row0_col5\" class=\"data row0 col5\" >0.230126</td>\n",
       "      <td id=\"T_92a1a_row0_col6\" class=\"data row0 col6\" >0.347358</td>\n",
       "      <td id=\"T_92a1a_row0_col7\" class=\"data row0 col7\" >0.383468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92a1a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_92a1a_row1_col0\" class=\"data row1 col0\" >169</td>\n",
       "      <td id=\"T_92a1a_row1_col1\" class=\"data row1 col1\" >0.379745</td>\n",
       "      <td id=\"T_92a1a_row1_col2\" class=\"data row1 col2\" >0.261974</td>\n",
       "      <td id=\"T_92a1a_row1_col3\" class=\"data row1 col3\" >0.190057</td>\n",
       "      <td id=\"T_92a1a_row1_col4\" class=\"data row1 col4\" >0.143036</td>\n",
       "      <td id=\"T_92a1a_row1_col5\" class=\"data row1 col5\" >0.230126</td>\n",
       "      <td id=\"T_92a1a_row1_col6\" class=\"data row1 col6\" >0.347358</td>\n",
       "      <td id=\"T_92a1a_row1_col7\" class=\"data row1 col7\" >0.383468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92a1a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_92a1a_row2_col0\" class=\"data row2 col0\" >169</td>\n",
       "      <td id=\"T_92a1a_row2_col1\" class=\"data row2 col1\" >0.379745</td>\n",
       "      <td id=\"T_92a1a_row2_col2\" class=\"data row2 col2\" >0.261974</td>\n",
       "      <td id=\"T_92a1a_row2_col3\" class=\"data row2 col3\" >0.190057</td>\n",
       "      <td id=\"T_92a1a_row2_col4\" class=\"data row2 col4\" >0.143036</td>\n",
       "      <td id=\"T_92a1a_row2_col5\" class=\"data row2 col5\" >0.230126</td>\n",
       "      <td id=\"T_92a1a_row2_col6\" class=\"data row2 col6\" >0.347358</td>\n",
       "      <td id=\"T_92a1a_row2_col7\" class=\"data row2 col7\" >0.383468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92a1a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_92a1a_row3_col0\" class=\"data row3 col0\" >167</td>\n",
       "      <td id=\"T_92a1a_row3_col1\" class=\"data row3 col1\" >0.363466</td>\n",
       "      <td id=\"T_92a1a_row3_col2\" class=\"data row3 col2\" >0.255381</td>\n",
       "      <td id=\"T_92a1a_row3_col3\" class=\"data row3 col3\" >0.187278</td>\n",
       "      <td id=\"T_92a1a_row3_col4\" class=\"data row3 col4\" >0.143328</td>\n",
       "      <td id=\"T_92a1a_row3_col5\" class=\"data row3 col5\" >0.226238</td>\n",
       "      <td id=\"T_92a1a_row3_col6\" class=\"data row3 col6\" >0.351060</td>\n",
       "      <td id=\"T_92a1a_row3_col7\" class=\"data row3 col7\" >0.427266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92a1a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_92a1a_row4_col0\" class=\"data row4 col0\" >169</td>\n",
       "      <td id=\"T_92a1a_row4_col1\" class=\"data row4 col1\" >0.379745</td>\n",
       "      <td id=\"T_92a1a_row4_col2\" class=\"data row4 col2\" >0.261974</td>\n",
       "      <td id=\"T_92a1a_row4_col3\" class=\"data row4 col3\" >0.190057</td>\n",
       "      <td id=\"T_92a1a_row4_col4\" class=\"data row4 col4\" >0.143036</td>\n",
       "      <td id=\"T_92a1a_row4_col5\" class=\"data row4 col5\" >0.230126</td>\n",
       "      <td id=\"T_92a1a_row4_col6\" class=\"data row4 col6\" >0.347358</td>\n",
       "      <td id=\"T_92a1a_row4_col7\" class=\"data row4 col7\" >0.383468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92a1a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_92a1a_row5_col0\" class=\"data row5 col0\" >24</td>\n",
       "      <td id=\"T_92a1a_row5_col1\" class=\"data row5 col1\" >0.329043</td>\n",
       "      <td id=\"T_92a1a_row5_col2\" class=\"data row5 col2\" >0.239179</td>\n",
       "      <td id=\"T_92a1a_row5_col3\" class=\"data row5 col3\" >0.179779</td>\n",
       "      <td id=\"T_92a1a_row5_col4\" class=\"data row5 col4\" >0.138005</td>\n",
       "      <td id=\"T_92a1a_row5_col5\" class=\"data row5 col5\" >0.224116</td>\n",
       "      <td id=\"T_92a1a_row5_col6\" class=\"data row5 col6\" >0.366952</td>\n",
       "      <td id=\"T_92a1a_row5_col7\" class=\"data row5 col7\" >0.331240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92a1a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_92a1a_row6_col0\" class=\"data row6 col0\" >167</td>\n",
       "      <td id=\"T_92a1a_row6_col1\" class=\"data row6 col1\" >0.363466</td>\n",
       "      <td id=\"T_92a1a_row6_col2\" class=\"data row6 col2\" >0.255381</td>\n",
       "      <td id=\"T_92a1a_row6_col3\" class=\"data row6 col3\" >0.187278</td>\n",
       "      <td id=\"T_92a1a_row6_col4\" class=\"data row6 col4\" >0.143328</td>\n",
       "      <td id=\"T_92a1a_row6_col5\" class=\"data row6 col5\" >0.226238</td>\n",
       "      <td id=\"T_92a1a_row6_col6\" class=\"data row6 col6\" >0.351060</td>\n",
       "      <td id=\"T_92a1a_row6_col7\" class=\"data row6 col7\" >0.427266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f822365fa10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## x_transformer+_ca10_768_dense_x2_CheXpert_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca10_768_dense_x2_CheXpert_fc/'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7207f_row0_col1, #T_7207f_row1_col2, #T_7207f_row1_col3, #T_7207f_row1_col4, #T_7207f_row1_col5, #T_7207f_row2_col2, #T_7207f_row2_col3, #T_7207f_row2_col4, #T_7207f_row2_col5, #T_7207f_row3_col2, #T_7207f_row3_col3, #T_7207f_row3_col4, #T_7207f_row3_col5, #T_7207f_row4_col2, #T_7207f_row4_col3, #T_7207f_row4_col4, #T_7207f_row4_col5, #T_7207f_row5_col0, #T_7207f_row5_col6, #T_7207f_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7207f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7207f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7207f_row0_col0\" class=\"data row0 col0\" >60</td>\n",
       "      <td id=\"T_7207f_row0_col1\" class=\"data row0 col1\" >0.299345</td>\n",
       "      <td id=\"T_7207f_row0_col2\" class=\"data row0 col2\" >0.206293</td>\n",
       "      <td id=\"T_7207f_row0_col3\" class=\"data row0 col3\" >0.146513</td>\n",
       "      <td id=\"T_7207f_row0_col4\" class=\"data row0 col4\" >0.106663</td>\n",
       "      <td id=\"T_7207f_row0_col5\" class=\"data row0 col5\" >0.201947</td>\n",
       "      <td id=\"T_7207f_row0_col6\" class=\"data row0 col6\" >0.327486</td>\n",
       "      <td id=\"T_7207f_row0_col7\" class=\"data row0 col7\" >0.234511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7207f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7207f_row1_col0\" class=\"data row1 col0\" >25</td>\n",
       "      <td id=\"T_7207f_row1_col1\" class=\"data row1 col1\" >0.298635</td>\n",
       "      <td id=\"T_7207f_row1_col2\" class=\"data row1 col2\" >0.208436</td>\n",
       "      <td id=\"T_7207f_row1_col3\" class=\"data row1 col3\" >0.149314</td>\n",
       "      <td id=\"T_7207f_row1_col4\" class=\"data row1 col4\" >0.109948</td>\n",
       "      <td id=\"T_7207f_row1_col5\" class=\"data row1 col5\" >0.203322</td>\n",
       "      <td id=\"T_7207f_row1_col6\" class=\"data row1 col6\" >0.332357</td>\n",
       "      <td id=\"T_7207f_row1_col7\" class=\"data row1 col7\" >0.264182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7207f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7207f_row2_col0\" class=\"data row2 col0\" >25</td>\n",
       "      <td id=\"T_7207f_row2_col1\" class=\"data row2 col1\" >0.298635</td>\n",
       "      <td id=\"T_7207f_row2_col2\" class=\"data row2 col2\" >0.208436</td>\n",
       "      <td id=\"T_7207f_row2_col3\" class=\"data row2 col3\" >0.149314</td>\n",
       "      <td id=\"T_7207f_row2_col4\" class=\"data row2 col4\" >0.109948</td>\n",
       "      <td id=\"T_7207f_row2_col5\" class=\"data row2 col5\" >0.203322</td>\n",
       "      <td id=\"T_7207f_row2_col6\" class=\"data row2 col6\" >0.332357</td>\n",
       "      <td id=\"T_7207f_row2_col7\" class=\"data row2 col7\" >0.264182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7207f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7207f_row3_col0\" class=\"data row3 col0\" >25</td>\n",
       "      <td id=\"T_7207f_row3_col1\" class=\"data row3 col1\" >0.298635</td>\n",
       "      <td id=\"T_7207f_row3_col2\" class=\"data row3 col2\" >0.208436</td>\n",
       "      <td id=\"T_7207f_row3_col3\" class=\"data row3 col3\" >0.149314</td>\n",
       "      <td id=\"T_7207f_row3_col4\" class=\"data row3 col4\" >0.109948</td>\n",
       "      <td id=\"T_7207f_row3_col5\" class=\"data row3 col5\" >0.203322</td>\n",
       "      <td id=\"T_7207f_row3_col6\" class=\"data row3 col6\" >0.332357</td>\n",
       "      <td id=\"T_7207f_row3_col7\" class=\"data row3 col7\" >0.264182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7207f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7207f_row4_col0\" class=\"data row4 col0\" >25</td>\n",
       "      <td id=\"T_7207f_row4_col1\" class=\"data row4 col1\" >0.298635</td>\n",
       "      <td id=\"T_7207f_row4_col2\" class=\"data row4 col2\" >0.208436</td>\n",
       "      <td id=\"T_7207f_row4_col3\" class=\"data row4 col3\" >0.149314</td>\n",
       "      <td id=\"T_7207f_row4_col4\" class=\"data row4 col4\" >0.109948</td>\n",
       "      <td id=\"T_7207f_row4_col5\" class=\"data row4 col5\" >0.203322</td>\n",
       "      <td id=\"T_7207f_row4_col6\" class=\"data row4 col6\" >0.332357</td>\n",
       "      <td id=\"T_7207f_row4_col7\" class=\"data row4 col7\" >0.264182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7207f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7207f_row5_col0\" class=\"data row5 col0\" >117</td>\n",
       "      <td id=\"T_7207f_row5_col1\" class=\"data row5 col1\" >0.263903</td>\n",
       "      <td id=\"T_7207f_row5_col2\" class=\"data row5 col2\" >0.183362</td>\n",
       "      <td id=\"T_7207f_row5_col3\" class=\"data row5 col3\" >0.133782</td>\n",
       "      <td id=\"T_7207f_row5_col4\" class=\"data row5 col4\" >0.100972</td>\n",
       "      <td id=\"T_7207f_row5_col5\" class=\"data row5 col5\" >0.190379</td>\n",
       "      <td id=\"T_7207f_row5_col6\" class=\"data row5 col6\" >0.334071</td>\n",
       "      <td id=\"T_7207f_row5_col7\" class=\"data row5 col7\" >0.265469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7207f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7207f_row6_col0\" class=\"data row6 col0\" >33</td>\n",
       "      <td id=\"T_7207f_row6_col1\" class=\"data row6 col1\" >0.185478</td>\n",
       "      <td id=\"T_7207f_row6_col2\" class=\"data row6 col2\" >0.126932</td>\n",
       "      <td id=\"T_7207f_row6_col3\" class=\"data row6 col3\" >0.093134</td>\n",
       "      <td id=\"T_7207f_row6_col4\" class=\"data row6 col4\" >0.071823</td>\n",
       "      <td id=\"T_7207f_row6_col5\" class=\"data row6 col5\" >0.166171</td>\n",
       "      <td id=\"T_7207f_row6_col6\" class=\"data row6 col6\" >0.318165</td>\n",
       "      <td id=\"T_7207f_row6_col7\" class=\"data row6 col7\" >0.309278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f821fda8d10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## x_transformer+_ca10BiP_768_dense_x2_Chexpert_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca10BiP_768_dense_x2_Chexpert_fc/'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a0bf5_row0_col1, #T_a0bf5_row0_col5, #T_a0bf5_row1_col0, #T_a0bf5_row1_col2, #T_a0bf5_row2_col3, #T_a0bf5_row2_col4, #T_a0bf5_row3_col3, #T_a0bf5_row3_col4, #T_a0bf5_row4_col1, #T_a0bf5_row4_col5, #T_a0bf5_row5_col6, #T_a0bf5_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a0bf5_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a0bf5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a0bf5_row0_col0\" class=\"data row0 col0\" >45</td>\n",
       "      <td id=\"T_a0bf5_row0_col1\" class=\"data row0 col1\" >0.364816</td>\n",
       "      <td id=\"T_a0bf5_row0_col2\" class=\"data row0 col2\" >0.246327</td>\n",
       "      <td id=\"T_a0bf5_row0_col3\" class=\"data row0 col3\" >0.173274</td>\n",
       "      <td id=\"T_a0bf5_row0_col4\" class=\"data row0 col4\" >0.125569</td>\n",
       "      <td id=\"T_a0bf5_row0_col5\" class=\"data row0 col5\" >0.227719</td>\n",
       "      <td id=\"T_a0bf5_row0_col6\" class=\"data row0 col6\" >0.341502</td>\n",
       "      <td id=\"T_a0bf5_row0_col7\" class=\"data row0 col7\" >0.273409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0bf5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a0bf5_row1_col0\" class=\"data row1 col0\" >112</td>\n",
       "      <td id=\"T_a0bf5_row1_col1\" class=\"data row1 col1\" >0.361328</td>\n",
       "      <td id=\"T_a0bf5_row1_col2\" class=\"data row1 col2\" >0.248206</td>\n",
       "      <td id=\"T_a0bf5_row1_col3\" class=\"data row1 col3\" >0.175298</td>\n",
       "      <td id=\"T_a0bf5_row1_col4\" class=\"data row1 col4\" >0.127373</td>\n",
       "      <td id=\"T_a0bf5_row1_col5\" class=\"data row1 col5\" >0.223365</td>\n",
       "      <td id=\"T_a0bf5_row1_col6\" class=\"data row1 col6\" >0.342713</td>\n",
       "      <td id=\"T_a0bf5_row1_col7\" class=\"data row1 col7\" >0.244963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0bf5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a0bf5_row2_col0\" class=\"data row2 col0\" >41</td>\n",
       "      <td id=\"T_a0bf5_row2_col1\" class=\"data row2 col1\" >0.346005</td>\n",
       "      <td id=\"T_a0bf5_row2_col2\" class=\"data row2 col2\" >0.242184</td>\n",
       "      <td id=\"T_a0bf5_row2_col3\" class=\"data row2 col3\" >0.177997</td>\n",
       "      <td id=\"T_a0bf5_row2_col4\" class=\"data row2 col4\" >0.136441</td>\n",
       "      <td id=\"T_a0bf5_row2_col5\" class=\"data row2 col5\" >0.210943</td>\n",
       "      <td id=\"T_a0bf5_row2_col6\" class=\"data row2 col6\" >0.345650</td>\n",
       "      <td id=\"T_a0bf5_row2_col7\" class=\"data row2 col7\" >0.333017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0bf5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a0bf5_row3_col0\" class=\"data row3 col0\" >41</td>\n",
       "      <td id=\"T_a0bf5_row3_col1\" class=\"data row3 col1\" >0.346005</td>\n",
       "      <td id=\"T_a0bf5_row3_col2\" class=\"data row3 col2\" >0.242184</td>\n",
       "      <td id=\"T_a0bf5_row3_col3\" class=\"data row3 col3\" >0.177997</td>\n",
       "      <td id=\"T_a0bf5_row3_col4\" class=\"data row3 col4\" >0.136441</td>\n",
       "      <td id=\"T_a0bf5_row3_col5\" class=\"data row3 col5\" >0.210943</td>\n",
       "      <td id=\"T_a0bf5_row3_col6\" class=\"data row3 col6\" >0.345650</td>\n",
       "      <td id=\"T_a0bf5_row3_col7\" class=\"data row3 col7\" >0.333017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0bf5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a0bf5_row4_col0\" class=\"data row4 col0\" >45</td>\n",
       "      <td id=\"T_a0bf5_row4_col1\" class=\"data row4 col1\" >0.364816</td>\n",
       "      <td id=\"T_a0bf5_row4_col2\" class=\"data row4 col2\" >0.246327</td>\n",
       "      <td id=\"T_a0bf5_row4_col3\" class=\"data row4 col3\" >0.173274</td>\n",
       "      <td id=\"T_a0bf5_row4_col4\" class=\"data row4 col4\" >0.125569</td>\n",
       "      <td id=\"T_a0bf5_row4_col5\" class=\"data row4 col5\" >0.227719</td>\n",
       "      <td id=\"T_a0bf5_row4_col6\" class=\"data row4 col6\" >0.341502</td>\n",
       "      <td id=\"T_a0bf5_row4_col7\" class=\"data row4 col7\" >0.273409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0bf5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a0bf5_row5_col0\" class=\"data row5 col0\" >24</td>\n",
       "      <td id=\"T_a0bf5_row5_col1\" class=\"data row5 col1\" >0.313614</td>\n",
       "      <td id=\"T_a0bf5_row5_col2\" class=\"data row5 col2\" >0.223871</td>\n",
       "      <td id=\"T_a0bf5_row5_col3\" class=\"data row5 col3\" >0.164426</td>\n",
       "      <td id=\"T_a0bf5_row5_col4\" class=\"data row5 col4\" >0.124317</td>\n",
       "      <td id=\"T_a0bf5_row5_col5\" class=\"data row5 col5\" >0.216897</td>\n",
       "      <td id=\"T_a0bf5_row5_col6\" class=\"data row5 col6\" >0.355243</td>\n",
       "      <td id=\"T_a0bf5_row5_col7\" class=\"data row5 col7\" >0.267273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0bf5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a0bf5_row6_col0\" class=\"data row6 col0\" >50</td>\n",
       "      <td id=\"T_a0bf5_row6_col1\" class=\"data row6 col1\" >0.346635</td>\n",
       "      <td id=\"T_a0bf5_row6_col2\" class=\"data row6 col2\" >0.241936</td>\n",
       "      <td id=\"T_a0bf5_row6_col3\" class=\"data row6 col3\" >0.177494</td>\n",
       "      <td id=\"T_a0bf5_row6_col4\" class=\"data row6 col4\" >0.135414</td>\n",
       "      <td id=\"T_a0bf5_row6_col5\" class=\"data row6 col5\" >0.223639</td>\n",
       "      <td id=\"T_a0bf5_row6_col6\" class=\"data row6 col6\" >0.355195</td>\n",
       "      <td id=\"T_a0bf5_row6_col7\" class=\"data row6 col7\" >0.393643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8297b0d490>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## x_transformer+_random_768_dense_x2_CheXpert_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_random_768_dense_x2_CheXpert_fc/'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_40f33_row0_col1, #T_40f33_row0_col2, #T_40f33_row0_col5, #T_40f33_row1_col1, #T_40f33_row1_col2, #T_40f33_row1_col5, #T_40f33_row2_col3, #T_40f33_row3_col4, #T_40f33_row4_col1, #T_40f33_row4_col2, #T_40f33_row4_col5, #T_40f33_row5_col6, #T_40f33_row6_col0, #T_40f33_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_40f33_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_40f33_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_40f33_row0_col0\" class=\"data row0 col0\" >325</td>\n",
       "      <td id=\"T_40f33_row0_col1\" class=\"data row0 col1\" >0.370663</td>\n",
       "      <td id=\"T_40f33_row0_col2\" class=\"data row0 col2\" >0.254142</td>\n",
       "      <td id=\"T_40f33_row0_col3\" class=\"data row0 col3\" >0.180322</td>\n",
       "      <td id=\"T_40f33_row0_col4\" class=\"data row0 col4\" >0.131034</td>\n",
       "      <td id=\"T_40f33_row0_col5\" class=\"data row0 col5\" >0.225965</td>\n",
       "      <td id=\"T_40f33_row0_col6\" class=\"data row0 col6\" >0.335531</td>\n",
       "      <td id=\"T_40f33_row0_col7\" class=\"data row0 col7\" >0.255504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f33_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_40f33_row1_col0\" class=\"data row1 col0\" >325</td>\n",
       "      <td id=\"T_40f33_row1_col1\" class=\"data row1 col1\" >0.370663</td>\n",
       "      <td id=\"T_40f33_row1_col2\" class=\"data row1 col2\" >0.254142</td>\n",
       "      <td id=\"T_40f33_row1_col3\" class=\"data row1 col3\" >0.180322</td>\n",
       "      <td id=\"T_40f33_row1_col4\" class=\"data row1 col4\" >0.131034</td>\n",
       "      <td id=\"T_40f33_row1_col5\" class=\"data row1 col5\" >0.225965</td>\n",
       "      <td id=\"T_40f33_row1_col6\" class=\"data row1 col6\" >0.335531</td>\n",
       "      <td id=\"T_40f33_row1_col7\" class=\"data row1 col7\" >0.255504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f33_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_40f33_row2_col0\" class=\"data row2 col0\" >304</td>\n",
       "      <td id=\"T_40f33_row2_col1\" class=\"data row2 col1\" >0.367644</td>\n",
       "      <td id=\"T_40f33_row2_col2\" class=\"data row2 col2\" >0.253131</td>\n",
       "      <td id=\"T_40f33_row2_col3\" class=\"data row2 col3\" >0.180829</td>\n",
       "      <td id=\"T_40f33_row2_col4\" class=\"data row2 col4\" >0.133003</td>\n",
       "      <td id=\"T_40f33_row2_col5\" class=\"data row2 col5\" >0.222174</td>\n",
       "      <td id=\"T_40f33_row2_col6\" class=\"data row2 col6\" >0.338156</td>\n",
       "      <td id=\"T_40f33_row2_col7\" class=\"data row2 col7\" >0.301323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f33_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_40f33_row3_col0\" class=\"data row3 col0\" >206</td>\n",
       "      <td id=\"T_40f33_row3_col1\" class=\"data row3 col1\" >0.354527</td>\n",
       "      <td id=\"T_40f33_row3_col2\" class=\"data row3 col2\" >0.247621</td>\n",
       "      <td id=\"T_40f33_row3_col3\" class=\"data row3 col3\" >0.180051</td>\n",
       "      <td id=\"T_40f33_row3_col4\" class=\"data row3 col4\" >0.135577</td>\n",
       "      <td id=\"T_40f33_row3_col5\" class=\"data row3 col5\" >0.222982</td>\n",
       "      <td id=\"T_40f33_row3_col6\" class=\"data row3 col6\" >0.349056</td>\n",
       "      <td id=\"T_40f33_row3_col7\" class=\"data row3 col7\" >0.344732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f33_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_40f33_row4_col0\" class=\"data row4 col0\" >325</td>\n",
       "      <td id=\"T_40f33_row4_col1\" class=\"data row4 col1\" >0.370663</td>\n",
       "      <td id=\"T_40f33_row4_col2\" class=\"data row4 col2\" >0.254142</td>\n",
       "      <td id=\"T_40f33_row4_col3\" class=\"data row4 col3\" >0.180322</td>\n",
       "      <td id=\"T_40f33_row4_col4\" class=\"data row4 col4\" >0.131034</td>\n",
       "      <td id=\"T_40f33_row4_col5\" class=\"data row4 col5\" >0.225965</td>\n",
       "      <td id=\"T_40f33_row4_col6\" class=\"data row4 col6\" >0.335531</td>\n",
       "      <td id=\"T_40f33_row4_col7\" class=\"data row4 col7\" >0.255504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f33_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_40f33_row5_col0\" class=\"data row5 col0\" >148</td>\n",
       "      <td id=\"T_40f33_row5_col1\" class=\"data row5 col1\" >0.336748</td>\n",
       "      <td id=\"T_40f33_row5_col2\" class=\"data row5 col2\" >0.235236</td>\n",
       "      <td id=\"T_40f33_row5_col3\" class=\"data row5 col3\" >0.171130</td>\n",
       "      <td id=\"T_40f33_row5_col4\" class=\"data row5 col4\" >0.128178</td>\n",
       "      <td id=\"T_40f33_row5_col5\" class=\"data row5 col5\" >0.217470</td>\n",
       "      <td id=\"T_40f33_row5_col6\" class=\"data row5 col6\" >0.349165</td>\n",
       "      <td id=\"T_40f33_row5_col7\" class=\"data row5 col7\" >0.347079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f33_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_40f33_row6_col0\" class=\"data row6 col0\" >366</td>\n",
       "      <td id=\"T_40f33_row6_col1\" class=\"data row6 col1\" >0.343732</td>\n",
       "      <td id=\"T_40f33_row6_col2\" class=\"data row6 col2\" >0.241335</td>\n",
       "      <td id=\"T_40f33_row6_col3\" class=\"data row6 col3\" >0.176282</td>\n",
       "      <td id=\"T_40f33_row6_col4\" class=\"data row6 col4\" >0.132676</td>\n",
       "      <td id=\"T_40f33_row6_col5\" class=\"data row6 col5\" >0.218380</td>\n",
       "      <td id=\"T_40f33_row6_col6\" class=\"data row6 col6\" >0.347697</td>\n",
       "      <td id=\"T_40f33_row6_col7\" class=\"data row6 col7\" >0.397143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8220899c90>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b0929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## x_transformer+_ca30_512_dense_x2_CheXpert_fc_dropout_schedule_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca30_512_dense_x2_CheXpert_fc_dropout_schedule_concat/'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e0977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f37c2_row0_col1, #T_f37c2_row0_col2, #T_f37c2_row0_col3, #T_f37c2_row0_col5, #T_f37c2_row1_col1, #T_f37c2_row1_col2, #T_f37c2_row1_col3, #T_f37c2_row1_col5, #T_f37c2_row2_col1, #T_f37c2_row2_col2, #T_f37c2_row2_col3, #T_f37c2_row2_col5, #T_f37c2_row3_col4, #T_f37c2_row3_col6, #T_f37c2_row4_col1, #T_f37c2_row4_col2, #T_f37c2_row4_col3, #T_f37c2_row4_col5, #T_f37c2_row5_col4, #T_f37c2_row5_col6, #T_f37c2_row6_col0, #T_f37c2_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f37c2_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f37c2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f37c2_row0_col0\" class=\"data row0 col0\" >106</td>\n",
       "      <td id=\"T_f37c2_row0_col1\" class=\"data row0 col1\" >0.392538</td>\n",
       "      <td id=\"T_f37c2_row0_col2\" class=\"data row0 col2\" >0.271221</td>\n",
       "      <td id=\"T_f37c2_row0_col3\" class=\"data row0 col3\" >0.196499</td>\n",
       "      <td id=\"T_f37c2_row0_col4\" class=\"data row0 col4\" >0.147485</td>\n",
       "      <td id=\"T_f37c2_row0_col5\" class=\"data row0 col5\" >0.234646</td>\n",
       "      <td id=\"T_f37c2_row0_col6\" class=\"data row0 col6\" >0.350003</td>\n",
       "      <td id=\"T_f37c2_row0_col7\" class=\"data row0 col7\" >0.369026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f37c2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f37c2_row1_col0\" class=\"data row1 col0\" >106</td>\n",
       "      <td id=\"T_f37c2_row1_col1\" class=\"data row1 col1\" >0.392538</td>\n",
       "      <td id=\"T_f37c2_row1_col2\" class=\"data row1 col2\" >0.271221</td>\n",
       "      <td id=\"T_f37c2_row1_col3\" class=\"data row1 col3\" >0.196499</td>\n",
       "      <td id=\"T_f37c2_row1_col4\" class=\"data row1 col4\" >0.147485</td>\n",
       "      <td id=\"T_f37c2_row1_col5\" class=\"data row1 col5\" >0.234646</td>\n",
       "      <td id=\"T_f37c2_row1_col6\" class=\"data row1 col6\" >0.350003</td>\n",
       "      <td id=\"T_f37c2_row1_col7\" class=\"data row1 col7\" >0.369026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f37c2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f37c2_row2_col0\" class=\"data row2 col0\" >106</td>\n",
       "      <td id=\"T_f37c2_row2_col1\" class=\"data row2 col1\" >0.392538</td>\n",
       "      <td id=\"T_f37c2_row2_col2\" class=\"data row2 col2\" >0.271221</td>\n",
       "      <td id=\"T_f37c2_row2_col3\" class=\"data row2 col3\" >0.196499</td>\n",
       "      <td id=\"T_f37c2_row2_col4\" class=\"data row2 col4\" >0.147485</td>\n",
       "      <td id=\"T_f37c2_row2_col5\" class=\"data row2 col5\" >0.234646</td>\n",
       "      <td id=\"T_f37c2_row2_col6\" class=\"data row2 col6\" >0.350003</td>\n",
       "      <td id=\"T_f37c2_row2_col7\" class=\"data row2 col7\" >0.369026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f37c2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f37c2_row3_col0\" class=\"data row3 col0\" >24</td>\n",
       "      <td id=\"T_f37c2_row3_col1\" class=\"data row3 col1\" >0.360923</td>\n",
       "      <td id=\"T_f37c2_row3_col2\" class=\"data row3 col2\" >0.258474</td>\n",
       "      <td id=\"T_f37c2_row3_col3\" class=\"data row3 col3\" >0.193326</td>\n",
       "      <td id=\"T_f37c2_row3_col4\" class=\"data row3 col4\" >0.148531</td>\n",
       "      <td id=\"T_f37c2_row3_col5\" class=\"data row3 col5\" >0.230451</td>\n",
       "      <td id=\"T_f37c2_row3_col6\" class=\"data row3 col6\" >0.369010</td>\n",
       "      <td id=\"T_f37c2_row3_col7\" class=\"data row3 col7\" >0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f37c2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f37c2_row4_col0\" class=\"data row4 col0\" >106</td>\n",
       "      <td id=\"T_f37c2_row4_col1\" class=\"data row4 col1\" >0.392538</td>\n",
       "      <td id=\"T_f37c2_row4_col2\" class=\"data row4 col2\" >0.271221</td>\n",
       "      <td id=\"T_f37c2_row4_col3\" class=\"data row4 col3\" >0.196499</td>\n",
       "      <td id=\"T_f37c2_row4_col4\" class=\"data row4 col4\" >0.147485</td>\n",
       "      <td id=\"T_f37c2_row4_col5\" class=\"data row4 col5\" >0.234646</td>\n",
       "      <td id=\"T_f37c2_row4_col6\" class=\"data row4 col6\" >0.350003</td>\n",
       "      <td id=\"T_f37c2_row4_col7\" class=\"data row4 col7\" >0.369026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f37c2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f37c2_row5_col0\" class=\"data row5 col0\" >24</td>\n",
       "      <td id=\"T_f37c2_row5_col1\" class=\"data row5 col1\" >0.360923</td>\n",
       "      <td id=\"T_f37c2_row5_col2\" class=\"data row5 col2\" >0.258474</td>\n",
       "      <td id=\"T_f37c2_row5_col3\" class=\"data row5 col3\" >0.193326</td>\n",
       "      <td id=\"T_f37c2_row5_col4\" class=\"data row5 col4\" >0.148531</td>\n",
       "      <td id=\"T_f37c2_row5_col5\" class=\"data row5 col5\" >0.230451</td>\n",
       "      <td id=\"T_f37c2_row5_col6\" class=\"data row5 col6\" >0.369010</td>\n",
       "      <td id=\"T_f37c2_row5_col7\" class=\"data row5 col7\" >0.331680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f37c2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f37c2_row6_col0\" class=\"data row6 col0\" >155</td>\n",
       "      <td id=\"T_f37c2_row6_col1\" class=\"data row6 col1\" >0.341331</td>\n",
       "      <td id=\"T_f37c2_row6_col2\" class=\"data row6 col2\" >0.230019</td>\n",
       "      <td id=\"T_f37c2_row6_col3\" class=\"data row6 col3\" >0.167435</td>\n",
       "      <td id=\"T_f37c2_row6_col4\" class=\"data row6 col4\" >0.128559</td>\n",
       "      <td id=\"T_f37c2_row6_col5\" class=\"data row6 col5\" >0.221127</td>\n",
       "      <td id=\"T_f37c2_row6_col6\" class=\"data row6 col6\" >0.338896</td>\n",
       "      <td id=\"T_f37c2_row6_col7\" class=\"data row6 col7\" >0.445863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8d56589210>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745395",
   "metadata": {},
   "source": [
    "## x_transformer+_ca50_512_dense_x2_CheXpert_fc_dropout_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/x_transformer+_ca50_512_dense_x2_CheXpert_fc_dropout_schedule/'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_124bc_row0_col0, #T_124bc_row0_col1, #T_124bc_row1_col2, #T_124bc_row2_col3, #T_124bc_row2_col4, #T_124bc_row2_col5, #T_124bc_row3_col3, #T_124bc_row3_col4, #T_124bc_row3_col5, #T_124bc_row4_col3, #T_124bc_row4_col4, #T_124bc_row4_col5, #T_124bc_row5_col6, #T_124bc_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_124bc_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_124bc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_124bc_row0_col0\" class=\"data row0 col0\" >273</td>\n",
       "      <td id=\"T_124bc_row0_col1\" class=\"data row0 col1\" >0.383505</td>\n",
       "      <td id=\"T_124bc_row0_col2\" class=\"data row0 col2\" >0.243192</td>\n",
       "      <td id=\"T_124bc_row0_col3\" class=\"data row0 col3\" >0.163935</td>\n",
       "      <td id=\"T_124bc_row0_col4\" class=\"data row0 col4\" >0.114503</td>\n",
       "      <td id=\"T_124bc_row0_col5\" class=\"data row0 col5\" >0.219716</td>\n",
       "      <td id=\"T_124bc_row0_col6\" class=\"data row0 col6\" >0.304645</td>\n",
       "      <td id=\"T_124bc_row0_col7\" class=\"data row0 col7\" >0.197786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_124bc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_124bc_row1_col0\" class=\"data row1 col0\" >73</td>\n",
       "      <td id=\"T_124bc_row1_col1\" class=\"data row1 col1\" >0.370044</td>\n",
       "      <td id=\"T_124bc_row1_col2\" class=\"data row1 col2\" >0.254802</td>\n",
       "      <td id=\"T_124bc_row1_col3\" class=\"data row1 col3\" >0.182976</td>\n",
       "      <td id=\"T_124bc_row1_col4\" class=\"data row1 col4\" >0.135586</td>\n",
       "      <td id=\"T_124bc_row1_col5\" class=\"data row1 col5\" >0.215295</td>\n",
       "      <td id=\"T_124bc_row1_col6\" class=\"data row1 col6\" >0.337221</td>\n",
       "      <td id=\"T_124bc_row1_col7\" class=\"data row1 col7\" >0.227114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_124bc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_124bc_row2_col0\" class=\"data row2 col0\" >36</td>\n",
       "      <td id=\"T_124bc_row2_col1\" class=\"data row2 col1\" >0.353092</td>\n",
       "      <td id=\"T_124bc_row2_col2\" class=\"data row2 col2\" >0.251520</td>\n",
       "      <td id=\"T_124bc_row2_col3\" class=\"data row2 col3\" >0.184381</td>\n",
       "      <td id=\"T_124bc_row2_col4\" class=\"data row2 col4\" >0.138948</td>\n",
       "      <td id=\"T_124bc_row2_col5\" class=\"data row2 col5\" >0.225200</td>\n",
       "      <td id=\"T_124bc_row2_col6\" class=\"data row2 col6\" >0.354407</td>\n",
       "      <td id=\"T_124bc_row2_col7\" class=\"data row2 col7\" >0.257398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_124bc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_124bc_row3_col0\" class=\"data row3 col0\" >36</td>\n",
       "      <td id=\"T_124bc_row3_col1\" class=\"data row3 col1\" >0.353092</td>\n",
       "      <td id=\"T_124bc_row3_col2\" class=\"data row3 col2\" >0.251520</td>\n",
       "      <td id=\"T_124bc_row3_col3\" class=\"data row3 col3\" >0.184381</td>\n",
       "      <td id=\"T_124bc_row3_col4\" class=\"data row3 col4\" >0.138948</td>\n",
       "      <td id=\"T_124bc_row3_col5\" class=\"data row3 col5\" >0.225200</td>\n",
       "      <td id=\"T_124bc_row3_col6\" class=\"data row3 col6\" >0.354407</td>\n",
       "      <td id=\"T_124bc_row3_col7\" class=\"data row3 col7\" >0.257398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_124bc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_124bc_row4_col0\" class=\"data row4 col0\" >36</td>\n",
       "      <td id=\"T_124bc_row4_col1\" class=\"data row4 col1\" >0.353092</td>\n",
       "      <td id=\"T_124bc_row4_col2\" class=\"data row4 col2\" >0.251520</td>\n",
       "      <td id=\"T_124bc_row4_col3\" class=\"data row4 col3\" >0.184381</td>\n",
       "      <td id=\"T_124bc_row4_col4\" class=\"data row4 col4\" >0.138948</td>\n",
       "      <td id=\"T_124bc_row4_col5\" class=\"data row4 col5\" >0.225200</td>\n",
       "      <td id=\"T_124bc_row4_col6\" class=\"data row4 col6\" >0.354407</td>\n",
       "      <td id=\"T_124bc_row4_col7\" class=\"data row4 col7\" >0.257398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_124bc_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_124bc_row5_col0\" class=\"data row5 col0\" >47</td>\n",
       "      <td id=\"T_124bc_row5_col1\" class=\"data row5 col1\" >0.332531</td>\n",
       "      <td id=\"T_124bc_row5_col2\" class=\"data row5 col2\" >0.234309</td>\n",
       "      <td id=\"T_124bc_row5_col3\" class=\"data row5 col3\" >0.172456</td>\n",
       "      <td id=\"T_124bc_row5_col4\" class=\"data row5 col4\" >0.131865</td>\n",
       "      <td id=\"T_124bc_row5_col5\" class=\"data row5 col5\" >0.217184</td>\n",
       "      <td id=\"T_124bc_row5_col6\" class=\"data row5 col6\" >0.354728</td>\n",
       "      <td id=\"T_124bc_row5_col7\" class=\"data row5 col7\" >0.337589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_124bc_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_124bc_row6_col0\" class=\"data row6 col0\" >83</td>\n",
       "      <td id=\"T_124bc_row6_col1\" class=\"data row6 col1\" >0.347833</td>\n",
       "      <td id=\"T_124bc_row6_col2\" class=\"data row6 col2\" >0.237904</td>\n",
       "      <td id=\"T_124bc_row6_col3\" class=\"data row6 col3\" >0.173802</td>\n",
       "      <td id=\"T_124bc_row6_col4\" class=\"data row6 col4\" >0.133262</td>\n",
       "      <td id=\"T_124bc_row6_col5\" class=\"data row6 col5\" >0.214491</td>\n",
       "      <td id=\"T_124bc_row6_col6\" class=\"data row6 col6\" >0.347400</td>\n",
       "      <td id=\"T_124bc_row6_col7\" class=\"data row6 col7\" >0.342859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8d4f775910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd33a14",
   "metadata": {},
   "source": [
    "# IU DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e0a0b6",
   "metadata": {},
   "source": [
    "## iu_x_transformer+_ca30_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/iu_x_transformer+_ca30_best/'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8c96b_row0_col1, #T_8c96b_row0_col2, #T_8c96b_row0_col3, #T_8c96b_row0_col5, #T_8c96b_row1_col1, #T_8c96b_row1_col2, #T_8c96b_row1_col3, #T_8c96b_row1_col5, #T_8c96b_row2_col1, #T_8c96b_row2_col2, #T_8c96b_row2_col3, #T_8c96b_row2_col5, #T_8c96b_row3_col4, #T_8c96b_row4_col1, #T_8c96b_row4_col2, #T_8c96b_row4_col3, #T_8c96b_row4_col5, #T_8c96b_row5_col6, #T_8c96b_row6_col0, #T_8c96b_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8c96b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8c96b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8c96b_row0_col0\" class=\"data row0 col0\" >8</td>\n",
       "      <td id=\"T_8c96b_row0_col1\" class=\"data row0 col1\" >0.390551</td>\n",
       "      <td id=\"T_8c96b_row0_col2\" class=\"data row0 col2\" >0.259085</td>\n",
       "      <td id=\"T_8c96b_row0_col3\" class=\"data row0 col3\" >0.176304</td>\n",
       "      <td id=\"T_8c96b_row0_col4\" class=\"data row0 col4\" >0.117493</td>\n",
       "      <td id=\"T_8c96b_row0_col5\" class=\"data row0 col5\" >0.189783</td>\n",
       "      <td id=\"T_8c96b_row0_col6\" class=\"data row0 col6\" >0.331742</td>\n",
       "      <td id=\"T_8c96b_row0_col7\" class=\"data row0 col7\" >0.333802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c96b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8c96b_row1_col0\" class=\"data row1 col0\" >8</td>\n",
       "      <td id=\"T_8c96b_row1_col1\" class=\"data row1 col1\" >0.390551</td>\n",
       "      <td id=\"T_8c96b_row1_col2\" class=\"data row1 col2\" >0.259085</td>\n",
       "      <td id=\"T_8c96b_row1_col3\" class=\"data row1 col3\" >0.176304</td>\n",
       "      <td id=\"T_8c96b_row1_col4\" class=\"data row1 col4\" >0.117493</td>\n",
       "      <td id=\"T_8c96b_row1_col5\" class=\"data row1 col5\" >0.189783</td>\n",
       "      <td id=\"T_8c96b_row1_col6\" class=\"data row1 col6\" >0.331742</td>\n",
       "      <td id=\"T_8c96b_row1_col7\" class=\"data row1 col7\" >0.333802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c96b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8c96b_row2_col0\" class=\"data row2 col0\" >8</td>\n",
       "      <td id=\"T_8c96b_row2_col1\" class=\"data row2 col1\" >0.390551</td>\n",
       "      <td id=\"T_8c96b_row2_col2\" class=\"data row2 col2\" >0.259085</td>\n",
       "      <td id=\"T_8c96b_row2_col3\" class=\"data row2 col3\" >0.176304</td>\n",
       "      <td id=\"T_8c96b_row2_col4\" class=\"data row2 col4\" >0.117493</td>\n",
       "      <td id=\"T_8c96b_row2_col5\" class=\"data row2 col5\" >0.189783</td>\n",
       "      <td id=\"T_8c96b_row2_col6\" class=\"data row2 col6\" >0.331742</td>\n",
       "      <td id=\"T_8c96b_row2_col7\" class=\"data row2 col7\" >0.333802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c96b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8c96b_row3_col0\" class=\"data row3 col0\" >11</td>\n",
       "      <td id=\"T_8c96b_row3_col1\" class=\"data row3 col1\" >0.369803</td>\n",
       "      <td id=\"T_8c96b_row3_col2\" class=\"data row3 col2\" >0.240185</td>\n",
       "      <td id=\"T_8c96b_row3_col3\" class=\"data row3 col3\" >0.170599</td>\n",
       "      <td id=\"T_8c96b_row3_col4\" class=\"data row3 col4\" >0.122841</td>\n",
       "      <td id=\"T_8c96b_row3_col5\" class=\"data row3 col5\" >0.188498</td>\n",
       "      <td id=\"T_8c96b_row3_col6\" class=\"data row3 col6\" >0.321275</td>\n",
       "      <td id=\"T_8c96b_row3_col7\" class=\"data row3 col7\" >0.337532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c96b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8c96b_row4_col0\" class=\"data row4 col0\" >8</td>\n",
       "      <td id=\"T_8c96b_row4_col1\" class=\"data row4 col1\" >0.390551</td>\n",
       "      <td id=\"T_8c96b_row4_col2\" class=\"data row4 col2\" >0.259085</td>\n",
       "      <td id=\"T_8c96b_row4_col3\" class=\"data row4 col3\" >0.176304</td>\n",
       "      <td id=\"T_8c96b_row4_col4\" class=\"data row4 col4\" >0.117493</td>\n",
       "      <td id=\"T_8c96b_row4_col5\" class=\"data row4 col5\" >0.189783</td>\n",
       "      <td id=\"T_8c96b_row4_col6\" class=\"data row4 col6\" >0.331742</td>\n",
       "      <td id=\"T_8c96b_row4_col7\" class=\"data row4 col7\" >0.333802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c96b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_8c96b_row5_col0\" class=\"data row5 col0\" >7</td>\n",
       "      <td id=\"T_8c96b_row5_col1\" class=\"data row5 col1\" >0.372116</td>\n",
       "      <td id=\"T_8c96b_row5_col2\" class=\"data row5 col2\" >0.249080</td>\n",
       "      <td id=\"T_8c96b_row5_col3\" class=\"data row5 col3\" >0.172092</td>\n",
       "      <td id=\"T_8c96b_row5_col4\" class=\"data row5 col4\" >0.117585</td>\n",
       "      <td id=\"T_8c96b_row5_col5\" class=\"data row5 col5\" >0.189602</td>\n",
       "      <td id=\"T_8c96b_row5_col6\" class=\"data row5 col6\" >0.338857</td>\n",
       "      <td id=\"T_8c96b_row5_col7\" class=\"data row5 col7\" >0.324915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c96b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_8c96b_row6_col0\" class=\"data row6 col0\" >37</td>\n",
       "      <td id=\"T_8c96b_row6_col1\" class=\"data row6 col1\" >0.360329</td>\n",
       "      <td id=\"T_8c96b_row6_col2\" class=\"data row6 col2\" >0.220609</td>\n",
       "      <td id=\"T_8c96b_row6_col3\" class=\"data row6 col3\" >0.149414</td>\n",
       "      <td id=\"T_8c96b_row6_col4\" class=\"data row6 col4\" >0.108349</td>\n",
       "      <td id=\"T_8c96b_row6_col5\" class=\"data row6 col5\" >0.186701</td>\n",
       "      <td id=\"T_8c96b_row6_col6\" class=\"data row6 col6\" >0.298910</td>\n",
       "      <td id=\"T_8c96b_row6_col7\" class=\"data row6 col7\" >0.441676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5e9075c090>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e0a0b6",
   "metadata": {},
   "source": [
    "## iu_x_transformer+_ca30_dropout0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec577be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "multiple-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='./experiments/iu_x_transformer+_ca30_dropout0.5'\n",
    "log_val_path=os.path.join(root, 'log.csv')\n",
    "\n",
    "log_val=pd.read_csv(log_val_path)\n",
    "metrics=log_val.columns\n",
    "\n",
    "best_epoch=[]\n",
    "for i in range(1, len(log_val.columns)):\n",
    "    max_idx=log_val[log_val.columns[i]].idxmax()\n",
    "    best_epoch.append(max_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2fb1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_by_metric=log_val.iloc[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd98194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    return np.where(s == np.nanmax(s.values), props, '')\n",
    "\n",
    "\n",
    "bold_best=best_epoch_by_metric.reset_index(drop=True).style.apply(highlight_max, props='font-weight:bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd49e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_db7c6_row0_col0, #T_db7c6_row0_col1, #T_db7c6_row0_col5, #T_db7c6_row1_col2, #T_db7c6_row1_col3, #T_db7c6_row1_col7, #T_db7c6_row2_col2, #T_db7c6_row2_col3, #T_db7c6_row2_col7, #T_db7c6_row3_col4, #T_db7c6_row4_col0, #T_db7c6_row4_col1, #T_db7c6_row4_col5, #T_db7c6_row5_col6, #T_db7c6_row6_col2, #T_db7c6_row6_col3, #T_db7c6_row6_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_db7c6_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th class=\"col_heading level0 col1\" >Bleu_1</th>\n",
       "      <th class=\"col_heading level0 col2\" >Bleu_2</th>\n",
       "      <th class=\"col_heading level0 col3\" >Bleu_3</th>\n",
       "      <th class=\"col_heading level0 col4\" >Bleu_4</th>\n",
       "      <th class=\"col_heading level0 col5\" >METEOR</th>\n",
       "      <th class=\"col_heading level0 col6\" >ROUGE_L</th>\n",
       "      <th class=\"col_heading level0 col7\" >CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_db7c6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_db7c6_row0_col0\" class=\"data row0 col0\" >17</td>\n",
       "      <td id=\"T_db7c6_row0_col1\" class=\"data row0 col1\" >0.389378</td>\n",
       "      <td id=\"T_db7c6_row0_col2\" class=\"data row0 col2\" >0.240804</td>\n",
       "      <td id=\"T_db7c6_row0_col3\" class=\"data row0 col3\" >0.159985</td>\n",
       "      <td id=\"T_db7c6_row0_col4\" class=\"data row0 col4\" >0.106367</td>\n",
       "      <td id=\"T_db7c6_row0_col5\" class=\"data row0 col5\" >0.192843</td>\n",
       "      <td id=\"T_db7c6_row0_col6\" class=\"data row0 col6\" >0.304696</td>\n",
       "      <td id=\"T_db7c6_row0_col7\" class=\"data row0 col7\" >0.317191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db7c6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_db7c6_row1_col0\" class=\"data row1 col0\" >8</td>\n",
       "      <td id=\"T_db7c6_row1_col1\" class=\"data row1 col1\" >0.381769</td>\n",
       "      <td id=\"T_db7c6_row1_col2\" class=\"data row1 col2\" >0.249623</td>\n",
       "      <td id=\"T_db7c6_row1_col3\" class=\"data row1 col3\" >0.167003</td>\n",
       "      <td id=\"T_db7c6_row1_col4\" class=\"data row1 col4\" >0.110001</td>\n",
       "      <td id=\"T_db7c6_row1_col5\" class=\"data row1 col5\" >0.185179</td>\n",
       "      <td id=\"T_db7c6_row1_col6\" class=\"data row1 col6\" >0.330140</td>\n",
       "      <td id=\"T_db7c6_row1_col7\" class=\"data row1 col7\" >0.346084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db7c6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_db7c6_row2_col0\" class=\"data row2 col0\" >8</td>\n",
       "      <td id=\"T_db7c6_row2_col1\" class=\"data row2 col1\" >0.381769</td>\n",
       "      <td id=\"T_db7c6_row2_col2\" class=\"data row2 col2\" >0.249623</td>\n",
       "      <td id=\"T_db7c6_row2_col3\" class=\"data row2 col3\" >0.167003</td>\n",
       "      <td id=\"T_db7c6_row2_col4\" class=\"data row2 col4\" >0.110001</td>\n",
       "      <td id=\"T_db7c6_row2_col5\" class=\"data row2 col5\" >0.185179</td>\n",
       "      <td id=\"T_db7c6_row2_col6\" class=\"data row2 col6\" >0.330140</td>\n",
       "      <td id=\"T_db7c6_row2_col7\" class=\"data row2 col7\" >0.346084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db7c6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_db7c6_row3_col0\" class=\"data row3 col0\" >5</td>\n",
       "      <td id=\"T_db7c6_row3_col1\" class=\"data row3 col1\" >0.368064</td>\n",
       "      <td id=\"T_db7c6_row3_col2\" class=\"data row3 col2\" >0.243852</td>\n",
       "      <td id=\"T_db7c6_row3_col3\" class=\"data row3 col3\" >0.166645</td>\n",
       "      <td id=\"T_db7c6_row3_col4\" class=\"data row3 col4\" >0.111328</td>\n",
       "      <td id=\"T_db7c6_row3_col5\" class=\"data row3 col5\" >0.180398</td>\n",
       "      <td id=\"T_db7c6_row3_col6\" class=\"data row3 col6\" >0.320541</td>\n",
       "      <td id=\"T_db7c6_row3_col7\" class=\"data row3 col7\" >0.253763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db7c6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_db7c6_row4_col0\" class=\"data row4 col0\" >17</td>\n",
       "      <td id=\"T_db7c6_row4_col1\" class=\"data row4 col1\" >0.389378</td>\n",
       "      <td id=\"T_db7c6_row4_col2\" class=\"data row4 col2\" >0.240804</td>\n",
       "      <td id=\"T_db7c6_row4_col3\" class=\"data row4 col3\" >0.159985</td>\n",
       "      <td id=\"T_db7c6_row4_col4\" class=\"data row4 col4\" >0.106367</td>\n",
       "      <td id=\"T_db7c6_row4_col5\" class=\"data row4 col5\" >0.192843</td>\n",
       "      <td id=\"T_db7c6_row4_col6\" class=\"data row4 col6\" >0.304696</td>\n",
       "      <td id=\"T_db7c6_row4_col7\" class=\"data row4 col7\" >0.317191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db7c6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_db7c6_row5_col0\" class=\"data row5 col0\" >7</td>\n",
       "      <td id=\"T_db7c6_row5_col1\" class=\"data row5 col1\" >0.341019</td>\n",
       "      <td id=\"T_db7c6_row5_col2\" class=\"data row5 col2\" >0.219318</td>\n",
       "      <td id=\"T_db7c6_row5_col3\" class=\"data row5 col3\" >0.144704</td>\n",
       "      <td id=\"T_db7c6_row5_col4\" class=\"data row5 col4\" >0.096554</td>\n",
       "      <td id=\"T_db7c6_row5_col5\" class=\"data row5 col5\" >0.179075</td>\n",
       "      <td id=\"T_db7c6_row5_col6\" class=\"data row5 col6\" >0.336230</td>\n",
       "      <td id=\"T_db7c6_row5_col7\" class=\"data row5 col7\" >0.322613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db7c6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_db7c6_row6_col0\" class=\"data row6 col0\" >8</td>\n",
       "      <td id=\"T_db7c6_row6_col1\" class=\"data row6 col1\" >0.381769</td>\n",
       "      <td id=\"T_db7c6_row6_col2\" class=\"data row6 col2\" >0.249623</td>\n",
       "      <td id=\"T_db7c6_row6_col3\" class=\"data row6 col3\" >0.167003</td>\n",
       "      <td id=\"T_db7c6_row6_col4\" class=\"data row6 col4\" >0.110001</td>\n",
       "      <td id=\"T_db7c6_row6_col5\" class=\"data row6 col5\" >0.185179</td>\n",
       "      <td id=\"T_db7c6_row6_col6\" class=\"data row6 col6\" >0.330140</td>\n",
       "      <td id=\"T_db7c6_row6_col7\" class=\"data row6 col7\" >0.346084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5e9075c250>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold_best # 36"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74718085999496aceb448166212b885722618ffb65d95b4ac224147130c54247"
  },
  "kernelspec": {
   "display_name": "medinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
