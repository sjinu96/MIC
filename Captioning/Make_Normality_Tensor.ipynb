{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input image --> Resize(512) + Noramlize + ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list(file_list):\n",
    "                                    # tag vector 들의 list\n",
    "    filename_list = []                                  # image name 들의 list\n",
    "    with open(file_list, 'r') as f:\n",
    "        for line in f:\n",
    "            items = line.split()\n",
    "            image_name = items[0]                       # 해당 image name ex) CXR1972_IM-0633-1001\n",
    "            image_name = '{}.jpg'.format(image_name)\n",
    "            filename_list.append(image_name)\n",
    "            \n",
    "    return filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "train_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/mimic_train.txt'\n",
    "train_filename_list=load_list(train_txt)\n",
    "print(len(train_filename_list))\n",
    "val_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/mimic_val.txt'\n",
    "val_filename_list=load_list(val_txt)\n",
    "print(len(val_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n"
     ]
    }
   ],
   "source": [
    "train_filename_list = train_filename_list + val_filename_list\n",
    "print(len(train_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 normal image 개수 :  360\n",
      "Train / VAl normal image 개수 : 322\n"
     ]
    }
   ],
   "source": [
    "master='/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/master_sheet.csv'\n",
    "\n",
    "master=pd.read_csv(master)\n",
    "\n",
    "# abnormal_idx=master['Normal']==0\n",
    "normal_idx=master['Normal']==1\n",
    "\n",
    "# abnormal_image_names = master['path'][abnormal_idx].str.slice(30, 74).values +'.jpg'\n",
    "normal_image_names = master['path'][normal_idx].str.slice(30,74).values + '.jpg'\n",
    "print('전체 normal image 개수 : ', len(normal_image_names))\n",
    "# Only use Train / val\n",
    "normal_image_names = [image  for image in normal_image_names if (image in train_filename_list)]\n",
    "print('Train / VAl normal image 개수 :', len(normal_image_names))\n",
    "\n",
    "input_image_names = master['path'].str.slice(30, 74).values + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_image_folder = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/all_jpgs'\n",
    "image_folder ='/home/mskang/jinsu/med/XTransformer/mimic/normal_images'\n",
    "new_image_folder = os.path.join(image_folder, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(new_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in normal_image_names:\n",
    "\n",
    "    origin_image_path = os.path.join(origin_image_folder, image_name)\n",
    "    new_image_path = os.path.join(new_image_folder, image_name)\n",
    "\n",
    "    shutil.copy(origin_image_path, new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(512),\n",
    "        # transforms.RandomCrop(448),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensor_folder = './mimic/normal_images/full_tensor'\n",
    "# os.mkdir(new_tensor_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20071/1561499504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormal_image_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_images_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_image_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_image_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensor_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_image_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jsp_med/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jsp_med/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jsp_med/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jsp_med/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "normal_images_name = os.listdir(new_image_folder)\n",
    "assert len(normal_images_name) == 322\n",
    "\n",
    "import os\n",
    "\n",
    "for normal_image_name in normal_images_name:\n",
    "    image = Image.open(os.path.join(new_image_folder, normal_image_name)).convert('RGB')\n",
    "    image_tensor = transform(image)\n",
    "    torch.save(image_tensor, os.path.join(new_tensor_folder, normal_image_name[:-3] +'pt'))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(new_tensor_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_tensors_folder = './mimic/normal_images/full_tensor'\n",
    "normal_tensors_name = os.listdir(normal_tensors_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './mimic/normal_images/full_tensor'\n",
    "\n",
    "import os\n",
    "random_idxes = np.random.randint(0, len(os.listdir(path)), 10)\n",
    "normal_tensors = []\n",
    "for idx in random_idxes:\n",
    "    normal_tensor = torch.load(os.path.join(normal_tensors_folder, normal_tensors_name[idx]))\n",
    "    normal_tensors.append(transforms.RandomCrop(448)(normal_tensor).unsqueeze(0))\n",
    "\n",
    "normal_images = torch.cat(normal_tensors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 448, 448])\n"
     ]
    }
   ],
   "source": [
    "print(normal_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1008, -2.1008, -2.1008,  ..., -2.0665, -2.0665, -2.0665],\n",
       "         [-2.1008, -2.1008, -2.1008,  ..., -2.0665, -2.0665, -2.0665],\n",
       "         [-2.1008, -2.1008, -2.1008,  ..., -2.0665, -2.0665, -2.0665],\n",
       "         ...,\n",
       "         [-0.9534, -0.8849, -0.9534,  ..., -0.3027, -0.3027, -0.3198],\n",
       "         [-1.0219, -0.9705, -1.0048,  ..., -0.3027, -0.3027, -0.3198],\n",
       "         [-1.0562, -0.9877, -0.9363,  ..., -0.3027, -0.3027, -0.3198]],\n",
       "\n",
       "        [[-2.0182, -2.0182, -2.0182,  ..., -1.9832, -1.9832, -1.9832],\n",
       "         [-2.0182, -2.0182, -2.0182,  ..., -1.9832, -1.9832, -1.9832],\n",
       "         [-2.0182, -2.0182, -2.0182,  ..., -1.9832, -1.9832, -1.9832],\n",
       "         ...,\n",
       "         [-0.8452, -0.7752, -0.8452,  ..., -0.1800, -0.1800, -0.1975],\n",
       "         [-0.9153, -0.8627, -0.8978,  ..., -0.1800, -0.1800, -0.1975],\n",
       "         [-0.9503, -0.8803, -0.8277,  ..., -0.1800, -0.1800, -0.1975]],\n",
       "\n",
       "        [[-1.7870, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],\n",
       "         [-1.7870, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],\n",
       "         [-1.7870, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],\n",
       "         ...,\n",
       "         [-0.6193, -0.5495, -0.6193,  ...,  0.0431,  0.0431,  0.0256],\n",
       "         [-0.6890, -0.6367, -0.6715,  ...,  0.0431,  0.0431,  0.0256],\n",
       "         [-0.7238, -0.6541, -0.6018,  ...,  0.0431,  0.0431,  0.0256]]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input image --> Resize(1024)+ Noramlize + ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list(file_list):\n",
    "                                    # tag vector 들의 list\n",
    "    filename_list = []                                  # image name 들의 list\n",
    "    with open(file_list, 'r') as f:\n",
    "        for line in f:\n",
    "            items = line.split()\n",
    "            image_name = items[0]                       # 해당 image name ex) CXR1972_IM-0633-1001\n",
    "            image_name = '{}.jpg'.format(image_name)\n",
    "            filename_list.append(image_name)\n",
    "            \n",
    "    return filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "train_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/mimic_train.txt'\n",
    "train_filename_list=load_list(train_txt)\n",
    "print(len(train_filename_list))\n",
    "val_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/mimic_val.txt'\n",
    "val_filename_list=load_list(val_txt)\n",
    "print(len(val_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n"
     ]
    }
   ],
   "source": [
    "train_filename_list = train_filename_list + val_filename_list\n",
    "print(len(train_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 normal image 개수 :  360\n",
      "Train / VAl normal image 개수 : 322\n"
     ]
    }
   ],
   "source": [
    "master='/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/master_sheet.csv'\n",
    "\n",
    "master=pd.read_csv(master)\n",
    "\n",
    "# abnormal_idx=master['Normal']==0\n",
    "normal_idx=master['Normal']==1\n",
    "\n",
    "# abnormal_image_names = master['path'][abnormal_idx].str.slice(30, 74).values +'.jpg'\n",
    "normal_image_names = master['path'][normal_idx].str.slice(30,74).values + '.jpg'\n",
    "print('전체 normal image 개수 : ', len(normal_image_names))\n",
    "# Only use Train / val\n",
    "normal_image_names = [image  for image in normal_image_names if (image in train_filename_list)]\n",
    "print('Train / VAl normal image 개수 :', len(normal_image_names))\n",
    "\n",
    "input_image_names = master['path'].str.slice(30, 74).values + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin_image_folder = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/all_jpgs'\n",
    "image_folder ='/home/mskang/jinsu/med/XTransformer/mimic/normal_images'\n",
    "new_image_folder = os.path.join(image_folder, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(new_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_name in normal_image_names:\n",
    "\n",
    "#     origin_image_path = os.path.join(origin_image_folder, image_name)\n",
    "#     new_image_path = os.path.join(new_image_folder, image_name)\n",
    "\n",
    "#     shutil.copy(origin_image_path, new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(1024),\n",
    "        # transforms.RandomCrop(448),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensor_folder = './mimic/normal_images/full_tensor_1024'\n",
    "os.mkdir(new_tensor_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images_name = os.listdir(new_image_folder)\n",
    "assert len(normal_images_name) == 322\n",
    "\n",
    "import os\n",
    "\n",
    "for normal_image_name in normal_images_name:\n",
    "    image = Image.open(os.path.join(new_image_folder, normal_image_name)).convert('RGB')\n",
    "    image_tensor = transform(image)\n",
    "    torch.save(image_tensor, os.path.join(new_tensor_folder, normal_image_name[:-3] +'pt'))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(new_tensor_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_tensors_folder = './mimic/normal_images/full_tensor_1024'\n",
    "normal_tensors_name = os.listdir(normal_tensors_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './mimic/normal_images/full_tensor'\n",
    "\n",
    "import os\n",
    "random_idxes = np.random.randint(0, len(os.listdir(path)), 50)\n",
    "normal_tensors = []\n",
    "for idx in random_idxes:\n",
    "    normal_tensor = torch.load(os.path.join(normal_tensors_folder, normal_tensors_name[idx]))\n",
    "    normal_tensors.append(normal_tensor.unsqueeze(0))\n",
    "    # normal_tensors.append(transforms.RandomCrop(896)(normal_tensor).unsqueeze(0))\n",
    "\n",
    "# normal_images = torch.cat(normal_tensors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input image --> Resize(512) + Noramlize + ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list(file_list):\n",
    "                                    # tag vector 들의 list\n",
    "    filename_list = []                                  # image name 들의 list\n",
    "    with open(file_list, 'r') as f:\n",
    "        for line in f:\n",
    "            items = line.split()\n",
    "            image_name = items[0]                       # 해당 image name ex) CXR1972_IM-0633-1001\n",
    "            image_name = '{}.png'.format(image_name)\n",
    "            filename_list.append(image_name)\n",
    "            \n",
    "    return filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lines(path):\n",
    "    with open(path, 'r') as fid:\n",
    "        lines = [line.strip() for line in fid]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all :  2394\n"
     ]
    }
   ],
   "source": [
    "all_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_iu/all_data_2.txt'\n",
    "all_filename_list=load_list(all_txt)\n",
    "print('all : ' ,len(all_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  1911\n",
      "val :  238\n",
      "test :  245\n"
     ]
    }
   ],
   "source": [
    "train_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_iu/train_data_2.txt'\n",
    "train_filename_list=load_list(train_txt)\n",
    "print('train : ' ,len(train_filename_list))\n",
    "val_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_iu/val_data_2.txt'\n",
    "val_filename_list=load_list(val_txt)\n",
    "print('val : ', len(val_filename_list))\n",
    "test_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_iu/test_data_2.txt'\n",
    "test_filename_list=load_list(test_txt)\n",
    "print('test : ', len(test_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['cardiac monitor', 'lymphatic diseases', 'pulmonary disease', 'osteophytes', 'foreign body', 'dish', 'aorta, thoracic', 'atherosclerosis', 'histoplasmosis', 'hypoventilation', 'catheterization, central venous', 'pleural effusions', 'pleural effusion', 'callus', 'sternotomy', 'lymph nodes', 'tortuous aorta', 'stent', 'interstitial pulmonary edema', 'cholecystectomies', 'neoplasm', 'central venous catheter', 'pneumothorax', 'metastatic disease', 'vena cava, superior', 'cholecystectomy', 'scoliosis', 'subcutaneous emphysema', 'thoracolumbar scoliosis', 'spinal osteophytosis', 'pulmonary fibroses', 'rib fractures', 'sarcoidosis', 'eventration', 'fibrosis', 'spine', 'obstructive lung disease', 'pneumonitis', 'osteopenia', 'air trapping', 'demineralization', 'mass lesion', 'pulmonary hypertension', 'pleural diseases', 'pleural thickening', 'calcifications of the aorta', 'calcinosis', 'cystic fibrosis', 'empyema', 'catheter', 'lymph', 'pericardial effusion', 'lung cancer', 'rib fracture', 'granulomatous disease', 'chronic obstructive pulmonary disease', 'rib', 'clip', 'aortic ectasia', 'shoulder', 'scarring', 'scleroses', 'adenopathy', 'emphysemas', 'pneumonectomy', 'infection', 'aspiration', 'bilateral pleural effusion', 'bulla', 'lumbar vertebrae', 'lung neoplasms', 'lymphadenopathy', 'hyperexpansion', 'ectasia', 'bronchiectasis', 'nodule', 'pneumonia', 'right-sided pleural effusion', 'osteoarthritis', 'thoracic spondylosis', 'picc', 'cervical fusion', 'tracheostomies', 'fusion', 'thoracic vertebrae', 'catheters', 'emphysema', 'trachea', 'surgery', 'cervical spine fusion', 'hypertension, pulmonary', 'pneumoperitoneum', 'scar', 'atheroscleroses', 'aortic calcifications', 'volume overload', 'right upper lobe pneumonia', 'apical granuloma', 'diaphragms', 'copd', 'kyphoses', 'spinal fractures', 'fracture', 'clavicle', 'focal atelectasis', 'collapse', 'thoracotomies', 'congestive heart failure', 'calcified lymph nodes', 'edema', 'degenerative disc diseases', 'cervical vertebrae', 'diaphragm', 'humerus', 'heart failure', 'normal', 'coronary artery bypass', 'pulmonary atelectasis', 'lung diseases, interstitial', 'pulmonary disease, chronic obstructive', 'opacity', 'deformity', 'chronic disease', 'pleura', 'aorta', 'tuberculoses', 'hiatal hernia', 'scolioses', 'pleural fluid', 'malignancy', 'kyphosis', 'bronchiectases', 'congestion', 'discoid atelectasis', 'nipple', 'bronchitis', 'pulmonary artery', 'cardiomegaly', 'thoracic aorta', 'arthritic changes', 'pulmonary edema', 'vascular calcification', 'sclerotic', 'central venous catheters', 'catheterization', 'hydropneumothorax', 'aortic valve', 'hyperinflation', 'prostheses', 'pacemaker, artificial', 'bypass grafts', 'pulmonary fibrosis', 'multiple myeloma', 'postoperative period', 'cabg', 'right lower lobe pneumonia', 'granuloma', 'degenerative change', 'atelectasis', 'inflammation', 'effusion', 'cicatrix', 'tracheostomy', 'aortic diseases', 'sarcoidoses', 'granulomas', 'interstitial lung disease', 'infiltrates', 'displaced fractures', 'chronic lung disease', 'picc line', 'intubation, gastrointestinal', 'lung diseases', 'multiple pulmonary nodules', 'intervertebral disc degeneration', 'pulmonary emphysema', 'spine curvature', 'fibroses', 'chronic granulomatous disease', 'degenerative disease', 'atelectases', 'ribs', 'pulmonary arterial hypertension', 'edemas', 'pectus excavatum', 'lung granuloma', 'plate-like atelectasis', 'enlarged heart', 'hilar calcification', 'heart valve prosthesis', 'tuberculosis', 'old injury', 'patchy atelectasis', 'histoplasmoses', 'exostoses', 'mastectomies', 'right atrium', 'large hiatal hernia', 'hernia, hiatal', 'aortic aneurysm', 'lobectomy', 'spinal fusion', 'spondylosis', 'ascending aorta', 'granulomatous infection', 'fractures, bone', 'calcified granuloma', 'degenerative joint disease', 'intubation, intratracheal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.index('normal') # 116번째 : normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149\n"
     ]
    }
   ],
   "source": [
    "total_filename_list= train_filename_list + val_filename_list\n",
    "print(len(total_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Normal Image:  75 / 1911\n",
      "Val Normal Images 134 / 238\n",
      "Test Normal Image:  119 / 245\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_sheet = load_lines(train_txt)\n",
    "\n",
    "train_count = 0\n",
    "train_indexes=[]\n",
    "for i in range(len(train_sheet)):\n",
    "    if '1' == train_sheet[i].split()[1:][115]:\n",
    "        train_count+=1\n",
    "        # print('sample:',  i)\n",
    "        train_indexes.append(i)\n",
    "\n",
    "print('Train Normal Image: ',  train_count, '/', len(train_sheet))\n",
    "\n",
    "val_sheet = load_lines(val_txt)\n",
    "\n",
    "val_count = 0\n",
    "val_indexes=[]\n",
    "for i in range(len(val_sheet)):\n",
    "    if '1' == val_sheet[i].split()[1:][115]:\n",
    "        val_count+=1\n",
    "        # print('sample:',  i) \n",
    "        val_indexes.append(i)\n",
    "\n",
    "print('Val Normal Images',  val_count, '/', len(val_sheet))\n",
    "\n",
    "test_sheet = load_lines(test_txt)\n",
    "\n",
    "test_count = 0\n",
    "test_indexes=[]\n",
    "for i in range(len(test_sheet)):\n",
    "    if '1' == test_sheet[i].split()[1:][115]:\n",
    "        test_count+=1\n",
    "        # print('sample:',  i)\n",
    "        test_indexes.append(i)\n",
    "\n",
    "print('Test Normal Image: ',  test_count, '/', len(test_sheet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function shutil.copy(src, dst, *, follow_symlinks=True)>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_input_folder='../H_LSTM_Transformer/data/images_frontal'\n",
    "\n",
    "to_input_folder = 'iu/input_images'\n",
    "to_normal_folder = 'iu/normal_images/full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(train_filename_list)):\n",
    "    src = os.path.join(from_input_folder, train_filename_list[idx])\n",
    "    dst = os.path.join(to_input_folder, train_filename_list[idx])\n",
    "\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(val_filename_list)):\n",
    "    src = os.path.join(from_input_folder, val_filename_list[idx])\n",
    "    dst = os.path.join(to_input_folder, val_filename_list[idx])\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(test_filename_list)):\n",
    "    src = os.path.join(from_input_folder, test_filename_list[idx])\n",
    "    dst = os.path.join(to_input_folder, test_filename_list[idx])\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in train_indexes:\n",
    "    src = os.path.join(from_input_folder, train_filename_list[idx])\n",
    "    dst = os.path.join(to_normal_folder, train_filename_list[idx])\n",
    "    shutil.copy(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in val_indexes:\n",
    "    src = os.path.join(from_input_folder, val_filename_list[idx])\n",
    "    dst = os.path.join(to_normal_folder, val_filename_list[idx])\n",
    "    shutil.copy(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394\n",
      "209\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(to_input_folder)))\n",
    "print(len(os.listdir(to_normal_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all Normal Image:  328 / 2394\n"
     ]
    }
   ],
   "source": [
    "all_count = 0\n",
    "all_indexes=[]\n",
    "for i in range(len(all_sheet)):\n",
    "    if '1' == all_sheet[i].split()[1:][115]:\n",
    "        all_count+=1\n",
    "        # print('sample:',  i)\n",
    "        all_indexes.append(i)\n",
    "\n",
    "print('all Normal Image: ',  all_count, '/', len(all_sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(512),\n",
    "        # transforms.RandomCrop(448),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensor_folder = './iu/normal_images/full_tensor'\n",
    "# os.mkdir(new_tensor_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images_name = os.listdir(to_normal_folder)\n",
    "assert len(normal_images_name) == 209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images_name = os.listdir(to_normal_folder)\n",
    "assert len(normal_images_name) == 209\n",
    "\n",
    "import os\n",
    "\n",
    "for normal_image_name in normal_images_name:\n",
    "    image = Image.open(os.path.join(to_normal_folder, normal_image_name)).convert('RGB')\n",
    "    image_tensor = transform(image)\n",
    "    torch.save(image_tensor, os.path.join(new_tensor_folder, normal_image_name[:-3] +'pt'))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(new_tensor_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_tensors_folder = './iu/normal_images/full_tensor'\n",
    "normal_tensors_name = os.listdir(normal_tensors_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './iu/normal_images/full_tensor'\n",
    "\n",
    "import os\n",
    "random_idxes = np.random.randint(0, len(os.listdir(path)), 10)\n",
    "normal_tensors = []\n",
    "for idx in random_idxes:\n",
    "    normal_tensor = torch.load(os.path.join(normal_tensors_folder, normal_tensors_name[idx]))\n",
    "    normal_tensors.append(transforms.RandomCrop(448)(normal_tensor).unsqueeze(0))\n",
    "\n",
    "normal_images = torch.cat(normal_tensors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 448, 448])\n"
     ]
    }
   ],
   "source": [
    "print(normal_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4739, -0.4568, -0.4226,  ..., -0.2342,  0.1939,  0.6906],\n",
       "          [-0.4568, -0.4397, -0.4226,  ..., -0.2171,  0.2282,  0.7419],\n",
       "          [-0.4397, -0.4226, -0.4739,  ..., -0.1486,  0.2796,  0.7762],\n",
       "          ...,\n",
       "          [ 1.6838,  1.7180,  1.7009,  ..., -2.1179, -2.1008, -2.1008],\n",
       "          [ 1.7180,  1.7352,  1.7523,  ..., -2.1179, -2.1008, -2.1008],\n",
       "          [ 1.7865,  1.7523,  1.7523,  ..., -2.1179, -2.1179, -2.1008]],\n",
       "\n",
       "         [[-0.3550, -0.3375, -0.3025,  ..., -0.1099,  0.3277,  0.8354],\n",
       "          [-0.3375, -0.3200, -0.3025,  ..., -0.0924,  0.3627,  0.8880],\n",
       "          [-0.3200, -0.3025, -0.3550,  ..., -0.0224,  0.4153,  0.9230],\n",
       "          ...,\n",
       "          [ 1.8508,  1.8859,  1.8683,  ..., -2.0357, -2.0182, -2.0182],\n",
       "          [ 1.8859,  1.9034,  1.9209,  ..., -2.0357, -2.0182, -2.0182],\n",
       "          [ 1.9559,  1.9209,  1.9209,  ..., -2.0357, -2.0357, -2.0182]],\n",
       "\n",
       "         [[-0.1312, -0.1138, -0.0790,  ...,  0.1128,  0.5485,  1.0539],\n",
       "          [-0.1138, -0.0964, -0.0790,  ...,  0.1302,  0.5834,  1.1062],\n",
       "          [-0.0964, -0.0790, -0.1312,  ...,  0.1999,  0.6356,  1.1411],\n",
       "          ...,\n",
       "          [ 2.0648,  2.0997,  2.0823,  ..., -1.8044, -1.7870, -1.7870],\n",
       "          [ 2.0997,  2.1171,  2.1346,  ..., -1.8044, -1.7870, -1.7870],\n",
       "          [ 2.1694,  2.1346,  2.1346,  ..., -1.8044, -1.8044, -1.7870]]],\n",
       "\n",
       "\n",
       "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.0152, -2.0494, -2.0837],\n",
       "          ...,\n",
       "          [-0.9534, -0.9534, -0.9534,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-0.9363, -0.9363, -0.9534,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-0.9363, -0.9363, -0.9534,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "\n",
       "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -1.9307, -1.9657, -2.0007],\n",
       "          ...,\n",
       "          [-0.8452, -0.8452, -0.8452,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-0.8277, -0.8277, -0.8452,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-0.8277, -0.8277, -0.8452,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "\n",
       "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.6999, -1.7347, -1.7696],\n",
       "          ...,\n",
       "          [-0.6193, -0.6193, -0.6193,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-0.6018, -0.6018, -0.6193,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-0.6018, -0.6018, -0.6193,  ..., -1.8044, -1.8044, -1.8044]]],\n",
       "\n",
       "\n",
       "        [[[-2.1008, -2.1008, -2.1179,  ..., -2.0837, -2.1008, -2.1179],\n",
       "          [-2.1008, -2.1179, -2.1179,  ..., -2.0665, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.0837, -2.1179, -2.1008],\n",
       "          ...,\n",
       "          [ 1.4440,  1.2557,  1.1187,  ...,  0.8447,  0.8789,  0.8961],\n",
       "          [ 1.4098,  1.2214,  1.0844,  ...,  0.8104,  0.8447,  0.8618],\n",
       "          [ 1.3927,  1.2385,  1.1015,  ...,  0.7762,  0.8104,  0.8276]],\n",
       "\n",
       "         [[-2.0182, -2.0182, -2.0357,  ..., -2.0007, -2.0182, -2.0357],\n",
       "          [-2.0182, -2.0357, -2.0357,  ..., -1.9832, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0007, -2.0357, -2.0182],\n",
       "          ...,\n",
       "          [ 1.6057,  1.4132,  1.2731,  ...,  0.9930,  1.0280,  1.0455],\n",
       "          [ 1.5707,  1.3782,  1.2381,  ...,  0.9580,  0.9930,  1.0105],\n",
       "          [ 1.5532,  1.3957,  1.2556,  ...,  0.9230,  0.9580,  0.9755]],\n",
       "\n",
       "         [[-1.7870, -1.7870, -1.8044,  ..., -1.7696, -1.7870, -1.8044],\n",
       "          [-1.7870, -1.8044, -1.8044,  ..., -1.7522, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.7696, -1.8044, -1.7870],\n",
       "          ...,\n",
       "          [ 1.8208,  1.6291,  1.4897,  ...,  1.2108,  1.2457,  1.2631],\n",
       "          [ 1.7860,  1.5942,  1.4548,  ...,  1.1759,  1.2108,  1.2282],\n",
       "          [ 1.7685,  1.6117,  1.4722,  ...,  1.1411,  1.1759,  1.1934]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.2796,  0.2624,  0.2624,  ...,  0.1597,  0.1597,  0.1254],\n",
       "          [ 0.2796,  0.2624,  0.2624,  ...,  0.1597,  0.1426,  0.1254],\n",
       "          [ 0.2796,  0.2624,  0.2624,  ...,  0.1597,  0.1426,  0.1083],\n",
       "          ...,\n",
       "          [-0.4397, -0.4226, -0.4226,  ..., -1.0562, -1.0219, -1.0219],\n",
       "          [-0.4397, -0.4226, -0.4054,  ..., -1.0562, -1.0390, -1.0219],\n",
       "          [-0.4568, -0.4054, -0.3712,  ..., -1.0733, -1.0390, -1.0390]],\n",
       "\n",
       "         [[ 0.4153,  0.3978,  0.3978,  ...,  0.2927,  0.2927,  0.2577],\n",
       "          [ 0.4153,  0.3978,  0.3978,  ...,  0.2927,  0.2752,  0.2577],\n",
       "          [ 0.4153,  0.3978,  0.3978,  ...,  0.2927,  0.2752,  0.2402],\n",
       "          ...,\n",
       "          [-0.3200, -0.3025, -0.3025,  ..., -0.9503, -0.9153, -0.9153],\n",
       "          [-0.3200, -0.3025, -0.2850,  ..., -0.9503, -0.9328, -0.9153],\n",
       "          [-0.3375, -0.2850, -0.2500,  ..., -0.9678, -0.9328, -0.9328]],\n",
       "\n",
       "         [[ 0.6356,  0.6182,  0.6182,  ...,  0.5136,  0.5136,  0.4788],\n",
       "          [ 0.6356,  0.6182,  0.6182,  ...,  0.5136,  0.4962,  0.4788],\n",
       "          [ 0.6356,  0.6182,  0.6182,  ...,  0.5136,  0.4962,  0.4614],\n",
       "          ...,\n",
       "          [-0.0964, -0.0790, -0.0790,  ..., -0.7238, -0.6890, -0.6890],\n",
       "          [-0.0964, -0.0790, -0.0615,  ..., -0.7238, -0.7064, -0.6890],\n",
       "          [-0.1138, -0.0615, -0.0267,  ..., -0.7413, -0.7064, -0.7064]]],\n",
       "\n",
       "\n",
       "        [[[-1.0733, -1.0562, -1.0562,  ..., -2.0152, -2.0152, -2.0152],\n",
       "          [-1.0562, -1.0390, -1.0048,  ..., -2.0152, -2.0152, -2.0152],\n",
       "          [-1.0219, -1.0048, -0.9705,  ..., -2.0152, -2.0152, -2.0152],\n",
       "          ...,\n",
       "          [ 1.7865,  1.7865,  1.7865,  ..., -2.0323, -2.0323, -2.0323],\n",
       "          [ 1.7865,  1.7865,  1.7865,  ..., -2.0323, -2.0323, -2.0323],\n",
       "          [ 1.7865,  1.7865,  1.7865,  ..., -2.0323, -2.0323, -2.0323]],\n",
       "\n",
       "         [[-0.9678, -0.9503, -0.9503,  ..., -1.9307, -1.9307, -1.9307],\n",
       "          [-0.9503, -0.9328, -0.8978,  ..., -1.9307, -1.9307, -1.9307],\n",
       "          [-0.9153, -0.8978, -0.8627,  ..., -1.9307, -1.9307, -1.9307],\n",
       "          ...,\n",
       "          [ 1.9559,  1.9559,  1.9559,  ..., -1.9482, -1.9482, -1.9482],\n",
       "          [ 1.9559,  1.9559,  1.9559,  ..., -1.9482, -1.9482, -1.9482],\n",
       "          [ 1.9559,  1.9559,  1.9559,  ..., -1.9482, -1.9482, -1.9482]],\n",
       "\n",
       "         [[-0.7413, -0.7238, -0.7238,  ..., -1.6999, -1.6999, -1.6999],\n",
       "          [-0.7238, -0.7064, -0.6715,  ..., -1.6999, -1.6999, -1.6999],\n",
       "          [-0.6890, -0.6715, -0.6367,  ..., -1.6999, -1.6999, -1.6999],\n",
       "          ...,\n",
       "          [ 2.1694,  2.1694,  2.1694,  ..., -1.7173, -1.7173, -1.7173],\n",
       "          [ 2.1694,  2.1694,  2.1694,  ..., -1.7173, -1.7173, -1.7173],\n",
       "          [ 2.1694,  2.1694,  2.1694,  ..., -1.7173, -1.7173, -1.7173]]],\n",
       "\n",
       "\n",
       "        [[[-0.6794, -0.6623, -0.6623,  ..., -0.3712, -0.4054, -0.4226],\n",
       "          [-0.6452, -0.6623, -0.6623,  ..., -0.4397, -0.4226, -0.4226],\n",
       "          [-0.6109, -0.6452, -0.6452,  ..., -0.4226, -0.4568, -0.4568],\n",
       "          ...,\n",
       "          [-1.3302, -1.2103, -1.1247,  ..., -0.0116, -0.0287, -0.0458],\n",
       "          [-1.3644, -1.2445, -1.1589,  ..., -0.0116, -0.0287, -0.0458],\n",
       "          [-1.3815, -1.2617, -1.1760,  ..., -0.0116, -0.0287, -0.0458]],\n",
       "\n",
       "         [[-0.5651, -0.5476, -0.5476,  ..., -0.2500, -0.2850, -0.3025],\n",
       "          [-0.5301, -0.5476, -0.5476,  ..., -0.3200, -0.3025, -0.3025],\n",
       "          [-0.4951, -0.5301, -0.5301,  ..., -0.3025, -0.3375, -0.3375],\n",
       "          ...,\n",
       "          [-1.2304, -1.1078, -1.0203,  ...,  0.1176,  0.1001,  0.0826],\n",
       "          [-1.2654, -1.1429, -1.0553,  ...,  0.1176,  0.1001,  0.0826],\n",
       "          [-1.2829, -1.1604, -1.0728,  ...,  0.1176,  0.1001,  0.0826]],\n",
       "\n",
       "         [[-0.3404, -0.3230, -0.3230,  ..., -0.0267, -0.0615, -0.0790],\n",
       "          [-0.3055, -0.3230, -0.3230,  ..., -0.0964, -0.0790, -0.0790],\n",
       "          [-0.2707, -0.3055, -0.3055,  ..., -0.0790, -0.1138, -0.1138],\n",
       "          ...,\n",
       "          [-1.0027, -0.8807, -0.7936,  ...,  0.3393,  0.3219,  0.3045],\n",
       "          [-1.0376, -0.9156, -0.8284,  ...,  0.3393,  0.3219,  0.3045],\n",
       "          [-1.0550, -0.9330, -0.8458,  ...,  0.3393,  0.3219,  0.3045]]]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['cardiac monitor', 'lymphatic diseases', 'pulmonary disease', 'osteophytes', 'foreign body', 'dish', 'aorta, thoracic', 'atherosclerosis', 'histoplasmosis', 'hypoventilation', 'catheterization, central venous', 'pleural effusions', 'pleural effusion', 'callus', 'sternotomy', 'lymph nodes', 'tortuous aorta', 'stent', 'interstitial pulmonary edema', 'cholecystectomies', 'neoplasm', 'central venous catheter', 'pneumothorax', 'metastatic disease', 'vena cava, superior', 'cholecystectomy', 'scoliosis', 'subcutaneous emphysema', 'thoracolumbar scoliosis', 'spinal osteophytosis', 'pulmonary fibroses', 'rib fractures', 'sarcoidosis', 'eventration', 'fibrosis', 'spine', 'obstructive lung disease', 'pneumonitis', 'osteopenia', 'air trapping', 'demineralization', 'mass lesion', 'pulmonary hypertension', 'pleural diseases', 'pleural thickening', 'calcifications of the aorta', 'calcinosis', 'cystic fibrosis', 'empyema', 'catheter', 'lymph', 'pericardial effusion', 'lung cancer', 'rib fracture', 'granulomatous disease', 'chronic obstructive pulmonary disease', 'rib', 'clip', 'aortic ectasia', 'shoulder', 'scarring', 'scleroses', 'adenopathy', 'emphysemas', 'pneumonectomy', 'infection', 'aspiration', 'bilateral pleural effusion', 'bulla', 'lumbar vertebrae', 'lung neoplasms', 'lymphadenopathy', 'hyperexpansion', 'ectasia', 'bronchiectasis', 'nodule', 'pneumonia', 'right-sided pleural effusion', 'osteoarthritis', 'thoracic spondylosis', 'picc', 'cervical fusion', 'tracheostomies', 'fusion', 'thoracic vertebrae', 'catheters', 'emphysema', 'trachea', 'surgery', 'cervical spine fusion', 'hypertension, pulmonary', 'pneumoperitoneum', 'scar', 'atheroscleroses', 'aortic calcifications', 'volume overload', 'right upper lobe pneumonia', 'apical granuloma', 'diaphragms', 'copd', 'kyphoses', 'spinal fractures', 'fracture', 'clavicle', 'focal atelectasis', 'collapse', 'thoracotomies', 'congestive heart failure', 'calcified lymph nodes', 'edema', 'degenerative disc diseases', 'cervical vertebrae', 'diaphragm', 'humerus', 'heart failure', 'normal', 'coronary artery bypass', 'pulmonary atelectasis', 'lung diseases, interstitial', 'pulmonary disease, chronic obstructive', 'opacity', 'deformity', 'chronic disease', 'pleura', 'aorta', 'tuberculoses', 'hiatal hernia', 'scolioses', 'pleural fluid', 'malignancy', 'kyphosis', 'bronchiectases', 'congestion', 'discoid atelectasis', 'nipple', 'bronchitis', 'pulmonary artery', 'cardiomegaly', 'thoracic aorta', 'arthritic changes', 'pulmonary edema', 'vascular calcification', 'sclerotic', 'central venous catheters', 'catheterization', 'hydropneumothorax', 'aortic valve', 'hyperinflation', 'prostheses', 'pacemaker, artificial', 'bypass grafts', 'pulmonary fibrosis', 'multiple myeloma', 'postoperative period', 'cabg', 'right lower lobe pneumonia', 'granuloma', 'degenerative change', 'atelectasis', 'inflammation', 'effusion', 'cicatrix', 'tracheostomy', 'aortic diseases', 'sarcoidoses', 'granulomas', 'interstitial lung disease', 'infiltrates', 'displaced fractures', 'chronic lung disease', 'picc line', 'intubation, gastrointestinal', 'lung diseases', 'multiple pulmonary nodules', 'intervertebral disc degeneration', 'pulmonary emphysema', 'spine curvature', 'fibroses', 'chronic granulomatous disease', 'degenerative disease', 'atelectases', 'ribs', 'pulmonary arterial hypertension', 'edemas', 'pectus excavatum', 'lung granuloma', 'plate-like atelectasis', 'enlarged heart', 'hilar calcification', 'heart valve prosthesis', 'tuberculosis', 'old injury', 'patchy atelectasis', 'histoplasmoses', 'exostoses', 'mastectomies', 'right atrium', 'large hiatal hernia', 'hernia, hiatal', 'aortic aneurysm', 'lobectomy', 'spinal fusion', 'spondylosis', 'ascending aorta', 'granulomatous infection', 'fractures, bone', 'calcified granuloma', 'degenerative joint disease', 'intubation, intratracheal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input image --> Resize(1024)+ Noramlize + ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list(file_list):\n",
    "                                    # tag vector 들의 list\n",
    "    filename_list = []                                  # image name 들의 list\n",
    "    with open(file_list, 'r') as f:\n",
    "        for line in f:\n",
    "            items = line.split()\n",
    "            image_name = items[0]                       # 해당 image name ex) CXR1972_IM-0633-1001\n",
    "            image_name = '{}.jpg'.format(image_name)\n",
    "            filename_list.append(image_name)\n",
    "            \n",
    "    return filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "train_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/mimic_train.txt'\n",
    "train_filename_list=load_list(train_txt)\n",
    "print(len(train_filename_list))\n",
    "val_txt = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/mimic_val.txt'\n",
    "val_filename_list=load_list(val_txt)\n",
    "print(len(val_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n"
     ]
    }
   ],
   "source": [
    "train_filename_list = train_filename_list + val_filename_list\n",
    "print(len(train_filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 normal image 개수 :  360\n",
      "Train / VAl normal image 개수 : 322\n"
     ]
    }
   ],
   "source": [
    "master='/home/mskang/jinsu/med/H_LSTM_Transformer/data/new_data_mimic/master_sheet.csv'\n",
    "\n",
    "master=pd.read_csv(master)\n",
    "\n",
    "# abnormal_idx=master['Normal']==0\n",
    "normal_idx=master['Normal']==1\n",
    "\n",
    "# abnormal_image_names = master['path'][abnormal_idx].str.slice(30, 74).values +'.jpg'\n",
    "normal_image_names = master['path'][normal_idx].str.slice(30,74).values + '.jpg'\n",
    "print('전체 normal image 개수 : ', len(normal_image_names))\n",
    "# Only use Train / val\n",
    "normal_image_names = [image  for image in normal_image_names if (image in train_filename_list)]\n",
    "print('Train / VAl normal image 개수 :', len(normal_image_names))\n",
    "\n",
    "input_image_names = master['path'].str.slice(30, 74).values + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(normal_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin_image_folder = '/home/mskang/jinsu/med/H_LSTM_Transformer/data/all_jpgs'\n",
    "image_folder ='/home/mskang/jinsu/med/XTransformer/mimic/normal_images'\n",
    "new_image_folder = os.path.join(image_folder, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(new_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_name in normal_image_names:\n",
    "\n",
    "#     origin_image_path = os.path.join(origin_image_folder, image_name)\n",
    "#     new_image_path = os.path.join(new_image_folder, image_name)\n",
    "\n",
    "#     shutil.copy(origin_image_path, new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(1024),\n",
    "        # transforms.RandomCrop(448),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensor_folder = './mimic/normal_images/full_tensor_1024'\n",
    "os.mkdir(new_tensor_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images_name = os.listdir(new_image_folder)\n",
    "assert len(normal_images_name) == 322\n",
    "\n",
    "import os\n",
    "\n",
    "for normal_image_name in normal_images_name:\n",
    "    image = Image.open(os.path.join(new_image_folder, normal_image_name)).convert('RGB')\n",
    "    image_tensor = transform(image)\n",
    "    torch.save(image_tensor, os.path.join(new_tensor_folder, normal_image_name[:-3] +'pt'))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74718085999496aceb448166212b885722618ffb65d95b4ac224147130c54247"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('jsp_med': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
